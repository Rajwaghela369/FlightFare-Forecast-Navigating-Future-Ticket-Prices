Authors,Pubslish_Date,Title,Text,Image,Link,Category
['The New York Times'],2023-08-22 00:00:00,"In Latest Moon Race, India Aims to Claim First Successful Southern Pole Landing","Pinned

Updated Aug. 23, 2023, 5:31 a.m. ET Aug. 23, 2023, 5:31 a.m. ET

It’s been almost four years since India’s last attempt to land on the moon, Chandrayaan-2, ended in a crash. On Wednesday, India is hoping that the uncrewed Chandrayaan-3 mission will reach the lunar surface in one piece.

The Indian people and government feel great pride for their nation’s surging space program. But the stakes for Wednesday’s landing attempt have been amplified by the crash on Saturday of Luna-25, a lunar lander from Russia that was to set down in the same region of the moon as Chandrayaan-3. If India achieves a landing just after Russia failed, it will highlight the technological accomplishments of the world’s most populous country.

India’s space program is a source of national pride, as is the country’s growing cadre of commercial space start-ups. India’s recent efforts in space exploration also closely mirror the country’s diplomatic push as an ambitious power on the rise. But Chandrayaan-3 is also taking place amid renewed interest in exploring the moon. The United States and China are both aiming to send astronauts there in the coming years, and there are more robotic missions from Japan and the United States that could head there this year. Like India, many other lunar missions are aiming for the moon’s south polar region. Scientists believe it may contain water ice that could be used by astronauts in the future. Here’s what you need to know: The Chandrayaan-3 landing module is expected to reach the moon’s surface on Wednesday at 8:34 a.m. Eastern time (it will be 6:04 p.m. in India).

The lander is in an elliptical orbit of the moon, swinging as close as about 15 miles above the surface. On Wednesday at around 8:14 a.m. Eastern time, ISRO says the spacecraft will fire its engines to bring itself out of orbit and begin a descent to the surface. The engines will further brake its fall, to help it achieve a soft landing.

The nation’s space program, the Indian Space Research Organization, will provide a livestream from the mission control room in Bengaluru. You can watch it on ISRO’s YouTube channel or website starting at 7:50 a.m. Eastern.

Chandrayaan means “moon craft” in Hindi. In addition to the propulsion module that pushed the spacecraft into orbit around the moon, the landing module consists of the Vikram lander and the Pragyan rover that will attempt to set down on the lunar surface in the moon’s south polar region. The mission is robotic and there are no astronauts aboard.

The Aug. 23 landing was selected because it is the day when the sun will rise at the landing site. The mission is to conclude two weeks later when the sun sets. While on the surface, the solar-powered lander and rover will use a range of instruments to make thermal, seismic and mineralogical measurements.

Show more",https://static01.nyt.com/images/2023/08/22/science/22india-moon-steup-vid-image/22india-moon-steup-vid-image-facebookJumbo.png,https://www.nytimes.com/live/2023/08/23/science/india-moon-landing-chandrayaan-3,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
['Jackie Wattles'],2023-08-22 00:00:00,"Luna 25 crash and Chandrayaan-3 landing attempt may signal another shift in the space race, experts say","Sign up for CNN’s Wonder Theory science newsletter. Explore the universe with news on fascinating discoveries, scientific advancements and more.

CNN —

A Russian spacecraft malfunctioned over the weekend, sending the vehicle crashing into the moon. The failed landing attempt has experts questioning the future of the country’s lunar exploration ambitions and the geopolitical dynamics that underpin modern space exploration efforts.

The spacecraft, Luna 25, lost contact with operators at Russia’s space agency, Roscosmos, on Saturday, August 19. By Sunday, the vehicle was declared dead.

Initial reports from the head of Roscosmos, Yury Borisov, indicate there was a problem with the vehicle’s engines, causing it to misfire as it attempted to adjust its orbit in the days before landing.

The failure was a major blow to the space agency’s ambitions. Russia had been seeking to prove that its civil space program, which analysts say has faced issues for decades, can still achieve the stunning feats it showcased during the 20th-century space race.

“Russia’s Cold War legacy will be just that — a legacy — unless they can actually do this themselves,” said Victoria Samson, the Washington office director for Secure World Foundation, a nonprofit that promotes the peaceful exploration of outer space.

Under the former Soviet Union, Russia managed to safely land seven spacecraft on the lunar surface, including the first-ever soft landing in 1966.

Borisov acknowledged that the Soviet successes of last century weren’t easily repeatable.

“We have to essentially master all the technologies all over again — of course, at a new technical level,” he said during an interview with Russian state media on Monday.

This photo released by the Roscosmos State Space Corporation on August 17, shows an image of the lunar south pole region on the far side of the moon captured by Russia's Luna 25 spacecraft before its failed attempt to land. Roscosmos/AP

Borisov has offered assurance that Roscosmos can get back on track. He said the space agency will accelerate its next two moon missions: Luna 26 and Luna 27, which could give Roscosmos all the science it lost with the failure of Luna 25.

Still, space policy experts question whether the Russian government has the power or the will to make that happen, particularly as the country faces sanctions around the war in Ukraine and Roscosmos appears to be of diminishing importance to the Kremlin.

“Even if they said they were going to continue (the Luna program), that doesn’t necessarily mean anything at this point. And the question is: Can they continue? Do they have the capability to continue it?” said Robert Pearson, a former ambassador to Turkey, former director general of the U.S. Foreign Service, and a founding member of Duke University’s Space Diplomacy Lab.

The consequence of this failure, Pearson added, is that on the global stage, it raises the question of whether Russia is “seriously in the space race” at all.

A changing civil space landscape

Russia’s failed moon landing attempt comes amid a rush of other lunar exploration efforts, largely designed by countries that haven’t been seen as traditional space powers. Luna 25 was flying alongside India’s Chandrayaan-3 spacecraft, which will attempt to land on the moon as soon as Wednesday.

More than a dozen other countries also have plans for moon missions in the coming years, including the United States’ ambitious Artemis III, which could land astronauts on the lunar surface as soon as 2025.

“I think it … speaks to how much the cost of space exploration has dropped,” Samson said. “It’s still not cheap by any stretch of the imagination, but it’s gotten a little more reasonable. … I think that’s why more countries are able to (attempt) it.”

But while the loss of Luna 25 may widely be seen as a setback for Russia’s space ambitions, it’s worth noting that putting a spacecraft on the moon remains an exceedingly difficult feat.

India’s last attempt, with the Chandrayaan-2 spacecraft, failed. And two other commercial spacecraft have also crash-landed since 2019.

Perhaps different expectations were placed on Russia, however, because of its extensive Soviet-era experience.

If India’s space agency manages to safely land its spacecraft, Pearson added, it could “really outline the loss of prestige and influence and technological ability on the part of Russia.”

The mission was also closely watched because of how the country’s civil space program has been evolving. In recent years, Roscosmos has been beleaguered by issues with funding, quality control issues and suspected corruption, Samson noted.

The space agency has also faced blowback from Western nations since Russia invaded Ukraine in February 2022. The European Space Agency, for example, was set to work with Roscosmos on the Luna 25 mission as well as several future exploration endeavors, but Europe pulled out of the partnership after the invasion of Ukraine.

Now, questions are swirling around how Russia’s closest modern space partner — China — might react to Luna 25’s failure.

The two countries had announced they would work together to establish the International Lunar Research Station, a moon base to rival plans by the US and its allies to create a permanent lunar outpost under NASA’s Artemis program.

Samson noted that China, which is so far the only country to soft-land spacecraft on the moon in the 21st century, has already been downplaying Russia’s role in the program.

“I’m sure China must be really wondering what they saddled themselves with” after the Luna 25 mission, Samson said.

Still, Samson and Pearson both noted that Russia continues to play a key role on the international stage. The country is the United States’ primary partner on the International Space Station, though Russia previously threatened to pull out of that operation. For years, Russia was also the only country capable of getting astronauts to and from the space station after NASA retired its space shuttle program. (Today, SpaceX has taken over that function for the US.)

Why missions like Luna 25 matter

The Luna 25 spacecraft was intended to land on the moon’s south pole. It’s the same region where India is aiming to put its Chandrayaan-3 lander and where NASA plans to put its astronauts as well as future robotic missions.

The widespread interest in the moon’s south pole can be attributed to one key feature: water ice. Scientists believe copious amounts of water are stored near the south pole, frozen solid in shadowy craters.

Water ice could be immensely valuable for the future of space exploration. The precious resource could be converted into rocket fuel for missions that explore deeper into the cosmos or turned into drinking water for astronauts on long-duration missions.

“That is really the big driver for why we need to head to the south pole — and they’re in sort of part of a ‘Space Race Part Two,’” said Dr. Angela Marusiak, an assistant research professor at the University of Arizona’s Lunar and Planetary Laboratory, in an August 18 interview.

Because orbital dynamics make the south pole difficult to reach, it hasn’t been as deeply explored as other areas. That gives Russia and every other nation with lunar ambitions a key reason to go: There is clear scientific — and strategic — interest.

But Pearson questioned why Russia chose to head straight for the south pole for its first lunar mission in nearly 50 years.

“All they had to do was land (somewhere on the moon) and they would have shown the world that they were in the space race,” Pearson said of Russia. “They took a desperate measure — in my opinion — when they should have picked a safer option.”

Which countries reach the moon, and when, could have implications for how scientists make use of the data gathered.

Exactly how information sharing will work is not exactly clear.

India, for example, is a signatory of NASA’s Artemis Accords, a document mapping out agreed-upon rules for lunar exploration that includes a commitment to sharing scientific data.

Russia, on the other hand, is not a signatory.

But Samson cautioned against characterizing these lunar missions as a race, suggesting those involved are opponents. Though it’s difficult to know exactly what dynamics will arise, the moon is a big place — and there is room for everyone.

“My concern is that if we look at this in an aggressive, adversarial manner,” she said, “then we will generate the exact circumstance we’re trying to avoid.”","https://media.cnn.com/api/v1/images/stellar/prod/230821151945-russia-luna-25-crash-landing-engine-issue.jpg?c=16x9&q=w_800,c_fill",https://www.cnn.com/2023/08/22/world/russia-luna-25-chandrayaan-3-global-space-race-scn/index.html,Science
['Jonathan Corum'],2023-08-22 00:00:00,"Racing to Land, or Crash, on the Moon","Russia’s Luna-25 spacecraft crashed into the moon on Saturday, two days before a planned landing attempt.

It was the latest in a series of impacts, belly flops and hard landings — some intentional, others unplanned — since 1959, when the Soviet Union’s Luna-2 became the first probe to hit the moon.

India’s Chandrayaan-3 mission will attempt to land on the moon on Wednesday, and other missions will follow in coming months.

An image taken on Sunday by the Chandrayaan-3 spacecraft in lunar orbit. ISRO

64 Years of Moon Crashes

Seven space programs and one private company have made hard landings on the moon: the Soviet Union, United States, Japan, European Space Agency, India, China, Israel and Ispace. Crash locations are shown on the map below.

Moon imagery from the Lunar Reconnaissance Orbiter Camera via NASA’s Scientific Visualization Studio. Some types of crashes, including used rocket engines and empty Apollo lunar modules, are not shown. Some locations are approximate, and other crash locations have not been determined.

Some crashes were setbacks. Others were intentional, marking the end of a successful mission. Whatever the cause, space agencies have learned from each collision. Crashes can reveal design flaws or software glitches, and expose material under the lunar surface for future study.

India’s Last Attempt

On Sept. 7, 2019, India’s Chandrayaan-2 lander lost communications with Earth as it descended toward a planned landing site near the moon’s south pole.

NASA’s Lunar Reconnaissance Orbiter flew over the area ten days later but was unable to locate the lander, known as Vikram.

Curtius Manzinus Moretus Chandrayaan-2 crash site Chandrayaan-3 target landing site Boguslawsky South Pole Path of the Lunar Reconnaissance Orbiter on Sept. 17, 2019 Curtius Manzinus Moretus Chandrayaan-2 crash site Chandrayaan-2 target landing site Boguslawsky South Pole Path of the Lunar Reconnaissance Orbiter on Sept. 17, 2019 Curtius Manzinus Moretus Chandrayaan-2 crash site Chandrayaan-3 target landing site Boguslawsky South Pole Path of the Lunar Reconnaissance Orbiter on Sept. 17, 2019 Curtius Manzinus Chandrayaan-2 crash site Chandrayaan-3 target landing site Path of the Lunar Reconnaissance Orbiter on Sept. 17, 2019 South Pole A map of the moon’s south polar region, showing elevation in false color. The New York Times; Map data from NASA, the Goddard Space Flight Center and Arizona State Univ.

Months later, an Indian space enthusiast spotted a bright speck in a publicly available NASA image, which turned out to be spacecraft debris from Vikram’s impact.

Vikram’s impact site 100 METERS Vikram’s impact site 100 METERS Vikram’s impact site 100 METERS Vikram’s impact site 100 METERS A composite image highlighting recent changes on the lunar surface. NASA; Goddard Space Flight Center; Arizona State Univ.

Future Missions

Japan plans to launch the SLIM mission to the moon this week, on Aug. 26. The mission would orbit the moon and attempt a landing near Shioli Crater.

An illustration of Japan’s SLIM lander. JAXA

Several companies are also competing to achieve the first private lunar landing. Japan’s Ispace launched the Hakuto-R Mission 1 spacecraft in 2022, but it crashed while landing in April.

Hakuto-R’s impact site 50 METERS Hakuto-R’s impact site 50 METERS Hakuto-R’s impact site 50 METERS Hakuto-R’s impact site 50 METERS A composite image highlighting recent changes on the lunar surface. NASA; Goddard Space Flight Center; Arizona State Univ.

Houston’s Intuitive Machines and Pittsburgh’s Astrobotic Technology may launch lunar missions by the end of the year.

Crewed Missions

NASA has named four astronauts for the Artemis II mission that could orbit the moon in late 2024. Both NASA and China hope to land astronauts by 2030, putting humans on the moon for the first time since Apollo 17 in 1972.

Apollo 17 commander Eugene A. Cernan on the lunar surface, Dec. 13, 1972. NASA



",https://static01.nyt.com/images/2023/08/22/science/moon-landings-and-crashes-1692717484491/moon-landings-and-crashes-1692717484491-facebookJumbo.jpg,https://www.nytimes.com/interactive/2023/08/22/science/moon-landing-crashes-russia-india.html,Science
[],2023-08-23 00:00:00,Russia launches cargo ship to the International Space Station – Spaceflight Now,"A Russian Progress cargo ship blasted off from the Baikonur Cosmodrome on Tuesday, Aug. 22 at 9:08 p.m. EDT (0108 UTC on Aug. 23) carrying supplies and equipment to the International Space Station.

The uncrewed spacecraft, which is carrying about three tons of cargo will make 34 orbits of Earth before using the Kours automated system to dock at the space station’s Zvezda module on Aug. 24 at 11:50 p.m. EDT (0350 UTC). The craft is expect to stay at the orbiting outpost for six months before departing on one final mission to dispose of the station’s trash in a fiery reentry.

NASA designates this mission Progress 85 but Russia uses the designation Progress MS-24. It will the 117th flight of a Progress spacecraft since its debut in 1978. The cargo freighter previously served the Salyut and Mir space stations launched during the era of the Soviet Union.",,https://spaceflightnow.com/2023/08/23/live-coverage-russia-to-launch-cargo-to-the-international-space-station/,Science
['Stephen Clark'],,"Valves are a regular concern at SpaceX, just like every other space company","SpaceX is launching a mission about once every four days, and most of those flights are going to space to deploy Internet satellites for the company's own Starlink broadband network. But this week is different. Aside from two more missions carrying Starlink satellites, SpaceX is preparing to send a four-person crew to the International Space Station early Friday.

The crew launch from the Kennedy Space Center in Florida will deliver NASA commander Jasmin Moghbeli, European Space Agency astronaut Andreas Mogensen, Japanese astronaut Satoshi Furukawa, and Russian cosmonaut Konstantin Borisov to the space station for a half-year stay. This mission, known as Crew-7, will be SpaceX's 11th astronaut flight and the company's seventh operational crew rotation mission for NASA using a Crew Dragon spacecraft.

Bill Gerstenmaier, SpaceX's vice president of build and flight reliability, says these crew missions are special. SpaceX and NASA managers met Monday for a flight readiness review, a customary milestone before every crew launch, to deliberate on any problems that could affect the upcoming mission.

“It’s nice to get a chance to step back and look at all the issues, problems, and things that are going right with the vehicles,"" Gerstenmaier said. ""We get a chance to take a look at the Falcon vehicle maybe in a little more in-depth way for crew flights than we do for other flights. We know the importance of flying crew, and the trust that the crew puts in us in delivering.""

SpaceX has launched its Falcon 9 and Falcon Heavy rockets 81 times over the last year (that number could climb to 83 by the end of the week). Since the start of 2023, the company has launched its Falcon rockets 57 times, on pace for roughly 90 missions by the end of the year. For an orbital-class rocket, this is an unmatched launch rate in the entire history of spaceflight.

“We have separate teams that are monitoring all these activities,"" Gerstenmaier said. ""In fact, we can support launches from three pads simultaneously with our support teams the way we are. So we’re not overstressed, we’re not overworking the workforce.""

Advertisement

According to BryceTech, SpaceX launched more than 447 metric tons of payload mass in the first half of this year, nearly 10 times more than all Chinese rockets.

""From the outside, it may look like we’re flying a lot of flights, and they’re all trouble-free,"" Gerstenmaier said. ""They are not all trouble-free. They are not easy. Every time we fly, we learn something. We spend the time to go analyze it.""

Cleared for flight

NASA and SpaceX officials gave the green light Monday to proceed with preparations to launch the Crew-7 mission Friday, but only after formally signing off on several technical issues. One of those involved a drogue parachute that took longer than anticipated to fully inflate on a Dragon crew capsule returning from the space station earlier this year.

That issue was cleared for the launch of the Crew-7 mission during the flight readiness review.

“The parachute system is something that we monitor very carefully,"" said Steve Stich, manager of NASA's commercial crew program. ""We have imagery of the chutes every landing, and SpaceX has done a great job of recovering those chutes from every single landing.”

Stich said the other ""special topic"" discussed Monday was a valve failure on a Dragon cargo capsule in June. During that mission, an isolation valve in the Dragon's propulsion system became stuck. There was no effect on the Dragon resupply mission because the valve in question is only used if there's a problem elsewhere in the propulsion system, when it would close or isolate a leaky thruster to avoid losing propellant.

SpaceX engineers removed the stuck valve from the Dragon cargo capsule after it splashed down at the end of its mission in June. They found signs of corrosion.

""The corrosion is caused by oxidizer vapors mixing with a little bit of moisture,"" Stich said. ""The materials are corrosion resistant, but if you get enough vapor from the oxidizer along with water, you can form a little bit of acid and get some corrosion.""

That may sound familiar for Ars readers. A test flight of Boeing's delay-stricken Starliner crew capsule, which still hasn't flown with astronauts, was grounded in 2021 after engineers discovered stuck valves in the spacecraft's propulsion system just hours before launch. Inspections revealed corrosion in the valves caused by moisture mixing with vapors of nitrogen tetroxide, the oxidizer used for maneuvering thrusters on both Starliner and Crew Dragon.

Advertisement

Stich said the process that led to the corrosion is ""somewhat similar"" to the issue facing the Starliner and Dragon spacecraft. ""We have, on the valves, an environmental seal that leaks a little bit of vapor across into the dry side of the valve, which is the electrical part that actuates the valve, and then forms corrosion on the components inside, combined with a little bit of moisture,"" he said.

There were numerous stuck valves inside Boeing's Starliner spacecraft, delaying its unpiloted test flight by more than nine months. Over the last couple of months, SpaceX was able to remove valves on the Crew Dragon Endurance spacecraft slated to fly the Crew-7 mission, replace some parts in the valves, then reassemble them and test them on the capsule. ""We know all of those valves are functioning just fine,"" Stich said.

""We’re very agile in the fact that we can get into tests (of hardware),"" Gerstenmaier said. ""We have a lot of vertical integration. We can do things ... to tear valves apart and dissect things. We use the NASA team where appropriate. We shift some of the work to them to go take a look. I think that’s a strength between us both to make sure we’re ready to fly.”

The valves on SpaceX's Crew Dragon Endeavour spacecraft currently docked at the space station are also functioning as designed. Ground teams will likely remove and inspect those valves after the capsule returns to Earth next month, following the launch of the Crew-7 mission.

""I would say we learned quite a bit from the investigation we did on Starliner, and it probably helped us get to the root cause a little bit faster on the Dragon valve issue,"" Stich said. ""The materials inside the valves are a little different, so the kind of corrosion is a little different between the Dragon valve and the Starliner valves, but it’s a similar mechanism.""

Stich said SpaceX and NASA would consider adding purge air to the propulsion system to keep vapors from building up and leading to corrosion. That's similar to something Boeing did to mitigate the problem with Starliner's corroded valves.

""I think we’re learning a little bit about capsules and valves between the two different vehicles—Starliner and Dragon—and we have a little bit more work ... to remediate the corrosion for the long term because we really want to re-fly each one of these (Dragon) vehicles up to five times,"" Stich said.",https://cdn.arstechnica.net/wp-content/uploads/2023/08/crewdragon-760x380.jpeg,https://arstechnica.com/space/2023/08/valves-are-a-regular-concern-at-spacex-just-like-every-other-space-company/,Science
"['Mike Wall', 'Senior Space Writer', 'Social Links Navigation']",2023-08-23 10:00:56+00:00,SpaceX Crew-7 astronauts rehearse ahead of Aug. 25 launch (photos),"The four astronauts of SpaceX's Crew-7 mission to the International Space Station rehearse inside their Crew Dragon spacecraft ahead of a planned Aug. 25, 2023 liftoff.

SpaceX and NASA are checking off boxes ahead of the company's next crewed launch to the International Space Station, which is scheduled for Friday (Aug. 25).

The four astronauts of that mission, which is called Crew-7, along with their associated SpaceX and NASA teams, have ""completed a full rehearsal of launch day activities,"" SpaceX wrote via X (formerly Twitter) early Tuesday morning (Aug. 22).

That post featured three photos: One showed the spaceflyers inside their Crew Dragon capsule Endurance, which is sitting atop a Falcon 9 rocket at Pad 39A at NASA's Kennedy Space Center in Florida. Another saw the crew in front of the Falcon 9-Endurance stack on the pad, and the third was taken in Pad 39A's crew access arm, the entry point into Endurance.

Related: SpaceX Crew-7 astronaut plans to snap aurora photos on the ISS

The Crew-7 astronauts stand inside the crew access arm at Kennedy Space Center's Pad 39A ahead of a planned Aug. 25, 2023 liftoff. (Image credit: SpaceX)

And, in another Tuesday morning X post, SpaceX announced that it had conducted a successful ""static fire"" test of Crew-7's Falcon 9. (In static fires, a rocket's first-stage engines are briefly ignited while the vehicle remains anchored to the ground.)

So everything remains on track for a Crew-7 liftoff from Pad 39A on Friday at 3:49 a.m. EDT (0749 GMT). You can watch the launch live here at Space.com when the time comes.

Crew-7 will send four spaceflyers to the International Space Station (ISS) for a roughly six-month stay.

Those four astronauts are NASA's Jasmin Moghbeli, the Crew-7 commander; Danish astronaut Andreas Mogensen of the European Space Agency, who will serve as pilot; and mission specialists Konstantin Borisov and Satoshi Furukawa, of the Russian space agency Roscosmos and the Japan Aerospace Exploration Agency, respectively.

The Crew-7 astronauts stand in front of their Falcon 9 rocket and Crew Dragon capsule at Kennedy Space Center's Pad 39A ahead of a planned Aug. 25, 2023 liftoff. (Image credit: SpaceX)

Another Crew Dragon capsule is already docked to the ISS — Endeavour, which flew four astronauts up on SpaceX's Crew-6 mission. The Crew-6 quartet will depart for Earth about five days after Crew-7 docks, a milestone scheduled to occur roughly 24 hours after launch.

And the ISS will get another visitor before Crew-7 lifts off, if all goes according to plan. A robotic Russian Progress cargo craft is scheduled to launch Tuesday evening and arrive at the orbiting lab late Thursday night (Aug. 24).",https://cdn.mos.cms.futurecdn.net/W38CCqfCB28LwqEqX4wJbH-1200-80.jpg,https://www.space.com/spacex-crew-7-astronauts-launch-rehearsal-photos,Science
[],2023-08-23 02:21:58-07:00,Two Rockets on Opposite Sides of the World Are Launching to the International Space Station,"Two rockets on opposite sides of the world are launching to the International Space Station (ISS) to deliver cargo and a new crew this week. The first spaceship launched from Kazakhstan on Tuesday night hauling supplies to replenish the Expedition 69 crew. The second will launch from Florida sending four new crew members to the orbital lab.

Roscosmos Progress 85 Cargo Mission

The Roscosmos Progress 85 cargo craft lifted off on a Soyuz rocket at 9:08 p.m. EDT on Tuesday, August 22 from the Baikonur Cosmodrome in Kazakhstan. It will orbit Earth for two days before docking to the aft port of the Zvezda service module at 11:50 p.m. on Thursday. A few hours later on Friday, cosmonauts Sergey Prokopyev and Dmitri Petelin will open Progress 85’s hatches and begin unpacking about three tons of food, fuel, and supplies.

SpaceX Crew-7 Launch Preparations

Four Commercial Crew astronauts were suited up inside the SpaceX Dragon Endurance spacecraft at NASA’s Kennedy Space Center in Florida overnight for their dry dress launch countdown. A few hours later, the Falcon 9 engines fired for 6 seconds as part of the pre-launch static fire test. SpaceX Crew-7 is slated to launch at 3:49 a.m. on Friday.

Crew-7 Commander Jasmin Moghbeli of NASA will lead Pilot Andreas Mogensen of ESA (European Space Agency), and Mission Specialists Satoshi Furukawa of JAXA (Japan Aerospace Exploration Agency) and Konstantin Borisov of Roscosmos during their ride to the orbital lab. The quartet, inside the Endurance, will dock to the Harmony module’s space-facing port at 2:02 a.m. on Saturday beginning a six-month space research mission.

Activities Aboard the ISS

Back aboard the orbital outpost on Tuesday, the seven crewmates from the U.S., UAE (United Arab Emirates), and Russia stayed focused on microgravity research and lab maintenance.

NASA Flight Engineers Frank Rubio and Stephen Bowen swapped out hardware inside the Fluids Integrated Rack for a boiling and condensation study that may improve thermal systems on Earth and in space. Rubio earlier joined UAE astronaut Sultan Alneyadi organizing cargo inside the Northrop Grumman Cygnus space freighter. Bowen began his day cleaning crew quarters ventilation systems and checking airflow sensors. Flight Engineer Woody Hoburg of NASA also assisted with the Cygnus work before configuring the Tranquility module’s Bishop airlock ahead of its depressurization.

Health and Departure Preparations

During the morning, Prokopyev attached various sensors to himself as part of a long-running Roscosmos heart study. Later, he partnered with Petelin to employ ultrasound techniques, investigating the digestive system’s adaptability in a weightless environment. Roscosmos Flight Engineer Andrey Fedyaev occupied himself with orbital plumbing duties inside the Nauka science module.

As the day drew to a close, a team consisting of Fedyaev, Bowen, Hoburg, and Alneyadi initiated preparations for their slated departure on September 1 aboard the SpaceX Dragon Endeavour spacecraft. The crew will land off Florida’s coast roughly 24 hours post-departure. Before concluding the day, the foursome communicated with ground experts, discussing the operations of the spacecraft for their Earthbound journey.",https://scitechdaily.com/images/NASAs-SpaceX-Crew-7-Preflight-scaled.jpg,https://scitechdaily.com/two-rockets-on-opposite-sides-of-the-world-are-launching-to-the-international-space-station/,Science
[],,Space Agencies Around The World Are Racing To Moon's South Pole. Here's Why,"Russia's Luna-25 craft had been scheduled to land on the south pole but crashed on Sunday.

India's space agency is attempting to land a spacecraft on the moon's south pole, a mission that could advance India's space ambitions and expand knowledge of lunar water ice, potentially one of the moon's most valuable resources.

Here's what's known about the presence of frozen water on the moon - and why space agencies and private companies see it as a key to a moon colony, lunar mining and potential missions to Mars.

HOW DID SCIENTISTS FIND WATER ON THE MOON?

As early as the 1960s, before the first Apollo landing, scientists had speculated that water could exist on the moon. Samples the Apollo crews returned for analysis in the late 1960s and early 1970s appeared to be dry.

In 2008, Brown University researchers revisited those lunar samples with new technology and found hydrogen inside tiny beads of volcanic glass. In 2009, a NASA instrument aboard the Indian Space Research Organisation's Chandrayaan-1 probe detected water on the moon's surface.

In the same year, another NASA probe that hit the south pole found water ice below the moon's surface. An earlier NASA mission, the 1998 Lunar Prospector, had found evidence that the highest concentration of water ice was in the south pole's shadowed craters.

WHY IS WATER ON THE MOON IMPORTANT?

Scientists are interested in pockets of ancient water ice because they could provide a record of lunar volcanoes, material that comets and asteroids delivered to Earth, and the origin of oceans.

If water ice exists in sufficient quantities, it could be a source of drinking water for moon exploration and could help cool equipment.

It could also be broken down to produce hydrogen for fuel and oxygen to breathe, supporting missions to Mars or lunar mining.

The 1967 United Nations Outer Space Treaty prohibits any nation from claiming ownership of the moon. There is no provision that would stop commercial operations.

A U.S.-led effort to establish a set of principles for moon exploration and the use of its resources, the Artemis Accords, has 27 signatories. China and Russia have not signed.

WHAT MAKES THE SOUTH POLE ESPECIALLY TRICKY?

Attempted landings on the moon have failed before. Russia's Luna-25 craft had been scheduled to land on the south pole this week but spun out of control on approach and crashed on Sunday.

The south pole - far from the equatorial region targeted by previous missions, including the crewed Apollo landings - is full of craters and deep trenches.

ISRO's Chandrayaan-3 mission is on track for an attempted landing on Wednesday, the space agency has said. A previous Indian mission failed in 2019 to safely land near the area targeted by Chandrayaan-3.

Both the United States and China have planned missions to the south pole.

(Except for the headline, this story has not been edited by NDTV staff and is published from a syndicated feed.)",https://c.ndtvimg.com/2023-08/ogfro2dg_luna-25-mission_625x300_19_August_23.jpg,https://www.ndtv.com/world-news/space-agencies-around-the-world-are-racing-to-moons-south-pole-heres-why-4320937,Science
[],,What to know about India's moon mission,,https://i.ytimg.com/vi/l8EhopA3PrQ/maxresdefault.jpg?sqp=-oaymwEmCIAKENAF8quKqQMa8AEB-AH-CYAC0AWKAgwIABABGEggZShkMA8=&rs=AOn4CLAS8465p8xebjSHF3lXPgdFzQNUDQ,https://www.youtube.com/watch?v=l8EhopA3PrQ,Science
"['Sky Uk Limited', 'Tom Acres', 'Technology Reporter']",,India moon landing: Chandrayaan-3 could make history in space today - here's what you need to know,"Besides a Cricket World Cup final win over Pakistan, it's difficult to envisage anything generating more excitement in India than its historic moon mission.

In what would be a landmark achievement for not just the country's space programme, but humanity's efforts to explore the cosmos, Chandrayaan-3 will attempt to land on the lunar south pole.

The spacecraft's looking to land at 1.34pm UK time - and you can watch it live on the Sky News website, app, and YouTube channel.

Here's what you need to know.

Why does landing on the south pole matter?

Only three nations - the US, China, and Soviet Union - have ever touched down on Earth's satellite, though none have successfully made it to the south pole.

The difficulty of doing so was made clear over the weekend when a Russian craft crashed during its own bid, meaning the door remained open for India to set a new bar for moon exploration.

It's thought the south pole's shadowed craters contain water ice that could support a future base on the moon, allowing astronauts and scientists to work there for extended periods.

Space agencies including NASA have detected frozen water in the moon's south pole craters before, but no country has ever actually ventured into the region.

Advertisement

If water ice is really there, it could be used for fuel, oxygen, and drinking water; and provide insight into past lunar volcanoes and the origins of our own oceans.

Image: A view of the moon from Chandrayaan-3

Why has nobody done it before?

As the failed Russian mission proved, it's extremely difficult.

India knows only too well, with Chandrayaan-3's forerunner (you guessed it, Chandrayaan-2) having crashed near its proposed landing site in 2019.

It managed to deploy an orbiter, but the lander and rover meant to actually reach the surface were destroyed.

The south pole is a long way from the region of the moon targeted by most previous missions, including the crewed Apollo landings from decades gone by.

One of the challenges facing space agencies is the moon's south pole has very rough terrain, with deep trenches and plenty of craters.

India's experts believe adjustments they've made to Chandrayaan-3, like sturdier legs, will stand it in good stead.

Image: Prayers are being held for the mission's success. Pic: AP

What happens if it lands?

First, probably scenes of delirious celebration at India's Space Research Organisation and on the streets of Delhi, Mumbai, Kolkata, and cities across the country.

Prime Minister Narendra Modi has drummed up the hype, hailing the mission as ""a new chapter in India's space odyssey"" that would elevate ""the dreams and ambitions of every Indian"".

Prayers have been held for the mission's success, schools are putting on telecasts, and watch parties are planned.

Chandrayaan-3's mission will be short but - hopefully - sweet.

It will only remain functional for two weeks if it lands, during which it will run a series of experiments to determine the mineral composition of the moon's surface.

Much of the work will be done by a rover, which will be deployed by the spacecraft's two-metre-high lander.

Chandrayaan-3's time on the moon will be far less than the time it took to get there, having launched from India's Andhra Pradesh spaceport on a LVM3 M4 rocket on 14 July.

Image: Space enthusiast Arun Haryani holds up a model of LVM3 M4, which was used to launch Chandrayaan-3

What will other countries make of a successful landing?

It's safe to say Russia will likely be very jealous, having seemed determined to beat India to the punch.

In the US, NASA's chief Bill Nelson has said he's ""looking forward"" to what could be learned from the mission.

The American agency is planning its own quest to the surface of the moon's south pole, as is China, having only explored using probes.

Read more:

Is this the 'holy grail' of physics?

The sci-fi epic that could change gaming

Nearly half of workers 'would use AI to help write CV'

Be the first to get Breaking News Install the Sky News app for free

NASA has co-ordinated with India before, sending equipment to the moon on board Chandrayaan-1 in 2009 which detected water.

That same year, one of its own probes also found water ice below the south pole's surface.

In the years ahead, private companies will also likely try their hand at exploring the moon - and Mr Modi hopes a successful landing on Wednesday will drive more Indian firms to invest in space.",https://e3.365dm.com/23/08/1600x900/skynews-chandrayaan-3-comp_6259859.jpg?20230823103405,https://news.sky.com/story/india-moon-landing-chandrayaan-3-could-make-history-in-space-today-heres-what-you-need-to-know-12945160,Science
[],,Will the new space race look like the ’60s or the 16th century?,,https://i.ytimg.com/vi/HoXEc895Q14/maxresdefault.jpg,https://www.youtube.com/watch?v=HoXEc895Q14,Science
[],,India joins the space race | 7NEWS,,https://i.ytimg.com/vi/1jQ8UCUDIHE/maxresdefault.jpg,https://www.youtube.com/watch?v=1jQ8UCUDIHE,Science
[],,India's historic Moon mission set for touchdown | AFP,,https://i.ytimg.com/vi/OICsrsrnrvw/maxresdefault.jpg,https://www.youtube.com/watch?v=OICsrsrnrvw,Science
[],,India holds its breath over moon landing mission | ANC,,https://i.ytimg.com/vi/NIJCn6rDp_o/maxresdefault.jpg,https://www.youtube.com/watch?v=NIJCn6rDp_o,Science
[],,India Poised to Make History with Moon mission set for touchdown | Developing | Dawn News English,,https://i.ytimg.com/vi/yns_rAsGQpE/maxresdefault.jpg,https://www.youtube.com/watch?v=yns_rAsGQpE,Science
"['Jeff Foust', 'More Jeff Foust']",2023-08-23 02:19:05+00:00,Target of European debris removal mission hit by other debris,"WASHINGTON — A payload adapter that is the target of a European debris cleanup mission may have itself been damaged by a debris impact.

The European Space Agency said Aug. 22 that it was informed 12 days earlier by the U.S. Space Force’s 18th Space Defense Squadron, responsible for space domain awareness activities, that it had identified several pieces of debris in the vicinity of a larger payload adapter called Vespa that has been in low Earth orbit since a Vega launch a decade ago.

The new debris, ESA said, likely originated from Vespa after a collision with a piece of debris too small to be tracked. Follow-up tracking by the 18th Space Defense Squadron as well as European facilities indicates that the payload adapter remains intact. ESA did not state how many pieces of debris from Vespa were bring tracked.

The incident is ironic because the Vespa adapter is the target of an ESA-backed mission to remove it from orbit. ESA selected Swiss startup ClearSpace in 2020 to fly a mission that would grapple the 113-kilogram adapter and remove it from orbit, awarding it a contract worth 86 million euros ($93 million).

That mission, called ClearSpace-1, passed a review at the end of 2022 that marked the end of its initial design phase. ClearSpace-1 is scheduled to launch in 2026 on a Vega C rocket. The company raised 26.7 million euros in January to support work on of the mission.

ESA said in the statement that it was too soon to know if the debris impact would affect the ClearSpace-1 mission: “The development of the ClearSpace-1 mission will continue as planned while additional data on the event is collected. ESA and industrial partners are carefully evaluating the event’s impact on the mission.” That analysis, ESA added, would take several weeks to complete.

ESA has made space safety, such as mitigating and remediating orbital debris, a priority. In July, ESA carried out an “assisted reentry” of an Earth science spacecraft, Aeolus, that lacked propellant needed to carry out a deliberate, targeted reentry at the end of its mission. That effort ensured the spacecraft reentered over uninhabited territory to avoid any risk to people on the ground from spacecraft debris that survived reentry.

ESA unveiled plans for a “Zero Debris Charter” during the Paris Air Show in June with the support of three major European satellite manufacturers: Airbus Defence and Space, OHB and Thales Alenia Space. Details about the charter have yet to be published, but the goal is to prevent the creation of new debris in Earth orbit.

“The principle is a very simple one,” said ESA Director General Josef Aschbacher at the event announcing the charter. “The Zero Debris Charter is a principle where we would like to ensure that there is zero debris left behind in space.”

ESA, though, has also contributed to the orbital debris problem. The defunct Envisat spacecraft was abandoned in low Earth orbit when it malfunctioned a decade after its launch in 2002. The large size of Envisat, which is predicted to remain in orbit for up to 150 years, makes it a potential source of debris from collisions like the one the Vespa adapter suffered.

A 2020 study by a group of space sustainability experts ranked Envisat 21st on a list of the 50 “statistically most concerning” debris objects in Earth orbit. Envisat was the highest-ranked satellite on the list, following a family of 20 Zenit rocket bodies all in similar orbits.",https://spacenews.com/wp-content/uploads/2023/02/Artistic-impression-of-the-servicer-ClearSpace-1-approaching-a-space-debris-object-VESPA-during-the-ClearSpace-1-mission-to-take-place-in-2026.-2023.-©ClearSpace.png,https://spacenews.com/target-of-european-debris-removal-mission-hit-by-other-debris/,Science
"['Elizabeth Howell', 'Staff Writer', 'Classical Motion', 'Social Links Navigation']",2023-08-22 22:00:11+00:00,Clearspace-1 space debris cleanup target in orbit just got struck by space debris,"The target for a space debris cleanup mission is apparently in pieces.

A leftover rocket adapter, expected to be removed from low Earth orbit in 2026, has new pieces of space debris floating nearby. That's a likely aftereffect of being hit by something small flying through space. The problem was spotted by the 18th Space Defense Squadron of the U.S. Space Force, which monitors satellite movements.

That's an unexpected event for the European Space Agency's ClearSpace-1 mission, which is a planned test mission to remove that adapter in 2026. The adapter is a conical-shaped leftover, roughly 250 pounds (113 kg) in mass, from a 2013 Vega launch that sent a small fleet of satellites into orbit. Space tracking systems found new objects nearby the adapter, which ESA learned about on Aug. 10. The objects are likely space debris from a ""hypervelocity impact of a small, untracked object"" that smacked into the payload adapter, the agency said. We may never know if the crashing object was natural or artificial, given it didn't appear in tracking systems.

Related: Space junk cleanup mission to launch in 2026 aboard Arianespace rocket

""This fragmentation event underlines the relevance of the ClearSpace-1 mission,"" ESA officials wrote in a statement Tuesday (Aug. 22). ""The most significant threat posed by larger objects of space debris is that they fragment into clouds of smaller objects, that can each cause significant damage to active satellites.""

While it appears only a small piece of the rocket hardware was lost after the collision, the mission plan assumed fully intact hardware. Now evaluations are ongoing to figure out what's next, and the analysis will persist for weeks at the least.

The planned ClearSpace-1 mission aims to ""rendezvous, capture and remove"" the adapter using a spacecraft from the Swiss startup ClearSpace, according to a recent release from mission partner Arianespace. A lightweight Vega-C rocket from Arianespace will bring the cleanup spacecraft to orbit under the ESA-funded mission.

The plan calls for ClearSpace's spider-shaped vehicle with ""legs"" to enclose and then push back into Earth a payload adapter, which is the structure that connects spacecraft with their launch vehicle.

With the planned launch of ClearSpace-1 three years away, there is time to figure out what to do. But the incident creates even more uncertainty for an already challenging mission. There is only so much ground stations can see above the orbit of the International Space Station; the original payload adapter was only six feet or two meters in diameter and at an altitude only as low as 410 miles (660 km).

Luckily, however, follow-up tracking from the U.S. Space Force and other stations in Germany and Poland found ""the main object remains intact and has experienced no significant alteration to its orbit,"" ESA said. And happily, the risk of these new objects hitting something else is ""negligible.""

Space debris from humans will take a while to address. Nearly 70 years of space exploration has left a staggering number of pieces to deal with. ESA estimates that Earth orbit has at least 36,500 debris objects that are more than 4 inches (10 centimeters) wide. Including the smallest trackable objects, that number balloons to an incredible 330 million objects bigger than 0.04 inches (1 millimeter).",https://cdn.mos.cms.futurecdn.net/uzZ6MwWNsG6FdySFoqakFc-1200-80.gif,https://www.space.com/space-debris-cleanup-mission-target-hit,Science
[],2023-08-22 00:00:00,Are you a robot?,"Why did this happen?

Please make sure your browser supports JavaScript and cookies and that you are not blocking them from loading. For more information you can review our Terms of Service and Cookie Policy.",,,Science
['Laura Dobberstein'],2023-08-23 00:00:00,Space debris targeted for cleanup mission hit by space junk,"On Tuesday, the European Space Agency (ESA) announced that a decade-old piece of space junk it had targeted for removal in a future space debris cleanup has been whacked by another piece of stray kit, thereby increasing the amount of trash in orbit around Earth.

The 112kg rocket part – named VEga Secondary Payload Adapter (VESPA) – was left in space after the 2013 launch of an Arianespace Vega rocket. In its past life as a payload adapter, it helped to deliver the Proba-V, VNREDSat-1 and ESTCube-1 satellites into space from ESA's spaceport in Kourou, French Guiana.

Now it resides, fragmented, in its low Earth orbit of 660km altitude perigee, 790km apogee and 98.7 degree inclination, according to the ESA.

The newly splintered parts of VESPA were detected by the United States 18th Space Defense Squadron, which oversees the US Space Surveillance Network (SSN) – an outfit that detects, tracks and catalogs objects humans have put in space.

ESA said the fragmentation was ""most likely"" caused by the ""hypervelocity impact of a small, untracked object."" The space org said the fragments aren't likely to pose a collision risk to other missions. Probably didn't think this collision was likely either.

Preliminary investigations indicate that ""the main object remains intact and has experienced no significant alteration to its orbit.""

All this is good news, because the ESA's ClearSpace-1 mission was scheduled to remove VESPA in 2026. ClearSpace-1 was planned to be the ""first-ever mission to remove an existing derelict object from orbit through highly precise, complex, close proximity operations, all in the name of cleaning up space.""

The technology demonstration is planned as the first step before more complex commercial and private missions can be put in the works.

The ESA signed a $126 million contract with Swiss startup ClearSpace SA to launch ClearSpace-1. The plan is to rendezvous with VESPA, capture it using four robotic tentacles, then pull it back towards Earth so the pair would burn up on reentry.

A visualization of the mission can be seen in the video below:

Youtube Video

So far, ESA says ClearSpace-1 will continue as planned but the org, alongside industry partners, is evaluating the event's impact.

""Stay tuned during ESA's analysis in progress,"" tweeted the Swiss startup on Tuesday in response to the news.

In the meantime, the ESA may have found a silver lining to the unfortunate event – it highlights the relevance of this type of work.

""The most significant threat posed by larger objects of space debris is that they fragment into clouds of smaller objects that can each cause significant damage to active satellites,"" said the ESA. ""To minimize the number of fragmentation events, we must urgently reduce the creation of new space debris and begin actively mitigating the impact of existing objects.""

The SSN is currently tracking tracking more than 27,000 pieces of space trash. According to NASA. ""Much more debris – too small to be tracked, but large enough to threaten human spaceflight and robotic missions – exists in the near-Earth space environment.""

Although once upon a time it was socially acceptable to leave an errant spacecraft floating about for up to 25 years, efforts are underway to require space operators to clean up after themselves in a more timely five years.

Those efforts coincide with a sharp increase in the number of items hurtled into space as systems such as SpaceX's Starlink continue to grow.

In July, Starlink devices reportedly comprised over half of all active satellites. ®",https://regmedia.co.uk/2021/03/16/junk.jpg,https://www.theregister.com/2023/08/23/space_debris_targeted_for_groundbreaking/,Science
['Human Brain Project'],,Researchers identify mathematical rule behind the distribution of neurons in our brains,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Neuron densities in cortical areas in the mammalian brain follow a consistent distribution pattern. Credit: Morales-Gregorio

Human Brain Project (HBP) researchers from Forschungszentrum Jülich and the University of Cologne (Germany) have uncovered how neuron densities are distributed across and within cortical areas in the mammalian brain. They have unveiled a fundamental organizational principle of cortical cytoarchitecture: the ubiquitous lognormal distribution of neuron densities.

Numbers of neurons and their spatial arrangement play a crucial role in shaping the brain's structure and function. Yet, despite the wealth of available cytoarchitectonic data, the statistical distributions of neuron densities remain largely undescribed. The new HBP study, published in Cerebral Cortex, advances our understanding of the organization of mammalian brains.

The team based their investigations on nine publicly available datasets of seven species: mouse, marmoset, macaque, galago, owl monkey, baboon and human. After analyzing the cortical areas of each, they found that neuron densities within these areas follow a consistent pattern—a lognormal distribution. This suggests a fundamental organizational principle underlying the densities of neurons in the mammalian brain.

A lognormal distribution is a statistical distribution characterized by a skewed bell-shaped curve. It arises, for instance, when taking the exponential of a normally distributed variable. It differs from a normal distribution in several ways. Most importantly, the curve of a normal distribution is symmetric, while the lognormal one is asymmetric with a heavy tail.

These findings are relevant for modeling the brain accurately. ""Not least because the distribution of neuron densities influences the network connectivity,"" says Sacha van Albada, leader of the Theoretical Neuroanatomy group at Forschungszentrum Jülich and senior author of the paper. ""For instance, if the density of synapses is constant, regions with lower neuron density will receive more synapses per neuron,"" she explains. Such aspects are also relevant for the design of brain-inspired technology such as neuromorphic hardware.

""Furthermore, as cortical areas are often distinguished on the basis of cytoarchitecture, knowing the distribution of neuron densities can be relevant for statistically assessing differences between areas and the locations of the borders between areas,"" van Albada adds.

These results are in agreement with the observation that surprisingly many characteristics of the brain follow a lognormal distribution. ""One reason why it may be very common in nature is because it emerges when taking the product of many independent variables,"" says Alexander van Meegen, joint first author of the study. In other words, the lognormal distribution arises naturally as a result of multiplicative processes, similarly to how the normal distribution emerges when many independent variables are summed.

""Using a simple model, we were able to show how the multiplicative proliferation of neurons during development may lead to the observed neuron density distributions,"" explains van Meegen.

According to the study, in principle, cortex-wide organizational structures might be by-products of development or evolution that serve no computational function; but the fact that the same organizational structures can be observed for several species and across most cortical areas suggests that the lognormal distribution serves some purpose.

""We cannot be sure how the lognormal distribution of neuron densities will influence brain function, but it will likely be associated with high network heterogeneity, which may be computationally beneficial,"" says Aitor Morales-Gregorio, first author of the study, citing previous works that suggest that heterogeneity in the brain's connectivity may promote efficient information transmission. In addition, heterogeneous networks support robust learning and enhance the memory capacity of neural circuits.

More information: Aitor Morales-Gregorio et al, Ubiquitous lognormal distribution of neuron densities in mammalian cerebral cortex, Cerebral Cortex (2023). DOI: 10.1093/cercor/bhad160 Journal information: Cerebral Cortex

Provided by Human Brain Project",https://scx2.b-cdn.net/gfx/news/hires/2023/human-brain-project-re-1.jpg,https://medicalxpress.com/news/2023-08-mathematical-neurons-brains.html,Science
['Picower Institute At Mit'],2023-08-22 06:41:09-07:00,Neural Navigators: How MIT Cracked the Code That Relates Brain and Behavior in a Simple Animal,"MIT researchers model and map how neurons across the tiny brain of a C. elegans worm encode its behaviors, revealing many new insights about the robustness and flexibility of its nervous system

To understand the intricate relationship between brain activity and behavior, scientists have needed a way to map this relationship for all of the neurons across a whole brain. Thus far this has been an insurmountable challenge. But after inventing new technologies and methods for the purpose, a team of scientists in The Picower Institute for Learning and Memory at MIT has produced a meticulous accounting of the neurons in the tractably tiny brain of a humble C. elegans worm, mapping out how its brain cells encode almost all of its essential behaviors, such as movement and feeding.

In the journal Cell on August 21, the team presented new brain-wide recordings and a mathematical model that accurately predicts the versatile ways that neurons represent the worm’s behaviors. Applying that model specifically to each cell, the team produced an atlas of how most cells, and the circuits they take part in, encode the animal’s actions. The atlas, therefore, reveals the underlying “logic” of how the worm’s brain produces a sophisticated and flexible repertoire of behaviors, even as its environmental circumstances change.

Insights from the Research

“This study provides a global map of how the animal’s nervous system is organized to control behavior,” said senior author Steven Flavell, Associate Professor in MIT’s Department of Brain and Cognitive Sciences. “It shows how the many defined nodes that make up the animal’s nervous system encode precise behavioral features, and how this depends on factors like the animal’s recent experience and current state.”

Graduate students Jungsoo Kim and Adam Atanas, who each earned their PhDs this spring for the research, are the study’s co-lead authors. They’ve also made all their data, and the findings of their model and atlas, freely available to fellow researchers at a website called the WormWideWeb.



A two-minute-long excerpt from an example neural/behavioral dataset. The blue, orange, and green dots are targets for tracking, which allowed the team to locate the worm’s head and keep the animal centered in view. A separate view of the microscope (not shown) tracks the simultaneous activity of each brain cell. Credit: Flavell Lab/MIT Picower Institute

Advanced Techniques and Observations

To make the measurements needed to develop their model, Flavell’s lab invented a new microscope and software system. This setup automatically tracks almost all behaviors of the worm (movement, feeding, sleeping, egg-laying, etc.) and the activity of every neuron in its head (cells are engineered to flash when calcium ions build up). Reliably distinguishing and tracking separate neurons as the worm wriggles around and bends required writing custom software, utilizing the latest tools from machine learning. It proved to be 99.7 percent accurate in sampling individual neuron’s activities with greatly improved signal-to-noise compared to previous systems, the scientists report.

The team used the system to record simultaneous behavior and neural data from more than 60 worms as they roved about their dishes, doing whatever they wanted.

Data analysis revealed three novel observations about neural activity in the worm: Neurons track behavior not only of the present moment but also the recent past; they tune their encoding of behaviors, such as motion, based on a surprising variety of factors; and many neurons simultaneously encode multiple behaviors.

For example, while the behavior of wriggling around one’s little laboratory dish might seem like a very simple act, neurons represented factors such as speed, steering, and whether the worm is eating or not. In some cases they represented the animal’s motion spanning back in time by about a minute. By encoding recent, rather than just current motion, these neurons could help the worm compute how its past actions influenced its current outcome. Many neurons also combined behavioral information to execute more complex maneuvers. Much like a human driver must remember to steer the car in the opposite way when going in reverse versus going forward, certain neurons in the worm’s brain integrated the animal’s direction of motion and steering direction.

By carefully analyzing these kinds of patterns of how neural activity correlated with behaviors the scientists developed the C. elegans Probabilistic Neural Encoding Model. The model, encapsulated in a single equation, accounts for how each neuron represents various factors to accurately predict whether and how the neural activity reflects behavior. Nearly 60 percent of the neurons in the worm’s head indeed accounted for at least one behavior.

In fitting the model, the research team used a probabilistic modeling approach that allowed them to understand how certain they were about each fit model parameter, an approach pioneered by co-author Vikash Mansinghka, a principal research scientist who leads MIT’s Probabilistic Computing Project.

Constructing the Atlas

In creating a model that could quantify and predict how any brain cell would represent behavior, the research team initially gathered data from neurons without tracking the cells’ specific identities. But a key goal of studying the worms is to understand how each cell and circuit contributes to behavior. So to apply the model’s capability to each of the worm’s specific neurons, which have all been previously mapped out, the team’s next step was to relate neural activity and behavior for each cell on the map. Doing that required labeling each neuron with a unique color so that its activity could be associated with its identity. The team did this in dozens of freely-moving animals, which provided them with information of how almost all of the defined neurons in the worm’s head related to the animal’s behavior.

The atlas resulting from this work revealed many insights, more fully mapping out the neural circuits that control each of the animal’s behaviors. These new findings will enable a more holistic understanding of how these behaviors are controlled, Flavell said.

“It allowed us to complete the circuits,” he said. “Our hope is that as our colleagues study aspects of neural circuit function, they can refer to this atlas to obtain a fairly complete view of the key neurons involved.”

Neural Flexibility

Another major outcome of the team’s work was the intriguing discovery that while most neurons always obeyed the predictions of the model, a smaller set of neurons in the worm’s brain—about 30 percent of those that encode behavior—was able to flexibly remap their behavior encoding, essentially performing new roles. The neurons in this group were reliably similar across animals, and were well connected with one another in the worm’s synaptic wiring diagram.

Theoretically, these remapping events could occur for any number of reasons, so the team ran further experiments to see if they could cause neurons to remap. As the worms wriggled around their dishes, the researchers applied a quick laser zap that heated the agar around the worm’s head. The heat was harmless but enough to annoy the worms for a while, inducing a change in the animal’s behavior state that lasted for minutes. From these recordings, the team was able to see that many neurons remapped their behavioral encoding right as animals switched behavioral states.

“Behavioral information is richly expressed across the brain in many different forms – with distinct tunings, timescales, and levels of flexibility – that map onto the defined neuron classes of the C. elegans connectome,” the authors wrote.

Reference: “Brain-wide representations of behavior spanning multiple timescales and states in C. elegans” by Adam A. Atanas, Jungsoo Kim, Ziyu Wang, Eric Bueno, McCoy Becker, Di Kang, Jungyeon Park, Talya S. Kramer, Flossie K. Wan, Saba Baskoylu, Ugur Dag, Elpiniki Kalogeropoulou, Matthew A. Gomes, Cassi Estrem, Netta Cohen, Vikash K. Mansinghka and Steven W. Flavell, 21 August 2023, Cell.

DOI: 10.1016/j.cell.2023.07.035

In addition to Atanas, Kim, Mansinghka, and Flavell, the paper’s other authors are Ziyu Wang, Eric Bueno, McCoy Becker, Di Kang, Jungyeon Park, Talya Kramer, Flossie Wan, Saba Baskoylu, Ugur Dag, Elpiniki Kalogeropoulou, Matthew Gomes, Cassi Estrem, and Netta Cohen.

Funding sources for the research include the National Institutes of Health, the National Science Foundation, The McKnight Foundation, The Alfred P. Sloan Foundation, The Picower Institute for Learning and Memory and The JPB Foundation.",https://scitechdaily.com/images/Brain-Neurons-Rendering-Art.jpg,https://scitechdaily.com/neural-navigators-how-mit-cracked-the-code-that-relates-brain-and-behavior-in-a-simple-animal/,Science
[],,We're This Close To Reverse Engineering A Nervous System,"One of the workhorses of in any biology lab is Caenorhabditis elegans or nematode worm just 1mm long. Biologist regularly use C. elegans to gain insight into topics ranging from embryonic development and aging to genetics and neurobiology.

In 1986, C. elegans became the first to have its entire nervous system mapped out. This creature, it turns out, contains just 302 neurons with 7000 synaptic connections between them, the fewest of any animal.

Scientists hoped that such a map — a connectome — would help them reverse-engineer the behavior of the nervous system by measuring how a stimulus to one neuron affects the others. This, they thought, would allow them to predict the behavior of the creature in any circumstances.

But things haven’t worked out like that. It turns out that measuring the effect of one neuron on another in a living creature is exceedingly difficult, let alone the effects on all 301 other neurons.

Since then, various breakthroughs have made these kinds of in vivo measurements significantly easier. Now Gal Haspel at the New Jersey Institute of Technology in Newark and colleagues, say that the goal of reverse-engineering C. elegans entire nervous system is now within grasp. “C. elegans has far fewer neurons and neuron-neuron connections, making it a great starting point,” they say.

Profound Discovery

Success would have profound implications. It would allow a computer to use these measurements to simulate the nervous system of a living organism for the first time — that’s reverse engineering. It would provide profound insights into the way creatures process sensory information, make decisions, and how they learn and behave. And it would pave the way for reverse engineering more complex brains, including our own, perhaps even inspiring entirely new kinds of artificial intelligence.

The connectome — an anatomical map of links between neurons — is insufficient to reconstruct the way the nervous system works in practice. That’s because the map lacks information about synapse strengths and the way each neuron behaves. What’s more, in C. elegans every neuron receives inputs from dozens of others.

Teasing all this apart can only be done with detailed, painstaking measurements that are beyond the capability of mortal human lab workers.

But that changed in the early 21st century when scientists developed a set of techniques for switching genes on and off with light. So-called optogenetics can be used to stimulate neurons with light and then measure the effects by looking for the light emitted.

At the same time, scientists have developed ways to automate the measurements of neural activity in vastly parallel experiments. This creates vast datasets which machine learning techniques can use to reconstruct the original behavior of the neurons in a wide range of conditions.

Haspel and co say these innovations should finally make it possible to reverse engineer C. elegans nervous system at last. And they have put together a large consortium of scientists with all the requisite skills to get it done.

They propose automating experiments on a massive scale to systematically understand all the connections between neurons. Optogenetics will allow researchers to activate neurons in C. elegans with light and to record the responses across the nervous system. Advanced microscopy will image the location of key molecules while also tracing neural morphology at nanoscale resolution.

The goal will be to determine how each neuron's output depends on the activity of every other neuron that connects to it. Modelling these interdependencies will reveal the computational rules embedded in the structure of C. elegans’ nervous system.

Brain States

By exhaustively mapping these functional connections between neurons, this large-scale initiative aims to reverse engineer a complete simulation of the C. elegans brain. “Modern machine-learning based modelling should then enable a simulation of C. elegans’ impressive breadth of brain states and behaviors,” say the team.

That’s an ambitious goal and one with significant implications. Having a virtual version of the C. elegans nervous system will allow rapid, inexpensive hypothesis testing. Researchers can tweak in-silico versions of neurons to observe the simulated effects on worm behavior. That could help screen potential drugs and gene therapies for neural disorders ahead of animal trials.

“Reverse engineering C. elegans will provide a Rosetta-stone-like translation between the language of annotated connectomes and functional properties,” say Halpern and colleagues.

Ultimately, the insights gained from reverse engineering the simple C. elegans nervous system could be used to create virtual models of more complex nervous systems with the ultimate goal of reproducing the human brain in all its complexity.

That’s still a distant dream but one with magnificent potential.

Ref: To reverse engineer an entire nervous system : https://arxiv.org/abs/2308.06578

This article was prepared with the assistance of Claude.AI",https://images.ctfassets.net/cnu0m8re1exe/6cb3wHOrecixoSEpVhBMlh/f7430537b59c24cc841b3f4ff20880a1/shutterstock_1151870249.jpg,https://www.discovermagazine.com/the-sciences/were-this-close-to-reverse-engineering-a-nervous-system,Science
"['Neuroscience News', 'Neuroscience News Posts Science Research News Labs', 'Universities', 'Hospitals', 'News Departments Around The World.', 'Science Articles Cover Neuroscience', 'Psychology', 'Ai', 'Robotics', 'Neurology']",2023-08-22 15:21:07+00:00,Neural Number Crunching: Why Mammal Brains Favor Lognormal Patterns,"Summary: New research delves into how the statistical distributions of neuron densities shape mammalian brains.

The study analyzed seven species, discovering that neuron densities follow a lognormal distribution – a fundamental organizational principle. This distribution is distinct due to its asymmetric curve and is significant for understanding brain connectivity and the design of brain-inspired technology.

As many attributes of the brain align with this distribution, it hints at its potential computational benefits.

Key Facts:

Neuron densities in the brains of seven studied mammalian species, including humans, follow a consistent lognormal distribution pattern. A lognormal distribution emerges as a result of multiplicative processes and influences network connectivity within the brain. Heterogeneity in brain connectivity, potentially linked to the lognormal distribution, can enhance information transmission, learning, and memory capacities of neural circuits.

Source: Human Brain Project

Numbers of neurons and their spatial arrangement play a crucial role in shaping the brain’s structure and function. Yet, despite the wealth of available cytoarchitectonic data, the statistical distributions of neuron densities remain largely undescribed.

The new HBP study, published in Cerebral Cortex, advances our understanding of the organisation of mammalian brains.

The team based their investigations on nine publicly available datasets of seven species: mouse, marmoset, macaque, galago, owl monkey, baboon and human. After analysing the cortical areas of each, they found that neuron densities within these areas follow a consistent pattern – a lognormal distribution.

These results are in agreement with the observation that surprisingly many characteristics of the brain follow a lognormal distribution. Credit: Neuroscience News

This suggests a fundamental organisational principle underlying the densities of neurons in the mammalian brain.

A lognormal distribution is a statistical distribution characterised by a skewed bell-shaped curve. It arises, for instance, when taking the exponential of a normally distributed variable. It differs from a normal distribution in several ways. Most importantly, the curve of a normal distribution is symmetric, while the lognormal one is asymmetric with a heavy tail.

These findings are relevant for modelling the brain accurately.

“Not least because the distribution of neuron densities influences the network connectivity,” says Sacha van Albada, leader of the Theoretical Neuroanatomy group at Forschungszentrum Jülich and senior author of the paper.

“For instance, if the density of synapses is constant, regions with lower neuron density will receive more synapses per neuron,” she explains. Such aspects are also relevant for the design of brain-inspired technology such as neuromorphic hardware.

“Furthermore, as cortical areas are often distinguished on the basis of cytoarchitecture, knowing the distribution of neuron densities can be relevant for statistically assessing differences between areas and the locations of the borders between areas,” van Albada adds.

These results are in agreement with the observation that surprisingly many characteristics of the brain follow a lognormal distribution. “One reason why it may be very common in nature is because it emerges when taking the product of many independent variables,” says Alexander van Meegen, joint first author of the study.

In other words, the lognormal distribution arises naturally as a result of multiplicative processes, similarly to how the normal distribution emerges when many independent variables are summed.

“Using a simple model, we were able to show how the multiplicative proliferation of neurons during development may lead to the observed neuron density distributions” explains van Meegen.

According to the study, in principle, cortex-wide organisational structures might be by-products of development or evolution that serve no computational function; but the fact that the same organisational structures can be observed for several species and across most cortical areas suggests that the lognormal distribution serves some purpose.

“We cannot be sure how the lognormal distribution of neuron densities will influence brain function, but it will likely be associated with high network heterogeneity, which may be computationally beneficial,” says Aitor Morales-Gregorio, first author of the study, citing previous works that suggest that heterogeneity in the brain’s connectivity may promote efficient information transmission.

In addition, heterogeneous networks support robust learning and enhance the memory capacity of neural circuits.

About this neuroscience research news

Author: Peter Zekert

Source: Human Brain Project

Contact: Peter Zekert – Human Brain Project

Image: The image is credited to Neuroscience News

Original Research: Open access.

“Ubiquitous lognormal distribution of neuron densities in mammalian cerebral cortex” by Sacha van Albada et al. Cerebral Cortex

Abstract

Ubiquitous lognormal distribution of neuron densities in mammalian cerebral cortex

Numbers of neurons and their spatial variation are fundamental organizational features of the brain. Despite the large corpus of cytoarchitectonic data available in the literature, the statistical distributions of neuron densities within and across brain areas remain largely uncharacterized.

Here, we show that neuron densities are compatible with a lognormal distribution across cortical areas in several mammalian species, and find that this also holds true within cortical areas.

A minimal model of noisy cell division, in combination with distributed proliferation times, can account for the coexistence of lognormal distributions within and across cortical areas.

Our findings uncover a new organizational principle of cortical cytoarchitecture: the ubiquitous lognormal distribution of neuron densities, which adds to a long list of lognormal variables in the brain.",https://neurosciencenews.com/files/2023/08/math-neuron-distribution-neurosince.jpg,https://neurosciencenews.com/neural-development-lognormal-23801/,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
[],2023-08-22 00:00:00,Ring Nebula revealed: Webb captures the extraordinary beauty of a dying star,"Although it's a well-known fact in astronomy, many people don't realize that when we see the Ring Nebula — the famed celestial oculi known as M57, whose hypnotic blue iris dazzles the northern constellation of Lyra — what we're actually seeing is the slow-motion death throes of a white dwarf star.

The catastrophic beauty of a dying star reaches its farewell crescendo when its crucible core surges with ionizing heat. The chemical light of its firework-spray nebula explodes in Technicolor spikes, wisps, rings — wild arcs that rip through the dark as the star thrashes off its atmosphere, shedding luminous clouds, as the Ring Nebula has, for thousands of years. Where once humans could only see the blurry glow of the Ring Nebula's distant fire, the latest images from NASA's James Webb Space Telescope have now given us a startlingly sharp map of its radiant halo and intricate inner-ring filaments, allowing us to discover for the first time what our own sun's final hours might look like.

In a Monday release from NASA, Cardiff University's Roger Wesson describes the Webb-enabled discovery thus: ""A surprising revelation was the presence of up to ten regularly-spaced, concentric features within this faint halo. These arcs must have formed about every 280 years as the central star was shedding its outer layers. When a single star evolves into a planetary nebula, there is no process that we know of that has that kind of time period. Instead, these rings suggest that there must be a companion star in the system, orbiting about as far away from the central star as Pluto does from our Sun. As the dying star was throwing off its atmosphere, the companion star shaped the outflow and sculpted it.""

The Ring Nebula's dense halos aren't the Webb's only discoveries, though. To learn more about the wonders revealed through the new telescope, feast your eyes on the latest batch of images capturing the birth of new stars, the extraordinarily detailed pictures of the famous Pillars of Creation — or even glimpse the earliest strings of the cosmic web, the filamentary structure of 10 threaded galaxies, considered a blueprint for all creation.",https://mediaproxy.salon.com/width/1200/https://media.salon.com/2023/08/ring_nebula_nircam_image_nasa_esa_01.jpg,https://www.salon.com/2023/08/22/ring-nebula-nasa-webb-telescope-dying-star-astronomy/,Science
"['Aliza Chasan', 'Aliza Chasan Is A Digital Producer At Minutes', 'Cbs News.']",,"James Webb Space Telescope makes ""surprising"" discovery in halo of dying star","Celebrating one year of images from the James Webb Space Telescope

New images from the James Webb Space Telescope have revealed intricate details of a dying star's final stages, NASA said Monday. The Ring Nebula images, featuring a glowing halo and vibrant colors, also led to a surprising discovery, one astronomer said.

Webb's Mid-Infrared Instrument provided the clearest view yet of the faint molecular halo, the space agency said. It captured up to 10 concentric ""arcs"" in the halo, which scientists believe formed about every 280 years as the central star shed its outer layers.

Roger Wesson, a research associate at Cardiff University who reviewed the Webb telescope's observations, called the discovery of the arcs a ""surprising revelation.""

""When a single star evolves into a planetary nebula, there is no process that we know of that has that kind of time period,"" Wesson said. ""Instead, these rings suggest that there must be a companion star in the system, orbiting about as far away from the central star as Pluto does from our Sun. As the dying star was throwing off its atmosphere, the companion star shaped the outflow and sculpted it. No previous telescope had the sensitivity and the spatial resolution to uncover this subtle effect.""

These aren't the first images of the Ring Nebula. The Hubble telescope captured images of it in 2013. The detailed Webb images revealed curious ""spikes"" in the Ring Nebula that were only faintly visible in the Hubble images.

Ring Nebula ESA/Webb, NASA, CSA, M. Barlow (University College London), N. Cox (ACRI-ST), R. Wesson (Cardiff University

""When we first saw the images, we were stunned by the amount of detail in them,"" Wesson said. ""The bright ring that gives the nebula its name is composed of about 20,000 individual clumps of dense molecular hydrogen gas, each of them about as massive as the Earth.""

The Ring Nebula is considered an ideal target to help scientists learn more about planetary nebulae, regions of cosmic gas and dust formed from the cast-off outer layers of dying stars, NASA said. The first planetary nebula ever discovered was spotted way back in 1764. They were once thought to be simple, round objects with a single, dying star at the center.

""Modern observations, though, show that most planetary nebulae display breathtaking complexity,"" Wesson said. ""It begs the question: how does a spherical star create such intricate and delicate non-spherical structures?""

The Ring Nebula was first discovered by French astronomer Antoine Darquier de Pellepoix in 1779. It's about 2,000 light-years away in the constellation Lyra. It can be spotted using a moderately-sized telescope.",https://assets1.cbsnewsstatic.com/hub/i/r/2023/08/22/b5257c44-7d0e-493f-a6fa-73cde97ddd8b/thumbnail/1200x630/a78ab51d0796f4e150bb0a2890fdd394/ring-nebula.png?v=2d4fe0207a5a36b9cd65a668b55f91b2,https://www.cbsnews.com/news/webb-telescope-makes-surprising-discovery-ring-nebula-halo/,Science
['Michelle Starr'],2023-08-22 23:00:06+00:00,Ring Nebula Positively Gleams in Stunning JWST Images,"The glowing debris surrounding a dying star is revealed in intricate new detail by images from the James Webb Space Telescope.

New observations of Messier 57, AKA the Ring Nebula, were unveiled earlier this month; now, cleaned, polished, and processed, the images show the dying star like you've never seen it before.

Using the near-infrared NIRCam and mid-infrared MIRI, the observations highlight different aspects of the death throes of the Sun-like star at the center of the nebula. NIRCam's observations reveal the intricacies of the filaments and knots of the nebula's inner regions, while MIRI reveals the delicate traceries of concentric features in the outer sections.

The Ring Nebula, some 2,750 light-years away, is what is known as a planetary nebula; the final stages of a star that, once upon a time, was a bit like the Sun. When Sun-like stars start running out of fuel to power the hydrogen fusion in their cores, they start becoming unstable, ejecting their outer material.

The stellar core, no longer supported by the outward pressure of fusion, collapses under gravity into a white dwarf. This is the eventual fate of the Sun and most of the stars in the Milky Way.

The Ring Nebula was created by a star that reached the end of fusion some time in the last 2,000 years (from our perspective). At its center is a white dwarf around 60 percent of the mass of the Sun; the material around this star is expanding outwards into space in a sphere that to us looks like a ring filled with glowing material.

The outer shell of the nebula is thick and dusty, carved into intricate structures where it punches into the interstellar medium. The new images reveal some 20,000 dense hydrogen-rich globules in the nebula, and the light from the main shell shows it is rich in polycyclic aromatic hydrocarbons – the type of carbon that soot is made of.

Concentric rings around the star are thought to be the product of an interaction with a binary companion. Deep within, the space glows with hot, tenuous gas.

Studying the particulars of these finer structures as revealed by the JWST will help astronomers better understand how most of the stars in the Universe are going to die.

""We are witnessing the final chapters of a star's life, a preview of the Sun's distant future so to speak, and JWST's observations have opened a new window into understanding these awe-inspiring cosmic events,"" astrophysicist Mike Barlow explained of University College London in the UK, and co-leader of the international JWST Ring Nebula Project.

""We can use the Ring Nebula as our laboratory to study how planetary nebulae form and evolve.""

You can download wallpaper-sized versions of the new images from the ESA Webb website.",https://www.sciencealert.com/images/2023/08/ring-nebula.jpg,https://www.sciencealert.com/ring-nebula-positively-gleams-in-stunning-jwst-images,Science
['Elizabeth Anne Brown'],2023-08-22 00:00:00,"Hogfish ‘See’ With Their Skin, Even When They’re Dead","As a marine biologist, Lorian Schweikert knew hogfish could change color to match their surroundings. But as an angler, she noticed something that wasn’t in the textbooks: Hogfish can camouflage even after they’re dead.

When Dr. Schweikert saw a hogfish with a conspicuous spearfishing hole through its body change color to match the texture of a boat’s deck, “it gave me this idea that the skin itself was ‘seeing’ the surrounding environment,” she said.

New research by Dr. Schweikert and her team provides a compelling explanation for how and why hogfish blend into their background, even in the afterlife. In a study published on Tuesday in the journal Nature Communications, they identified a mysterious new type of cell deep in the hogfish’s skin that might allow the fish not only to monitor its surroundings but also to edit its skin color.

Hogfish are masters of change. They’re sequential hermaphrodites, meaning every hogfish hatches female but can become male once it reaches a certain size or if a power vacuum arises in its social group. And as they cruise the reefs and sand flats of the western Atlantic, hogfish can toggle between three color morphs — a ruddy brown, a pearly white and a stripy or dappled red coloration — in less than a second.",https://static01.nyt.com/images/2023/08/22/autossell/22tb-hogfish/22tb-hogfish-facebookJumbo.jpg,https://www.nytimes.com/2023/08/22/science/hogfish-skin-camouflage-dead.html,Science
['Gabriella Sotelo'],2023-08-22 00:00:00,"Hogfish can use their skin to ‘see’ what colour they are, say scientists","What do you call a fish with no eyes? Fsh. What about a fish that can also use its skin as “eyes”? Well, that would be a hogfish.

Hogfish often use their ability to change colours to support their camouflaging abilities. They also have light-sensing skin, or skin vision, that can help them “see” their surroundings.

However, research suggests hogfish are not only using this skin vision to see their surroundings. Lorian Schweikert, a biologist at the University of North Carolina Wilmington, said they “could be using it to view themselves”.

To study this behaviour the team took samples of the hogfish’s skin and analysed them under a microscope. This up-close look showed many cells called chromatophores, which contain granules of colours.

Writing in Nature Communications, the research reports the cellular mechanism in chromatophore pigment activity and how the hogfish uses this ability.

Previous research found that hogfish have a light-sensitive protein called opsin in their skin, which is a different opsin to that found in their eyes.

The granules of colours move around in the cell. When they get close together they become transparent, while when they spread out the colours appear darker. The researchers then located the light-sensitive protein, which resided in cells below the chromatophores.

Schweikert said this meant that light striking the skin of the hogfish had to pass the chromatophores before it got to this light-sensitive layer.

This allows the fish to capture changes in the light and filter through these pigment-filled chromatophores – a bit like a Polaroid.

“The animals can literally take a photo of their own skin from the inside,” said Sönke Johnsen, a biologist at Duke University who was also part of the study. “In a way they can tell the animal what its skin looks like, since it can’t really bend over to look.”

Schweikert said that the skin did not function exactly like an eye: it is rather a sensory feedback mechanism that lets the hogfish monitor its own skin while it changes colours.

Lauren Sumner-Rooney, a researcher at the Museum of Natural History in Berlin, who is not affiliated with the research, said that the ability to colour change and get colours right for the hogfish was a matter of life or death.

She added that many animals could not see their whole body surface with their eyes, and needed another way of knowing whether they had expanded and contracted the right chromatophores.

“This provides a neat and simple mechanism by which fish can tell whether they have successfully changed colour, by using light sensors dispersed across their whole bodies, instead of relying on their eyes,” she said.

“This is the first time we’ve seen a strong body of evidence for exactly how this works in fish – dermal light sensing has been a rather enigmatic ability for a long time.”",https://i.guim.co.uk/img/media/20c157aaa0769d4ae066542e1c0601d7beb31e14/0_417_4608_2765/master/4608.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=04d940e910ffed3cbc9f0fb944f79c82,https://www.theguardian.com/environment/2023/aug/22/hogfish-can-use-their-skin-to-see-what-colour-they-are-say-scientists,Science
"['Holly Large', 'Editorial Assistant']",2023-08-22 16:28:50+00:00,"""Hogfish Can Sense Light With Their Skin – Even When They're Dead""","Hogfish, like many reef-dwelling sea creatures, are experts in changing the color of their skin – and it turns out they don’t even have to be alive to do so. Without the use of their eyes, how can hogfish detect the environmental changes that lead them to color shift in the first place? Researchers believe the answer lies underneath their skin.

When a hogfish in the Florida Keys swam towards the bait on biologist Lori Schweikert’s fishing rod, it probably wasn’t aware that a) it was about to meet an untimely end and b) it would open up a whole new avenue of research. Going to retrieve it from the boat deck, she noticed that the dead fish had changed color and pattern to match the floor. Given that it definitely no longer had use of its eyes, Schweikert wanted to know how it had detected a new environment and camouflaged.

Advertisement Advertisement

Hogfish can change color to adapt to their environment. Image Credit: Lorian Schweikert/Melissa D. Smith



Like many other color-changing creatures, hogfish have a layer of specialist pigment-containing cells in their skin called chromatophores. When the granules of pigment in these cells move closer together, or further apart, the skin changes color. In some animals, this process might be triggered visually; its eyes detect a predator, which triggers a signal to the brain, which in turn sends a signal to chromatophores. What researchers needed to figure out was what sparked the process when the eyes and brain of a hogfish weren’t involved.

Using microscopy, Schweikert and her team took a closer look at what was going on in the fish’s skin. Under the layer of chromatophores, they discovered another layer made up of another type of cell, crammed full of a light-detecting protein known as opsin. In a display of unconscious perfectionism, these layers work together to form a feedback loop that allows the hogfish to refine its color.

Hogfish skin under the microscope. Each dot is a chromatophore, containing the pigments that move around to change the color of the skin. Image Credit: Lorian Schweikert et al., Nature Communications



Opsins detect changes in the light that’s able to penetrate through the granules, acting like a live feed of the changes happening outside. “The animals can literally take a photo of their own skin from the inside,” said Sönke Johnsen, a member of the research team, in a statement. “In a way they can tell the animal what [its] skin looks like, since it can’t really bend over to look.”

The researchers are still not sure exactly how, but the opsins feed this information back to the chromatophores above, triggering the movement of pigment and a color change in the hogfish’s skin.

Advertisement Advertisement

Whilst this research finally gave a biologist an answer to why her seafood dinner changed color, it has implications beyond the natural world. The researchers involved hope that it can be used to improve technologies that also use sensory feedback loops.

The study is published in the journal Nature Communications.",https://assets.iflscience.com/assets/articleNo/70363/aImg/70153/hogfish-meta.jpg,https://www.iflscience.com/hogfish-can-sense-light-with-their-skin-even-when-theyre-dead-70363,Science
['Duke University'],,"This fish doesn't just see with its eyes, it also sees with its skin","This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

A pointy-snouted reef fish called the hogfish can change from white to spotted brown to reddish depending on its surroundings. Credit: Dean Kimberly and Lori Schweikert

A few years ago while on a fishing trip in the Florida Keys, biologist Lori Schweikert came face to face with an unusual quick-change act. She reeled in a pointy-snouted reef fish called a hogfish and threw it onboard. But later when she went to put it in a cooler she noticed something odd: its skin had taken on the same color and pattern as the deck of the boat.

A common fish in the western Atlantic Ocean from North Carolina to Brazil, the hogfish is known for its color-changing skin. The species can morph from white to mottled to reddish-brown in a matter of milliseconds to blend in with corals, sand or rocks.

Still, Schweikert was surprised because this hogfish had continued its camouflage even though it was no longer alive. Which got her wondering: can hogfish detect light using only their skin, independently of their eyes and brain?

""That opened up this whole field for me,"" Schweikert said.

In the years that followed, Schweikert started researching the physiology of ""skin vision"" as a postdoctoral fellow at Duke University and Florida International University.

In 2018, Schweikert and Duke biologist Sönke Johnsen published a study showing that hogfish carry a gene for a light-sensitive protein called opsin that is activated in their skin, and that this gene is different from the opsin genes found in their eyes.

Other color-changing animals from octopuses to geckos have been found to make light-sensing opsins in their skin, too. But exactly how they use them to help change color is unclear.

""When we found it in hogfish, I looked at Sönke and said, Why have a light detector in the skin?"" said Schweikert, now an assistant professor at the University of North Carolina Wilmington.

One hypothesis is that light-sensing skin helps animals take in their surroundings. But new findings suggest another possibility—""that they could be using it to view themselves,"" Schweikert said.

In a study appearing in the journal Nature Communications, Schweikert, Johnsen and colleagues teamed up to take a closer look at hogfish skin.

The researchers took pieces of skin from different parts of the fish's body and took pictures of them under a microscope.

Up close, a hogfish's skin looks like a pointillist painting. Each dot of color is a specialized cell called a chromatophore containing granules of pigment that can be red, yellow or black.

It's the movement of these pigment granules that changes the skin color. When the granules spread out across the cell, the color appears darker. When they cluster together into a tiny spot that's hard to see, the cell becomes more transparent.

Next, the researchers used a technique called immunolabeling to locate the opsin proteins within the skin. They found that in the hogfish, opsins aren't produced in the color-changing chromatophore cells. Instead, the opsins reside in other cells directly beneath them.

Images taken with a transmission electron microscope revealed a previously unknown cell type, just below the chromatophores, packed with opsin protein.

This means that light striking the skin must pass through the pigment-filled chromatophores first before it reaches the light-sensitive layer, Schweikert said.

The researchers estimate that the opsin molecules in hogfish skin are most sensitive to blue light. This happens to be the wavelength of light that the pigment granules in the fish's chromatophores absorb best.

The findings suggest that fish's light-sensitive opsins act somewhat like internal Polaroid film, capturing changes in the light that is able to filter through the pigment-filled cells above as the pigment granules bunch up or fan out.

""The animals can literally take a photo of their own skin from the inside,"" Johnsen said. ""In a way they can tell the animal what it's skin looks like, since it can't really bend over to look.""

""Just to be clear, we're not arguing that hogfish skin functions like an eye,"" Schweikert added. Eyes do more than merely detect light—they form images. ""We don't have any evidence to suggest that's what's happening in their skin,"" Schweikert said.

Rather, it's a sensory feedback mechanism that lets the hogfish monitor its own skin as it changes color, and fine-tune it to fit what it sees with its eyes.

""They appear to be watching their own color change,"" Schweikert said.

The researchers say the work is important because it could pave the way to new sensory feedback techniques for devices such as robotic limbs and self-driving cars that must fine-tune their performance without relying solely on eyesight or camera feeds.

""Sensory feedback is one of the tricks that technology is still trying to figure out,"" Johnsen said. ""This study is a nice dissection of a new sensory feedback system.""

""If you didn't have a mirror, and you couldn't bend your neck, how would you know if you're dressed appropriately?"" Schweikert said. ""For us it may not matter,"" she added. But for creatures that use their color-changing abilities to hide from predators, warn rivals or woo mates, ""it could be life or death.""

More information: Lorian Schweikert, Dynamic light filtering over dermal opsin as a sensory feedback system in fish color change, Nature Communications (2023). DOI: 10.1038/s41467-023-40166-4. www.nature.com/articles/s41467-023-40166-4 Journal information: Nature Communications",https://scx2.b-cdn.net/gfx/news/2023/this-fish-doesnt-just.jpg,https://phys.org/news/2023-08-fish-doesnt-eyes-skin.html,Science
['Eötvös Loránd University'],,Dog brains are tuned to dog-directed speech spoken by women,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Dogs show greater brain sensitivity to the speech directed at them than to adult-directed speech, especially if spoken by women. Credit: Dora Tuzson-Varga

Dogs show greater brain sensitivity to the speech directed at them than to adult-directed speech, especially if spoken by women, according to a new study in Communications Biology.

By conducting an fMRI study on trained dogs, Hungarian researchers at the Department of Ethology, Eötvös Loránd University, the Research Centre for Natural Sciences and the Eötvös Loránd Research Network revealed exciting similarities between infant and dog brains during the processing of speech with exaggerated prosody.

When communicating with individuals having limited linguistic competence (such as infants and dogs), to grab and maintain their attention, we speak with a specific speech-style characterized by exaggerated prosody. Infant-directed speech is very important as it helps kids' healthy cognitive, social and language development. So, it's no surprise that infant brains are tuned to this speech style, but are dog brains also sensitive to the way we speak to them?

To answer this question, Hungarian researchers measured dog brain activity via functional magnetic resonance imaging (fMRI). In the MRI, trained, conscious family dogs listened to dog-, infant-, and adult-directed speech recorded from 12 women and 12 men in real-life interactions.

""Studying how dog brains process dog-directed speech is exciting, because it can help us understand how exaggerated prosody contributes to efficient speech processing in a nonhuman species skilled at relying on different speech cues (e.g. follow verbal commands),"" Anna Gergely, co-first author of the study explains. Credit: Eötvös Loránd University

The study shows that dog auditory brain regions responded more to dog- and infant-directed than to adult-directed speech, which is the first neural evidence that dog brains are tuned to the speech directed specifically at them.

Interestingly, dog- and infant-directed speech sensitivity of dog brains was more pronounced when the speakers were women and was affected by voice pitch and its variation. These results suggest that the way we speak to our dogs does matter, and that their brain is specifically sensitive to the exaggerated prosody typical to the female voice.

""What makes this result particularly interesting is that in dogs, as opposed to infants, this sensitivity cannot be explained by either ancient responsiveness to conspecific signals or by intrauterine exposure to women's voice. Remarkably, the voice tone patterns characterizing women's dog-directed speech are not typically used in dog-dog communication—our results may thus serve evidence for a neural preference that dogs developed during their domestication.""

""Dog brains' increased sensitivity to dog-directed speech spoken by women specifically may be due to the fact that women more often speak to dogs with exaggerated prosody than men,"" explains Anna Gábor, co-first author of the study.

More information: Anna Gergely et al, Dog brains are sensitive to infant- and dog-directed prosody, Communications Biology (2023). DOI: 10.1038/s42003-023-05217-y Journal information: Communications Biology",https://scx2.b-cdn.net/gfx/news/2023/dog-brains-are-tuned-t.jpg,https://phys.org/news/2023-08-dog-brains-tuned-dog-directed-speech.html,Science
"['Robert Lea', 'Contributing Writer', 'Social Links Navigation']",2023-08-22 10:00:22+00:00,New XRISM X-ray mission to study the most violent events in the universe will launch on Aug. 26,"An illustration shows XRISM set to launch on Sat Aug. 26 as it studies the distant Coma cluster of galaxies in X-rays

A major X-ray observing mission is set to launch on Saturday (Aug. 26), aiming to provide astronomers with views of some of the universe's most extreme, explosive and hot objects and events.

The X-Ray Imaging and Spectroscopy Mission (XRISM), a collaboration between NASA and the Japanese Aerospace Exploration Agency (JAXA) with assistance from the European Space Agency (ESA), will study things like hot gas envelopes surrounding galaxy clusters and violent outbursts from monster black holes. Its results should help scientists better understand the evolution of the universe.

""X-ray astronomy enables us to study the most energetic phenomena in the universe,"" Matteo Guainazzi, ESA project scientist for XRISM, said in a statement. ""It holds the key to answering important questions in modern astrophysics: How the largest structures in the universe evolve, how the matter we are ultimately composed of was distributed through the cosmos, and how galaxies are shaped by massive black holes at their centers.""

Related: X-rays reveal how 450-year-old Tycho supernova became a giant cosmic particle accelerator

XRISM will launch atop an H-IIA (H-2A) expendable launch system operated by Mitsubishi Heavy Industries (MHI) from Tanegashima Space Center, Japan. It is expected to operate for at least three years.

Guainazzi explained that the 8% observing time ESA is allocated from XRISM's available operating time will help form a bridge between the space agency's currently operating XMM-Newton mission, which has spent 24 years in space collecting X-ray data, and Athena, set to launch in the late 2030s.

Seeing the the extreme universe in X-rays

While astronomers have become adept at seeing cosmic objects like stars and galaxies that emit light associated with the visible region of the electromagnetic spectrum, which is the section our eyes have evolved to see, these observations only paint part of the wider cosmic picture.

The cosmos is also permeated by electromagnetic radiation associated with low-energy infrared wavelengths, which the James Webb Space Telescope (JWST) captures to great effect, as well as high-energy X-rays and gamma-rays.

Though invisible to our eyes, those X-rays are emitted by things like gas lurking between stars and galaxies and from extreme and violent environments. Studying them can therefore add important details to our cosmic tapestry of the universe.

A diagram showing XRISM and identifying some of the key questions it will help answer. (Image credit: ESA/JAXA)

For example, one key function of XRISM will be to study X-rays coming from super-hot massive envelopes of gas that surround galaxy clusters — some of the largest structures in the known universe. This should help with measuring the masses of these clusters as well as their gas envelopes, thus allowing astronomers to better understand how these systems might've evolved.

In addition, X-rays from the gas envelopes could help astronomers determine how enriched the shells are with elements heavier than hydrogen and helium. Those heavier elements are called ""metals.""

Metal composition is important to know because when the universe first began to be populated with stars and galaxies, the only elements that existed in considerable amounts were hydrogen and helium plus a tiny smattering of metals like nitrogen. It was the first generation of stars that synthesized heavier elements through nuclear fusion of hydrogen and helium at their cores.

These heavy elements were then dispersed into the cosmos when the first stars exploded as supernovas at the end of their lives. This enriched gas clouds surrounding galaxies with metals. Then, when overly dense patches of those clouds collapsed, to birth the second generation of stars, they produced even more metal-rich stars.

An X-ray image of the Coma galaxy cluster shows the hot gas glowing as the purple and pink colors as seen by XMM-Newton and Sloan Digital Sky Survey (Image credit: ESA/XMM-Newton/SDSS/J. Sanders et al. 2019)

XRISM will be capable of measuring the energy of high-energy X-ray photons, or light particles, by using its Resolve instrument. ESA's forthcoming Athena mission will include a similar device that will be informed by how Resolve performs with XRISM.

Resolve will allow astronomers to measure the temperatures and velocities of hot gases the mission observes with a high degree of accuracy. Plus, by mapping the metals in these clouds via emitted X-rays, XRISM could help scientists better determine how the stellar-metal-enrichment process has proceeded throughout the last 13.8 billion years of cosmic history.

XRISM's innovative X-ray investigation will also help physicists learn more about some fundamental cosmic phenomena, too.

How XRISM will put Einstein to the test

Albert Einstein's 1915 theory of general relativity is currently known as the best explanation of gravity on cosmic scales we have, but there are still aspects of the universe that it struggles to account for. For instance, it doesn't quite explain the way the universe's expansion is accelerating.

This is why scientists still continue to test the limits of general relativity, which is also known as Einstein's geometric theory of gravity as it suggests objects with masses ""warp"" the fabric of space and time. According to general relativity, it is from this distortion that ""gravity"" arises. The more massive and dense an object is, the greater the distortion it causes.

The effects of such warping, interestingly, can also be seen when electromagnetic radiation or light passes by a distortion.

XRISM will make use of this effect when it looks at X-ray emissions from materials that surround the most massive and dense objects in the universe, namely supermassive black holes that lie at the center of most, if not all, large galaxies.

An artist's depiction of a black hole releasing jets which shine in X-rays that can be detected by XRISM (Image credit: NASA/JPL-Caltech)

As these supermassive black holes feed on matter around them, an act that forms a flattened disk called an accretion disk, that material gets heated to tremendous temperatures. Additionally, powerful magnetic fields of the supermassive black holes channel charged matter in these disks that doesn't actually fall ""into"" the black hole to the void's poles, from where it gets blasted out in the forms of jets and winds moving at close to the speed of light.

Both of these processes, including the heating of material in accretion disks and the blasting of powerful winds and jets, cause that matter to emit X-rays.

So, by looking at these X-rays with XRISM, scientists can determine how warped spacetime is around supermassive black holes, thus testing general relativity under perhaps the most extreme circumstances imaginable.

Performing such fundamental physics investigations with X-rays and any high-energy astronomy requires sophisticated technology, and XRISM certainly fits the bill.

XRISM sits in a vacuum chamber test room prior to launch (Image credit: ESA/JAXA)

The blast-off of XRISM is set for 8:34 pm ET (0034 GMT) on Saturday and can be watched live in Japanese and English on JAXA's YouTube channel. Live mission updates are available on JAXA's Twitter feed.",https://cdn.mos.cms.futurecdn.net/VDXHmdkJh75KhZmhsKo2hG-1200-80.png,https://www.space.com/xrism-x-ray-mission-launch-august-2023,Science
[],,XRISM: Inside the Mission Set to View Black Holes and Exploding Stars Like Never Before,"Seven years ago, astronomers at the Japan Aerospace Exploration Agency (JAXA) and their colleagues were wrestling with a dilemma.

The Hitomi spacecraft promised to unpack secrets of the highest-energy events across the universe, visible only in X-ray light. This is typically how astronomers find a black hole gobbling up matter, or capture the most critical details of a star exploding. Teams around the world were on the brink of success, as Hitomi gained a spectacular commissioning image of a cluster filled with thousands of galaxies.

But just a month after launch, the spacecraft began to spin uncontrollably, until it broke apart into pieces.

This week, there’s new hope for JAXA’s X-ray astronomy efforts, along with its international collaborators. A team of half a dozen NASA researchers has flown out to Tokyo, where they will then make their way to the south of Japan to the balmy island home to the country’s largest rocket launch complex, Tanegashima Space Center.

On April 28, 2016, the Japan Aerospace Exploration Agency (JAXA) announced that Hitomi had failed. This photo shows Takashi Kubota (right), space program director of (JAXA), answering questions beside a miniature version of Hitomi during a press conference. Kubota is with Saku Tsuneta (left), director general of the Institute of Space and Astronautical Science of JAXA, and Chikara Harada (center), head of JAXA Space Tracking and Communication Center. STR/AFP/Getty Images

That’s where Hitomi’s successor will launch. Called the X-ray Imaging and Spectroscopy Mission, or XRISM (pronounced “crism”), it is scheduled to launch on Saturday at 9:34 a.m. local time (Friday night at 8:34 p.m. Eastern in the United States). If it survives the commissioning phase (where a launched spacecraft is prepared for its official mission), XRISM will acquire the sharpest X-ray data to date about the most dynamic events in space.

The X-ray universe

Unlike Hubble or the James Webb Space Telescope, images aren’t the chief concern of XRISM. Instead, JAXA wants to use the mission to capture the spectra of these events. This is where you break down the incoming light into its constituent elements and other signals, in a process called spectroscopy. Brian J. Williams, XRISM project scientist at NASA Goddard Space Flight Center, and one of the privileged researchers traveling to Tanegashima, tells Inverse that spectroscopy is like a barcode or a fingerprint. With an observation of a particular wavelength of light, researchers narrow down the type of matter and severity in temperature of the emission source.

Williams specializes in one particular type of high-energy event, and a popular one, too: supernovas. Supernovas pack extraordinary heat, he says, on the order of 10,000 times hotter than the surface of the Sun.

A composite image of the Tycho supernova remnant, made with Spitzer Space Telescope and Chandra X-ray Observatory data. Universal History Archive/Universal Images Group/Getty Images

Supernovas emit X-rays, wavelengths invisible to the eye but which tell the tale of extraordinary power from many light-years away. “X-rays are just another form of light. They are just higher-energy photons than optical light, like Hubble sees, or infrared like James Webb sees,” he says.

The current reigning champion of this subfield is NASA’s Chandra X-ray Observatory, but it can’t do it all. The spacecraft achieves fantastic images. Since 1999, it has been observing X-rays coming from the most high-octane events in the universe. While supernovas are very high energy, X-rays also radiate from the millions-of-degrees gas in a galaxy cluster, and from clouds superheated when swirling just outside a supermassive black hole before falling inside.

But Chandra’s spectroscopy is limited. A line graph with Chandra data will feature curved peaks, with a general account of what material is around and the explosive processes that made them. XRISM’s data promises to be sharper, capable of filling in the gaps about how elements like those fundamental to the existence of life, like carbon and oxygen, enter our universe.

To observe X-ray events, you need to be high above the atmosphere. While blanketing us on the surface from harmful cosmic radiation, the atmosphere makes it hard on land to discern the distant drama whispering, via X-rays, in our direction. That’s why important spectra like this require a space telescope like XRISM.

The anticipation

When XRISM’s predecessor Hitomi delivered spectral data from the Perseus cluster of galaxies in 2016, Williams and the team were thrilled. They’d gain an unprecedented look at gas, heated to 90 million degrees Fahrenheit, that surrounds thousands of galaxies huddled together some 240 million light-years away.

“Seeing the technology actually work in space, and giving us the stuff we had only been able to simulate before, was really incredible,” Williams said.

“As a scientist, your mind just goes to all the other things that you could observe. Like alright, if we got this beautiful spectra from a galaxy cluster, what is it going to look like if we point at the nucleus of a galaxy? What is it going to look like if we point at a black hole with a star orbiting around it? Or a supernova remnant? And then,” Williams adds, “when the mission was lost a month in, one of my colleagues at Goddard put it well. He said it was sort of like being able to glimpse the promised land, but not actually walk in.”

An illustration depicting the active supermassive black hole at the center of a galaxy. It is releasing material as two strong jets (shown in red/orange) as well as through wide-angle outflows (shown in grey/blue). ESA/AOES Medialab

First light

Richard Kelley, XRISM mission scientist based at NASA Goddard, flew to Japan days before Williams to prepare the spacecraft for its upcoming relocation some 340 miles above Earth’s surface. XRISM and Hitomi are virtually the same mission, and like Williams, Kelley has waited a long time to see if the novel technology finally gets to operate in space.

XRISM launches on Saturday at 9:34 a.m. local time. If all goes well, its solar panels soon after release and lock into place. Their energy will power five cryocoolers to chill liquid hydrogen, which will keep the spacecraft cold enough to operate its two instruments. During commissioning, data is collected from a high-energy source that Kelley tells Inverse has yet to be decided. After that, the mission moves through more checks until late November or early December 2023.

It’s then astronomers anticipate having first light. So when a black hole superheats the gas clumps circling just beyond its event horizon, the unleashed energy will travel across space and strike the two bug-eyed-shaped mirror assemblies at one end of the spacecraft, funneling waves towards the novel instruments. And XRISM will open up a new window unto the universe.",https://imgix.bustle.com/uploads/image/2023/8/22/e0341395-8ba9-4672-a14c-d123ad11aa2d-fig_xrism01.png?w=1200&h=630&fit=crop&crop=focalpoint&fm=jpg&fp-x=0.1973&fp-y=0.3107,https://www.inverse.com/science/japanese-xray-spectroscopy-xrism-spacecraft-mission-preview,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
['Chris Young'],2023-08-22 04:47:08+00:00,JAXA and NASA's next-gen X-ray mission is ready to fly,"NASA and the Japan Aerospace Exploration Agency (JAXA) teamed up to develop the X-Ray Imaging and Spectroscopy Mission (XRISM) spacecraft which is only days away from launch.

XRISM is scheduled to launch into low Earth orbit aboard a H-IIA rocket from the Tanegashima Space Center in Japan at 09:34 JST (01:34 BST) on August 26.

The mission aims to shed new light on the evolution of the universe and the structure of spacetime. The launch itself will be viewable in Japanese and English on JAXA's YouTube channel.

JAXA and NASA's next-generation X-ray mission

XRISM, pronounced ""crism,"" will study extreme space regions, including the hottest regions and largest structures ever observed by humans, as well as objects with the strongest gravity.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/21/image/jpeg/IqqAtPVzycJWcytnfS51Vx9ZtGmyLduy3JcPiwim.jpg,https://interestingengineering.com/innovation/jaxa-nasas-next-gen-x-ray-mission-xrism,Science
[],2023-08-22 00:00:00,West Coast Falcon 9 launches SpaceX’s 100th Starlink mission – Spaceflight Now,"After delays caused by Hurricane Hilary, SpaceX launched its 100th Starlink mission on Tuesday. A Falcon 9 carrying 21 second-generation Starlink satellites lifted off from Vandenberg Space Force Base in California at 2:37 a.m. PDT (5:37 a.m. EDT / 0937 UTC).

It was the 100th Falcon 9 with the primary mission of deploying Starlink satellites since the first in 2019. Based on statistics compiled by Jonathan McDowell, an astronomer at the Harvard-Smithsonian Center for Astrophysics who maintains a space flight database, Tuesday’s launch brings the total number of Starlink satellites launched to 4,983.

In early May, SpaceX announced it had 1.5 million subscribers worldwide to its Starlink network which offers low latency, high speed Internet service worldwide. This was the 13th launch of the company’s next generation satellites, known as Starlink V2 Minis, which are larger and offer four times the broadband capacity of the previous models.

Eight and a half minutes after lifting off, the first stage of the Falcon 9, making its 15th flight, touched down on the drone ship ‘Of Course I Still Love You’ stationed in the Pacific about 400 miles (644 km) downrange off the coast of Baja California.

The second stage of the Falcon 9 deployed the 21 V2 mini Starlink satellites into a 184×178 mile (296×286 km) orbit with an inclination of 53 degrees just over an hour into flight, high above the Indian Ocean.

Another batch of Starlink satellites are due to launch from Cape Canaveral no earlier than Wednesday evening.",,https://spaceflightnow.com/2023/08/22/west-coast-falcon-9-launches-spacexs-100th-starlink-mission/,Science
['Jamie Groh'],2023-08-22 00:00:00,What you need to know: SpaceX reschedules Falcon 9 launch from Cape Canaveral to Wednesday,"What you need to know: SpaceX reschedules Falcon 9 launch from Cape Canaveral to Wednesday

Show Caption Hide Caption SpaceX Starlink 6-10 mission from Cape Canaveral Space Force Station A SpaceX Falcon 9 rocket launches the company's latest batch of Starlink satellites from Cape Canaveral Space Force Station on August 11, 2023. SpaceX

Update: Late Tuesday afternoon, Aug. 22, according to new federal filings, SpaceX teams have rescheduled the liftoff of the company's next Falcon 9 Starlink mission from Cape Canaveral Space Force Station to Wednesday, August 23.

Follow FLORIDA TODAY's Space Team live launch coverage beginning 90 minutes before liftoff.

If schedules hold, this would become the Space Coast's 43rd launch this year.

After initially targeting a Tuesday liftoff, according to new federal filings, SpaceX rescheduled the launch of its latest Falcon 9 Starlink mission to 24 hours later. The launch is now set to occur during a four-hour launch window from 8:22 p.m. EDT, Wednesday, Aug. 23, until 12:52 a.m. EDT, Thursday, Aug. 24.

Space Force forecasters last reported weather conditions to be 75% ""go"" for the duration of the window Tuesday night. Only a slight chance of cumulus clouds was listed as a concern.

Forecasters projected the weather conditions to be similar for the backup day, with a 75% chance of ""go"" favorable conditions around the Cape.

Cape Canaveral Space Force Station's Launch Complex 40 will host.

The payload is the company's next batch of Starlink internet-beaming satellites.

The 230-foot Falcon 9 rocket will follow a southeasterly trajectory threading between Florida and the Bahamas.

SpaceX Falcon 9 late-night launches: Are they getting louder? Teams set for two this week

Space Perspective: Company is building balloons in Titusville to elevate tourists to the edge of space

If it launches on time, it will mark the Space Coast's 43rd launch this year.

No local sonic booms with this mission.

The 130-foot first-stage booster will target a drone ship landing about eight minutes after liftoff.

The next Falcon 9 slated for liftoff from Florida will send NASA's SpaceX Crew-7 mission to the International Space Station from Launch Complex 39A at NASA’s Kennedy Space Center.

Targeted for liftoff at 3:49 a.m. EDT, Friday, Aug. 25, NASA astronaut Jasmin Moghbeli, European Space Agency astronaut Andreas Mogensen, along with Japan Aerospace Exploration Agency astronaut Satoshi Furukawa and Roscosmos cosmonaut Konstantin Borisov will fly aboard SpaceX's Endurance Dragon capsule to the space station for the six-month science mission.

An updated weather report for Friday's NASA SpaceX Crew-7 liftoff from KSC is expected to be released later in the week.

For the latest updates, visit floridatoday.com/launchschedule.

Contact Jamie Groh at JGroh@floridatoday.com and follow her on X.com at @AlteredJamie.

Space is important to us and that's why we're working to bring you top coverage of the industry and Florida launches. Journalism like this takes time and resources. Please support it with a subscription here.","https://www.gannett-cdn.com/presto/2022/02/21/PBRE/d084e6e2-d62b-4a43-9c71-bd8e7c042a86-Starlink_SLC40_Desktop.jpeg?auto=webp&crop=2124,1195,x249,y0&format=pjpg&width=1200",https://www.floridatoday.com/story/tech/science/space/2023/08/22/what-you-need-to-know-spacex-falcon-9-starlink-mission-from-the-cape/70623524007/,Science
[],2023-08-22 14:43:52.710000,SpaceX launches Falcon 9 from Vandenberg Space Force Base,"SpaceX launched a Falcon 9 rocket from Vandenberg Space Force Base in the early-morning hours Tuesday.

The launch lifted off at 2:37 a.m. and successfully launched 21 Starlink satellites into low-Earth Orbit.

SpaceX says it was the 15th time the first-stage booster, which landed on the “Of Course I Still love You” droneship in the Pacific Ocean, has been used.

The launch was originally scheduled for last Thursday but was pushed to this week due to Tropical Storm Hillary.",https://ewscripps.brightspotcdn.com/dims4/default/a582e8b/2147483647/strip/true/crop/470x247+0+82/resize/1200x630!/quality/90/?url=http%3A%2F%2Fewscripps-brightspot.s3.amazonaws.com%2Ff4%2F66%2F24ba6b364008ad00535c27317b80%2Ffalcon-9-8-22.JPG,https://www.ksby.com/news/local-news/spacex-launches-falcon-9-from-vandenberg-space-force-base,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
['Katyanna Quach'],2023-08-22 00:00:00,NASA still hopes to have astronauts on Moon station in 2028,"The first group of astronauts to set foot into NASA's Moon-orbiting Gateway space station will be the Artemis IV crew in 2028, if everything goes as planned.

The Americans have made it no secret they want to colonize the Moon, and envision eventually building infrastructure to make it a base to explore further into the solar system. The US space agency is taking small steps – or perhaps giant leaps – towards realizing this goal by launching astronauts to visit the surface of the Moon and build a space station around the natural satellite.

That station would be the Gateway, which is an ambitious project. It'll be humanity's first extraterrestrial space station – the ISS, in low-Earth orbit, doesn't count. NASA is collaborating with other international space agencies and private space companies to construct the habitat, which will be made up of several different modules to support astronauts living and working above the Moon's surface.

If everything goes smoothly, the first crew to reside in the space dorm will be the Artemis IV crew in 2028, according to Stephanie Dudley, the mission integration and utilization manager for Gateway, as Space.com reported.

What is Artemis? Artemis is NASA's mega-program to return humans to the Moon. Artemis I was a test flight around the Moon in 2022 by NASA's Space Launch System rocket with an unoccupied Orion crew capsule. Artemis II will be a crewed version of that mission in late 2024. And Artemis III is expected to take astronauts – the first woman and the first person of color, no less – to the surface of the Moon in late 2025. Artemis IV is aiming for the Gateway in 2028. A summary blueprint for the program is here [PDF].

""It is not a stretch to say that Gateway is very much a part of the [International Space Station] legacy,"" she said during a presentation at the International Space Station Research and Development Conference this month. While Gateway is expected to be a fifth of the size of the ISS by volume, the lessons learned building the venerable space lab have been crucial to Gateway's design, she said.

Plans to design and construct the Gateway are underway. NASA awarded a $1 billion contract to Northrop Grumman to build the Habitation and Logistics Outpost (HALO) module, which will serve as the living quarters for four astronauts. It will be put together on Earth and is expected to launch into space aboard a SpaceX Heavy Falcon rocket in November 2025.

There are other parts that need to be built, such as the Human Landing System (HLS) – a capsule that will ferry astronauts to the Moon's surface and dock with the Gateway in the future.

NASA came under fire for choosing SpaceX as the sole provider of the HLS. Rival Blue Origin filed a lawsuit over the decision, and temporarily forced SpaceX to halt its work crafting the capsule. NASA later awarded a contract to build a second lunar lander to Blue Origin.

Dudley said the Artemis V crew – remember we're not even at Artemis II yet – will add a refueling module and a second habitat module to Gateway. That mission is scheduled to launch in September 2029.

Unlike the ISS, Gateway won't need to be permanently occupied by astronauts to keep things ticking over. It will be designed to operate autonomously for up to three years, while using its sensor package to scan the Moon and provide constant data flows back to Earth. ®",https://regmedia.co.uk/2021/07/12/halo.jpg,https://www.theregister.com/2023/08/22/nasa_moon_space_station/,Science
"['Adam Hadhazy', 'Stanford University']",,"Silica particles found in food and makeup could be chemically reactive, study finds","This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

The Si 42 O 90 H 36 cluster used to model SiO 2 (001). (a) Top view. (b–d) Side views along different directions. Si atoms are blue. O atoms are red. H atoms are white. 28H atoms are light blue-green. Credit: Proceedings of the National Academy of Sciences (2023). DOI: 10.1073/pnas.2304735120

New Stanford University research has revealed that the mineral silica, a common food additive and popular cosmetics ingredient, is not a chemically inert substance, as has long been supposed.

As described in a new study, researchers placed commercially available silica particles in a water solution with biomolecules containing compounds called thiols. These thiol-containing biomolecules are widespread in nature and in the human body, for instance, in the form of glutathione, a key antioxidant found in most cells.

When exposed to silica, the thiol biomolecules underwent redox chemical reactions. These reactions, in which electrons are lost, could degrade or alter the molecules' function, potentially posing health risks. For instance, low levels of glutathione can lead to increased oxidative stress in the body that can damage all manner of cellular components, from membranes to DNA.

The findings highlight the need for further research into the reactivity of silica, especially given its extensive usage in everyday products.

""Silica particles are thought to be benign and inert, but our study's results indicate that silica is actually reactive,"" says Yangjie Li, a postdoctoral scholar in the Department of Chemistry in the Stanford School of Humanities and Sciences and lead author of the study, which published Aug. 17 in Proceedings of the National Academy of Sciences. ""We encourage further investigation into whether silica particle exposure can deplete glutathione and other critical compounds in the body.""

""Our findings sound an alarm for the continued use of silica particles,"" said senior author Richard Zare, the Marguerite Blake Wilbur Professor in Natural Science and a professor of chemistry in H&S. ""While it's too soon to say that silica is a health risk, at minimum silica poses the potential problem of introducing unwanted chemistry, particularly in food.""

Often consumed and applied

Silica—another name for compounds of silicon and oxygen—is a colorless, odorless, tasteless material. While silica occurs naturally in foods including leafy greens, manufacturers often add tiny, sand-like particles of silica as an anticaking agent to soups and coffee creamers, for instance. Currently, the Food and Drug Administration allows foods to contain as much as 2% by weight of silica particles.

For cosmetics, including skin care products, silica serves as a bulking or absorbing agent, or as an abrasive in scrubs. In health care, silica particles have also found significant use in the delivery of drugs and for medical imaging purposes. For those applications, silica particles are manufactured to have tiny holes, or pores, into which pharmaceuticals and other substances can be slotted.

Given this scope of applications, Li and Zare sought to examine the orthodoxy of silica as a chemically inert substance. Li has a background in probing presumed properties of everyday materials. For her doctoral dissertation work, Li investigated how glass—long relied on for stably storing medicines and other important materials—can, in certain circumstances, act as a catalyst and accelerate chemical reactions.

""We've seen before that so-called inert materials may not really be inert,"" said Zare. ""That story may be repeating itself with silica particles.""

Overlooked chemistry at work

For the study, the Stanford researchers purchased commercially available, pure silica particles, sold as a dry powder. Working with Kurt Kolasinski, a former graduate scholar of Zare and now a professor of physical chemistry at West Chester University, Li added silica to watery solutions containing one of three thiol-bearing biomolecules. The biomolecules studied were cysteine (a key amino acid), the aforementioned antioxidant glutathione, and penicillamine (a so-called heavy metal antagonist for treating Wilson's disease, a condition that occurs when too much copper accumulates in the body).

Li incubated the solutions in the dark for a day at room temperature. She obtained small samples of the solutions at half-hour, 2-hour, 4-hour, and 24-hour marks to gauge the rates of any chemical reactions that might have occurred, using an instrument called a mass spectrometer.

Over time, the biomolecules were oxidized (a loss of electrons in a chemical reaction) by incubation with silica, to the surprising tune of as much as 95% of the molecules in solution ultimately reacting in this way, while the control experiments without silica incubation showed minimal oxidation.

From a chemistry perspective, the reactive pure silica particles converted thiol-containing molecules to disulfide molecules. Spelled out in terms of their elemental compositions, the former molecules, which contain sulfur-hydrogen (S-H) bonded groups, changed to have disulfide bridges, symbolized S-S.

The reverse reaction is familiarly encountered, Zare pointed out, when curly hair is straightened by applying heat with a flat iron. The process breaks disulfide bonds in the proteins in the hair, allowing the hair to be reshaped into straight hair strands. ""When people use flat irons to straighten their hair, the chemistry of what's going on there is breaking disulfides and turning them into thiols, the reverse reaction of our study,"" said Zare.

For the observed reactions, the Stanford researchers think that upon contact with water, silica forms so-called surface-bound silyloxy radicals (a silicon atom bound to an oxygen atom in a configuration that has an unpaired electron). When encountering the radicals, thiol biomolecules in the solution transfer hydrogen atoms (H) to the radicals. Accordingly freed of bonded H, the sulfur atoms in two thiol molecules then recombine to form the S-S disulfides.

Looking ahead, the Zare lab researchers plan to further test how varying sizes of silica particles influence chemical reaction rates. Experiments with larger biomolecules are also ongoing.

Zare and Li hope that their initial findings prompt other researchers, and potentially regulators, to characterize the chemistry of silica more thoroughly.

""Silica is a material that shows up in a lot of places, in the things we eat, in the products we put on our skin, and in medical settings,"" said Zare. ""In light of this new study, we ought to know more about silica and its interactions with other materials.""",https://scx2.b-cdn.net/gfx/news/2023/silica-particles-found.jpg,https://phys.org/news/2023-08-silica-particles-food-makeup-chemically.html,Science
['Mrigakshi Dixit'],2023-08-22 13:43:28+00:00,22 people are enough to build and sustain Martian colony,"A myriad of science-fiction films have popularized the concept of space travel and creating a human colony on Mars.

In reality, however, it is a highly complicated engineering problem, with several logistical challenges to overcome in order to establish a viable settlement on Mars. Furthermore, the hostile condition of Mars necessitates that any habitat established there be essentially self-sustaining.

And creating a Martian habitat from scratch is completely reliant on future human explorers and their robotic helpers.

That said, scientists have been mulling over the number of people needed to execute this laborious task to build a self-sustaining colony in this distant world.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/22/image/jpeg/xSmnq66W6Kz4FBpjc2I7DLjJk8p6ea9VEKUHFwJi.jpg,https://interestingengineering.com/science/22-people-are-enough-to-build-and-sustain-martian-colony,Science
"['James Felton', 'Senior Staff Writer']",2023-08-22 09:11:19+00:00,"""Mars Simulation Finds One Personality Type Should Probably Not Colonize The Red Planet""","A new study has run simulations of colonies on Mars to determine the ideal number of Martian residents needed for such a settlement to survive, also finding that certain personality types should probably steer clear of such a mission.

Should humans ever decide to create a permanent outpost on another planet (and remember, humans have been continuously living in space since 2000, so it's not out of the realms of possibility) we will face a lot of unknowns. New research published on pre-print server arXiv, yet to be peer-reviewed, attempts to limit some of those unknowns, running multiple 28-year simulations to determine what size a colony created the best chance of survival.

Advertisement Advertisement

Previous studies have attempted to answer this question. In 2020, one determined that 110 was the number of people needed to fulfill all duties necessary for their survival without exceeding the work capacity of the colonists. Inspired by that paper, this new team made slightly different assumptions about life on the Red Planet, including that the colony had already been constructed and food, air, and water can be produced locally, and that power was being generated on the planet too.

One major difference is that they modeled that the colony would receive regular supplies from Earth, assuming that it would be more cost-effective to send re-supplies than it is to send humans to expand the size of the colony.

The agent simulation essentially assigns attributes to agents (think setting up your characters in The Sims) and then simulates working days for the colonists as well as interactions with other teammates (think The Sims but without the usual psychological torture).

""Each agent is granted skills associated with their civilian and military occupational specialties consistent with NASA’s Human Factors and Behavioral Performance Element research,"" the team explained in their paper, ""which analyzed the abilities that are generalizable across circumstances and crew roles and those that will be required by all crew members during a 30-month expedition to Mars.""

Advertisement Advertisement

The team also tried to factor personality into their agent simulation, giving the agents these different personality types: Agreeables, who were low on competitiveness and aggression; Socials, who are extroverted and need social interaction; Reactives, who have a ""competitive interpersonal orientation"" and are ""fixated on stringent routines""; and Neurotics, who are highly competitive and aggressive and are unable to cope with boredom and change to routine.

Each agent had a life bar that could deplete, killing them. Resupplies of new Martians, with their own personalities, would happen periodically to fill the dead space shoes. The simulations were run for 28 years and with different numbers of people starting the colonies, ranging from 10-170. They found that the lowest number necessary required to sustain a colony was 22, far lower than the previous study which had not assumed regular re-supply missions.

What they weren't expecting was the death rate among neurotics.

""The primary observed emergent phenomenon occurs in the decline of the Martian population,"" the team wrote. ""While the members of the settlement have an equal probability of being affected by lack of settlement resources, habitat accidents, or earth shipping disasters, Martians with the 'neurotic' psychology die at a much higher rate than those of other psychologies.""

Advertisement Advertisement

""Once their population reaches a low enough level, the settlement population stabilizes.""

The team notes that neurotic personalities suffered during life on the colony, and the colony improved when fewer people of that personality type were there.

""Martians with the neurotic psychology and a high coping capacity benefit the least from interaction with other Martians, and are penalized the most if they have a low coping capacity. Our results suggest that this effect is a driver of the Martian population decline, and once minimized or removed, can produce a stable settlement.""

Human interactions are of course less simple than in these models which simplify things to attempt to find trends. Real-life simulations are taking place, shutting residents inside fake Mars habitats and simulating life on the planet, and all the problems that could come with it.

Advertisement Advertisement

“The analog is critical for testing solutions to meet the complex needs of living on the Martian surface,” Grace Douglas, lead scientist for NASA’s Advanced Food Technology research effort at NASA’s Johnson Space Center in Houston, said in a 2021 statement. “Simulations on Earth will help us understand and counter the physical and mental challenges astronauts will face before they go.”

The study is available on pre-print server arXiv.",https://assets.iflscience.com/assets/articleNo/70335/aImg/70118/martian-meta.png,https://www.iflscience.com/mars-simulation-finds-one-personality-type-should-probably-not-colonize-the-red-planet-70335,Science
"['Joshua Hawkins', 'Chris Smith', 'Andy Meek', 'Jacob Siegal']",2023-08-22 19:49:00+00:00,"It takes just 22 people to start a Mars colony, new study claims","When you think of colonies on other planets, you probably think of large groups of people congregating in colony bases like you’ve seen in science fiction movies and shows. However, a new study claims you’d only need 22 people to start a Mars colony successfully. The study also found that some personalities might not be so great for planetary colonization.

Tech. Entertainment. Science. Your inbox. Sign up for the most interesting tech & entertainment news out there. Email: SIGN UP By signing up, I agree to the Terms of Use and have reviewed the Privacy Notice.

The study in question is currently available on the preprint server arXiv. The study not only ran simulations to see how many human colonists would be needed to optimally set up a colony, but it also compared different personalities to see how they would interact and behave on such a long and isolating mission.

The study says the magic number for the smallest population of colonists that could build and sustain a Mars colony would be 22. Further, the researchers say the simulation looked at four different personalities to see how they would handle the interactions between people with varying levels of skill, stress, and resilience.

Mars landscape captured by the Pathfinder lander. Image source: NASA/JPL

They found that people who were reactive, sociable, and agreeable could successfully work within the simulated Martian colony without much issue. However, they found that neurotics involved in the simulation were more likely to die than others, with a much higher death rate than other personality types.

This kind of information is extremely valuable, especially if we ever want to actually send humans to Mars and possibly colonize the planet in any way. It’s often easy to think of humans as numbers and pieces of an equation. But, as the researchers note in their study, our distinct personalities bring a lot of complexity to the situation, so it is important to take that into consideration as well.

“We wanted to show that if we neglect the social, behavioral and psychological aspects of space explorations, we can err grossly in our estimations, predictions and projections,” Anamaria Berea, co-author on the study, told The Register. NASA is also currently running a Martian colony simulation with four people that are locked in makeshift Mars bases.",https://bgr.com/wp-content/uploads/2022/12/AdobeStock_531142971.jpeg?quality=82&strip=all,https://bgr.com/science/it-takes-just-22-people-to-start-a-mars-colony-new-study-claims/,Science
[],2023-08-22 17:28:56-04:00,What Is the Perfect Number of People for a Mars Colony?,"SYFY's The Ark (streaming now on Peacock!) imagines a future, just a century from now, when humanity is embarking on its first expeditions to another star system. And when you’re going someplace that far away, you’re usually going for keeps. That means sending a carefully selected group of people to establish a colony on another world.

How to Watch Catch up on The Ark on Peacock or the SYFY app.

When building a new society from scratch (whether on Proxima centauri b or on Mars), it’s important to know what resources, and how many of those resources, you’re likely to need. That’s true even when those resources are people. If humanity hopes to build stable outposts on other cosmic islands, we’re going to need to know how many people to send. Apparently, that number is at least 22, according to a recent study posted to the pre-print server ArXiv.

Building a Martian Colony from Scratch

Any Martian colony will very likely have support from Earth, in the form of resupplies and even personnel reinforcements, something the crew of The Ark could only dream of. Even still, the travel times between Earth and Mars are measured in months or years, and any Martian colony will need to be largely self-sufficient from day to day.

RELATED: Humans Could Someday Be Living Underground on Mars

In addition to the technical and engineering problems which are destined to emerge on any deep space mission, they’ll also need to plan for and address psychological and social problems. Those challenges may even be more difficult to manage, as you can’t easily swap out a bolt to fix a crew member’s broken attitude.

Credit: NASA

For their study, researchers used agent-based modeling to simulate several different Martian colonies, with different variables, over the course of a 28-year period. Researchers simulated colonies with starting populations between 10 and 170, with individuals given one of four personality types: neurotic, reactive, social, and agreeable. Then they put those agents to work running their simulated colony, with all of the challenges and responsibilities that entails, and they waited to see what would happen.

Previous research has suggested that the minimum viable population for an isolated colony is at least 100 people, but the current study shows you can get away with less than a quarter of that, provided they’re the right people. See, people aren’t nuts and bolts, and that means they are less predictable but they’re also more versatile. The right 22 people can be much more effective than hundreds, if they work well together.

RELATED: NASA Volunteers Are Growing Real Food on a Fake Mars

In fact, personality type appeared to have way more to do with success than the raw number of people, with a clear preference toward people who are likely to cooperate. In their simulations, individuals with the agreeable personality type lived longer than any others while individuals with the neurotic personality type dropped like flies. Moreover, an excess of neurotics threatened the entire colony, with the population only stabilizing once their numbers dropped below a critical threshold.

The point is two-fold. If you’re building a Mars colony, be more concerned with the type of people you’re courting than the number. And if you’re going to Mars yourself (or any isolated, high-stress environment) do your best to be a bud. It’s not only better for your own survival, but also for the survival of the entire colony.

While waiting for your ticket to Mars, catch the complete first season of The Ark, streaming now on Peacock!",https://www.syfy.com/sites/syfy/files/2023/01/nup_198043_00939.jpg,https://www.syfy.com/syfy-wire/what-is-the-perfect-number-of-people-for-a-mars-colony,Science
['Andres Almeida'],,NASA Invites Digital Content Creators to Cover Psyche Launch,,http://www.nasa.gov/sites/default/files/thumbnails/image/psyche-large.jpg,https://www.nasa.gov/feature/nasa-invites-digital-content-creators-to-cover-psyche-launch,Science
"['Richard Tribou', 'Senior Content Editor', 'Richard Tribou Is The Senior Content Editor For Audience', 'Space', 'Cruise Reporter For The Orlando Sentinel.']",2023-08-22 00:00:00,Long wait nearly over for Psyche asteroid probe’s Space Coast launch,"TITUSVILLE — Just off a tree-covered side road past businesses selling boats and fishing gear sits a fenced-off building that’s home to a $700 million satellite nearly ready for launch. Its mission: To study the metal-rich asteroid Psyche, which scientists suspect could mirror the inner core of Earth and other planets in the solar system.

The probe, which also is named Psyche, awaits an October trip to the launch pad at Kennedy Space Center. But after missing a chance to launch in 2022, NASA parked it at the Astrotech Space Operations Facility across the river where it has been sitting in the center of the stark, white clean room.

With its solar panels installed this month, teams are finally set to load it with the fuel needed to send it on its 2.5-billion-mile trip to the asteroid orbiting the sun between Mars and Jupiter.

Liftoff on a SpaceX Falcon Heavy from KSC’s Launch Complex 39-A is targeting as soon as Oct. 5 with a window that stretches until Oct. 23. It’s not slated to arrive at Psyche, which can range from 235 million to 309 million miles away from Earth until August 2029, and only then will it get down to the business of figuring out what’s special about the distant asteroid.

The Psyche mission principal investigator, Lindy Elkins-Tanton, also a professor at Arizona State University’s School of Earth and Space Exploration, says Psyche could hold answers about how life was able to flourish on Earth.

“One of the key characteristics of our Earth is the metal core, which gives us our magnetic field, which shields our atmosphere and all the other great things the magnetic field does for us, including giving us auroras and the beautiful night sky,” she said. “And it’s long been humans’ dream to go to the metal core of our Earth. I mean, ask Jules Verne.”

Getting to our planet’s center is technologically beyond human ability, but the mission to Psyche opens up the door to understand how planets like Mercury, Venus, Earth and Mars are formed.

“If you think about the asteroid belt, it’s really the shrapnel that’s leftover after the creation of our rocky planets. It’s the material that got stranded, and never really incorporated into the planet that grew up to what we have now,” she said. “So if you think of the Earth as a finished cake, all the ingredients have been liquefied, they were melted, they were whipped together and then the metal core formed and then it’s left with the rocky exterior. Well, what were the ingredients?”

It’s a rare destination, one of only nine known asteroids either made of metal or with a metal surface out of the more than a million asteroids that have been found to date, she said. Data have shown it has a nickel-iron core and has an average diameter of 140 miles, or roughly the drive from Daytona Beach to Tampa on Interstate 4.

“We visited bodies that are made of rock, rocky asteroids. We visited icy asteroids. We’ve looked at comets. And the last characteristic, the last kind of category of object that we’ve never visited as a species in our solar system is bodies made of metal,” she said.

The asteroid was first discovered on March 17, 1852, by Italian astronomer Annibale de Gasparis, named for the Greek goddess of the soul who in mythology was born human, but married the Greek god of love Eros, aka Cupid.

“This is primary exploration, a new kind of object that humans have never seen before,” she said. “The biggest thrill of the whole mission to me is that we’re going to visit an unknown object.”

The path to launch, though, has not been simple. The mission has been in the works for 12 years, with proposals finally winning NASA’s approval in 2017 to become its 14th Discovery Program effort. The program includes missions such as Mars Pathfinder, Kepler space telescope, Lunar Prospector and 2021’s Space Coast launch of the Lucy probe on its way to study asteroids that orbit the sun in front of and behind Jupiter.

Psyche was supposed to launch in 2022, but issues that came to light with management at NASA’s Jet Propulsion Laboratory forced a very public delay along with an independent review of where the project went wrong. The delay of launch by more than a year was exponentially compounding the life of the mission because of Earth’s relative place in the solar system to where Psyche orbits. So instead of a 2022 launch with an arrival four years later in 2026, the delay meant tacking on an extra two years.

Maxar Technologies, which has nearly 100 similar satellites in orbit closer to Earth, helped construct the satellite including a plan to use solar arrays to power electric propulsion relying on nearly 2,200 pounds of xenon gas that will leave a light blue glow as it spits out ions nearly nonstop between launch and arrival to the asteroid.

Once it arrives, it has a 26-month mission to probe the asteroid, so teams are looking at a two-decade stretch between concept to scientific results.

The probe features cameras, a magnetometer, and a gamma-ray spectrometer to study the asteroid.

“That was a great scientific process to decide what we’re going to measure,” she said. “We need to be able to see the body so that’s what the cameras are for. Then we want to measure magnetic field. What we hope is that Psyche has recorded a magnetic field from its early, early beginning. And then it has kept a history of that magnetic field. it won’t be active today, but it might have recorded it, so magnetometers.

“Then we need to know the composition of Psyche What is it made of, and so our gamma ray and neutron spectrometer … and then we’ll get into gravity field using the radio communications.”

NASA is also hitching a ride to test out near-infrared-laser-based optical communication back to Earth during the first two years of the probe’s trip before it reaches Mars for a gravity-assist swing on its way to the asteroid belt. NASA’s hoping to prove out technology that will be needed for future missions to Mars.

Elkins-Tanton says Psyche is so far away that no images have ever been taken of what she thinks is a potato-shaped celestial body based on shape models from data collected from ground, and Hubble and the James Webb space telescopes.

She’s excited for the eventual probe’s arrival noting plans are to release images within 30 minutes of their transmission back to Earth.

“We’re all going to be discovering that at the same time,” she said. “We’re gonna let the whole world look at the same time at the same things that we’re looking at because that is what spaceflight is for. It’s to inspire all of us to look beyond our destiny, to see our place in the universe.”",https://www.orlandosentinel.com/wp-content/uploads/2023/08/psychecleanroom.jpg?w=1024&h=768,https://www.orlandosentinel.com/2023/08/22/long-wait-nearly-over-for-psyche-asteroid-probes-space-coast-launch/,Science
"['Jim Bell', 'Guest Author']",2023-08-22 16:06:42+00:00,"""NASA's Psyche Mission To A Metal World May Reveal The Mysteries Of Earth's Interior""","French novelist Jules Verne delighted 19th-century readers with the tantalizing notion that a journey to the center of the Earth was actually plausible.

Since then, scientists have long acknowledged that Verne’s literary journey was only science fiction. The extreme temperatures of the Earth’s interior – around 10,000 degrees Fahrenheit (5,537 Celsius) at the core – and the accompanying crushing pressure, which is millions of times more than at the surface, prevent people from venturing down very far.

Advertisement Advertisement

Still, there are a few things known about the Earth’s interior. For example, geophysicists discovered that the core consists of a solid sphere of iron and nickel that comprises 20% of the Earth’s radius, surrounded by a shell of molten iron and nickel that spans an additional 15% of Earth’s radius.

That, and the rest of our knowledge about our world’s interior, was learned indirectly – either by studying Earth’s magnetic field or the way earthquake waves bounce off different layers below the Earth’s surface.

But indirect discovery has its limitations. How can scientists find out more about our planet’s deep interior?

Planetary scientists like me think the best way to learn about inner Earth is in outer space. NASA’s robotic mission to a metal world is scheduled for liftoff on Oct. 5, 2023. That mission, the spacecraft traveling there, and the world it will explore all have the same name – Psyche. And for six years now, I’ve been part of NASA’s Psyche team.

About the asteroid Psyche

Asteroids are small worlds, with some the size of small cities and others as large as small countries. They are the leftover building blocks from our solar system’s early and violent period, a time of planetary formation.

Although most are rocky, icy or a combination of both, perhaps 20% of asteroids are worlds made of metal, and similar in composition to the Earth’s core. So it’s tempting to imagine that these metallic asteroids are pieces of the cores of once-existing planets, ripped apart by ancient cosmic collisions with each other. Maybe, by studying these pieces, scientists could find out directly what a planetary core is like.

Psyche is the largest-known of the metallic asteroids. Discovered in 1852, Psyche has the width of Massachusetts, a squashed spherical shape reminiscent of a pincushion, and an orbit between Mars and Jupiter in the main asteroid belt. An amateur astronomer can see Psyche with a backyard telescope, but it appears only as a pinpoint of light.

About the Psyche mission

In early 2017, NASA approved the US$1 billion mission to Psyche. To do its work, there’s no need for the uncrewed spacecraft to land – instead, it will orbit the asteroid repeatedly and methodically, starting from 435 miles (700 kilometers) out and then going down to 46 miles (75 km) from the surface, and perhaps even lower.

Advertisement Advertisement

Once it arrives in August 2029, the probe will spend 26 months mapping the asteroid’s geology, topography and gravity; it will search for evidence of a magnetic field; and it will compare the asteroid’s composition with what scientists know, or think we know, about Earth’s core.

The central questions are these: Is Psyche really an exposed planetary core? Is the asteroid one big bedrock boulder, a rubble pile of smaller boulders, or something else entirely? Are there clues that the previous outer layers of this small world – the crust and mantle – were violently stripped away long ago? And maybe the most critical question: Can what we learn about Psyche be extrapolated to solve some of the mysteries about the Earth’s core?

NASA’s Psyche spacecraft, undergoing final tests in a clean room at a facility near Florida’s Kennedy Space Center. Image credit: NASA/Frank Michaux



About the spacecraft Psyche

The probe’s body is about the same size and mass as a large SUV. Solar panels, stretching a bit wider than a tennis court, power the cameras, spectrometers and other systems.

A SpaceX Falcon Heavy rocket will take Psyche off the Earth. The rest of the way, Psyche will rely on ion propulsion – the gentle pressure of ionized xenon gas jetting out of a nozzle provides a continuous, reliable and low-cost way to propel spacecraft out into the solar system.

Advertisement Advertisement

The journey, a slow spiral of 2.5 billion miles (4 billion km) that includes a gravity-assist flyby past Mars, will take nearly six years. Throughout the cruise, the Psyche team at NASA’s Jet Propulsion Laboratory in Pasadena, California, and here at Arizona State University in Tempe, will stay in regular contact with the spacecraft. Our team will send and receive data using NASA’s Deep Space Network of giant radio antennas.

Even if we learn that Psyche is not an ancient planetary core, we’re bound to significantly add to our body of knowledge about the solar system and the way planets form. After all, Psyche is still unlike any world humans have ever visited. Maybe we can’t yet journey to the center of the Earth, but robotic avatars to places like Psyche can help unlock the mysteries hidden deep inside the planets – including our own.

Jim Bell, Professor of Earth and Space Exploration, Arizona State University

This article is republished from The Conversation under a Creative Commons license. Read the original article.",https://assets.iflscience.com/assets/articleNo/70365/aImg/70164/asteroid-psyche-meta.jpg,https://www.iflscience.com/nasas-psyche-mission-to-a-metal-world-may-reveal-the-mysteries-of-earths-interior-70365,Science
[],,Psyche Flight Systems Engineer Christina Hernandez – Behind the Spacecraft,,https://i.ytimg.com/vi/F4hlKZVjKsg/maxresdefault.jpg,https://www.youtube.com/watch?v=F4hlKZVjKsg,Science
['Amit Malewar'],2023-08-22 08:30:33+00:00,Quantum entanglement of photons captured in real-time,"Biphoton states in high dimensions are attractive sources for quantum applications, including quantum imaging and high-dimensional communications. When projective measurement methodologies are used, it is typically time-consuming and impractical to completely characterize these states; however, recent developments in coincident imaging technologies enable this by parallelizing many measurements.

In a new study, scientists from the University of Ottawa, in collaboration with Danilo Zia and Fabio Sciarrino from the Sapienza University of Rome, have introduced biphoton digital holography. The technology demonstrates a fast and efficient approach to reconstructing the full quantum state of entangled particles.

Using this technique, scientists visualized the wave function of two entangled photons in real-time.

A fundamental concept in quantum physics, the wave function thoroughly comprehends a particle’s quantum state. It enables quantum scientists to predict the probable outcomes of various measurements on a quantum entity, e.g., position, velocity, etc.

This predictive capacity is invaluable in the quickly developing field of quantum technology, where knowing a quantum state that is formed or input into a quantum computer will allow us to test the computer itself. Additionally, the quantum states used in quantum computing are very complicated and comprise numerous entities that could display potent non-local correlations (entanglement).

Determining the wave function of such a quantum system is a challenging task. This is also known as quantum state tomography or quantum tomography.

Full tomography requires a lot of measurements with standard techniques (based on the so-called projective operations), and this number rises quickly as the system becomes more complicated (dimensional). The study team’s earlier studies using this method demonstrated that it could take hours or even days to characterize or measure the high-dimensional quantum state of two entangled photons. The quality of the outcome is also very noise-sensitive and is influenced by the intricacy of the experimental setup.

The projective measuring approach to quantum tomography can be compared to gazing at the high-dimensional object’s shadows projected from various angles on various walls. The only thing a researcher can see are the shadows, and they may deduce the shape (state) of the entire object from them. For instance, a CT scan may rebuild the information of a 3D object from a collection of 2D images.

Another way of constructing a 3d object is called digital holography. It is based on recording a single image, called an interferogram, obtained by interfering with the light scattered by the object with reference light.

Scientists extended this concept to the case of two photons. It is necessary to superimpose a biphoton state with a supposedly well-known quantum state to reconstruct it. After that, the spatial distribution of the sites where two photons arrive simultaneously must be examined. A coincidence image is a picture taken when two photons arrive simultaneously.

These photons can originate from the known source or the reference source. According to quantum mechanics, it is impossible to pinpoint the origin of the photons. This generates an interference pattern that can be utilized to piece together the unknown wave function. A sophisticated camera that records events with nanosecond resolution (one billionth of a second) on each pixel made this experiment possible.

Dr. Alessio D’Errico, a postdoctoral fellow at the University of Ottawa and one of the co-authors of the paper, highlighted the immense advantages of this innovative approach: “This method is exponentially faster than previous techniques, requiring only minutes or seconds instead of days. Importantly, the detection time is not influenced by the system’s complexity – a solution to the long-standing scalability challenge in projective tomography.”

Journal Reference:",https://www.techexplorist.com/wp-content/uploads/2023/08/photon-dance.jpg,https://www.techexplorist.com/quantum-entanglement-photons-captured-real-time/67478/,Science
"['Dr. Alfredo Carpineti', 'Senior Staff Writer', 'Space Correspondent']",2023-08-22 15:38:38+00:00,"""Quantum Entangled Photons Visualized In Real Time""","Quantum mechanics, thanks to its peculiar properties, can outcompete classical applications. But those same advantageous properties require a lot of knowledge of the quantum system in question which might not always come easily. Researchers have now developed a way to visualize the wave function of two entangled photons in real time.

They are calling it biphoton digital holography, but let’s go one step at a time. A wave function is a crucial quantity in quantum mechanics, with it scientists can understand the properties of a particular object. The objects in this case are photons the particles of light that have also been entangled. Entanglement is a peculiar state where these two photons are intrinsically linked.

Advertisement Advertisement

Measuring one of the properties of the photon would collapse the wavefunction in a specific state, and due to entanglement, this change will be experienced instantaneously by the entangled partner no matter how far it might have gone. To understand the properties of a quantum state, many measurements are necessary and the more complex the state, the more measurements are needed.

In general, this is called quantum tomography because the states are “imaged” in sections. The team behind this research worked out a way to do this quantum tomography faster and more efficiently. They interfere a known quantum state with the one they tried to measure. This will create interference patterns. From these images, the properties of the quantum states can be understood.

And that’s where the holography part comes in. Holograms are 2D visualizations of 3D objects. So the holographic principle allows us to reduce the properties of a three-dimensional system to two dimensions. The researchers were able to use the interference pattern between the unknown quantum state and a known one, to reconstruct the unknown wave function.

A signal showing the Ying and Yang symbol is reconstructed using this interference holographic technique. Image credit: Zia et al., Nature Photonics, 2023 ( CC BY 4.0



But it's not just an interesting theoretical approach. This method also relies on a camera system that can record events with nanosecond resolution on each pixel.

Advertisement Advertisement

""This method is exponentially faster than previous techniques, requiring only minutes or seconds instead of days. Importantly, the detection time is not influenced by the system's complexity – a solution to the long-standing scalability challenge in projective tomography,"" Dr Alessio D'Errico, a postdoctoral fellow at the University of Ottawa, said in a statement.

The findings are published in Nature Photonics.

This article was amended to include an image from the paper.",https://assets.iflscience.com/assets/articleNo/70362/aImg/70152/jurik-peter-meta.jpg,https://www.iflscience.com/quantum-entangled-photons-visualized-in-real-time-70362,Science
['Tibi Puiu'],2023-08-22 09:29:10+00:00,Quantum Yin-Yang? Scientists visualize quantum entanglement of photons for the first time,"Biphoton state holographic reconstruction. Credit: Nature Photonics.

You may have heard of light as both particles and waves, but have you ever imagined the secret dance within? Researchers from the University of Ottawa and Sapienza University in Rome have just uncovered a groundbreaking technique that enables the real-time visualization of the wave function of entangled photons — the fundamental components of light.

The snapshot of a quantum dance

Imagine choosing a random shoe from a pair. If it's a ""left"" shoe, you immediately know the other shoe you've yet to unbox is meant to go on your right foot. This instantaneous information is certain whether the shoe box is within hand's reach or 4.3 light-years away on some planet in the Alpha Centauri system.

This analogy, though not perfect, captures the essence of quantum entanglement. At its core, quantum entanglement refers to the phenomenon where two or more particles become deeply interconnected in such a way that their properties become correlated, regardless of the spatial separation between them. This means that the state of one particle instantly influences the state of another, even if they are light-years apart.

Quantum entanglement might sound like something out of science fiction, but it's a very real phenomenon that has been observed in experiments. It challenges our conventional understanding of how the world works and delves into the strange and wondrous realm of quantum physics, where particles can be in multiple states at once and influence each other in ways that defy our everyday intuition.

This instantaneous connection seems to defy the fundamental speed limit of information transfer imposed by Einstein's theory of relativity. Indeed, the concept of entanglement was famously challenged by Albert Einstein, Boris Podolsky, and Nathan Rosen in a 1935 paper known as the EPR paradox. They proposed that entanglement was an incomplete description of physical reality, asserting that quantum mechanics must be missing hidden variables that determine particle properties independently.

However, subsequent experiments, notably the Bell tests, demonstrated that the EPR paradox couldn't be resolved with classical hidden variables. The results of these experiments aligned with quantum predictions, highlighting the genuine non-local nature of entanglement.

Wave functions, crucial in quantum mechanics, can provide important insight into a particle's quantum state. If we stick to the shoe analogy, the shoe's ""wave function"" carries information like size, color, left or right, and so on. But in quantum physics, scientists usually describe a particle's wave function in terms of position, velocity, spin, and other quantum properties.

Holography: A New Dimension of Quantum Insight

As you might imagine, determining the wave function of a quantum system is no trivial task. This process, known as quantum tomography, typically involves cumbersome measurements that introduce ""dimensionality"", the number of distinct properties or characteristics that a quantum system can possess and be measured for.

In quantum mechanics, each dimension represents a distinct property that can be measured, such as position, momentum, spin, etc. When dealing with entangled particles or more complex quantum systems, the number of dimensions grows significantly. This can result in entangled systems existing in a high-dimensional space, where the dimensions correspond to various properties of the entangled particles.

Previous experiments involving quantum tomography measuring the high-dimensional quantum state of two entangled photons could take hours or even days. Not only does the process take a very long time, the quality of the results is questionable, especially for increasingly complex systems. Imagine trying to reconstruct a high-dimensional object from its shadows cast on different walls. That's the challenge quantum scientists face when tackling quantum tomography.

But what if instead of just shadows, we have holograms? In classical optics, digital holography creates a three-dimensional image using a single interferogram — a result of light interference. The team of researchers led by Ebrahim Karimi from Ottawa University extended this concept to the realm of entangled photons.

To uncover the quantum secrets, researchers superimposed the entangled photons with a known quantum state. They watched as the photons arrived simultaneously, creating a breathtaking so-called ""coincidence image"". It's like capturing two dancers in perfect synchronization, frozen in time.

This key discovery was made possible thanks to a cutting-edge camera with nanosecond precision. This camera captured the photons' synchronized arrival, revealing an intricate interference pattern. This pattern, akin to a mesmerizing choreography, held the key to reconstructing the elusive wave function.

""This method is exponentially faster than previous techniques, requiring only minutes or seconds instead of days. Importantly, the detection time is not influenced by the system's complexity—a solution to the long-standing scalability challenge in projective tomography,"" said Dr. Alessio D'Errico, a postdoctoral fellow at the University of Ottawa and one of the co-authors of the paper.

Quantum entanglement might sound like an abstract concept, but it has profound practical implications. Researchers have harnessed entanglement for quantum cryptography, a method of secure communication based on the principles of quantum mechanics. This technology enables the transmission of cryptographic keys that are inherently secure, as any eavesdropping attempts would disrupt the entanglement and be detectable.

Entanglement also plays a pivotal role in quantum computing, a field that holds the promise of solving complex problems beyond the capabilities of classical computers. Quantum bits (qubits), which can be in entangled states, allow for exponentially faster computation due to their ability to exist in multiple states simultaneously.

As such, the findings add a new layer of understanding into quantum wave functions that could make quantum computers and other applications more stable. This method may also lead to the development of new quantum imaging techniques.

The findings appeared in the journal Nature Photonics.",https://cdn.zmescience.com/wp-content/uploads/2023/08/quantum-entanglement-mystery.jpg,https://www.zmescience.com/science/news-science/quantum-yin-yang-scientists-visualize-quantum-entanglement-of-photons-for-the-first-time/,Science
['University Of Ottawa'],,Visualizing the mysterious dance: Quantum entanglement of photons captured in real-time,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Biphoton state holographic reconstruction. Image reconstruction. a, Coincidence image of interference between a reference SPDC state and a state obtained by a pump beam with the shape of a Ying and Yang symbol (shown in the inset). The inset scale is the same as in the main plot. b, Reconstructed amplitude and phase structure of the image imprinted on the unknown pump. Credit: Nature Photonics (2023). DOI: 10.1038/s41566-023-01272-3

Researchers at the University of Ottawa, in collaboration with Danilo Zia and Fabio Sciarrino from the Sapienza University of Rome, recently demonstrated a novel technique that allows the visualization of the wave function of two entangled photons, the elementary particles that constitute light, in real-time.

Using the analogy of a pair of shoes, the concept of entanglement can be likened to selecting a shoe at random. The moment you identify one shoe, the nature of the other (whether it is the left or right shoe) is instantly discerned, regardless of its location in the universe. However, the intriguing factor is the inherent uncertainty associated with the identification process until the exact moment of observation.

The wave function, a central tenet in quantum mechanics, provides a comprehensive understanding of a particle's quantum state. For instance, in the shoe example, the ""wave function"" of the shoe could carry information such as left or right, the size, the color, and so on.

More precisely, the wave function enables quantum scientists to predict the probable outcomes of various measurements on a quantum entity, e.g. position, velocity, etc.

This predictive capability is invaluable, especially in the rapidly progressing field of quantum technology, where knowing a quantum state which is generated or input in a quantum computer will allow to test the computer itself. Moreover, quantum states used in quantum computing are extremely complex, involving many entities that may exhibit strong non-local correlations (entanglement).

Knowing the wave function of such a quantum system is a challenging task—this is also known as quantum state tomography or quantum tomography in short. With the standard approaches (based on the so-called projective operations), a full tomography requires large number of measurements that rapidly increases with the system's complexity (dimensionality).

Previous experiments conducted with this approach by the research group showed that characterizing or measuring the high-dimensional quantum state of two entangled photons can take hours or even days. Moreover, the result's quality is highly sensitive to noise and depends on the complexity of the experimental setup.

The projective measurement approach to quantum tomography can be thought of as looking at the shadows of a high-dimensional object projected on different walls from independent directions. All a researcher can see is the shadows, and from them, they can infer the shape (state) of the full object. For instance, in CT scan (computed tomography scan), the information of a 3D object can thus be reconstructed from a set of 2D images.

In classical optics, however, there is another way to reconstruct a 3D object. This is called digital holography, and is based on recording a single image, called interferogram, obtained by interfering the light scattered by the object with a reference light.

The team, led byEbrahim Karimi, Canada Research Chair in Structured Quantum Waves, co-director of uOttawa Nexus for Quantum Technologies (NexQT) research institute and associate professor in the Faculty of Science, extended this concept to the case of two photons.

Reconstructing a biphoton state requires superimposing it with a presumably well-known quantum state, and then analyzing the spatial distribution of the positions where two photons arrive simultaneously. Imaging the simultaneous arrival of two photons is known as a coincidence image. These photons may come from the reference source or the unknown source. Quantum mechanics states that the source of the photons cannot be identified.

This results in an interference pattern that can be used to reconstruct the unknown wave function. This experiment was made possible by an advanced camera that records events with nanosecond resolution on each pixel.

Dr. Alessio D'Errico, a postdoctoral fellow at the University of Ottawa and one of the co-authors of the paper, highlighted the immense advantages of this innovative approach, ""This method is exponentially faster than previous techniques, requiring only minutes or seconds instead of days. Importantly, the detection time is not influenced by the system's complexity—a solution to the long-standing scalability challenge in projective tomography.""

The impact of this research goes beyond just the academic community. It has the potential to accelerate quantum technology advancements, such as improving quantum state characterization, quantum communication, and developing new quantum imaging techniques.

The study ""Interferometric imaging of amplitude and phase of spatial biphoton states"" was published in Nature Photonics.

More information: Danilo Zia et al, Interferometric imaging of amplitude and phase of spatial biphoton states, Nature Photonics (2023). DOI: 10.1038/s41566-023-01272-3 Journal information: Nature Photonics",https://scx2.b-cdn.net/gfx/news/2023/visualizing-the-myster.jpg,https://phys.org/news/2023-08-visualizing-mysterious-quantum-entanglement-photons.html,Science
"['Ben Turner', 'Staff Writer', 'Social Links Navigation']",2023-08-22 18:00:41+00:00,"All of Neptune's clouds have mysteriously disappeared, and the sun may be to blame","All of Neptune's clouds have vanished, and scientists think the sun is to blame.

The disappearance of the wispy, white strands of frozen methane that usually streak Neptune's azure face has been linked to changes in ultraviolet (UV) radiation as the sun 's activity climbs to an 11-year maximum.

The clouds around the solar system's eighth and most distant planet — located roughly 2.8 billion miles (4.5 billion kilometers) from the sun — began fading in 2019 and were gone without a trace by 2020. The researchers who made the discovery will publish their findings in the Nov. 1 edition of the journal Icarus .

Related: Rare red asteroids around Neptune could reveal the secrets of the early solar system

""Even now, four years later, the most recent images we took this past June still show the clouds haven't returned to their former levels,"" Erandi Chavez , a graduate student at the Harvard-Smithsonian Center for Astrophysics who led the study as an undergraduate at the University of California, Berkeley, said in a statement . ""This is extremely exciting and unexpected, especially since Neptune's previous period of low cloud activity was not nearly as dramatic and prolonged.""

The sun's activity rises and falls in 11-year cycles, but recently, the sun has been far more active than expected, with sunspot appearances nearly double the number predicted by the National Oceanic and Atmospheric Administration's Space Weather Prediction Center . Scientists anticipate that the sun's activity, initially thought to reach its maximum in 2025, could peak as soon as the end of this year .

Astronomers have pegged the loss of cloud cover to the effects of sunlight hitting Neptune's atmosphere. By analyzing data collected by the Hubble Space Telescope, the Keck Observatory in Hawaii, and the Lick Observatory in California, astronomers observed that, following a two-year delay, peaks in the sun's activity generate more cloud cover over Neptune, while lows cause it to dissipate.

What, exactly, is causing the change isn't known for certain. The most likely explanation is that UV light from the sun starts chemical reactions in Neptune's upper atmosphere, ultimately creating the clouds.

""It's fascinating to be able to use telescopes on Earth to study the climate of a world more than 2.5 billion miles away from us,"" study co-author Carlos Alvarez, a staff astronomer at the Keck Observatory, said in the statement. ""Advances in technology and observations have enabled us to constrain Neptune's atmospheric models, which are key to understanding the correlation between the ice giant's climate and the solar cycle.""",https://cdn.mos.cms.futurecdn.net/3dqxFJ4HJrJMFu6n8uBLSe-1200-80.jpg,https://www.livescience.com/space/neptune/all-of-neptunes-clouds-have-mysteriously-disappeared-and-the-sun-may-be-to-blame,Science
['Kristen Rogers'],2023-08-22 00:00:00,Neptune’s disappearing clouds linked to solar cycle,"Sign up for CNN’s Wonder Theory science newsletter. Explore the universe with news on fascinating discoveries, scientific advancements and more.

CNN —

Astronomers have been puzzling over a mystery on Neptune, and now they think they have unlocked its secret.

The ice giant’s ghostly, cirrus-like clouds largely disappeared four years ago. Today, just a patch hovers over the planet’s south pole.

Thanks to an analysis of nearly three decades’ worth of Neptune observations captured by three space telescopes, scientists have determined the ice giant’s diminished clouds may indicate that shifts in their abundance are in sync with the solar cycle, according to a recent study published in the journal Icarus.

“These remarkable data give us the strongest evidence yet that Neptune’s cloud cover correlates with the Sun’s cycle,” said senior study author Imke de Pater, professor emeritus of astronomy at the University of California, Berkeley, in a news release. “Our findings support the theory that the Sun’s (ultraviolet) rays, when strong enough, may be triggering a photochemical reaction that produces Neptune’s clouds.”

During the solar cycle, the level of activity in the sun’s dynamic magnetic fields waxes and wanes. The magnetic field flips every 11 years as it becomes more tangled like a ball of yarn, according to NASA. When there is heightened activity on the sun, more intense ultraviolet radiation bombards the solar system.

With data from NASA’s Hubble Space Telescope, the W.M. Keck Observatory in Hawaii and the Lick Observatory in California, scientists observed 2.5 cycles of cloud activity over the 29-year period of Neptune observations — during which the planet’s reflectivity increased in 2002 and dimmed in 2007. Neptune brightened again in 2015, before darkening in 2020 to the lowest level ever seen. That’s when most of the cloud cover faded away.

“Even now, four years later, the most recent images we took this past June still show the clouds haven’t returned to their former levels,” said the study’s lead author Erandi Chavez, a doctoral student at the Center for Astrophysics, Harvard & Smithsonian, in a statement.

The findings are “extremely exciting and unexpected, especially since Neptune’s previous period of low cloud activity was not nearly as dramatic and prolonged,” Chavez added.

The ""Great Dark Spot,"" a storm in Neptune's atmosphere, and the accompanying bright smudge of clouds are captured by the NASA Voyager 2 spacecraft less than five days before its closest approach to the planet on August 25, 1989. NASA/JPL-Caltech/Handout/Reuters

A surprising correlation

The authors also found that two years after the cycle’s peak, more clouds appeared on Neptune — and that the more clouds there were, the brighter Neptune was from the sunlight reflecting off it. That connection was “surprising to planetary scientists because Neptune is our solar system’s farthest major planet and receives sunlight with about 0.1% of the intensity Earth receives,” according to NASA. The findings also contradict the idea of the clouds being affected by Neptune’s four seasons, which each last about 40 years.

“This is a very interesting paper and a very nice piece of good, old-fashioned detailed detective work,” said Patrick Irwin, a professor of planetary physics at the University of Oxford who wasn’t involved in the study, via email. “This new paper covers a longer time frame than previous studies and shows a convincing correlation of the observed cloud cover with the solar UV brightness.”

But there is a two-year time lag between the solar cycle’s peak and Neptune’s increased abundance of clouds. The authors think this gap could be explained by the photochemistry that occurs high in the planet’s upper atmosphere, which takes time to produce clouds.

The relationship between increased brightness of the sun and cloud formation could be due to the generation of ionized molecules that can act as cloud condensation nuclei and help initiate condensation, Irwin said.

“It’s fascinating to be able to use telescopes on Earth to study the climate of a world more than 2.5 billion miles away from us,” said study coauthor Carlos Alvarez, a staff astronomer at Keck Observatory, in a statement. “Advances in technology and observations have enabled us to constrain Neptune’s atmospheric models, which are key to understanding the correlation between the ice giant’s climate and the solar cycle.”

The research team is still monitoring Neptune’s cloud activity since more UV light could also darken the planet’s clouds, lowering its overall brightness, the authors said.

Additionally, Neptune storms rising from the deep atmosphere do influence the planet’s cloud cover — but aren’t related to clouds formed in the upper atmosphere. That variable could interfere with studies looking at correlations between photochemically produced clouds and the solar cycle. More research could also suggest how long the near absence of clouds on Neptune might last.

These pursuits, in turn, could not only expand astronomers’ knowledge of Neptune but also help researchers better understand the many exoplanets outside the solar system believed to have characteristics similar to the ice giant, according to NASA.

The study also “underlines the need to keep monitoring the solar system planets,” Irwin said. “It’s only by observing these planets at regular intervals that it is possible to build up a long-term, reliable dataset to probe for these periodic variations.”","https://media.cnn.com/api/v1/images/stellar/prod/230821173323-02-neptune-clouds.jpg?c=16x9&q=w_800,c_fill",https://www.cnn.com/2023/08/22/world/neptune-disappearing-clouds-solar-cycle-sun-scn/index.html,Science
"['Smithsonian Magazine', 'Will Sullivan', 'Daily Correspondent', 'Read More', 'Will Sullivan Is A Science Writer Based In Washington', 'D.C. His Work Has Appeared In']",,"Neptune’s Clouds Have Disappeared, and the Sun Might Be Responsible","As the outermost planet in the solar system, Neptune is more than 30 times farther from the sun than the Earth is, and it takes a staggering 165 years to circle our star. From the outskirts of the sun’s orbit, Neptune bathes in only 0.1 percent of the intensity of sunlight that we get on Earth.

Yet despite the distance between them, the sun still holds sway over the far-off planet. In a paper recently published in the journal Icarus, researchers theorize that the sun is the reason why Neptune’s clouds have recently disappeared. The paper suggests the planet’s cloud coverage could be tied to the ultraviolet rays the sun emits through the solar system.

“That UV emission from the sun could dictate Neptune’s cloud structure is akin to an orchestra conductor giving directions to a lone violin player 2.8 billion miles away,” Grant Tremblay, an astrophysicist at the Harvard-Smithsonian Center for Astrophysics who did not contribute to the research, tells the New York Times’ Robin George Andrews. “It’s another illustration that our sun truly is the lord of the solar system, even to its most distant reaches.”

Neptune’s clouds have been signature features in images of the planet for decades. But now, the world is essentially devoid of them. For the new study, researchers investigated whether the sun had anything to do with this shift on Neptune. They tracked changes in the planet’s clouds between 1994 and 2022, using observations from the Hubble Space Telescope, Keck Observatory and Lick Observatory, according to a statement from NASA.

The team found that cloud activity on Neptune peaked in both 2002 and 2015 and reached its lowest levels in 2007 and 2020. Clouds were almost totally gone in 2020—the lowest coverage ever observed—after they started fading around the planet’s mid-latitudes in 2019.

“Even now, four years later, the most recent images we took this past June still show the clouds haven’t returned to their former levels,” Erandi Chavez, first author of the new study and a researcher at the Harvard-Smithsonian Center for Astrophysics, says in NASA’s statement. “This is extremely exciting and unexpected, especially since Neptune’s previous period of low cloud activity was not nearly as dramatic and prolonged.”

These changes in cloud coverage appear to be tied to the solar cycle, or the steady oscillation between periods of high and low solar activity every 11 years. Solar activity includes phenomena like solar flares, coronal mass ejections and high-speed solar wind, according to the National Oceanic and Atmospheric Administration. When the solar cycle peaks, the sun’s magnetic field flips as well.

During Neptune’s two cloudiest years, the sun had hit its peak in activity only two years prior, which involves higher emissions of ultraviolet radiation, writes New Scientist’s Leah Crane. And in low-cloud years like 2020, solar activity was near its minimum.

The number of clouds over Neptune was also tied to the brightness of sunlight reflecting off the planet.

“These remarkable data give us the strongest evidence yet that Neptune’s cloud cover correlates with the sun’s cycle,” Imke de Pater, a co-author of the study and an astronomer at the University of California, Berkeley, says in NASA’s statement.

Still, the research did not reveal why Neptune’s current cloudless state is more dramatic than any other known period, per the New York Times.

Hubble chronicles #Neptune's cloud cover over three decades & finds that the number of clouds grows increasingly following a peak in the solar cycle.



Learn more https://t.co/pqVIK0bJ75



@NASA @esa E. Chavez (UC Berkeley), I. de Pater (UC Berkeley) pic.twitter.com/lpbA0aJ0pu — HUBBLE (@HUBBLE_space) August 17, 2023

As for why this pattern occurs, perhaps the strongest UV rays from the sun set off a chemical reaction in Neptune’s atmosphere that leads to cloud formation, per NASA. This might account for the two-year gap between the solar maximum and the peak of cloud coverage on Neptune—the chemical reactions may just take some time to occur.

This trend remains only a correlation, however, and more research is needed to prove solar activity is causing the changes in Neptune’s cloud coverage, writes New Scientist.

Currently, the sun is building to a peak in solar activity, which NASA has forecasted will occur in July 2025 (though other research has moved that date earlier). Watching Neptune to see if its clouds respond as predicted could give scientists more evidence to bolster this new theory.

Get the latest stories in your inbox every weekday.",https://th-thumbnailer.cdn-si-edu.com/UKWj0osE8bdgjlWCx08Ri8G26b0=/fit-in/1600x0/filters:focal(1094x1094:1095x1095)/https%3A%2F%2Ftf-cmsv2-smithsonianmag-media.s3.amazonaws.com%2Ffiler_public%2Fb8%2F8d%2Fb88dd61b-4a83-4dab-abd9-de0566176477%2Fpia01492orig.jpg,https://www.smithsonianmag.com/smart-news/neptunes-clouds-have-disappeared-and-the-sun-might-be-responsible-180982766/,Science
[],2023-08-22 15:43:57-04:00,Neptune's Clouds Have Disappeared and It's the Sun's Fault,"The Sun is such a constant presence, bathing us consistently in light and warmth, that we can easily forget how much influence it has. From the weather to the food chain, it all traces back to the Sun. So, it stands to reason that if something goes really wrong or really weird, the Sun may have had something to do with it. That’s the thinking behind the 2006 disaster flick Solar Attack (streaming now on Peacock) and, despite its wacky premise, the filmmakers may have been onto something.

The story hinges on a coronal mass ejection (CME) interacting with methane in Earth’s atmosphere and threatening to set the sky on fire. Now, real world scientists have found a similar (if less destructive) process gobbling up the clouds in the skies of Neptune. The results were published in the journal Icarus.

The Mysterious Missing Clouds of Neptune

When Voyager returned the first detailed pictures of Neptune in the summer of 1989, we got our first glimpse of the cloud features in its distant sky. Since then, astronomers have followed up those observations with telescopes on the ground and in space, and they noticed something weird.

RELATED: JWST’s Neptune: The Best Infrared View in 30 Years

Over the years, astronomers noticed a characteristic ebb and flow in the Neptunian cloud cover, but it wasn’t clear what was causing it. Now, more than three decades after Voyager sent back its first grainy images, astronomers may have figured it out and, you guessed it, it’s the Sun.

To figure out what was going on, astronomers pored through 29 years of observations from NASA’s Hubble Space Telescope, Hawaii’s Keck Observatory, and the Lick Observatory in California. Those observations included a series of eight Hubble images (below) collected between 1994 and 2020. In them, you can clearly see the disappearance and reappearance of clouds from image to image. Critically, recent observations reveal an almost complete absence of clouds.

Several observations of Neptune spanning a time frame from 1994 to 2022 Photo: NASA, ESA, Erandi Chavez (UC Berkeley), Imke de Pater (UC Berkeley)

The important clue was the frequency of change, with cloud activity peaking in 2002 and 2015 and slumping in 2007 and 2020. Those dates didn’t immediately line up with any celestial phenomena, but it all fell into place when astronomers realized there was a two-year delay in activity. Through that lens, the changes in cloud cover start to reveal themselves as a consequence of solar activity, with clouds peaking two years after solar maximum of each solar cycle.

How the Sun Forms Clouds in Neptune’s Atmosphere

The degree of effect is surprising, considering how far away Neptune is. We’re orbiting about 93 million miles away from the Sun. Neptune, by contrast, orbits at an average distance of 2.78 billion miles. At that great vantage point, Neptune receives only about 0.1% of the sunlight Earth enjoys, but that’s enough.

RELATED: Defying death, a monster storm on Neptune makes a U-turn

Solar radiation impacts weather patterns on Earth too, but in a different way. While the Sun feeds terrestrial weather systems largely through heat, on Neptune the relationship is subtler. As solar radiation strikes the atmosphere, it interacts with molecules to steal or donate an electron. Those ionized molecules in the upper atmosphere then serve as condensation points around which clouds can form.

That photochemical relationship also explains the two-year delay in solar maximum and maximum cloud production. While the travel time between the Sun and Neptune is only about 4 light-hours, actual cloud production can take years to spin up, resulting in partly cloudy skies in the Neptunian weather report roughly two years following solar maximum. Of course, 2.5 solar cycles of data is a pretty small sample size and astronomers will be looking to confirm this finding as the current solar cycle wraps up.

There aren’t any clouds in the Neptunian skies right now, but if researchers are correct, there will be in 2026 or 2027, on the other side of the Sun’s upcoming temper tantrum.

Want to prep for a worst case scenario? Catch Solar Attack, streaming now on Peacock!",https://www.syfy.com/sites/syfy/files/2022/12/Sun.jpg,https://www.syfy.com/syfy-wire/neptunes-clouds-have-disappeared-and-its-the-suns-fault,Science
"['Dr. Alfredo Carpineti', 'Senior Staff Writer', 'Space Correspondent']",2023-08-22 14:26:01+00:00,"""A 350-Year-Old Theorem Can Explain The Quantum Properties Of Light""","Light can behave both as a wave and a particle, a head-scratcher that confused scientists for centuries before the fact became obvious. This duality is a cornerstone of quantum mechanics, and the peculiar behavior of the quantum world has mostly left classical mechanics theorems behind in the realm of things our own size.

A research team has now used classical mechanics to explain two particular properties of light: polarization and entanglement. The first is the ability of light waves to have an orientation – a fact that is used in sunglasses to filter out some light. The second is the ability of entangled photons to form a quantum system whose parts remain connected even if separated by vast distances. Changes to one would mean instantaneous changes to the other.

Advertisement Advertisement

These don’t sound like classical mechanics at all, but the team considered whether there could be an analog to the behavior of polarization in the Huygens–Steiner theorem. That 350-year-old theorem is about how a solid body rotates with respect to an axis that doesn’t go through its center of mass, and it is useful in both technical applications and studying celestial objects.

""This is a well-established mechanical theorem that explains the workings of physical systems like clocks or prosthetic limbs,"" lead author Xiaofeng Qian, from the Stevens Institute of Technology, said in a statement. ""But we were able to show that it can offer new insights into how light works, too.""

The researchers used the intensity of light as an analog for the mass of a physical object, and the rest of the properties were able to be mapped out following the structure of the theorem, even though light is not a classical body.

""Essentially, we found a way to translate an optical system so we could visualize it as a mechanical system, then describe it using well-established physical equations,"" explained Qian. ""This was something that hadn't been shown before, but that becomes very clear once you map light's properties onto a mechanical system. What was once abstract becomes concrete: using mechanical equations, you can literally measure the distance between 'center of mass' and other mechanical points to show how different properties of light relate to one another.""

Advertisement Advertisement

The reason why these relationships exist and why the mapping works so well is currently not clear. Understanding this connection might have important implications for our understanding of quantum properties, as well as how we use them in applications.

The study is published in Physical Review Research.",https://assets.iflscience.com/assets/articleNo/70357/aImg/70146/agsandrew-meta.jpg,https://www.iflscience.com/a-350-year-old-theorem-can-explain-the-quantum-properties-of-light-70357,Science
['Ameya Paleja'],2023-08-22 13:30:00+00:00,350-year-old theorem unveils complex nature of light waves,"In 1673, Christiaan Huygens wrote a book on pendulums and how they work. A mechanical theorem mentioned in the book was used 350 years later by researchers at the Stevens Institute of Technology to explain the complex behaviors of light, a university statement said.

Although known to us for eons, humanity has found it difficult to explain the very nature of light. For centuries scientists have been divided on whether to call it a wave or a particle and when there seemed to be some agreement on what light could actually be, quantum physics threw a new curveball by suggesting that it existed as both at once.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/22/image/jpeg/cFQpfkz8xwXYW7xurXovRzqFKyyfUAUI8tdszdZa.jpg,https://interestingengineering.com/science/theorem-helps-scientists-explain-light,Science
['Stevens Institute Of Technology'],,Physicists use a 350-year-old theorem to reveal new properties of light waves,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Physicists at Stevens Institute of Technology use a 350-year-old theorem that explains the workings of pendulums and planets to reveal new properties of light waves. Credit: Stevens Institute of Technology

Since the 17th century, when Isaac Newton and Christiaan Huygens first debated the nature of light, scientists have been puzzling over whether light is best viewed as a wave or a particle—or perhaps, at the quantum level, even both at once. Now, researchers at Stevens Institute of Technology have revealed a new connection between the two perspectives, using a 350-year-old mechanical theorem—ordinarily used to describe the movement of large, physical objects like pendulums and planets—to explain some of the most complex behaviors of light waves.

The work, led by Xiaofeng Qian, assistant professor of physics at Stevens and reported in the August 17 online issue of Physical Review Research, also proves for the first time that a light wave's degree of non-quantum entanglement exists in a direct and complementary relationship with its degree of polarization. As one rises, the other falls, enabling the level of entanglement to be inferred directly from the level of polarization, and vice versa. This means that hard-to-measure optical properties such as amplitudes, phases and correlations—perhaps even these of quantum wave systems—can be deduced from something a lot easier to measure: light intensity.

""We've known for over a century that light sometimes behaves like a wave, and sometimes like a particle, but reconciling those two frameworks has proven extremely difficult,"" said Qian ""Our work doesn't solve that problem—but it does show that there are profound connections between wave and particle concepts not just at the quantum level, but at the level of classical light-waves and point-mass systems.""

Qian's team used a mechanical theorem, originally developed by Huygens in a 1673 book on pendulums, that explains how the energy required to rotate an object varies depending on the object's mass and the axis around which it turns. ""This is a well-established mechanical theorem that explains the workings of physical systems like clocks or prosthetic limbs,"" Qian explained. ""But we were able to show that it can offer new insights into how light works, too.""

This 350-year-old theorem describes relationships between masses and their rotational momentum, so how could it be applied to light where there is no mass to measure? Qian's team interpreted the intensity of a light as the equivalent of a physical object's mass, then mapped those measurements onto a coordinate system that could be interpreted using Huygens' mechanical theorem. ""Essentially, we found a way to translate an optical system so we could visualize it as a mechanical system, then describe it using well-established physical equations,"" explained Qian.

Once the team visualized a light wave as part of a mechanical system, new connections between the wave's properties immediately became apparent—including the fact that entanglement and polarization stood in a clear relationship with one another.

""This was something that hadn't been shown before, but that becomes very clear once you map light's properties onto a mechanical system,"" said Qian. ""What was once abstract becomes concrete: using mechanical equations, you can literally measure the distance between 'center of mass' and other mechanical points to show how different properties of light relate to one another.""

Clarifying these relationships could have important practical implications, allowing subtle and hard-to-measure properties of optical systems—or even quantum systems—to be deduced from simpler and more robust measurements of light intensity, Qian explained. More speculatively, the team's findings suggest the possibility of using mechanical systems to simulate and better-understand the strange and complex behaviors of quantum wave systems.

""That still lies ahead of us, but with this first study we've shown clearly that by applying mechanical concepts, it's possible to understand optical systems in an entirely new way,"" Qian said. ""Ultimately, this research is helping to simplify the way we understand the world, by allowing us to recognize the intrinsic underlying connections between apparently unrelated physical laws.""

More information: Xiao-Feng Qian et al, Bridging coherence optics and classical mechanics: A generic light polarization-entanglement complementary relation, Physical Review Research (2023). DOI: 10.1103/PhysRevResearch.5.033110 Journal information: Physical Review Research",https://scx2.b-cdn.net/gfx/news/2023/want-to-know-how-light.jpg,https://phys.org/news/2023-08-physicists-year-old-theorem-reveal-properties.html,Science
['George Washington University'],2023-08-21 11:11:02-07:00,Exploring Cosmic Extremes: The Unusual Jet Structure of the Brightest of All Time Gamma-Ray Burst,"Researchers studying GRB 221009A, the Brightest of All Time (BOAT) gamma-ray burst, found its jet exhibited an unusual structure, which may explain its extreme nature and prolonged visible afterglow. These findings could challenge standard theories about gamma-ray bursts and shape future studies.

When astronomers detected the gamma-ray burst known as GRB 221009A on October 9, 2022, they dubbed it the BOAT, or the brightest-of-all-time. Now, months after its initial burst, scientists studying GRB 221009A describe an unusual structure to the jet of material expelled during the explosion that may explain GRB 221009A’s extreme nature and why its afterglow remained visible for so long after the event. Researchers at George Washington University (GW) and collaborating institutions published their findings recently in the journal Science Advances.

Gamma-ray bursts are the most violent and energetic explosions in the Universe, releasing the same amount of energy in just a few seconds that the Sun produces over its entire lifetime. According to scientists, GRB 221009A resulted from the collapse of a massive star into a black hole.

Examining troves of multi-wavelength data from October’s gamma-ray burst, the research team discovered that GRB 221009A’s jet exhibited a narrow core with wide sloping wings. This was different from the types of jets seen in gamma-ray bursts produced by other cataclysmic events and may explain why scientists kept seeing GRB 221009A’s multi-wavelength glow for months after the explosion.



Learn more about GRB’s and the importance of studying them with Brendan O’Connor, GW graduate student, and lead study author. Credit: The George Washington University

“GRB 221009A represents a massive step forward in our understanding of gamma-ray bursts, and demonstrates that the most extreme explosions do not obey the standard physics assumed for garden variety gamma-ray bursts,” Brendan O’Connor, GW graduate student and lead study author, says. O’Connor led the research team that was using the Gemini South Telescope in Chile to observe the event last October. “GRB 221009A might be the equivalent Rosetta stone of long GRBs, forcing us to revise our standard theories of how relativistic outflows are formed in collapsing massive stars.”

The findings will drive future studies of gamma-ray bursts and motivate scientists to develop simulations of gamma-ray burst jet structures.

“For a long time, we have thought about jets as being shaped like ice cream cones,” says Alexander van der Horst, associate professor of physics at GW and study co-author. “However, some gamma-ray bursts in recent years, and in particular the work presented here, show that we need more complex models and detailed computer simulations of gamma-ray burst jets.”

The study, “A structured jet explains the extreme GRB 221009A,” was published in the journal Science Advances.

For more on this study:

Reference: “A structured jet explains the extreme GRB 221009A” by Brendan O’Connor, Eleonora Troja, Geoffrey Ryan, Paz Beniamini, Hendrik van Eerten, Jonathan Granot, Simone Dichiara, Roberto Ricci, Vladimir Lipunov, James H. Gillanders, Ramandeep Gill, Michael Moss, Shreya Anand, Igor Andreoni, Rosa L. Becerra, David A. H. Buckley, Nathaniel R. Butler, Stephen B. Cenko, Aristarkh Chasovnikov, Joseph Durbak, Carlos Francile, Erica Hammerstein, Alexander J. van der Horst, Mansi M. Kasliwal, Chryssa Kouveliotou, Alexander S. Kutyrev, William H. Lee, Gokul P. Srinivasaragavan, Vladislav Topolev, Alan M. Watson, Yuhan Yang and Kirill Zhirkov, 7 June 2023, Science Advances.

DOI: 10.1126/sciadv.adi1405

In addition to O’Connor and van der Horst, several other GW scientists contributed to this study and others related to GRB 221009A, including physics graduate student Michael Moss, Professor Chryssa Kouveliotou, Associate Professor Sylvain Guiriec, and Research Faculty George Younes, Jonathan Granot and Paz Beniamini.” Researchers from the University of Rome also contributed to this study, which was funded by NASA, European Research Council, and Smithsonian Astrophysical Observatory.",https://scitechdaily.com/images/Black-Hole-Drives-Powerful-Jets-of-Particles.jpg,https://scitechdaily.com/exploring-cosmic-extremes-the-unusual-jet-structure-of-the-brightest-of-all-time-gamma-ray-burst/,Science
"['Monisha Ravisetti', 'Astronomy Channel Editor', 'Social Links Navigation']",2023-08-22 18:45:34+00:00,"Supermassive black hole chews up huge star, spits stellar 'guts' into space (video)","On Tuesday (Aug. 22), scientists announced they might have found evidence of the most massive star ever seen ripped apart by a black hole — and the behemoth charged with this crime appears to have literally tossed its stellar victim's insides into the darkness of space.

""We are seeing the guts of what used to be a star,"" Jon Miller of the University of Michigan, who led a study on the findings, said in a statement . ""The elements left behind are clues we can follow to figure out what sort of star met its demise.""

Such elemental analysis led the team to believe that the ravaged star once harbored about three times the mass of our sun, meaning it is only rivaled for its title by a glimmering beast associated with something known as the "" Scary Barbie "" event reported earlier this year. Scary Barbie is the name given to a possible cosmic affair in which a star with a staggering 14 times the mass of our sun was obliterated by a black hole. For context, the sun's mass is 333,000 times that of Earth. But there's considerable uncertainty surrounding the Scary Barbie event, as you'll see below.

The recently studied event, dubbed ASASSN-14li , sounds much more formal than Scary Barbie. And, unlike the Scary Barbie star, there's considerable proof of the ASASSN-14li object's size, thanks to new information gleaned from NASA's Chandra X-ray Observatory and the European Space Agency's XMM-Newton . To be clear, however, ASASSN-14li was first discovered in 2014.

""Observing the destruction of a massive star by a supermassive black hole is spellbinding because more massive stars are expected to be significantly less common than lower-mass stars,"" Enrico Ramirez-Ruiz of the University of California, Santa Cruz, a co-author of the study, said in the statement.

Related: Black hole jet surprises scientists with 'peculiar' radio signal

An illustration of the black hole associated with the studied tidal disruption event. (Image credit: NASA/CXC/M.Weiss)

""These X-ray telescopes can be used as forensic tools in space,"" fellow co-author Brenna Mockler, of Carnegie Observatories and the University of California, Los Angeles, said in the statement.

Events like ASASSN-14li and Scary Barbie, which involve a black hole that terrorizes a star, are called tidal disruption events, or TDEs. According to the press release, as a black hole's gravitational forces start impacting a misfortunate star that got too close, a flare emitting optical, ultraviolet and X-ray wavelengths is sent out. This flare happens in conjunction with the star's debris heating up.

So, the researchers employed their two powerful instruments to study those TDE-rooted wavelengths and figure out the concentrations of elements surrounding the black hole in ASASSN-14li, which sits some 280 million light-years from Earth. In doing so, they parsed the ratio of nitrogen to carbon present at the cosmic crime scene with stunning detail.

And most importantly, that observed ratio seemed to be in line with what's expected to lie within the interior of a star about three times more massive than the sun, Mockler explained.

From there, the team reasoned that what they've been studying is actually the ""guts"" of a doomed star with those dimensions, caught in the grips of a supermassive black hole.

These findings contrast with previous work, published in 2017, which suggested the star in ASASSN-14li held something like 0.6 times the mass of our sun. In fact, some other studies, the team points out, even suggested the gas surrounding ASASSN-14li's black hole wasn't associated with a single star at all, but rather stemmed from a bunch of eruptions spit out from the void itself.

""ASASSN-14li is exciting because one of the hardest things with tidal disruptions is being able to measure the mass of the unlucky star, as we have done here,"" Ramirez-Ruiz said.

Scientists used an X-ray spectrum from Chandra to probe the elements contained in this wind, including the detection of nitrogen. The X-ray data indicates that the star in ASASSN-14li was about three times the mass of the sun, making it one of the largest stars ever known to be destroyed in a TDE. (Image credit: NASA/CXC/Univ of Michigan/J. Miller et al)

But, perhaps Scary Barbie's star will live up to its wrestler-sounding name and eventually take the cake. Right now, the only evidence we have of this hefty stellar object comes from the brightness of its flare, not exactly the chemical composition of it. Maybe best to live in bliss, assuming the world in which gargantuan black holes rip apart 14-solar-mass stars may not be the one we're in.",https://cdn.mos.cms.futurecdn.net/TbiUWvAwrUxKVot7DQuMDD-1200-80.jpg,https://www.space.com/supermassive-black-hole-giant-star-guts-tidal-disruption-event,Science
[],,A giant black hole destroys a massive star,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

This release features an artist's illustration of red stellar debris swirling around a giant, spherical black hole. The debris field represents the remains of a star with three times the mass of our Sun, which was ripped apart by the black hole's immense gravity. This tidal disruption event is known as ASASSN-14li. Its aftermath was studied by NASA's Chandra X-ray Observatory, ESA's XMM-Newton, and other telescopes. At the center of the illustration is the spherical black hole, half-submerged in the debris field, which resembles the top half of a jet black ball. The ball sits at the core of the disk-shaped debris field, which is composed of distinct orange and red rings. A long, wide, ribbon of red cloud, representing part of the star's residual gas, enters the illustration at our lower left corner. This ribbon of red gas sweeps toward our center right across the black, starry sky. There, the gas curves back to the left, behind the black hole. Drawn in by gravity, the ribbon of gas encircles the ringed disk of brick red and golden orange stellar debris. This debris orbits, and eventually falls into, the black hole. Faint blue mist appears to radiate from the black hole and the orbiting stellar debris field. This mist represents the portion of stellar gas driven away from the ringed disk by a wind. Credit: NASA

Astronomers have made a thorough forensic study of a star that was torn apart when it ventured too close to a giant black hole and then had its insides tossed out into space.

NASA's Chandra X-ray Observatory and ESA's XMM-Newton studied the amount of nitrogen and carbon near a black hole known to have torn apart a star. Astronomers think these elements were created inside the star before it was ripped apart as it neared the black hole.

""We are seeing the guts of what used to be a star,"" said Jon Miller of the University of Michigan who led the study. ""The elements left behind are clues we can follow to figure out what sort of star met its demise.""

Astronomers have found many examples of ""tidal disruption events"" in recent years, where the gravitational forces from a massive black hole destroy a star. This causes a flare, often seen in optical and ultraviolet light and X-rays, as the star's debris is heated up. This event, called ASASSN-14li, stands out for several reasons. Credit: NASA

At the time of discovery in November 2014 it was the closest tidal disruption to Earth (290 million light-years) discovered in about a decade. Because of this proximity, ASASSN-14li has provided an extraordinary level of detail about the destroyed star. Miller's team applied new theoretical models to make improved estimates, compared to previous work, of the amount of nitrogen and carbon around the black hole.

""These X-ray telescopes can be used as forensic tools in space,"" said co-author Brenna Mockler of Carnegie Observatories and the University of California, Los Angeles. ""The relative amount of nitrogen to carbon that we found points to material from the interior of a doomed star weighing about three times the mass of the sun.""

The star in ASASSN-14li is therefore one of the most massive—and perhaps the most massive—that astronomers have seen ripped apart by a black hole to date.

""ASASSN-14li is exciting because one of the hardest things with tidal disruptions is being able to measure the mass of the unlucky star, as we have done here,"" said co-author Enrico Ramirez-Ruiz of the University of California, Santa Cruz. ""Observing the destruction of a massive star by a supermassive black hole is spellbinding because more massive stars are expected to be significantly less common than lower-mass stars.""

Narrow, 2.5 Å slices of the XMM-Newton spectra of ASASSN-14li shown in Figure 1. The RGS1 spectrum is shown in black; the RGS2 spectrum in gray. Both spectra are shifted to the host frame. The model in blue is XMMs with solar abundances; the model in red is XMMt with thawed N and C abundances, giving [N/C] ≥ 2.4. The left panel centers the H-like N vii line at 24.78 Å, the middle panel centers the He-like N vi line at 28.78 Å, and the right panel centers the H-like C vi line at 33.73 Å. Credit: The Astrophysical Journal Letters (2023). DOI: 10.3847/2041-8213/ace03c

Earlier this year, another team of astronomers reported the ""Scary Barbie"" event where they estimated a star with about 14 times the mass of the sun was destroyed by a black hole. However, this has not yet been confirmed as a tidal disruption, with the estimate of the star's mass mainly based on the brightness of the flare, not on a detailed analysis of material around the black hole as with ASASSN-14li.

Another exciting aspect of the ASASSN-14li result is what it means for future studies. Astronomers have seen moderately massive stars like ASASSN-14li's in the star cluster that contains the supermassive black hole in the center of our galaxy. Therefore, the ability to estimate stellar masses of tidally disrupted stars potentially gives astronomers a way to identify the presence of star clusters around supermassive black holes in more distant galaxies.

Until this study there was a strong possibility that the elements observed in X-rays might have come from gas released in previous eruptions from the supermassive black hole. The pattern of elements analyzed here, however, appears to have come from a single star.

Previous work published in 2017 by Chenwie Yang from the University of Science and Technology in Hefei, China, used ultraviolet data from NASA's Hubble Space Telescope to show that there is enhanced nitrogen compared to carbon in ASASSN-14li, but by a smaller amount than Miller's team found using X-ray data. Those authors found the star to be only more massive than 0.6 times that of the sun.

The work is published in The Astrophysical Journal Letters.

More information: Jon M. Miller et al, Evidence of a Massive Stellar Disruption in the X-Ray Spectrum of ASASSN-14li, The Astrophysical Journal Letters (2023). DOI: 10.3847/2041-8213/ace03c Journal information: Astrophysical Journal Letters

Provided by NASA",https://scx2.b-cdn.net/gfx/news/hires/2023/a-giant-black-hole-des.jpg,https://phys.org/news/2023-08-giant-black-hole-destroys-massive.html,Science
['Mrigakshi Dixit'],2023-08-23 09:13:53+00:00,Scientists find colossal star torn apart by giant black hole,"Certain massive stars meet their stellar demise explosively, exploding as a bright supernova. In contrast, smaller and medium-mass stars conclude their lives by shedding material, collapsing, and cooling into a compact core.

Nevertheless, a subset of stars faces unfortunate fates as they approach immense cosmic entities—black holes. This close encounter tears the star apart, ultimately being devoured by a voracious black hole.

This violent act is known as a tidal disruption event (TDE), in which a black hole gobbles a doomed star that ventures too close. The entire act is highly influenced by the tremendous gravitational forces of a supermassive black hole lurking at the center of galaxies.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/23/image/jpeg/athi9GR6sQaoMtZ0bkdmjOQipVvPDaVFQAz1vmTs.jpg,https://interestingengineering.com/science/nasa-esa-chandra-star-supermassive-black-hole,Science
[],,"Black hole tears apart huge star, tosses 'guts' into space",,https://i.ytimg.com/vi/75ItUTfRn6A/maxresdefault.jpg,https://www.youtube.com/watch?v=75ItUTfRn6A,Science
[],,Yahooist Teil der Yahoo Markenfamilie,,https://s.yimg.com/oa/build/images/favicons/yahoo.png,,Science
['Bob Yirka'],,Simulations suggest some black holes could be moving at nearly one-tenth the speed of light,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Display of peak velocity vs. γv and spin for merging holes. Credit: Physical Review Letters (2023). DOI: 10.1103/PhysRevLett.131.071401

A pair of astrophysicists at the Rochester Institute of Technology has found via simulations that some black holes might be traveling through space at nearly one-tenth the speed of light. In their study, reported in Physical Review Letters, James Healy and Carlos Lousto used supercomputer simulations to determine how fast black holes might be moving after formation due to a collision between two smaller black holes.

Prior research has shown that it is possible for two black holes to smash into each other. And when they do, they tend to merge. Mergers generate gravitational waves, and an ensuing recoil can occur in the opposite direction, similar to the recoil of a gun. The energy of that recoil can send the resulting black hole hurtling through space at incredible speeds.

Prior research has suggested such black holes may reach top speeds of approximately 5,000 km/sec. In this new effort, the researchers took a closer look at black hole speeds to determine just how fast they might travel after merging.

To that end, the researchers created a mathematical simulation. One of the main data points involved the angle at which the two black holes approached one another prior to merging. Prior research has shown that for all but a direct head-on collision, there is likely to be a period of time when the two black holes circle each other before merging.

The researchers ran their simulation on a supercomputer to calculate the results of merging by black holes that approach each other from 1,300 different angles, including direct collisions and close flybys.

They found that under the best-case scenario, grazing collisions, it should be possible for a recoil to send the merged black hole zipping through space at approximately 28,500 kilometers per second—a rate that would send it the distance between the Earth and the moon in just 13 seconds.

© 2023 Science X Network",https://scx2.b-cdn.net/gfx/news/2023/simulations-suggests-s.jpg,https://phys.org/news/2023-08-simulations-black-holes-one-tenth.html,Science
"['Anna Demming', 'Live Science Contributor', 'Social Links Navigation']",2023-08-22 20:18:20+00:00,Newly discovered black hole 'speed limit' hints at new laws of physics,"Researchers have identified a new speed limit for the universe’s most extreme collisions. According to a study published in the journal Physical Review Letters , the ""maximum possible recoil velocity"" for colliding black holes exceeds a whopping 63 million mph (102 million km/h) — about one-tenth the speed of light . This peak occurs when the collision conditions are at the tipping point between the two black holes either merging together or scattering apart as they approach each other, according to the study authors.

Next, the researchers hope to mathematically prove that this velocity cannot be exceeded using Einstein's equations for relativity , posing potential implications for the fundamental laws of physics.

""We are just scratching the surface of something that could be a more universal description,"" study co-author Carlos Lousto , a professor of mathematics and statistics at the Rochester Institute of Technology (RIT) in New York, told Live Science. This newly discovered speed limit could be part of a larger set of physical laws that affect everything ""from the smallest to the largest objects in the universe,"" Lousto said.

Related: 'Runaway' black hole the size of 20 million suns caught speeding through space with a trail of newborn stars behind it

Quakes in the fabric of space-time

When two black holes pass close by each other, they will either merge or swerve around their common center of mass before flying apart. Whether the black holes fly apart or spiral into each other depends on their separation at the point of nearest approach.

To identify the maximum possible recoil speed of black holes flying apart, Lousto and study co-author James Healy , a research associate in the RIT School of Mathematics and Statistics, used supercomputers to run numerical simulations. These calculations stepped through the equations of general relativity describing how two interacting black holes will evolve. Lousto explained that although people began trying to solve these equations numerically more than 50 years ago, numerical techniques for predicting the size of gravitational waves from such collisions were not developed until 2005 — just 10 years before gravitational waves themselves were detected for the first time by the Laser Interferometer Gravitational-Wave Observatory (LIGO).

The James Webb Space Telescope observes two galaxies with supermassive black holes at their centers in the act of merging. (Image credit: ESA)

Since then, LIGO has observed nearly 100 black hole collisions . Comparing the data of one such collision with numerical relativity data revealed an ""eccentric,"" or elliptical, black hole trajectory. Previously, scientists thought black holes approaching each other would spiral toward each other in near-circular orbits, Lousto said. The discovery of elliptical orbits broadened the range of possible collision events, and prompted them to look for extreme collision scenarios. ""What we wanted to do is kind of push the limits of these collisions,"" said Lousto.

Lousto and Healy looked at how adjusting four parameters affected the outcome of gravitational engagement between two black holes: the initial momenta of the black holes, the separation between them at the point of closest approach, the orientation of any rotation the black hole might have around its own axis, and the magnitude of that rotation.

By running 1,381 simulations — each of which took two to three weeks — the researchers found a peak in the possible recoil velocities for black holes with opposite spins grazing past each other. While black holes give out gravitational radiation in all directions, the opposing spins distort this radiation, creating a thrust that adds to the recoil velocity.

""The recoil of black holes after they merge is a critical piece of their interaction,"" Imre Bartos , Associate Professor in the Physics Department at the University of Florida, told Live Science via email. (Bartos was not involved in the new study). This interaction is especially significant for places in the universe with a high density of black holes, since large recoil kicks might expel a remnant black hole from the region altogether.

""As with every limiting theoretical quantity, it will be interesting to see whether nature exceeds this in some situation that could signal deviations from our understanding of how black holes work,"" Bartos added.

Related: Could a black hole devour the universe?

An illustration of two supermassive black holes about to collide as gravitational waves spill into space. (Image credit: Getty)

New fundamental physics

According to Lousto, the ""tipping point"" that determines whether two colliding black holes will merge or recoil is open to a bit of variability in the black holes' orbits. Because of this, Lousto likens this interaction to a smooth phase transition, like the second-order phase transitions of magnetism and superconductivity , as opposed to the explosive first-order phase transitions of heated water, for example, where a finite amount of latent heat is absorbed before it all boils. The researchers also glimpsed what might resemble the scaling factors characteristic of these phase transitions, although further high-resolution simulations are needed to identify these definitively.

Nonetheless, these aspects of the results hint at the possibility of ""an overarching principle"" that applies across scales from atoms to colliding black holes, Lousto said.

What is more, while marrying the two main pillars of fundamental physics — general relativity for gravity and quantum theory for the other fundamental forces — remains elusive, descriptions of black holes are closely tied to several theories that have opened chinks in the barriers between the two.

""This is far from rigorous proof,"" Lousto said. ""But there is a line that deserves further research that maybe someone else or ourselves can make something of.""",https://cdn.mos.cms.futurecdn.net/yscm3ideeLA8cC7gb5CdAH-1200-80.jpg,https://www.livescience.com/physics-mathematics/newly-discovered-black-hole-speed-limit-hints-at-new-laws-of-physics,Science
['Michelle Starr'],2023-08-22 02:41:35+00:00,"Zooming Black Holes Can Reach ~10% The Speed of Light, Scientists Say","Black holes could be right now zooming through the Universe at astonishing speeds just under 10 percent of the speed of light.

Based on simulations of collisions between these extreme objects, that's the maximum velocity black holes can attain following an energetic collision.

That's way faster than previous calculations, suggesting that, while we still have a lot to learn about how black holes collide, we're getting closer to understanding these violent events and their aftermaths.

""We have been able to provide an accurate estimate of the ultimate recoil, product of the high energy collision of two black holes,"" write researchers James Healy and Carlos Lousto of the Rochester Institute of Technology.

""Extrapolation to extreme spins have led us to estimate the value of 28,562±342 kilometers per second for the ultimate recoil, placing thus a bound for it of below 10 percent the speed of light.""

frameborder=""0″ allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"" allowfullscreen>

When two black holes merge, the end product doesn't necessarily end up just sitting occupying the original galactic orbital position as the binary. The collision, depending on its energy, can produce a recoil that ""kicks"" the final black hole – the product of the original two – off on a new trajectory and velocity.

This occurs when the gravitational energy is unevenly distributed, with more emitted in one direction – the result of unequal masses, or spins, or both, in the pre-merger pair of black holes.

Previous estimates put the maximum velocity that could be reached from this effect at around 5,000 kilometers (3,107 miles) per second with respect to its point of origin.

To date, one speeding black hole has been detected that scientists think was the product of a recoil kick. It's traveling at around 1,542 kilometers per second. But defining the limitations of the process can help astronomers figure out how frequently it happens.

This is crucial information for black hole science. For instance, we have detected black holes that are more massive than theory suggests they should be.

A high number of black holes zipping around after being yeeted in a collision could explain it. More black holes moving around raises the chances of collisions, which could produce black holes more massive than the core-collapse mass limit.

Healy and Lousto used a supercomputer to perform 1,381 full numerical simulations of collisions between two equal-mass black holes with opposite spins pointing along their orbital plane.

This is how they got their maximum velocity: 28,562 kilometers (17,748 miles) per second. That's over 100 million kilometers per hour. Escape velocity for an object speeding through the Milky Way from the solar neighborhood is 497 kilometers per second.

The fastest object ever built by humans is the Parker Solar Probe, which reached 163 kilometers per second in 2021.

So black holes in optimal collision conditions? Pretty danged fast. Luckily, the exact scenario used by the researchers is fairly unlikely to happen; but discovering extreme limitations defines the arena for future studies.

That's somewhat comforting to know, actually. A study a few years ago found that there could be hundreds of black holes punted by a recoil kick zooming around the Milky Way even as you read these words.

If they're traveling a little more slowly, the notion seems a little less intimidating (even though they're not likely to smack into us anyway).

Healy and Lousto also noted that the spin and orientation of the black holes in their simulation was critical to the resulting kick velocity. They plan to explore the role of spin in finer detail in a future paper.

The research has been published in Physical Review Letters.",https://www.sciencealert.com/images/2023/08/black-hole-rogue.jpg,https://www.sciencealert.com/zooming-black-holes-can-reach-10-the-speed-of-light-scientists-say,Science
['Ashley Palya'],2023-08-22 17:01:53+00:00,Scientists reveal ‘exact speed of black holes’ zooming around universe – ‘faster & more destructive than first thought’,"BLACK holes can swarm through the universe way faster than scientists originally predicted following a recent study.

Scientists found that black holes can move just under 10 percent the speed of light which proved there is much more to learn about the mysterious energy voids.

3 The 10 percent of the speed of light or 17,748 miles per second speed comes right after two separate black holes merge together Credit: Getty

3 Scientists did tons of numerical simulations to determine the maximum speed of black holes Credit: Healy & Lousto, Phys. Rev. Lett., 2023

The discovery was determined after an experiment “performed a series of 1381 full numerical simulations of high energy collision of black holes to search for the maximum recoil velocity after their merger,” per the study published on August 18 in APS journal.

The 10 percent of the speed of light or 17,748 miles per second speed comes right after two separate black holes merge together.

It was also determined that 10 percent of the speed of light is also the maximum velocity they can reach.

""We have been able to provide an accurate estimate of the ultimate recoil, product of the high energy collision of two black holes,"" lead researchers in the study James Healy and Carlos Lousto of the Rochester Institute of Technology said, per Science Alert.

""Extrapolation to extreme spins has led us to estimate the value of 28,562±342 kilometers per second for the ultimate recoil, placing thus a bound for it of below 10 percent the speed of light.""

The high speed is created by a “recoil that kicks the final black hole” - leaving a final powerful black hole.

Previously, it was estimated that when this occurs black holes would only reach a maximum speed of just 3,107 miles per second, per the study.

In conclusion, the discovery has led scientists to now know that black holes are much more massive and destructive than they originally thought.

The scientists added that the simulation they created is fairly unlikely to happen but does accurately explain the max level of speed they can reach.",https://www.thesun.co.uk/wp-content/uploads/2023/08/SC-Black-Hole-Speed-Off-Plat-copy.jpg?strip=all&quality=100&w=1920&h=1080&crop=1,https://www.thesun.co.uk/tech/23604106/black-holes-merge-speed-light-universe-faster-destructive/,Science
"['Posted By', 'View Articles']",2023-08-22 11:06:10+00:00,New comet visible to the eye in September 2023?,"Hideo Nishimura of Kakegawa, Japan, was photographing the night sky on August 11 and 12, 2023, when he captured a new comet that now bears his name. Comet C/2023 P1 Nishimura is currently moving in front of the constellation Gemini the Twins, low in the dawn sky. The comet was hiding in the sun’s glare before Nishimura picked it up in his images. It will continue to brighten as it closes in on the sun, bringing it into binocular range. But will it get bright enough to see with the eye alone?

Although estimates indicate that the comet might get bright enough to see without optical aid, at its brightest the comet will be very close to the area of the sky where the sun is. Thus, the comet will probably be difficult to locate against the glare of the sun or daylight. However, during the last days of August and first days of September, we still have opportunities to try to spot the celestial visitor using binoculars, a small telescope, or long-exposure photos, before it gets too close to the sun’s vicinity. And of course, we can always hope for an outburst while it’s still a ways from the sun.

The current observed magnitude is at around 9.2, which means people using telescopes in a dark sky can spot it. Other observations report that the comet’s tail is eight arcminutes long. The comet should continue to brighten and the tail to grow as it nears the sun. The comet will be at its brightest in September when it’s closest to the sun and Earth.

Comet Nishimura is racing toward the sun

By August 15-16, 2023, the comet was already passing Earth’s orbit as it’s approaching the sun. Comet Nishimura is traveling so fast that it will reach Venus’ orbit in just a few days … by August 27, 2023.

Sky enthusiasts can observe the comet with a small telescope during the remaining days of August (see the charts below). It’s best to try to see it now, because it may not survive its passage near the sun. This is due to its extremely close pass to our star. Comet Nishimura will pass closer to the sun than Mercury’s orbit. If it does survive through August, Comet Nishimura should become a binocular object during the first mornings of September. Then, observers with an unobstructed view to the east-northeastern horizon might get good binocular views of Comet C/2023 P1 (Nishimura) around September 10, some 45 minutes before sunrise.

The path of the new comet

With a comet this new, there haven’t been many observations, and the path is still being defined. As of August 21, 2023, NASA/JPL made new orbital calculations that indicate that Comet Nishimura orbits the sun every 202 years, which suggests this is a “local” comet from our solar system and not an interstellar comet.

The closest approach to Earth and the sun have also been updated by a day each. Closest approach to Earth will occur on September 12, 2023, when the comet will pass at 78 million miles (125 million km) from Earth. Perihelion – or closest approach to the sun – will be on September 17, 2023, passing at 27 million miles (43.7 million km) from our star.

Some details may be updated as new observations allow scientists to better refine the comet’s orbit.

Comet Nishimura is taking a tour of the zodiacal constellations. It will move from Gemini into the constellation of Cancer in late August and early September. It will traverse Leo in the middle of September and then visit Virgo in the second half of September.

How bright will the comet be?

It’s always challenging to estimate a comet’s brightness because they’re so unpredictable. While Comet Nishimura could be bright enough to see with the unaided eye, it could also fall apart as it nears the sun. But here’s an approximation of how bright the comet will be on certain dates and where to find it.

Starwalk is estimating the comet to be magnitude 4.9 – within range of the unaided eye – on September 11. On the morning of September 11, you can look for the comet before dawn. The first object you’ll notice in the eastern sky is a crescent moon, followed by brilliant Venus nearby. The comet will be near the pair and close to the star Adhafera (Zeta Leonis) in Leo’s Sickle (backward question mark). Keep in mind that the bright sunlight coming from below the horizon will make spotting anything in the sky incredibly challenging.

The comet’s closest approach to Earth is on September 12, when it’s 0.85 AU away. Around this time, the comet transitions from being a morning object to an evening object. On September 15, the comet will be just 10 arcminutes from the second brightest star in Leo, Denebola. But the pair will also be just 12 degrees from the sun, making it difficult to catch them after sunset before they set themselves.

Starwalk estimates the comet at magnitude 3.2 during perihelion – when the comet is closest to the sun – on September 17. Again, when the comet is bright and close to the sun, it will be difficult to see because it will be close to the sun on the dome of our sky as well.

Maps for new comet C/2023 P1

Saying goodbye to Comet Nishimura

As the comet pulls away from the sun, it will fade in brightness. By mid-October it will be farther from the sun in our sky (20 degrees) but becoming dimmer. It will also be in daylight or below the horizon most of the time. How long can you follow Nishimura as it exits?

Bottom line: A new comet, named Nishimura, may be bright enough to see with the unaided eye in September. Learn how to see it here.

Via NASA

Via MPEC

Via Starwalk",https://earthsky.org/upl/2023/08/comet-and-person-howen-unsplash.jpg,https://earthsky.org/tonight/new-comet-c-2023-p1-nishimura-bright-august-september-october-2023/,Science
[],,Look Up! An 'interstellar comet' is nearing Earth and will never be seen again,"A comet, which has been recently discovered and is moving towards Earth, is likely to have originated from outside our solar system and is expected to get catapulted back into interstellar space after it performs an intense gravitational slingshot around the sun.

However, before the comet's forever departure from our cosmic space, the icy object is likely to turn 100 times brighter which means it is likely to shine like a star in the night sky.

The comet, which has been designated C/2023 P1, was discovered by amateur Japanese astronomer Hideo Nishimura on August 12 while falling towards the heart of the solar system. As per the follow-up observations, the object which has been nicknamed Comet Nishimura has a hyperbolic orbit, as stated by Spaceweather.com.

A hyperbolic orbit is when a cosmic object slingshots around a bigger body. like the sun, providing enough energy to smaller objects to escape the gravitational pull of the larger ones.

The orbit of Comet Nishimura means that this is most probably going to be the comet's first and final trip through the inner solar system.

Comet Nishimura to make its closest approach to Earth on Sept 13

The origin of the comet likely took place outside our start system, which makes it the third known interstellar object ever detected, after 'Oumuamua' - which was speculatively suggested by some astronomers as an alien spacecraft — and Comet 2I/Borisov.

There is also a possibility that the origin of the comet is in the outer reaches of the Oort Cloud, which is a reservoir of comets and other icy objects beyond Neptune's orbit - and has been floating on the solar system's edge for millennia before it got caught in the gravitational pull of the sun.

WATCH | NASA loses contact with Voyager-2, spacecraft is travelling in interstellar space | WION

On September 13, Comet Nishimura will make its closest approach to Earth and will be at its closest proximity to the sun on September 18.

When it will come closer to the sun, the comet will get brighter, with an apparent magnitude ranging between 5 and 3 in the night sky, which will be as bright as a typical star, as per Spaceweather.com.

(With inputs from agencies)

You can now write for wionews.com and be a part of the community. Share your stories and opinions with us here.",https://cdn.wionews.com/sites/default/files/2023/08/22/374772-untitled-design-2023-08-22t163406435.png,https://www.wionews.com/science/interstellar-comet-to-shine-like-a-star-and-become-visible-to-naked-eye-before-leaving-solar-system-627939,Science
"['Dr. Russell Moul', 'Science Writer']",2023-08-22 11:07:09+00:00,"""Ancient Megafauna Were Likely Killed By Human-Set Fires 13,000 Years Ago""","Researchers examining fossilized remains in the La Brea Tar Pit, Southern California, have come to a disturbing conclusion. According to a new, in-depth analysis, changing temperatures and human activity led to more wildfires at the end of the Pleistocene era, which caused the extinction of megafauna species that once thrived in the area. The results are worrying given the increasing number of wildfires blazing across many parts of America and Europe today.

At the end of the last Ice Age (about 13,000 years ago), around two-thirds of the planet’s large mammals outside of Africa disappeared in what probably represents the initial spike in the ongoing extinction processes we are witnessing today.

Advertisement Advertisement

Across the globe, this mass extinction coincided with changes in the climate as well as the arrival of new human colonies. However, despite its significance for the ecosystem of the time (not to mention our understanding of the impacts our current crisis could have), we are still not completely sure what caused this event. This is because we lack reliably dated fossils and a precise chronology that shows when extinctions occurred in relation to environmental and human changes.

“The megafaunal extinction at the end of the Ice Age was the biggest extinction event to happen since an asteroid slammed into Earth and wiped out all the large dinosaurs,” co-author Dr Emily Lindsey, Associate Curator and Excavation Site Director at La Brea Tar Pits, said in a statement. “The problem has been that nobody has been able to determine exactly when most of these big mammals actually disappeared because the fossil record is really spotty. It’s hard to say much about what caused an extinction if you don’t know when it happened.”

To overcome this, Dr Lindsey and colleagues analyzed fossil records from the La Brea Tar Pits that belonged to eight large mammal species, including coyotes, horses, sabertoothed cats, the American Lion, dire wolves, and an ancient camel called a Camelops hesternus. Radiocarbon dating has shown that seven of these species went extinct around 13,000 years ago.

The La Brea Tar Pits are located across 13 acres (5 hectares) of land and are still active – filled with bubbling black asphalt that has risen to the surface from below the Earth. Once upon a time, prehistoric animals who got stuck in this broiling mass would slowly sink and die in it, which allowed their remains to be preserved as asphalt fossils.

Advertisement Advertisement

Although this sucking ooze is deadly for those that get stuck in it, the remains that it holds are invaluable for scientific research. By comparing them with climate, pollen, and fire records from the area, as well as data on human population movement and growth, the researchers were able to rule out some of the competing explanations for the mass extinction. And unfortunately, it’s bad news.

“At the point where we found the human population to really start to increase in North America, we see an interval of profound climatic and ecologic change coupled with unprecedented fire happening right here, and it's in this interval when all of the megafauna species disappear,” Lisa Martinez, a PhD student at UCLA who worked on the study, said.

The research establishes a disastrous chain of ecological connections that involved climate warming, reduction in tree pollen, and an increase in human populations, which culminated in the decline of large herbivores. According to their analysis, the loss of tree pollen also indicated an increase in fires, but the real cause of many fires was linked to human activity.

“When humans arrive we see major changes in the frequency of fires and fire intensity,” Dr Regan Dunn, paleobotanist and Assistant Curator at La Brea Tar Pits, added. “[Ninety-five] percent of the fires we see today are caused by anthropogenic sources from power lines or campfires that have gotten away, from highways or cigarettes or something like that. In a sense, we already know what happened, and what we learned from the past can help inform what will happen in the future and how better to plan to avoid ecosystem collapses.”

Advertisement Advertisement

Regrettably, we now find ourselves bound in the same chain of events that led to this last mass extinction. Human-caused climate change is creating the conditions for prolonged droughts and large mammals are increasingly at risk of dying out. On top of this, wildfires are becoming bigger and more frequent. As such, it is important for us to pay attention to the warnings recovered from the black goop of La Brea Tar Pits. There is still time for us to act, but that window is closing quickly.

The study is published in Science.",https://assets.iflscience.com/assets/articleNo/70350/aImg/70136/la-brea-tar-pits-california-meta.jpg,https://www.iflscience.com/ancient-megafauna-were-likely-killed-by-human-set-fires-13000-years-ago-70350,Science
"['The Conversation', ""View 'S Article Archive""]",2023-08-21 13:55:02+00:00,"Climate change, overpopulation, and wildfires sparked the last mass extinction − can we prevent another?","Over the past decade, deadly wildfires have become increasingly common because of both human-caused climate change and disruptive land management practices. Southern California, where the three of us live and work, has been hit especially hard.

Southern California also experienced a wave of wildfires 13,000 years ago. These fires permanently transformed the region’s vegetation and contributed to Earth’s largest extinction in more than 60 million years.

As paleontologists, we have a unique perspective on the long-term causes and consequences of environmental changes, both those linked to natural climate fluctuations and those wrought by humans.

In a new study, published in August 2023, we sought to understand changes that were happening in California during the last major extinction event at the end of the Pleistocene, a time period known as the Ice Age. This event wiped out most of Earth’s large mammals between about 10,000 and 50,000 years ago. This was a time marked by dramatic climate upheavals and rapidly spreading human populations.

The last major extinction

Scientists often call the past 66 million years of Earth’s history the Age of Mammals. During this time, our furry relatives took advantage of the extinction of the dinosaurs to become the dominant animals on the planet.

During the Pleistocene, Eurasia and the Americas teemed with enormous beasts like woolly mammoths, giant bears and dire wolves. Two species of camels, three species of ground sloths and five species of large cats roamed what is now Los Angeles.

Then, abruptly, they were gone. All over the world, the large mammals that had characterized global ecosystems for tens of millions of years disappeared. North America lost more than 70% of mammals weighing more than 97 pounds (44 kilograms). South America lost more than 80%, Australia nearly 90%. Only Africa, Antarctica and a few remote islands retain what could be considered “natural” animal communities today.

The reason for these extinctions remains obscure. For decades, paleontologists and archaeologists have debated potential causes. What has befuddled scientists is not that there are no obvious culprits but that there are too many.

As the last ice age ended, a warming climate led to altered weather patterns and the reorganization of plant communities. At the same time, human populations were rapidly increasing and spreading around the globe.

Either or both of these processes could be implicated in the extinction event. But the fossil record of any region is usually too sparse to know exactly when large mammal species disappeared from different regions. This makes it difficult to determine whether habitat loss, resource scarcity, natural disasters, human hunting or some combination of these factors is to blame.

A deadly combination

Some records offer clues. La Brea Tar Pits in Los Angeles, the world’s richest ice age fossil site, preserves the bones of thousands of large mammals that were trapped in viscous asphalt seeps over the past 60,000 years. Proteins in these bones can be precisely dated using radioactive carbon, giving scientists unprecedented insight into an ancient ecosystem and an opportunity to illuminate the timing – and causes – of its collapse.

Our recent study from La Brea Tar Pits and nearby Lake Elsinore has unearthed evidence of a dramatic event 13,000 years ago that permanently transformed Southern California’s vegetation and caused the disappearance of La Brea’s iconic mega-mammals.

Sediment archives from the lake’s bottom and archaeological records provide evidence of a deadly combination – a warming climate punctuated by decadeslong droughts and rapidly rising human populations. These factors pushed the Southern California ecosystem to a tipping point.

Similar combinations of climate warming and human impacts have been blamed for ice age extinctions elsewhere, but our study found something new. The catalyst for this dramatic transformation seems to have been an unprecedented increase in wildfires, which were probably set by humans.

The processes that led to this collapse are familiar today. As California warmed coming out of the last ice age, the landscape became drier and forests receded. At La Brea, herbivore populations declined, probably from a combination of human hunting and habitat loss. Species associated with trees, like camels, disappeared entirely.

In the millennium leading up to the extinction, mean annual temperatures in the region rose 10 degrees Fahrenheit (5.5 degrees Celsius), and the lake began evaporating. Then, 13,200 years ago, the ecosystem entered a 200-year-long drought. Half of the remaining trees died. With fewer large herbivores to eat it, dead vegetation built up on the landscape.

At the same time, human populations began expanding across North America. And as they spread, people brought with them a powerful new tool – fire.

Humans and our ancestors have used fire for hundreds of thousands of years, but fire has different impacts in different ecosystems. Charcoal records from Lake Elsinore reveal that before humans, fire activity was low in coastal Southern California. But 13,200 to 13,000 years ago, as human populations grew, fire in the region increased by an order of magnitude.

Our research suggests that the combination of heat, drought, herbivore loss and human-set fires had pushed this system to a tipping point. At the end of this period, Southern California was covered in chaparral plants, which thrive after fires. A new fire regime had become established, and the iconic La Brea megafauna had disappeared.

Lessons for the future

Studying the causes and consequences of the Pleistocene extinctions in California can provide valuable context for understanding today’s climate and biodiversity crises. A similar combination of climate warming, expanding human populations, biodiversity loss and human-ignited fires that characterized the ice age extinction interval in Southern California are playing out again today.

The alarming difference is that temperatures today are rising 10 times faster than they did at the end of the ice age, primarily because of the burning of fossil fuels. This human-caused climate change has contributed to a fivefold increase in fire frequency and intensity and the amount of area burned in the state of California in the past 45 years.

While California is now famous for extreme fires, our study reveals that fire is a relatively new phenomenon in this region. In the 20,000 years leading up to the extinction, the Lake Elsinore record shows very low incidence of any fire even during comparable periods of drought. Only after human arrival does fire become a regular part of the ecosystem.

Even today, downed power lines, campfires and other human activities start over 90% of wildfires in coastal California.

The parallels between the late Pleistocene megafaunal extinctions and today’s environmental crises are striking. The past teaches us that the ecosystems we depend upon are vulnerable to collapse when stressed by multiple intersecting pressures. Redoubling efforts to eliminate greenhouse gas emissions, prevent reckless fire ignitions and preserve Earth’s remaining megafauna can help avert another, even more catastrophic transformation.

This article is republished from The Conversation under a Creative Commons license. Read the original article.

You might also be interested in:",https://studyfinds.org/wp-content/uploads/2021/11/AdobeStock_84850955-scaled.jpeg,https://studyfinds.org/the-last-mass-extinction/,Science
[],,Scientists fear death by wildfires that wiped out ancient mammals,"Could all-consuming wildfires sparked by ancient climate change and human negligence have caused the extinction of thousands of species of large mammals over 13,000 years ago?

New research by a team of California scientists suggests that the answer is yes, and they draw a dangerous parallel between then and now.

Among the myriad chapters of our planet's past, the late Ice Age (Pleistocene era) stands out as a time of profound ecological upheaval, marked by the disappearance of numerous large mammals (megafauna) from diverse regions worldwide.

The cause of this wave of extinctions has long been a subject of intense scientific discourse, with global warming and human interventions emerging as leading contenders.

Yet one phenomenon has been largely ignored. Thirteen millennia ago, a torrent of wildfires swept across California.

View of a wildfire in Aljezur, Portugal, August 7, 2023. (credit: REUTERS/PEDRO NUNES)

In their latest research, published this month in Science, American scholar F. Robin O'Keefe and team used fossil records at California's La Brea tar pits to prove a connection between increased wildfires and the extinction of these large mammals.

According to their report, the Americas and Eurasia teemed with enormous beasts during most of the Ice Age. The great extinction resulted in the loss of more than 70% of mammals in North America that weighed more than 44 kilograms and as many as 90% in Australia.

""At the end of the Pleistocene, most of Earth's large mammals became extinct,"" the authors wrote in their introduction. ""These extinctions occurred at different times globally, resulting in a drastic reorganization of terrestrial ecosystems.

""Despite decades of research on extinction causality, the relative importance of late-Quaternary climate changes and spreading human impacts have been difficult to disentangle because poor chronological resolution in the fossil record has precluded alignment of these rapidly occurring, tightly linked phenomena,” they further explained.

However, the researchers found that some records could offer clues.

They turned to the La Brea Tar Pits in Los Angeles, the world's most extensive collection of ice age fossils. The site's naturally occurring asphalt seeps entrapped and preserved the bones of large mammals from the 50,000 years of the Ice Age - most with their original collagen. The scientists were able to use modern radioactive carbon dating technology to shed new insight into the timing and causes of collapse of the ancient ecosystem.

Specifically, they obtained dates on 172 specimens from seven extinct and one extant species: sabertoothed cat, dire wolf, coyote, American lion, ancient bison, western horse, Harland's ground sloth and yesterday's camel - all of which died off between 10,000 and 15,000 years ago.

""To investigate the potential roles of late-Quaternary environmental change and human activities in driving the observed patterns, we compared our analyses of population structure and megafaunal extirpation against well-resolved regional and continental paleoclimatic proxies, vegetation records, and modeled human demographic growth,"" the authors explained in their abstract. ""We used time-series modeling to investigate the dynamics of ecosystem change and evaluate causal relationships among these different phenomena.""

The modeling found that most large mammals disappeared with a regional ecological shift, including drastically increasing fires.

Now, the scientists have raised a red flag

""The processes that led to this collapse are familiar today,"" warned co-authors and California-based researchers Emily Lindsey, Lisa N. Martinez, and Regan E. Dunn explained in an open-source article on their paper published on The Conversation website.

""Humans and our ancestors have used fire for hundreds of thousands of years, but fire has different impacts in different ecosystems."" The researchers

California warmed by as much as 5.5 degrees Celcius. Then, the ecosystem entered a 200-year-long drought, which led the trees to dry up. At the same time, the human population expanded in the region, and the people lit fires.

""Humans and our ancestors have used fire for hundreds of thousands of years, but fire has different impacts in different ecosystems. Charcoal records from Lake Elsinore reveal that before humans, fire activity was low in coastal Southern California,"" the researchers said in their article. ""But 13,200 to 13,000 years ago, as human populations grew, fire in the region increased by an order of magnitude.

""Our data document a transition from a postglacial megafaunal woodland to a human-mediated chaparral ecosystem in Southern California before the onset of the Younger Dryas,"" they continued. ""This transition began with gradual opening and drying of the landscape over two millennia and terminated in an abrupt (300-year) regime shift characterized by the complete extirpation of megafauna and unprecedented fire activity. This state shift appears to have been triggered by human-ignited fires in an ecosystem stressed by rapid warming, a megadrought, and a millennial-scale trend toward the loss of large herbivores from the landscape. This event parallels processes occurring in Mediterranean ecosystems today.""

They said that by studying what caused extinction at the end of the Ice Age in California, scientists can contextualize the potential impact of today's climate and biodiversity crises.

""The alarming difference is that temperatures today are rising 10 times faster than they did at the end of the ice age, primarily because of the burning of fossil fuels,"" Lindsey, Martinez and Dunn said. ""This human-caused climate change has contributed to a fivefold increase in fire frequency and intensity and the amount of area burned in the state of California in the past 45 years.""

A separate report by the University of California found more than 3,350 fires in 2009 and 2018 in California, 1.4 times more than the per-decade average number of fires between 1979 and 2009.

Most of those fires were caused not only by highly flammable dry grasses, shrubs, and pine needles but by human activities, such as downed power lines, campfires, and more, according to reports.

Lindsey, Martinez, and Dunn said that “the past teaches us that the ecosystems we depend upon are vulnerable to collapse when stressed by multiple intersecting pressures.”

As such, they said, ""redoubling efforts to eliminate greenhouse gas emissions, prevent reckless fire ignitions and preserve Earth's remaining megafauna can help avert another, even more catastrophic transformation.""","https://images.jpost.com/image/upload/f_auto,fl_lossy/c_fill,g_faces:center,h_407,w_690/549029",https://www.jpost.com/environment-and-climate-change/article-755491,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
[],,Space scientist discusses India's moon landing mission,,https://i.ytimg.com/vi/wopdt_KpLVE/maxresdefault.jpg,https://www.youtube.com/watch?v=wopdt_KpLVE,Science
[],,&quot;Chances Of Success High&quot; ISRO Former Scientist YS Rajan on Chandrayaan-3 Landing,"Speaking on landing of Chandrayaan-3 on the moon, Former ISRO Scientist Yagnaswami Sundara Rajan on August 22 said that the chances of success are exceeding high. ""About 80 pc changes are done (in Chandrayaan-3)...They incorporated many things into Chandrayaan-3. Earlier it was seeing only the height when it is landing, called altimeter, now in addition to that they've also added a velocity meter called doppler, so you will know the height and also velocity, so that it can control itself…The chances of success are exceeding high,"" YS Rajan told ANI.",https://c.ndtvimg.com/2023-08/rar63t9_ys-rajan_160x120_23_August_23.jpg,https://www.ndtv.com/video/news/news/chances-of-success-high-isro-former-scientist-ys-rajan-on-chandrayaan-3-landing-719305,Science
[],,Once That 5.47 Is Gone It Goes To The Automatic Landing ...: Dr YS Rajan On Chandrayaan 3's Landing,,https://i.ytimg.com/vi/FcHQu2gf2Vo/maxresdefault.jpg,https://www.youtube.com/watch?v=FcHQu2gf2Vo,Science
"['Jeff Foust', 'More Jeff Foust']",2023-08-22 21:56:09+00:00,Polaris Dawn mission likely to slip to 2024,"WASHINGTON — The billionaire backing a series of private astronaut missions with SpaceX says the first of those flights will likely be delayed to some time in 2024.

In a recent interview with the CNBC Manifest Space podcast, Jared Isaacman said preparations were continuing for Polaris Dawn, the first of three missions of his Polaris program announced in early 2022. That mission will fly Isaacman and three others on a Crew Dragon spacecraft that will spend several days in low Earth orbit.

“We’re making a lot of progress. We’re still hoping for the end of the year, but I suspect it will probably slip into the beginning of next year,” he said in the brief interview. “This should be expected. It’s a test and development program.”

When Isaacman and SpaceX announced Polaris in February 2022, they scheduled the Polaris Dawn mission for as soon as the fourth quarter of 2022. However, by last October the launch slipped to at least March 2023, which the program attributed to readiness of the vehicle and training as well as the schedule of other Crew Dragon missions.

In a talk at a conference in February, Isaacman said he expected Polaris Dawn to launch this summer. “We’re now just months away from flying,” he said then. The program has not provided any formal schedule updates about the mission since then, with the most recent update on the program’s website published in May.

A delay beyond the end of this year would likely push Polaris Dawn later than the beginning of 2024. Axiom Space is planning its third private astronaut mission to the International Space Station in January 2024, followed as soon as a month later by NASA’s Crew-8 mission to the station, both using Crew Dragon spacecraft. While Polaris Dawn is not going to the ISS, availability of Crew Dragon spacecraft and other resources needed for crewed missions could delay Polaris Dawn to later in the year.

Isaacman, in the podcast interview, suggested the delays were linked to the development of a new spacesuit required for a spacewalk, the first by a private astronaut mission, planned for Polaris Dawn.

“We’ve had a little bit more free time this summer than we probably would have expected,” he said, which he attributed to the timing of spacesuit development and training. That effort “doesn’t always sync up, so we’ve had a little more free time with family and work this summer.”

That new suit, billed as the first new spacesuit developed in the United States in four decades, is critical to future human activities on moon and Mars, he argued. “We’re going to need spacesuits that don’t cost hundreds of millions of dollars in order to do that. We’re pretty excited because the suit that we are testing out, the evolution of it someday could be very well worn by people that are walking on the moon or Mars.”

However, it’s not clear when that SpaceX-developed spacesuit would next be used. NASA awarded contracts in June 2022 to Axiom Space and Collins Aerospace for development of spacesuits to both replace those currently used on the ISS as well as for future Artemis lunar landing missions. While SpaceX’s Starship will be used for at least the Artemis 3 and 4 missions to land on the lunar surface, those missions will use spacesuits from Axiom or Collins.

Polaris Dawn is the first of three missions in a program that will culminate in the first crewed launch of Starship. That final mission is “pretty far out there,” Isaacman said, noting that SpaceX still had a lot of progress to make on Starship before flying people on it. “Clearly it’s going to need a lot more launches and that design is going to have to evolve to the extent that it’s going to be safe for human spaceflight.”

Since the announcement of the Polaris program, one option that has emerged for the second mission is a Crew Dragon flight to reboost the Hubble Space Telescope. Isaacman participated in a NASA briefing last September that announced an unfunded Space Act Agreement between NASA and SpaceX to study such a mission.

NASA has not disclosed the outcome of that effort, but confirmed in May that the study was complete and that the agency was “internally evaluating the findings and working to determine next steps.” The agency also received eight responses to a separate request for information from companies developing satellite servicing technologies that could reboost Hubble.

Isaacman said on the podcast that the ball was in NASA’s court about a Crew Dragon mission to Hubble. “There are obviously a lot of important things that being discussed right now at NASA, but hopefully they will get around to this proposal and perhaps we’ll have a pretty exciting Polaris 2 to follow,” he said.

At a NASA Science Mission Directorate town hall meeting July 27, Mark Clampin, director of NASA’s astrophysics division, said NASA was still evaluating options for raising Hubble’s orbit. “Part of that review means looking at the capabilities of the Hubble Space Telescope itself and how this would work,” he said, “and make sure the telescope itself remains safe during the process.” He did not state when that review would be completed.",https://spacenews.com/wp-content/uploads/2022/02/polarisdawn.jpg,https://spacenews.com/polaris-dawn-mission-likely-to-slip-to-2024/,Science
[],,The expanding Universe: 100 years later,"From the moment in 1915 that Einstein released his theory of General Relativity out into the world, he knew he had a Universe-sized problem to reckon with. His new theory of gravitation was incredible in many ways. It reproduced all of its predecessor’s (Newtonian gravity) successes, from laboratory to Solar system scales. It successfully explained puzzles, like the precession of Mercury’s orbit, that Newtonian gravity could not. And it made several new predictions, like the deflection of starlight by massive objects, that differed from Newton’s old theories. By replacing Newton’s inverse square force law acting instantaneously between any two masses in the Universe with an underlying curved spacetime that affected and was affected by masses and all forms of energy, Einstein knew he was fomenting a scientific revolution.

But Einstein himself had a doubt about what he published. He knew, after all, that the Universe was full of matter: stars were present everywhere, in all directions, for as far as astronomers could see. And he knew that the positions of these stars seemed to be stable over time, moving slowly and randomly relative to ourselves and one another. But his own theory of gravitation, if he worked out the details, showed that if you had a collection of masses randomly distributed throughout the space it occupied, the underlying spacetime would be unstable. No matter what you did, it would inevitably collapse.

Originally a paradox to Einstein, this would become the starting point from which the expanding Universe was born. Here’s the story of how, 100 years ago, we took the critical step to get there.

In a Universe that isn’t expanding, you can fill it with stationary matter in any configuration you like, but it will always collapse down to a black hole. Such a Universe is unstable in the context of Einstein’s gravity, and must be expanding to be stable, or we must accept its inevitable fate. Credit: E. Siegel/Beyond the Galaxy

Einstein’s big worry, although he didn’t realize it at the time, is actually a feature of General Relativity. If you have masses placed down all throughout your initially static spacetime, those masses will curve your spacetime’s fabric and cause it to evolve in a specific way: by collapsing. This isn’t the same type of gravitational collapse you’d get in Newtonian gravity, where the masses simply attract one another and accelerate toward one another until they meet. Instead, the fabric of spacetime itself evolves by collapsing into itself, drawing the various masses into a central point that becomes a singularity: where space and time end in a state of infinite density.

In order to prevent this from happening, Einstein turned to the only place he could think of: the cosmological constant. The only term you’re allowed to add into Einstein’s field equations, in General Relativity, without destroying the theory’s successes is a constant term that affects the underlying metric: i.e., the structure of spacetime itself. That term, known as a cosmological constant, could counteract the gravitational collapse that would occur in an otherwise matter-rich Universe, enabling spacetime to remain static and stable. It was an ugly fix with no underlying physical motivation, but Einstein recognized that a collapsing Universe would contradict the already-existent observations, and so he put it in to make his theory consistent with the Universe as he knew it.

A mural of the Einstein field equations, with an illustration of light bending around the eclipsed sun, the observations that first validated General Relativity back in 1919. The Einstein tensor is shown decomposed, at left, into the Ricci tensor and Ricci scalar, with the cosmological constant term added in after that. Novel tests of new theories, particularly against the differing predictions of the previously prevailing theory, are essential tools in scientifically testing an idea. Credit: Vysotsky / Wikimedia Commons

Other theorists, however, were less forgiving. Many pointed out that if the cosmological constant weren’t precisely tuned in a way that exactly counteracted the rate at which gravitation would draw spacetime into itself, things would either collapse or fly apart. That if there were any initial gravitational imperfections — if the masses weren’t perfectly uniformly distributed at the start — those imperfections would lead to the same consequence: things either collapsing or flying apart.

In 1917, Willem de Sitter considered the behavior of a Universe with only a cosmological constant (and no matter) in it, and discovered that it didn’t just expand, but expanded relentlessly: at an exponential rate. If you took two points separated by a certain distance, then after a finite amount of time, that distance would double, and then after that same amount of time elapses again, the distance between those points would double again, and so on and so on.

On the theoretical front, a huge advancement would come in 1922: when Alexander Friedmann calculated the behavior of a Universe that had, on average, equal amounts of energy distributed uniformly throughout it.

A photo of Ethan Siegel at the American Astronomical Society’s hyperwall in 2017, along with the first Friedmann equation at right. The first Friedmann equation details the Hubble expansion rate squared on the left hand side, which governs the evolution of spacetime. The right side includes all the different forms of matter and energy, along with spatial curvature (in the final term), which determines how the Universe evolves in the future. This has been called the most important equation in all of cosmology and was derived by Friedmann in essentially its modern form back in 1922. Credit: Harley Thronson (photograph) and Perimeter Institute (composition)

What Friedmann found — irrespective of whether that energy was a cosmological constant, matter, radiation, or any other type of energy — is that a “static” universe was an inherently unstable condition. If your Universe were equally filled everywhere with any form of energy, it must either expand or contract, with no exceptions.

But how did those theoretical predictions line up with what astronomers were observing when it came to the actual Universe?

The stars didn’t seem to hold a clue, as they appeared roughly uniformly distributed, with only small motions relative to ourselves and one another. But out among the stars were nebulae: fuzzy, faint, extended objects in the sky. Some of these nebulae, upon close inspection, were collections of stars, such as open star clusters or globular star clusters. Others were individual stars in the process of dying or evolving: the planetary nebulae. But a class of these faint, fuzzy objects — the spiral and elliptical nebulae — stood out for being different than the rest. Whereas these other objects moved only at a few tens of kilometers-per-second relative to our own Solar System, spiral and elliptical nebulae appeared to be moving much, much faster.

Only by breaking the light from a distant object up into its component wavelengths and by identifying the signature of atomic or ionic electron transitions that can be linked to a redshift, and hence, the expanding Universe, can a confident redshift (and hence, distance) be arrived at. This was part of the key evidence uncovered supporting the expanding Universe. Credit: Vesto Slipher, 1917, Proc. Amer. Phil. Soc.

One key set of observations came from Vesto Slipher, who was a pioneer in leveraging the astronomical technique of spectroscopy. All objects that emit light do so over a variety of wavelengths: the total light they emit is the sum of light of all different wavelengths/colors added together. What spectroscopy involves is taking that panchromatic light and breaking it up into all of the separate wavelengths that compose it: for any individual object we’re interested in.

Slipher, in the 1910s, began taking the spectrum of a wide variety of objects, including many of the spiral and elliptical nebulae found throughout the sky. What he found was shocking to many.

These spirals and ellipticals, instead of moving at a few tens of kilometers-per-second, moved at hundreds or even thousands of kilometers-per-second.

Although a few of them were blueshifted, indicating a motion toward us, most of them were redshifted, indicating a motion away from us.

And that the smaller the spiral or elliptical nebula appeared, the greater the magnitude of its motion, and the more likely it was to be redshifted rather than blueshifted.

It was suggestive evidence — but not conclusive proof — that these spirals and ellipticals were objects well beyond and outside our own home galaxy, the Milky Way. If so, perhaps it meant that the Universe wasn’t static, after all.

The Hooker Telescope: the largest and most powerful telescope in the world from 1917–1949. This telescope was 100 inches (2.54 meters) in diameter, making it larger than the primary mirror on the Hubble Space Telescope today. It held the crown for largest telescope in the world until the Hale telescope, double the diameter of this one, was finally completed in 1949, 21 years after work was begun on it. This was the one telescope, more than any other, that was the key to unlocking the expanding Universe. Credit: H. Armstrong Roberts/ClassicStock

The very first key piece of evidence that would take the notion of the expanding Universe from a theoretical curiosity with speculative observational evidence to the leading description of the Universe we inhabited arrived quite by surprise in 1923: one year after Friedmann’s theoretical tour de force and just a few years after Slipher’s key spectroscopic observations.

That evidence would come from Edwin Hubble and the most powerful telescope of those times: the 100-inch Hooker telescope. With a new, larger telescope than ever before at his disposal, Hubble could achieve greater resolution and gather more light than ever before, making it possible to tease out fainter, more distant details about objects than ever before.

One of Hubble’s early projects was categorizing novae: luminous flare-ups that occur atop the corpses of old, deceased stars. When enough matter accumulates on these stellar remnants, a brief burst of nuclear fusion occurs, causing a rapid brightening and a more gradual fadeaway thereafter. Hubble was looking for novae in the closest, largest spiral nebula to us: Andromeda. In 1923, over the course of a few nights, Hubble found what looked to be a nova in Andromeda in one location, and then he found a second, and then a third. And then, the unimaginable occurred.

Perhaps the most famous photographic plate in all of history, this image from October of 1923 features the great nebula (now galaxy) in Andromeda along with the three novae that Hubble observed within them. When a fourth brightening event happened in the same location as the first, Hubble recognized this was no nova, but a Cepheid variable star. The “VAR!” written in red pen was Hubble having a spectacular realization. Credit: Carnegie Observatories

Did you guess, “What, he found a fourth nova?”

If so, it’s a good guess; in fact, it’s the same guess Hubble had as to what he expected to find. But that fourth nova — or rather, the fourth major brightening event — that he saw, somehow, occurred in the exact same position that the first nova did. Even back in 1923, Hubble knew that was impossible; it must take novae centuries or even millennia to accumulate enough matter to flare like they do. While in modern times, we’ve observed a few recurring novae with timespans of decades or even just a handful of years, almost all of them are one-and-done on human timescales, and none recur on timescales of less than a year.

But what Hubble found was that this point of light in Andromeda didn’t just brighten a second time, but did so over and over again, with a regular periodicity. We had known about stars like this for a long time: since the late 1800s and the work of Henrietta Leavitt. These stars are known as Cepheid variables, and they drop from a peak brightness to a minimum brightness and then rise again back to the peak, all with a regular period. These bright, blue stars are varying because their outer layers are pulsing, regularly expanding and contracting, and changing temperature and brightness when they do. Every few days, a Cepheid variable star goes from peak brightness to minimum brightness and back again, regularly, in a predictable fashion. What Hubble initially identified as a nova was, in fact, a variable star.

Hubble’s discovery of a Cepheid variable in the Andromeda galaxy, M31, opened up the Universe to us, giving us the observational evidence we needed for galaxies beyond the Milky Way and leading us, in short order, to the discovery of the expanding Universe. Credits: NASA, ESA and the Hubble Heritage Team (STScI/AURA); Illustration via NASA, ESA, and Z. Levay (STScI)

But Leavitt’s work went beyond describing the behavior of a Cepheid; it also suggested a remarkable relationship. Leavitt noticed that the peak brightness of a Cepheid was correlated with how quickly it varied: from peak brightness to minimum brightness and back again. If you measured the period of a Cepheid, you could immediately know — from all the other Cepheids that had been measured — how intrinsically bright it was.

That was all the help Hubble needed to take the next giant leap forward for astronomy: to use the observed brightness of this Cepheid in Andromeda, along with Leavitt’s method for inferring the star’s intrinsic brightness, to determine how far away the star had to be. If you know you’re looking at a 100-Watt light bulb and measure a certain brightness for it, you can infer how far away it is from the brightness you observe. Using that same method, Hubble determined the distance to this star (and therefore, to Andromeda), and determined that it was somewhere close to 1 million light-years away from us: far beyond any of the known stars within the Milky Way. (Modern methods place the distance to Andromeda at about 2.5 million light-years.)

Just like that, Hubble demonstrated that these spirals and ellipticals were located outside of the Milky Way, and even measured the distance to the first one. Using this same method, he realized he could measure the distance to any galaxy in the Universe where his telescope was powerful enough to resolve individual Cepheid variables inside.

When light is emitted from a source, it has a particular wavelength. The longer it must travel through the expanding Universe before being absorbed by an observer, the greater the amount that the wavelength of that light will be redshifted, or stretched to longer values, compared to the wavelength it has when it was emitted. Credit: Ben Gibson/Big Think

If you were alive at that time and were following this saga closely, including:

the theoretical development that a static and stationary universe could not be stable,

Friedmann’s work indicating that a universe filled with “stuff” must be either expanding or contracting,

Slipher’s work indicating that spirals and ellipticals moved at great speeds, with the faintest, potentially most distant spirals and ellipticals showing the greatest recession speeds,

and Hubble’s work, measuring individual stars within a spiral or elliptical to determine their distance,

Travel the Universe with astrophysicist Ethan Siegel. Subscribers will get the newsletter every Saturday. All aboard! Notice: JavaScript is required for this content.

you could’ve been among the first to put these pieces together and conclude, “the Universe is expanding.”

Hubble immediately went to work measuring the Cepheids found within more and more of these spirals and ellipticals, obtaining distance measurements as a result. As one might have expected, the farther away a spiral or elliptical was determined to be, the greater the likelihood you had of finding that it was redshifted at a significant speed. This redshift wouldn’t be due to just a simple motion away from us, but rather — as illustrated above — because the light that this object emitted was getting stretched by the expanding Universe during its journey: from emission at the source to its eventual absorption by astronomers and telescopes here on Earth.

Edwin Hubble’s original plot of galaxy distances versus redshift (left), establishing the expanding Universe, versus a more modern counterpart from approximately 70 years later (right). In agreement with both observation and theory, the Universe is expanding, and the slope of the line relating distance to recession speed is a constant. Credit: E. Hubble; R. Kirshner, PNAS, 2004

Over the next few years, the data to emerge from the Hooker telescope became better and more comprehensive. In 1927, Georges Lemaître became the first to put all of these pieces together in a published work, concluding that the Universe was expanding. In 1928, Howard Robertson independently drew the same conclusion, and Hubble presented evidence for the redshift-distance relation — the key observation behind the expanding Universe — in 1929. Throughout the 1930s, with increasingly better data, more and more scientists abandoned the idea of a static Universe, with Einstein eventually coming around and decrying the insertion of his cosmological constant back in the initial formulation of General Relativity as his “greatest blunder.”

Although the expanding Universe has been confirmed and validated by many lines of evidence, the last key puzzle piece that allowed us to discover it was firmly in place back in 1923: a full 100 years ago as of this year (2023). The underlying fabric of the Universe, spacetime, is not a static entity, but rather it evolves over time, dragging matter and radiation along with it and stretching the wavelength of radiation that passes through it to greater, longer distances. The farther away a galaxy is from us, the greater in magnitude its observed redshift will be. We’ve understood this for a full century now, and all of our other cosmic successes, from the Big Bang to our current ΛCDM paradigm, wouldn’t have been possible without this key piece of early evidence.","https://bigthink.com/wp-content/uploads/2023/08/Hubble-M31-Export.png?resize=1200,630",https://bigthink.com/starts-with-a-bang/expanding-universe-100-years-later/,Science
"['Brian Koberlein', 'Universe Today']",,A new way to measure the expansion rate of the universe: Redshift drift,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Cosmological redshift depends upon a galaxy's distance. Credit: NASA/JPL-Caltech/R. Hurt (Caltech-IPAC)

In 1929 Edwin Hubble published the first solid evidence that the universe is expanding. Drawing upon data from Vesto Slipher and Henrietta Leavitt, Hubble demonstrated a correlation between galactic distance and redshift. The more distant a galaxy was, the more its light appeared shifted to the red end of the spectrum.

We now know this is due to cosmic expansion. Space itself is expanding, which makes distant galaxies appear to recede away from us. The rate of this expansion is known as the Hubble parameter, and while we have a good idea of its value, there is still a bit of tension between different results.

One of the difficulties in resolving this tension is that thus far we can only measure cosmic expansion as it appears right now. This also means we can't determine whether cosmic expansion is due to general relativity or a more subtle extension of Einstein's model. But as powerful new telescopes are built, we might be able to observe the evolution of cosmic expansion thanks to what is known as the redshift drift effect.

The Hubble parameter has a value of about 70 km/s per megaparsec. This means if a galaxy is about 1 megaparsec away (about 3 million light-years), then the galaxy appears to be moving away from us at about 70 km/s. If a galaxy is 2 megaparsecs away, it will appear to recede at about 140 km/s. The greater a galaxy's distance, the greater its apparent speed.

Since the universe is still expanding, with each passing year a galaxy is a bit more distant, and that means its redshift should become slightly larger. In other words, cosmic expansion means that the redshifts of galaxies should drift more to the red over time.

Theoretical redshift drift based on the standard model. Credit: ESO / ELT Science Case

This drift is extremely small. For a galaxy 12 billion light-years away, its apparent speed would be about 95% of the speed of light, while its drift would be just 15 cm/s each year. That's much too small for current telescopes to observe. But when the Extremely Large Telescope (ELT) starts gathering data in 2027, it should be able to observe this drift in time. Estimates are that after 5–10 years of precise observations, ELT should be able to see redshift drifts on the order of 5 cm/s.

While this will become a powerful tool in our understanding of the universe, it will take a lot of data and a lot of time. So a new paper, published on the preprint server arXiv, proposes a different method using gravitational lensing.

The authors call this effect redshift difference. Rather than observing the redshift of a galaxy over decades, the team proposes looking for distant galaxies that are gravitationally lensed by a closer galaxy. Lots of distant galaxies are lensed by a closer galaxy between us and the distant one, but most lensed galaxies appear as a single distorted arc to the side of the foreground galaxy.

How gravitational lensing can create multiple galaxy images. Credit: NASA/CXC/M.Weiss

But sometimes gravitational lensing can create multiple images of a distant galaxy. Since each image of the distant galaxy takes a slightly different path to reach us, the distance of each path is also slightly different. So instead of waiting decades for a galaxy to move farther away from us, we can get snapshots of the galaxy separated by years or decades. Each image would have a slightly different redshift, and by comparing these we could measure the redshift drift.

This is still beyond our current ability to detect. But while we are waiting for telescopes such as the ELT to come online, we can search for distant lensed galaxies with multiple images. That way when we do have the ability to detect redshift drift, we won't have to wait decades for the result.",https://scx2.b-cdn.net/gfx/news/2023/a-new-way-to-measure-t.jpg,https://phys.org/news/2023-08-expansion-universe-redshift-drift.html,Science
[],,"New JWST data confirms, worsens the Hubble tension","One of today’s greatest cosmic puzzles concerns the expanding Universe.

For the first several billion years of our Universe’s history, the Universe’s expansion rate was decreasing and distant galaxies slow in their recession from ours, as the matter and radiation densities drop. However, for the past ~6 billion years, distant galaxies have been speeding up in their recession, and the expansion rate, though still dropping, is not headed toward zero. Two different methods of measuring the expanding rate give conflicting values; the actual rate of expansion remains controversial. Credit: NASA/STSci/Ann Feild

Two major methods each give low-error, but incompatible, answers.

Taking us beyond the limits of any prior observatory, including all of the ground-based telescopes on Earth as well as Hubble, NASA’s JWST has shown us the most distant galaxies in the Universe ever discovered. If we assign 3D positions to the galaxies that have been sufficiently observed-and-measured, we can construct a visualized fly-through of the Universe, as the CEERS data from JWST enables us to do here. Measuring the expansion rate is a challenge, as different methods yield different, mutually incompatible results. Credits: Frank Summers (STScI), Greg Bacon (STScI), Joseph DePasquale (STScI), Leah Hustak (STScI), Joseph Olmsted (STScI), Alyssa Pagan (STScI); Science by: Steve Finkelstein (UT Austin), Rebecca Larson (RIT), Micaela Bagley (UT Austin)

By tracking an early, relic signal’s evolution, we measure expansion of 67 km/s/Mpc.

We can look arbitrarily far back in the Universe if our telescopes allow, and the clustering of galaxies should reveal a specific distance scale – the acoustic scale – that should evolve with time in a particular fashion, just as the acoustic “peaks and valleys” in the cosmic microwave background reveal this scale as well. The evolution of this scale, over time, is an early relic that reveals a low expansion rate of ~67 km/s/Mpc. Credit: E M Huff, the SDSS-III team and the South Pole Telescope team; graphic by Zosia Rostomian

By starting nearby and observing increasing recession with distance, we measure 73 km/s/Mpc.

The construction of the cosmic distance ladder involves going from our Solar System to the stars to nearby galaxies to distant ones. Each “step” carries along its own uncertainties, especially the steps where the different “rungs” of the ladder connect. However, recent improvements in the distance ladder have demonstrated how robust its results are. Credit: NASA, ESA, A. Feild (STScI), and A. Riess (JHU)

This discrepancy — the “Hubble tension” — is a modern cosmic conundrum.

Modern measurement tensions from the distance ladder (red) with early signal data from the CMB and BAO (blue) shown for contrast. It is plausible that the early signal method is correct and there’s a fundamental flaw with the distance ladder; it’s plausible that there’s a small-scale error biasing the early signal method and the distance ladder is correct, or that both groups are right and some form of new physics (shown at top) is the culprit. The idea that there was an early form of dark energy is interesting, but that would imply more dark energy at early times, and that it has (mostly) since decayed away. Credit: A.G. Riess, Nat Rev Phys, 2020

Many speculate an observational error on the “distance ladder” side could be the culprit.

Back in 2001, there were many different sources of error that could have biased the best distance ladder measurements of the Hubble constant, and the expansion of the Universe, to substantially higher or lower values. Thanks to the painstaking and careful work of many, that is no longer possible, as errors have been greatly reduced. New JWST work, not shown here, has reduced Cepheid-related and period-luminosity errors even further than is shown here. Credit: A.G. Riess et al., ApJ, 2022

We start by observing Cepheid variable stars within the Milky Way.

The Variable Star RS Puppis, with its light echoes shining through the interstellar clouds. Variable stars come in many varieties; one of them, Cepheid variables, can be measured both within our own galaxy and in galaxies up to 50–60 million light years away. This enables us to extrapolate distances from our own galaxy to far more distant ones in the Universe. RR Lyrae and tip-of-the AGB branch stars can be used in a similar fashion. Credit: NASA, ESA, G. Bacon (STScI), the Hubble Heritage Team (STScI/AURA)-ESA/Hubble Collaboration, and H. Bond (STScI and Pennsylvania State University)

We accurately infer their distances by measuring astronomical parallax.

The stars that are closest to Earth will appear to shift periodically with respect to the more distant stars as the Earth moves through space in orbit around the Sun. Before the heliocentric model was established, we weren’t looking for “shifts” with a ~300,000,000 kilometer baseline over the span of ~6 months, but rather a ~12,000 kilometer baseline over the span of one night: Earth’s diameter as it rotated on its axis. The distances to the stars are so great that it wasn’t until the 1830s that the first parallax, with a 300 million km baseline, was detected. Today, we’ve measured the parallax of over 1 billion stars with ESA’s Gaia mission. Credit: ESA/ATG medialab

Then we measure Cepheids in nearby, well-measured galaxies.

The top two panels show two nearby, Cepheid-rich galaxies: NGC 4258 (left) and NGC 5584 (right), with JWST’s field-of-view overlaid atop them. The bottom panels show JWST views, with individually identified Cepheid variables highlighted in each image. Credit: A.G. Riess et al., ApJ submitted/arXiv:2307.15806, 2023

Finally, we measure type Ia supernovae within those galaxies and beyond, linking these cosmic “rungs” together.

As recently as 2019, there were only 19 published galaxies that contained distances as measured by Cepheid variable stars that also were observed to have type Ia supernovae occur in them. We now have distance measurements from individual stars in galaxies that also hosted at least one type Ia supernova in 42 galaxies, 35 of which have excellent Hubble imagery. Those 35 galaxies are shown here. Credit: A.G. Riess et al., ApJ, 2022

Could an error in Cepheids be biasing our measured expansion rate?

Using the cosmic distance ladder means stitching together different cosmic scales, where one always worries about uncertainties where the different “rungs” of the ladder connect. As shown here, we are now down to as few as three “rungs” on that ladder, and the full set of measurements agree with one another spectacularly. Credit: A.G. Riess et al., ApJ, 2022

By measuring Cepheids in nearby galaxies, JWST probes this possibility.

This nearby spiral galaxy, NGC 4258 (also known as Messier 106), is just ~20 million light-years away but contains many known Cepheids that are similar to Cepheids found in the Milky Way. This is an important galaxy for calibrating the cosmic distance ladder. Credit: NASA, ESA, the Hubble Heritage Team (STScI/AURA), and R. Gendler (for the Hubble Heritage Team); Acknowledgment: J. GaBany

Observing galaxy NGC 4258, JWST found no photometric bias for Cepheids.

This image shows several Cepheid variable stars with different periods within nearby galaxy NGC 4258: an important galaxy for Cepheid and distance calibrations. The bottom 6 rows show the same stars as measured by both Hubble (grey labels) and JWST (purple labels) at various wavelengths. The superior resolution in JWST images reduces prior Hubble errors by significant, substantial amounts while validating and remaining consistent with prior results. Credit: A.G. Riess et al., ApJ submitted/arXiv:2307.15806, 2023

Instead, it confirmed and enhanced previous Hubble Space Telescope findings.

This composite image shows the barred spiral galaxy NGC 5584 with supernova SN 2007af shining brightly within it. Nearby galaxies with identifiable Cepheid variable stars and that have hosted at least one type Ia supernova within them are incredibly important to the cosmic distance ladder method of measuring the expanding Universe. Credit: ESO

Cepheids in NGC 5584, which also had a (2007-era) type Ia supernova, also reveal no bias.

This graph shows the relationship between the magnitude of the brightness of Cepheid variable stars (y-axis) versus their period of variability (x-axis) in galaxies NGC 5584 (top) and NGC 4258 (bottom). The new JWST data is shown in red, while the old Hubble data is shown in grey. The errors and uncertainties of this relation in both galaxies are greatly reduced, primarily owing to JWST’s superior resolution over Hubble’s. Credit: A.G. Riess et al., ApJ submitted/arXiv:2307.15806, 2023

The period-luminosity relation, a key calibrator of Cepheids, is now more precise than ever.

By enabling a better understanding of Cepheid variables in nearby galaxies NGC 4258 and NGC 5584, JWST has reduced the uncertainties in their distances even further. The lowest points on the graph show the estimate for the distance to NGC 5584 from the expansion rates inferred from the distance ladder (left side) and what’s expected from the early relic method (right side). The mismatch is significant and compelling. Credit: A.G. Riess et al., ApJ submitted/arXiv:2307.15806, 2023

With superior resolution, JWST has reduced any uncertainties down to their smallest values ever.

Standard candles (left) and standard rulers (right) are two different techniques astronomers used to measure the expansion of space at various times/distances in the past. Based on how quantities like luminosity or angular size change with distance, we can infer the expansion history of the Universe. Using the candle method is part of the distance ladder, yielding 73 km/s/Mpc. Using the ruler is part of the early signal method, yielding 67 km/s/Mpc. With new JWST data, the mystery over the Universe’s expansion rate has deepened further. Credit: NASA/JPL-Caltech

Mostly Mute Monday tells an astronomical story in images, visuals, and no more than 200 words.","https://bigthink.com/wp-content/uploads/2023/08/NGC_5584_captured_by_the_Hubble_Space_Telescope.jpg?resize=1200,630",https://bigthink.com/starts-with-a-bang/jwst-confirms-worsens-hubble-tension/,Science
['National Astronomical Observatory Of Japan'],,Investigating the past and future of the universe using statistical methods to measure distance,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

A conceptual diagram of this research. Signals from supernovae (bottom right inset), quasars (middle left inset), and gamma-ray bursts (top center inset) reach Earth in the Milky Way Galaxy (background), where we can use them to measure cosmological parameters. Credit: NAOJ

New research has improved the accuracy of the parameters governing the expansion of the universe. More accurate parameters will help astronomers determine how the universe grew to its current state and how it will evolve in the future.

It is well established that the universe is expanding. But with no landmarks in space, it is difficult to accurately measure how fast it is expanding. So, astronomers search for reliable landmarks. The same way a candle looks fainter as it gets farther away, even though the candle itself hasn't changed, distant objects in the universe look fainter.

If we know the intrinsic (initial) brightness of an object, we can calculate its distance based on its observed brightness. Objects of known brightness in the universe that allow us to calculate the distance are called ""standard candles.""

An international team led by Maria Giovanna Dainotti, Assistant Professor at the National Astronomical Observatory of Japan (NAOJ), and Giada Bargiacchi, Ph.D. student at the Scuola Superiore Meridionale in Naples, with the aid of the supercomputing facilities at NAOJ run by Kazunari Iwasaki, Assistant Professor at NAOJ and member of the Center for Computational Astrophysics, ushered in a new research field by leveraging the use of a variety of new statistical methods.

They have analyzed data for various standard candles such as supernovae, quasars (powerful black holes consuming matter in the distant universe), and gamma ray bursts (sudden flashes of powerful radiation). Different standard candles are useful in different distant ranges, so combining multiple standard candles allowed the team to map larger areas of the universe. Their work has been published in two articles in The Astrophysical Journal.

The new results reduce the uncertainty of key parameters by up to 35%. More accurate parameters will help determine whether the universe will continue expanding forever or will eventually fall back in on itself.

More information: Maria Giovanna Dainotti et al, Reducing the Uncertainty on the Hubble Constant up to 35% with an Improved Statistical Analysis: Different Best-fit Likelihoods for Type Ia Supernovae, Baryon Acoustic Oscillations, Quasars, and Gamma-Ray Bursts, The Astrophysical Journal (2023). DOI: 10.3847/1538-4357/acd63f M. G. Dainotti et al, Quasars: Standard Candles up to z = 7.5 with the Precision of Supernovae Ia, The Astrophysical Journal (2023). DOI: 10.3847/1538-4357/accea0 Journal information: Astrophysical Journal",https://scx2.b-cdn.net/gfx/news/hires/2023/rewriting-the-past-and.jpg,https://phys.org/news/2023-08-future-universe-statistical-methods-distance.html,Science
['Trinity College Dublin'],2023-08-21 17:01:41-07:00,“Forgetting” Might Not Be a Bad Thing – Scientists Propose That It Could Be a Functional Feature of the Brain,"Neuroscientists have unveiled initial findings from experiments investigating the concept that “forgetting” might not be a bad thing, and that it may represent a form of learning – and outline results that support their core idea.

Previously, these scientists proposed that changes in our ability to retrieve certain memories stem from environmental feedback and predictability. They argued that instead of being a flaw, forgetting could be an intentional characteristic of the brain, enabling it to adaptively engage with ever-changing surroundings.

In a changing world like the one we and many other organisms live in, forgetting some memories would be beneficial, they reasoned, as this can lead to more flexible behavior and better decision-making. If memories were gained in circumstances that are not wholly relevant to the current environment, forgetting them could be a positive change that improves our well-being.

In a paper published in the leading international journal Cell Reports, they present the first in a series of new experimental studies where the effect of natural, “everyday” forgetting was investigated with respect to how normal forgetting processes affect particular memories in the brain.

The team studied a form of forgetting called retroactive interference, where different experiences occurring closely in time can cause the forgetting of recently formed memories. In their study, mice were asked to associate a specific object with a particular context or room, and then recognize that an object that was displaced from its original context. However, mice forget these associations when competing experiences are allowed to ‘interfere’ with the first memory.

To study the result of this form of forgetting on memory itself, the neuroscientists genetically labeled a contextual “engram” (a group of brain cells that store a specific memory) in the brains of these mice, and followed the activation and functioning of these cells after forgetting had happened. Crucially, using a technique called optogenetics they found that stimulation of the engram cells with light retrieved the apparently lost memories in more than one behavioral situation. Furthermore, when the mice were given new experiences that related to the forgotten memories, the ‘lost’ engrams could be naturally rejuvenated.

Dr. Tomás Ryan, Associate Professor in the School of Biochemistry and Immunology and the Trinity College Institute of Neuroscience at Trinity College Dublin, is the lead author of the just-published journal article.

Dr. Ryan, whose research team is based in the Trinity Biomedical Sciences Institute (TBSI), said: “Memories are stored in ensembles of neurons called ‘engram cells’ and successful recall of these memories involves the reactivation of these ensembles. By logical extension, forgetting occurs when engram cells cannot be reactivated. However, it is increasingly becoming clear that the memories themselves are still there, but the specific ensembles are not activated and so the memory is not recalled. It’s as if the memories are stored in a safe but you can’t remember the code to unlock it.”

Dr. Livia Autore, Irish Research Council (IRC) Postgraduate Scholar, who spearheaded this work in the Ryan Lab in Trinity, added: “Our findings here support the idea that competition between engrams affects recall and that the forgotten memory trace can be reactivated by both natural and artificial cues as well as updated with new information. The continuous flow of environmental changes leads to the encoding of multiple engrams that compete for their consolidation and expression.

“So while some may persist undisturbed, some will be subjected to interference by new incoming and prevailing information. However, the interfered memories can still be reactivated by surrounding cues leading to memory expression or by misleading or novel experiences ending up in an updated behavioral outcome.”

Because we now know that “natural forgetting” is reversible in certain circumstances, this work has significant implications for disease states – such as in people living with Alzheimer’s disease for example, where these everyday forgetting processes may be mistakenly activated by brain disease.

Reference: “Adaptive expression of engrams by retroactive interference” by Livia Autore, James D. O’Leary, Clara Ortega-de San Luis and Tomás J. Ryan, 16 August 2023, Cell Reports.

DOI: 10.1016/j.celrep.2023.112999

The study was funded by the European Research Council, the Canadian Institute for Advanced Research, the Irish Research Council, and the Science Foundation Ireland.",https://scitechdaily.com/images/Brain-Boost-Art-Concept.jpg,https://scitechdaily.com/forgetting-might-not-be-a-bad-thing-scientists-propose-that-it-could-be-a-functional-feature-of-the-brain/,Science
[],,Forgetting things may be an intentional brain feature - study,"Forgetfulness is one of the most irritating and bothersome consequences of our brain activity, but it turns out that being forgetful might not be so bad – in fact, it may be a deliberate form of adaptation, according to a recent study.

The findings of this study were published in the peer-reviewed academic journal Cell Reports.

As our world is constantly changing, the researchers behind this study argue that forgetting is actually the perfect way of learning.

Don't forget: Forgetting is good, remember?

If you ever forgot something, chances are you wouldn't remember it. That is, after all, the very point of forgetting something: Your brain essentially no longer retains information that it previously did.

Naturally, one might assume that this is a sort of screw-up on the part of your brain. A deficit in its functionality.

An illustrative image of a brain. (credit: INGIMAGE)

However, that may not be the case.

When the brain learns something and absorbs information, there are physical changes that occur in the brain's neurons and synapses.

This process is then facilitated by engram cells, which help store memory, consolidate it, retrieve it, and forget it. What happens to engram cells when something is forgotten isn't clear, though. But considering memory can sometimes come back even when forgotten, the cells likely don't just vanish.

To figure out what happens to them, researchers from Ireland tracked the engram cells in mice to see what happened when they were forgotten. Then, they were able to stimulate the cells with light, which seemingly reactivated the cells and the previously forgotten memories.

These cells were also found to reactivate normally, should more information be given to the mice that related to the forgotten memories.

This discovery has several implications, but what stands out the most is:

""Naturally forgetting"" something is often a reversible process.

When you ""forget"" information, that information hasn't actually vanished, it's just hidden away.

But why does the brain just forget things?

The theory behind it is that by forgetting things, which still exist in the brain, it is possible for the mind to adapt. This can lead to more flexibility and better decision-making, rather than relying on memories not relevant to the situation at hand.

But the fact that these memories can be retrieved holds incredible significance for future research.

""By logical extension, forgetting occurs when engram cells cannot be reactivated. However, it is increasingly becoming clear that the memories themselves are still there, but the specific ensembles are not activated and so the memory is not recalled."" Dr. Tomás Ryan

""By logical extension, forgetting occurs when engram cells cannot be reactivated. However, it is increasingly becoming clear that the memories themselves are still there, but the specific ensembles are not activated and so the memory is not recalled,"" explained lead author Dr. Tomás Ryan of Trinity College Dublin. ""It's as if the memories are stored in a safe but you can't remember the code to unlock it.""

Consider that several conditions, such as Alzheimer's, are characterized by memory loss. Because these memories can sometimes return in lucid periods, that means the engram cells are still there. It also could mean that, in theory, there may be a way to help treat them.

But that's a subject for future research to explore.","https://images.jpost.com/image/upload/f_auto,fl_lossy/c_fill,g_faces:center,h_407,w_690/549360",https://www.jpost.com/science/article-755803,Science
"['Neuroscience News', 'Neuroscience News Posts Science Research News Labs', 'Universities', 'Hospitals', 'News Departments Around The World.', 'Science Articles Cover Neuroscience', 'Psychology', 'Ai', 'Robotics', 'Neurology']",2023-08-21 14:10:06+00:00,"Forgetting: Not a Flaw, But a Brain’s Hidden Feature of Memory","Summary: Recent studies suggest that forgetting might not just be a mere oversight of our brains, but a dynamic response to our changing environments. Neuroscientists propose that as environments shift, forgetting irrelevant memories can foster adaptability and better decision-making.

Experiments revealed that even after certain memories in mice seemed forgotten, they could be retrieved with the right cues. This breakthrough understanding about the nature of memory could have major implications, especially for conditions like Alzheimer’s disease.

Key Facts:

Forgetting might be a strategic feature of the brain to adapt to ever-changing environments. In experiments with mice, ‘lost’ memories could be revived with the right triggers or new related experiences. Understanding the reversible nature of “natural forgetting” might offer insights into diseases like Alzheimer’s.

Source: TCD

Neuroscientists today report the first results from experimental tests designed to explore the idea that “forgetting” might not be a bad thing, and that it may represent a form of learning—and outline results that support their core idea.

Last year the neuroscientists behind the new theory suggested that changes in our ability to access specific memories are based on environmental feedback and predictability. And that rather than being a bug, forgetting may be a functional feature of the brain, allowing it to interact dynamically with a dynamic environment.

Credit: Neuroscience News

In a changing world like the one we and many other organisms live in, forgetting some memories would be beneficial, they reasoned, as this can lead to more flexible behavior and better decision-making. If memories were gained in circumstances that are not wholly relevant to the current environment, forgetting them could be a positive change that improves our well-being.

In Cell Reports they present the first in a series of new experimental studies where the effect of natural, “every day” forgetting was investigated with respect to how normal forgetting processes affect particular memories in the brain.

The team studied a form of forgetting called retroactive interference, where different experiences occurring closely in time can cause the forgetting of recently formed memories.

In their study, mice were asked to associate a specific object with a particular context or room, and then recognize that an object that was displaced from its original context. However, mice forget these associations when competing experiences are allowed to ‘interfere’ with the first memory.

To study the result of this form of forgetting on memory itself, the neuroscientists genetically labeled a contextual “engram” (a group of brain cells that store a specific memory) in the brains of these mice, and followed the activation and functioning of these cells after forgetting had happened.

Crucially, using a technique called optogenetics they found that stimulation of the engram cells with light retrieved the apparently lost memories in more than one behavioral situation. Furthermore, when the mice were given new experiences that related to the forgotten memories, the ‘lost’ engrams could be naturally rejuvenated.

Dr. Tomás Ryan, Associate Professor in the School of Biochemistry and Immunology and the Trinity College Institute of Neuroscience at Trinity College Dublin, is lead author of the just-published journal article.

Dr. Ryan, whose research team is based in the Trinity Biomedical Sciences Institute (TBSI), said, “Memories are stored in ensembles of neurons called ‘engram cells’ and successful recall of these memories involves the reactivation of these ensembles.”

“By logical extension, forgetting occurs when engram cells cannot be reactivated. However, it is increasingly becoming clear that the memories themselves are still there, but the specific ensembles are not activated and so the memory is not recalled. It’s as if the memories are stored in a safe but you can’t remember the code to unlock it.”

Dr. Livia Autore, Irish Research Council (IRC) Postgraduate Scholar, who spearheaded this work in the Ryan Lab in Trinity, added, “Our findings here support the idea that competition between engrams affects recall and that the forgotten memory trace can be reactivated by both natural and artificial cues as well as updated with new information.

“The continuous flow of environmental changes leads to the encoding of multiple engrams that compete for their consolidation and expression.”

“So while some may persist undisturbed, some will be subjected to interference by new incoming and prevailing information. However, the interfered memories can still be reactivated by surrounding cues leading to memory expression or by misleading or novel experiences ending up in an updated behavioral outcome.”

Because we now know that “natural forgetting” is reversible in certain circumstances, this work has significant implications for disease states—such as in people living with Alzheimer’s disease for example, where these every day forgetting processes may be mistakenly activated by brain disease.

About this memory research news

Author: Tomás Ryan

Source: TCD

Contact: Tomás Ryan – TCD

Image: The image is credited to Neuroscience News

Original Research: Open access.

“Adaptive expression of engrams by retroactive interference” by Tomás Ryan et al. Cell Reports

Abstract

Adaptive expression of engrams by retroactive interference

Highlights

Retroactive interference causes forgetting by the competition of two memory engrams

Forgotten engrams can be expressed or updated by reexposure to training cues

Artificial reactivation of engram cells rescues interference-induced forgetting

Interference is an active process that requires the activation of the suppressed engram

Summary

Long-term memories are stored as configurations of neuronal ensembles, termed engrams.

Although investigation of engram cell properties and functionality in memory recall has been extensive, less is known about how engram cells are affected by forgetting.

We describe a form of interference-based forgetting using an object memory behavioral paradigm.

By using activity-dependent cell labeling, we show that although retroactive interference results in decreased engram cell reactivation during recall trials, optogenetic stimulation of the labeled engram cells is sufficient to induce memory retrieval.

Forgotten engrams may be reinstated via the presentation of similar or related environmental information. Furthermore, we demonstrate that engram activity is necessary for interference to occur.

Taken together, these findings indicate that retroactive interference modules engram expression in a manner that is both reversible and updatable. Inference may constitute a form of adaptive forgetting where, in everyday life, new perceptual and environmental inputs modulate the natural forgetting process.",https://neurosciencenews.com/files/2023/08/forgetting-memory-neuroscience.jpg,https://neurosciencenews.com/forgetting-memory-engrams-23784/,Science
['Monika Luabeya'],,A Gateway to the Moon,,http://www.nasa.gov/sites/default/files/thumbnails/image/gateway_summer_req_images_rev2_11orig.png,https://www.nasa.gov/image-feature/a-gateway-to-the-moon,Science
[],,Yahooist Teil der Yahoo Markenfamilie,,https://s.yimg.com/oa/build/images/favicons/yahoo.png,,Science
[],2023-08-22 09:35:41+05:30,Roads and buildings on Moon? See these shared by Canadian space agency,"Recently, the Canadian Space Agency, shared the image of a 108 million-year-old Tycho Crater in the Moon's southern hemisphere. However, the imge of the crater left netizens bewildered after they spotted roads and buildings alongside the supposed crater.

The space agency shared the image of the crater on social media platform X and within a nick of time, it ended up at the centre of a controversy around the authenticity of the image of the supposed crater.

The caption of the image post said, ""Boom! An impact crater is formed when an object like an asteroid or meteorite crashes into the surface of a larger solid object like a planet, or a moon! Here is Tycho Crater, in the Moon's southern hemisphere, believed to be about 108 million years old."" The post credited NASA as the source of the photo.

What amused the netizens the most was the presence of human-made structures around the crater. The post also erupted humurous remarks and jokes on the Canadian Space Agency.

How did trucks and roads appeared on Moon?

After some time, it became clear that the image was mistakenly uploaded as that of Moon's Tycho Crater. But it was actually of Barringer Meteor Crater located in Arizona, United States, a spot known to attract tourists. After the mistake, Canadian Space Agency immediately deleted the post. But it was too late, as the micro-blogging site was filled with tweets mocking the space agency for its mistake.

One X user shared the image of Barringer Meteor Crater and captioned it as 'Actual photo of me on the moon, according to Canada's Space Agency.'",https://www.livemint.com/lm-img/img/2023/08/22/600x338/moon_crater_1692675342542_1692675342719.jfif,https://www.livemint.com/science/news/canadian-space-agency-shares-image-of-108-million-yr-old-moon-crater-with-roads-buildings-netizens-react-11692675000478.html,Science
"['India Tv News', 'Ottawa', 'Canada', 'Image Source']",2023-08-22 00:00:00,SERIOUSLY? Canadian Space Agency mistakes Arizona's Meteor Crater as 108-million-year-old moon crater,"Follow us on Image Source : NASA Arizona's Barringer Crater

A recent post by the Canadian Space Agency on X (formerly Twitter) went viral after it shared a picture claiming it to be a 108-million-year-old Tycho crater on the surface of the Moon's southern hemisphere. However, netizens quickly reacted as the picture showed roads and buildings around the crater.

Image Source : TWITTERCanadian Space Agency's viral post on X (formerly Twitter)

""Boom! An impact crater is formed when an object like an asteroid or meteorite crashes into the surface of a larger solid object like a planet, or a moon! Here is Tycho Crater, in the Moon's southern hemisphere, believed to be about 108 million years old,"" said the Canadian Space Agency. The picture was shared by the agency on August 19 and credited the National Aeronautics and Space Administration (NASA).

Netizens were quick to point out the presence of roads and buildings around the crater and lambasted the Canadian Space Agency for the epic mistake. It soon turned out that the picture actually shows the Barringer Crater (Meteor Crater) in Arizona, United States.

""Sadly, the Canadian Space Agency has posted a picture of Meteor Crater, Arizona (complete with Visitor Center) instead. We all make mistakes and sometimes tweet silly things,"" tweeted a user on X.

Another user wrote, ""There are roads right next to this crater. Does the Canadian Space agency think there are roads & visitor centers on the moon?""

About Arizona's Barringer Crater

The Barringer Crater in Arizona, also called Meteor Crater, is 50,000 years old on Earth and is unusually well preserved in the climate of the Colorado Plateau, according to NASA. It was formed after the impact of an iron-nickel asteroid about 46 metres across and most of the asteroid melted or vaporized on impact.

""The collision initially formed a crater over 1,200 meters (4,000) feet across and 210 meters (700 feet) deep. Subsequent erosion has partially filled the crater, which is now only 150 meters (550 feet) deep,"" said NASA.

What is the Tycho Crater?

The Tycho Crater is one of the most prominent craters on the surface of the Moon and appears as a bright spot in the southern highlands with rays of bright material streching across the surface visible from Earth. It is approximately 85 kilometres in diameter.

According to NASA, the Tycho Crater formed recently enough that its beautiful rays, material ejected during the impact event, are still visible as bright streaks.

ALSO READ | Russian space agency chief reveals reasons for Luna-25 lander's crash on Moon I Details inside

Latest World News",https://resize.indiatvnews.com/en/resize/newbucket/1200_-/2023/08/rizona-crater-1692704429.jpg,https://www.indiatvnews.com/news/world/canadian-space-agency-viral-post-arizona-barringer-crater-as-moon-crater-netizens-react-tycho-latest-updates-2023-08-22-888219,Science
['Hiral Goyal'],,Pic of US crater shared as crater on Moon by Canadian space agency,"The Canadian Space Agency shared a picture of what it claimed was a crater on Moon. ""Here is Tycho Crater, in the Moon's southern hemisphere, believed to be about 108 million years old,"" it wrote. However, the picture was of Barringer Meteor Crater located in Arizona, US. Some X users highlighted presence of roads and buildings alongside the supposed crater.",https://static.inshorts.com/inshorts/images/v1/variants/jpg/m/2023/08_aug/22_tue/img_1692687192729_611.jpg,https://inshorts.com/en/news/pic-of-us-crater-shared-as-crater-on-moon-by-canadian-space-agency-1692689142540,Science
[],2023-08-20 15:43:03+05:30,"Canadian space agency shares ‘Moon Crater’ picture, but it has roads, buildings","A recent post by the Canadian Space Agency on social media platform X (formerly Twitter) sharing an image of what it called 108 million-year-old Tycho Crater in the Moon's southern hemisphere, caused quite a stir. The picture gained attention as users highlighted roads and buildings alongside the supposed crater. Canadian Space Agency posts picture of 'Moon crater' (L), Google Maps annotated Arizona Crater image, actual Tycho Moon Crater (R)

Also read- Luna 25 crashes: Russian spacecraft collides onto Moon's surface, says Roscosmos

The caption accompanying the image read, ""Boom! An impact crater is formed when an object like an asteroid or meteorite crashes into the surface of a larger solid object like a planet, or a moon! Here is Tycho Crater, in the Moon's southern hemisphere, believed to be about 108 million years old.” The post credited NASA as the source of the photo.

The social media post from the Canadian Space Agency.(X)

However, sharp-eyed netizens quickly noticed the presence of human-made structures around the crater, prompting humorous remarks and jokes aimed at the Canadian Space Agency.

As the confusion unfolded, it was understood that the image was not of the Moon's Tycho Crater but rather of Barringer Meteor Crater located in Arizona, United States – a spot known to attract tourists.

“Yeah, bit of an Epic Fail with the image there Canadian Space Agency…surprised the road to the left wasn’t enough of a dead giveaway for you before you decided to post. Alas, we all make mistakes,” a user jokingly replied to the post on X.

“This isn’t April Fools, or is it in Canada? You realise this is an Earth crater with human development,” another user poked fun.

Some even decided to come harshly on the space agency tweet: “This is what it looks like when kids that got participation trophies in school grow up to be rocket scientists. Arizona is now a moon crater.”

The post was also later flagged by X community notes, which added context, “The location shown is not Tycho Crater but Meteor Crater. It is not on the Moon's southern hemisphere, but on Earth, in Arizona, about an hour's drive away from Flagstaff. It is not thought to be 108 million years old, but a mere 50,000 years old. And it has a visitor centre.”

What is Tycho Crater on the moon?

According to NASA, Tycho Crater, 85 kilometres in diameter, is one of the most prominent craters on the moon. It appears as a bright spot in the southern highlands with rays of bright material that stretch across much of the nearside.

The space agency added that the crater formed recently enough that its beautiful rays, material ejected during the impact event, are still visible as bright streaks.

What is Barringer Crater in Arizona?

On the other hand, Barringer Crater on Earth is 50,000 years, well preserved 150 meters deep Meteor impact crater in the arid climate of the Colorado Plateau.

NASA says the Meteor Crater formed from the impact of an iron-nickel asteroid about 46 meters across.

SHARE THIS ARTICLE ON",https://www.hindustantimes.com/ht-img/img/2023/08/20/1600x900/canada_1692518835971_1692518847057.png,https://www.hindustantimes.com/technology/canadian-space-agency-shares-moon-crater-picture-but-it-has-roads-buildings-101692515553391.html,Science
"['Tamara Dietrich', 'Thomas Jefferson National Accelerator Facility']",,Ringing protons give insight into early universe,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

This Feynman diagram shows the physics of how an electron scattering from a proton can be used to theoretically access the 3D picture of the transition between the proton and the Δ++ resonance. Credit: Stefan Diehl

In the middle of the last century, physicists found that protons can resonate, much like a ringing bell. Advances over the last three decades have led to 3D pictures of the proton and significant insight into its structure in its ground state. But little is known about the 3D structure of the resonating proton.

Now, an experiment to explore the 3D structures of resonances of protons and neutrons at the U.S. Department of Energy's Thomas Jefferson National Accelerator Facility has added one more puzzle piece to the vast picture of the chaotic, nascent universe that existed just after the Big Bang.

Studying the fundamental properties and behaviors of nucleons offers critical insights into the basic building blocks of matter. Nucleons are the protons and neutrons that make up the nuclei of atoms. Each nucleon consists of three quarks tightly bound together by gluons by the strong interaction—the strongest force in nature.

The most stable, lowest-energy state of a nucleon is called its ground state. But when a nucleon is forcibly excited into a higher-energy state, its quarks rotate and vibrate against each other, exhibiting what's known as a nucleon resonance.

A group of physicists from Justus Liebig Universitat (JLU) Giessen in Germany and the University of Connecticut led the CLAS Collaboration effort to conduct an experiment exploring these nucleon resonances. The experiment was carried out at Jefferson Lab's world-class Continuous Electron Beam Accelerator Facility (CEBAF). CEBAF is a DOE Office of Science user facility that supports the research of more than 1,800 nuclear physicists worldwide. Results of the research were published in the journal Physical Review Letters.

Analysis leader Stefan Diehl said the team's work sheds light on the basic properties of nucleon resonances. Diehl, is a postdoctoral researcher and project leader at the 2nd Physics Institute at JLU Giessen and a research professor at the University of Connecticut. He said the work is also inspiring fresh investigations of the 3D structure of the resonating proton and the excitation process.

""This is the first time we have some measurement, some observation, which is sensitive to the 3D characteristics of such an excited state,"" said Diehl. ""In principle, this is just the beginning, and this measurement is opening a new field of research.""

The mystery of how matter formed

The experiment was conducted in Experimental Hall B in 2018-2019 using Jefferson Lab's CLAS12 detector. A high-energy electron beam was sent into a chamber of cooled hydrogen gas. The electrons impacted the target's protons to excite the quarks within and produce nucleon resonance in combination with a quark-antiquark state—a so-called meson.

The excitations are fleeting, but they leave behind evidence of their existence in the form of new particles that are made from the excited particles' energy as it fritters away. These new particles live long enough for the detector to pick them up, so the team could reconstruct the resonance.

Diehl and others will discuss their results as part of a joint workshop on ""Exploring resonance structure with transition GPDs"" August 21–25 in Trento, Italy. The research has already inspired two theory groups to publish papers on the work.

The team also plans more experiments at Jefferson Lab using different targets and polarizations. By scattering electrons from polarized protons, they can access different characteristics of the scattering process. In addition, the study of similar processes, such as the production of a resonance in combination with an energetic photon, can provide further important information.

Through such experiments, Diehl said, physicists can tease out the properties of the early cosmos after the Big Bang.

""In the beginning, the early cosmos only had some plasma consisting of quarks and gluons, which were all spinning around because the energy was so high,"" said Diehl. ""Then, at some point, matter started to form, and the first things that formed were the excited nucleon states. When the universe expanded further, it cooled down and the ground state nucleons manifested.

""With these studies, we can learn about the characteristics of these resonances. And this will tell us things about how matter was formed in the universe and why the universe exists in its present form.""

More information: S. Diehl et al, First Measurement of Hard Exclusive π−Δ++ Electroproduction Beam-Spin Asymmetries off the Proton, Physical Review Letters (2023). DOI: 10.1103/PhysRevLett.131.021901 Journal information: Physical Review Letters",https://scx2.b-cdn.net/gfx/news/2023/ringing-protons-give-i.jpg,https://phys.org/news/2023-08-protons-insight-early-universe.html,Science
"['Alison Hatt', 'Lawrence Berkeley National Laboratory']",,Advances in quantum emitters mark progress toward a quantum internet,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Left, model of the atomic structure of the quantum light-emitting defect in silicon (gray), composed of two substitutional carbon atoms (black), and one silicon interstitial atom (pink). The size of the quantum emitter is about 1 nanometer (1 billionth of a meter). Right, spectra from quantum emitters showing more intense light emission following exposure of a silicon crystal to a high flux of protons from intense pulses (black) compared to the conventional method of low flux exposure to protons over extended periods of time (blue). Credit: Wei Liu

The prospect of a quantum internet, connecting quantum computers and capable of highly secure data transmission, is enticing, but making it poses a formidable challenge. Transporting quantum information requires working with individual photons rather than the light sources used in conventional fiber optic networks.

To produce and manipulate individual photons, scientists are turning to quantum light emitters, also known as color centers. These atomic-scale defects in semiconductor materials can emit single photons of fixed wavelength or color and allow photons to interact with electron spin properties in controlled ways.

A team of researchers has recently demonstrated a more effective technique for creating quantum emitters using pulsed ion beams, deepening our understanding of how quantum emitters are formed. The work was led by Department of Energy Lawrence Berkeley National Laboratory (Berkeley Lab) researchers Thomas Schenkel, Liang Tan, and Boubacar Kanté who is also an associate professor of electrical engineering and computer sciences at the University of California, Berkeley.

The results appeared in Physical Review Applied and are part of a larger effort by the team to identify the best quantum defect emitters for processing and transporting quantum information and to produce them with precision.

""The color centers we're making are candidates for becoming the backbone of a quantum internet and a key resource for scalable quantum information processing,"" said Schenkel, a senior scientist in Berkeley Lab's Accelerator Technology & Applied Physics (ATAP) Division. ""They could support linking quantum-computing nodes for scalable quantum computing.""

In this work, the team targeted the fabrication of a specific type of color center in silicon comprising two substitutional carbon atoms and a slightly dislodged silicon atom. The conventional method of producing the defects is to hit the silicon with a continuous beam of high-energy ions; however, the researchers discovered that a pulsed ion beam is significantly more efficient, producing many more of the desired color centers.

""We were surprised to find these defects can be more easily generated with pulsed ion beams,"" said Wei Liu, a postdoctoral scholar in ATAP and first author of the publication. ""Right now, industry and academia mainly use continuous beams, but we've demonstrated a more efficient approach.""

The researchers believe that the transient excitations created by the pulsed beam, where the temperature and system energetics change rapidly, are key to the more efficient color center formation, which they established through an earlier study using pulsed ion beams from a laser-driven accelerator published in Communications Materials.

(a) The shift of the ZPL transition energy versus the distance between the GCB and the perturbing defect, where the defect is a vacancy (blue circles) or a silicon self-interstitial (red cross). (b),(c) Histograms of the ZPL shift due to (b) vacancies and (c) self-interstitials for the region marked by the green box in (a). Credit: Physical Review Applied (2023). DOI: 10.1103/PhysRevApplied.20.014058

The team characterized the color centers at cryogenic temperatures using highly sensitive near-infrared detectors to probe their optical signals. They found that the intensity of the ion beam used to create the color centers changed the optical properties of the photons they emitted.

Large-scale computer simulations on the Perlmutter system at the National Energy Research Scientific Computing Center (NERSC) provided further insight into the discovery, revealing that the wavelength of emitted photons is sensitive to strain in the crystal lattice.

""First-principles electronic structure calculations have become the go-to method for understanding defect properties,"" added Vsevolod Ivanov, a postdoctoral scholar at the Molecular Foundry and co-first author of the publication. ""We have reached the point where we can predict how a defect behaves, even in complex environments.""

The findings also suggest a new application for quantum emitter color centers as sensors for radiation.

""It opens new directions,"" said Tan, a staff scientist at Berkeley Lab's Molecular Foundry. ""We can form this color center by just hitting silicon with a proton. We could potentially use that as a dark-matter or neutrino detector with directionality because we see these different strain fields depending on which way the radiation came.""

With this deeper understanding of quantum emitter formation and properties, the team continues to expand its exploration of color centers. Ongoing work includes generating a database of color centers predicted to exist in silicon, using computer simulations to identify those best suited to quantum computing and networking applications, and refining fabrication techniques to gain deterministic control over creating individual color centers.

""We're working towards a new paradigm of qubits by design,"" said Kanté. ""Can we reliably make a given color center that operates in the telecom band, has sufficient brightness, isn't too hard to make, has a memory, etcetera? We're engaged in that quest and have demonstrated some exciting progress.""

""The new pathways to forming color centers using intense beams uncovered in this work are an exciting application of high energy density conditions and plasma science to improving technologies for quantum information science,"" said ATAP Division Director Cameron Geddes.

More information: Wei Liu et al, Quantum Emitter Formation Dynamics and Probing of Radiation-Induced Atomic Disorder in Silicon, Physical Review Applied (2023). DOI: 10.1103/PhysRevApplied.20.014058",https://scx2.b-cdn.net/gfx/news/hires/2023/advances-in-quantum-em.jpg,https://phys.org/news/2023-08-advances-quantum-emitters-internet.html,Science
['Auburn University Department Of Physics'],,Exascale revolution: Supercomputers unleash a new era in biophysics discovery,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Illustration of a protein placed over a computer chip. New, powerful computers are helping scientists design and understand proteins like never before. Credit: Rafael C. Bernardi

In a recently published article featured on the cover of the Biophysical Journal, Dr. Rafael Bernardi, assistant professor of biophysics at the Department of Physics at Auburn University, and Dr. Marcelo Melo, a postdoctoral researcher in Dr. Bernardi's group, shed light on the transformative capabilities of the next generation of supercomputers in reshaping the landscape of biophysics.

The researchers at Auburn delve into the harmonious fusion of computational modeling and experimental biophysics, providing a perspective for a future in which discoveries are made with unparalleled precision. Rather than being mere observers, today's biophysicists, with the aid of advanced high-performance computing (HPC), are now trailblazers who can challenge longstanding biological assumptions, illuminate intricate details, and even create new proteins or design novel molecular circuits.

One of the most important aspects discussed in their perspective article is the new ability of computational biophysicists to simulate complex biological processes that range from the subatomic to whole-cell models, in extraordinary detail.

As Dr. Bernardi articulates, ""The new exascale computers allow computational biophysicists to go beyond what can done experimentally and simulate biological processes with a much higher level of detail. For instance, we can now understand how pathogenic bacteria bind to humans during infection at an atomistic level, generating data for AI models and opening new roads of exploration.""

Historically, fields such as physics and chemistry have relied heavily on theoretical models to guide experiments. Today, biology stands at a similar crossroads, with novel software and specialized hardware becoming pivotal in deciphering experimental data and proposing innovative models.

The inaugural public exascale supercomputer, Frontier, which was deployed by the Oak Ridge National Laboratory in late 2021, coupled with the rapid proliferation of artificial intelligence tools tailored for biophysics, exemplifies the profound strides being made to seamlessly bridge simulation with actual observation.

The momentum gained by computational biophysics signifies a monumental shift. As biophysical research progresses, the seamless integration of experimental and computational efforts is expected to redefine the frontiers of knowledge, laying the groundwork for unprecedented discoveries that could reshape our understanding of the biological world.

More information: Marcelo C.R. Melo et al, Fostering discoveries in the era of exascale computing: How the next generation of supercomputers empowers computational and experimental biophysics alike, Biophysical Journal (2023). DOI: 10.1016/j.bpj.2023.01.042 Journal information: Biophysical Journal

Provided by Auburn University Department of Physics",https://scx2.b-cdn.net/gfx/news/hires/2023/exascale-revolution-su.jpg,https://phys.org/news/2023-08-exascale-revolution-supercomputers-unleash-era.html,Science
['Bob Yirka'],,Penetrating radar aboard the Chang'E-4 rover reveals layers of the moon's history,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Image taken by the panoramic camera (PCAM) on board the Chinese Yutu 2 lunar rover as it looked back at the Chang'e 4 lander. Credit: Nature Communications (2019). DOI: 10.1038/s41467-019-12278-3/Wikimedia Commons/CC BY-SA

A team of space scientists at the Planetary Science Institute, working with colleagues from the Chinese Academy of Sciences, Shenzhen University and the University of Aberdeen, has used data from China's Chang'E-4 rover to learn more about the history of the moon. In their study, reported in the Journal of Geophysical Research: Planets, the group analyzed lunar-penetrating radar (LPR) data sent back from the rover.

China's Chang'E-4 rover has been wandering around on the far side of the moon since 2018. And during its meanderings, it has been sending radio signals downward using its LPR device. That same device detects and records signals that are bounced back—a form of radar. Three years ago, another team of researchers used a subset of the same data to create a subsurface map extending 40 meters below the surface. In this new paper, the research team has built on that effort, creating a subsurface map extending 300 meters below the surface.

The research team has found that the top 300 meters of the moon's surface is made up of several layers of material, some broken rock, some dust and some soil. The researchers have also found evidence of a hidden crater. Below that, they found layers of lava—evidence of the moon's volcanic past.

Prior research has suggested that the moon was formed approximately 4.5 billion years ago—it is believed that it was created when a large planet collided with the Earth, blasting a chunk of the combined planetary matter into orbit. Prior research has also suggested that some time later, a large object struck the moon, cracking its surface. That allowed some of the molten material inside to seep to the surface.

Data from Chang'E-4 bolsters that theory. In analyzing the layers of lava, they found that each succeeding layer was thinner than the prior layer, evidence of cooling and closing of fissures. Prior research has suggested that volcanic activity ceased on the moon approximately 1 billion years ago, and it is now considered geologically dead.

The researchers note that Chang'E-4 is still sending and listening to radio signals, which means there is more yet to learn.

© 2023 Science X Network",https://scx2.b-cdn.net/gfx/news/2023/penetrating-radar-aboa.jpg,https://phys.org/news/2023-08-penetrating-radar-aboard-change-rover.html,Science
['Web Desk'],,Scientists in China map hidden structures of moon's far side,"Chinese Lunar probe rover Yutu-2 roll on the far side of the Moon in this picture. — CTGN/CSNA/File

The first-ever Chinese lunar space probe to land on the far side of the moon has allowed scientists to study deep hidden structures of the Earth's natural satellite which can enhance the understanding of the researchers about its history and evolution.

The Yutu-2 rover under Chang’e-4 space mission discovered the structures using Lunar Penetrating Radar (LPR) which enabled experts to map deep into the moon’s surface by listening to hidden echoes of sound that bounced back off structures deep inside regolith.

The Chinese lunar robot was the first in 2019 to land far on the moon which does not face the Earth.

Earlier, experts launched efforts using the probe’s ground penetrating radar (GPR), however, it only mapped the top 40m, or about 130ft, of the surface. The current discovery is at depths of about 300m (984ft).

According to a new study published in the Journal of Geophysical Research: Planets, scientists found that the first 130ft is made up of layers of dust, soil, and rocks.

The presence of a buried crater was also found that was formed when a large object hit the moon.

""The GPR sends electromagnetic pulses into the lunar interior and receives echoes from subsurface layers. We use the high-frequency channel data to detect the structure of the upper 40 m along the rover’s path, primarily consisting of rock debris and soil,"" researchers explained in the study.

Researchers believe that the broken rocks surrounding this formation were likely debris produced by the impact.

They wrote: ""Through this investigation, we have discovered multiple layers in the upper 300 m, which likely indicate a series of basalt eruptions that occurred billions of years ago.""

The volcanic rock layers were found to be thinner near the lunar surface.

""The thickness variation of these lava flows suggests a decrease in eruption scale over time,"" they noted.

According to the evidence, they maintained that the lunar volcanic activity cooled gradually since the moon’s formation over 4.5 billion years ago when a Mars-sized object hit Earth and broke off a chunk that eventually became the moon.

Researchers concluded: “The thickness of the strata decreases with the decreasing depth, suggesting a progressively smaller lava effusion rate over time.”",https://www.geo.tv/assets/uploads/updates/2023-08-23/l_506368_034150_updates.jpg,https://www.geo.tv/latest/506368-scientists-in-china-map-hidden-structures-of-moons-far-side,Science
[],,Beneath the Moon’s Surface: Chinese Rover Reveals Astonishing Discoveries,"The Moon hides many more secrets than it seems, and here’s an example. China’s lunar rover, Yutu-2, has discovered hidden structures beneath the lunar surface that have impressed the scientific community. These structures were detected using a radar capable of “seeing” tens of meters below the surface.

NASA App DOWNLOAD

The study that addresses this significant discovery has been published in the scientific journal Journal of Geophysical Research: Planets, detailing the process and its potential implications for the Moon’s future. The Yutu-2 rover made its lengthy journey to the Moon in 2018, aboard the Chang’e-4 spacecraft.

As detailed by Space.com, Yutu-2 can send radio signals that penetrate through the lunar surface using a tool called the Lunar Penetrating Radar (LPR). “Then, it listens to the echoes that dance back,” explained Jianqing Feng, an astrogeological researcher at the Institute of Planetary Science, to Live Science.

Once the “echoes” are collected, scientists can reconstruct where the radio waves bounced off the subterranean structures, similar to the echolocation of bats. This marks the first time scientists have used the LPR to penetrate beyond the first 40 meters of the lunar surface.

The new data collected in this study demonstrates that the Moon’s surface is composed of layers of fractured rocks, among which five layers of lunar lava are hidden. Scientists believe that this lava could have resulted from the impact of asteroids crashing into the Moon (which would also explain the existence of the famous lunar craters).

A widely held hypothesis in the scientific community is that the Moon was once part of Earth but separated when a celestial body collided with the planet about 4.51 billion years ago. It’s believed that the impact led to a series of fissures which, in turn, caused a series of volcanic explosions as magma seeped to the Moon’s surface.

NASA App DOWNLOAD

“The Moon was cooling slowly and running out of steam in its final volcanic stage,” Feng said. “Its energy weakened over time.” Despite scientists almost universally acknowledging that the Moon’s volcanic activity ceased about 1 billion years ago, Feng believes that there might still be some magma left beneath its surface.

Some of the links added in the article are part of affiliate campaigns and may represent benefits for Softonic.","https://articles-img.sftcdn.net/f_auto,t_article_cover_xl/auto-mapping-folder/sites/3/2023/08/Luna-estructuras-ocultas-bajo-su.jpg",https://en.softonic.com/articles/what-the-chinese-rover-has-discovered-under-the-surface-of-the-moon,Science
[],,MSN,,,,Science
['News Staff'],2023-08-22 17:11:56+00:00,Could Saber-Toothed Cats and American Lions Roar?,"The American lion (Panthera atrox) may have roared, while the saber-toothed cat Smilodon fatalis may have produced vocalizations similar to living purring cats but at a lower frequency.

Modern cats belong to one of two groups: either the pantherine ‘big cats,’ including the roaring lions, tigers and jaguars; or Felinae ‘little cats,’ which include purring cats like lynxes, cougars, ocelots and domestic cats.

“Evolutionarily speaking, sabertooths split off the cat family tree before these other modern groups did,” North Carolina State University’s Professor Adam Hartstone-Rose.

“This means that lions are more closely related to housecats than either are to sabertooths.”

“That’s important because the debate over the kind of vocalization a sabertooth tiger would have made relies upon analyzing the anatomy of a handful of tiny bones located in the throat.”

“And the size, shape and number of those bones differ between modern roaring and purring cats.”

Although vocalization is driven by the larynx and soft tissue in the throat, not bones, anatomists noticed that the bones responsible for anchoring those tissues in place — the hyoid bones — differed in size and number between roaring and purring cats.

“While humans have only one hyoid bone, purring cats have nine bones linked together in a chain and roaring cats have seven,” said Ashley Deutsch, a Ph.D. student at North Carolina State University.

“The missing bones are located toward the top of the hyoid structure near where it connects to the skull.”

“Because saber-toothed tigers only have seven bones in their hyoid structure, the argument has been that of course they roared,” Professor Hartstone-Rose said.

“But when we looked at the anatomy of modern cats, we realized that there isn’t really hard evidence to support this idea, since the bones themselves aren’t responsible for the vocalization.”

“That relationship between the number of bones and the sound produced hasn’t ever really been proven.”

The researchers compared the hyoid structures of four species of roaring cats (lions, tigers, leopards and jaguars) and five species of purring cats (cougars, cheetahs, caracals, servals and ocelots) to 105 hyoid bones from Smilodon fatalis and one from Panthera atrox.

“You can argue that since the sabertooths only have seven bones they roared, but that’s not the whole story,” Professor Hartstone-Rose said.

“The anatomy is weird. They’re missing extra bones that purring cats have, but the shape and size of the hyoid bones are distinct. Some of them are shaped more like those of purring cats, but much bigger.”

According to the researchers, if the missing bones (called epihyoid bones) were key to different vocalizations, the bones most closely connected to them should look different between the two groups.

However, those bones looked very similar in shape whether they came from purring or roaring cats.

In fact, the researchers saw more shape variation in the bones closer to the vocal apparatus; i.e., the thyrohyoid and basihyoid bones.

The uniformity of the upper bones between the two groups suggests that if the hyoid structure plays a role in vocalization, the lower bones are more important than the upper ones.

So having these key hyoid bones shaped like those of purring cats could indicate that they purred rather than roared.

“Panthera atrox and Smilodon fatalis had larger and more robust hyoids than living cats, potentially reflecting the ability to produce lower frequency vocalizations as well as more substantial muscles associated with swallowing and respiration.”

“Based on the shape of the hyoid elements, Panthera atrox resembled roaring cats, while Smilodon fatalis was quite variable and, contrary to suggestions from previous research, more similar overall to purring felids.”

“Thus Panthera atrox may have roared and Smilodon fatalis may have produced vocalizations similar to extant purring cats but at a lower frequency.”

“Due to the confounding of vocalization repertoire and phylogenetic history in living Felidae, we cannot distinguish between morphological signals related to vocalization behavior and those related to shared evolutionary history unrelated to vocalization.”

The findings were published in the Journal of Morphology.

_____

Ashley R. Deutsch et al. The roar of Rancho La Brea? Comparative anatomy of modern and fossil felid hyoid bones. Journal of Morphology, published online August 20, 2023; doi: 10.1002/jmor.21627",https://cdn.sci.news/images/2023/08/image_12199f-Smilodon-fatalis.jpg,https://www.sci.news/paleontology/panthera-atrox-smilodon-fatalis-vocalizations-12199.html,Science
['North Carolina State University'],2023-08-22 22:50:52-07:00,Sabertooth Secrets: Did These Ancient Beasts Purr or Roar?,"The answer might be found in a tiny string of bones.

When a sabertooth tiger called out, what sound did it produce – a powerful roar or a deep purr? Recent research from North Carolina State University delved into the evidence supporting each theory, discovering that the answer might be more complex than initially believed – and that it could depend on the shape of a few small bones.

Present-day felines can be categorized into two primary groups: the pantherine “big cats”, such as roaring lions, tigers, and jaguars; and the Felinae “small cats”, which encompass purring species like lynxes, cougars, ocelots, and domestic cats.

“Evolutionarily speaking, sabertooths split off the cat family tree before these other modern groups did,” says Adam Hartstone-Rose, professor of biological sciences at NC State and corresponding author of the research. “This means that lions are more closely related to housecats than either are to sabertooths.

“That’s important because the debate over the kind of vocalization a sabertooth tiger would have made relies upon analyzing the anatomy of a handful of tiny bones located in the throat,” Hartstone-Rose says. “And the size, shape, and number of those bones differ between modern roaring and purring cats.”

Although vocalization is driven by the larynx and soft tissue in the throat, not bones, anatomists noticed that the bones responsible for anchoring those tissues in place – the hyoid bones – differed in size and number between roaring and purring cats.

“While humans have only one hyoid bone, purring cats have nine bones linked together in a chain and roaring cats have seven,” says Ashley Deutsch, a Ph.D. student at NC State and lead author of the research. “The missing bones are located toward the top of the hyoid structure near where it connects to the skull.”

“Because sabertooth tigers only have seven bones in their hyoid structure, the argument has been that of course, they roared,” Hartstone-Rose says. “But when we looked at the anatomy of modern cats, we realized that there isn’t really hard evidence to support this idea, since the bones themselves aren’t responsible for the vocalization. That relationship between the number of bones and the sound produced hasn’t ever really been proven.”

The researchers looked at the hyoid structures of four species of roaring cats: lions, tigers, leopards, and jaguars; and five species of purring cats: cougars, cheetahs, caracals, servals, and ocelots. They compared these to 105 hyoid bones from the iconic sabertooth tiger Smilodon fatalis.

“You can argue that since the sabertooths only have seven bones they roared, but that’s not the whole story,” Hartstone-Rose says. “The anatomy is weird. They’re missing extra bones that purring cats have, but the shape and size of the hyoid bones are distinct. Some of them are shaped more like those of purring cats, but much bigger.”

According to the researchers, if the missing bones (called epihyoid bones) were key to different vocalizations, the bones most closely connected to them should look different between the two groups. However, those bones looked very similar in shape whether they came from purring or roaring cats.

In fact, the researchers saw more shape variation in the bones closer to the vocal apparatus; i.e., the thyrohyoid and basihyoid bones. The uniformity of the upper bones between the two groups suggests that if the hyoid structure plays a role in vocalization, the lower bones are more important than the upper ones. So having these key hyoid bones shaped like those of purring cats could indicate that they purred rather than roared.

“We found that despite what history has told us about the number of bones in the hyoid structure, no one has validated the significance of that difference,” Hartstone-Rose says. “If vocalization is about the number of bones in the hyoid structure, then sabertooths roared. If it’s about shape, they might have purred. Due to the fact that the sabertooths have things in common with both groups, there could even be a completely different vocalization.”

“It is perhaps most likely that the size of the hyoids plays a role in the pitch of vocalization,” says Deutsch. “Although Smilodon wasn’t quite as big as the largest modern cats, its hyoid bones are substantially larger than those of any of their living relatives, so potentially they had even deeper vocalizations than the largest tigers and lions.”

Reference: “The roar of Rancho La Brea? Comparative anatomy of modern and fossil felid hyoid bones” by Ashley R. Deutsch, R. Brian Langerhans, Deanna Flores and Adam Hartstone-Rose, 20 August 2023, Journal of Morphology.

DOI: 10.1002/jmor.21627

The work appears in the Journal of Morphology and was supported by NC State’s Office of Undergraduate Research. Brian Langerhans, associate professor of biology at NC State, and former NC State undergraduate Deanna Flores also contributed to the work.",https://scitechdaily.com/images/Smilodon-fatalis-scaled.jpg,https://scitechdaily.com/sabertooth-secrets-did-these-ancient-beasts-purr-or-roar/,Science
"['Laura Baisas', 'Laura Is A Science News Writer', 'Covering A Wide Variety Of Subjects', 'But She Is Particularly Fascinated All Things Aquatic', 'Paleontology', 'Nanotechnology', 'Exploring How Science Influences Daily Life. Laura Is A Proud Former Resident Of The New Jersey Shore', 'A Competitive Swimmer', 'A Fierce Defender Of The Oxford Comma.']",2023-08-22 13:00:00-04:00,Mighty sabertooth tigers may have purred like kittens,"If the mighty Ice Age sabertooth tiger called out in a forest, and no one was around to hear it, did it even make a sound? A team of researchers from North Carolina State University set out to answer that philosophical question by investigating if sabertooth cats had a throaty purr or a mighty roar. They found that tiny bones in the tiger’s throat might present a more nuanced answer. Their findings were published August 21 in the Journal of Morphology.

[Related: Life in Los Angeles was brutal for saber-toothed cats.]

Present-day cats belong to two subfamilies who make different vocalizations. The pantherine or “big cats” include lions, jaguars, and tigers who typically roar. Felinae or “little cats” includes domestic cats, ocelots, lynxes, and cougars who purr. For cats that roar, the structures that surround their larynx (or voice box) generally aren’t stiff enough to make the purring sound.

“Evolutionarily speaking, sabertooths split off the cat family tree before these other modern groups did,” study co-author and NC state biologist Adam Hartstone-Rose said in a statement. “This means that lions are more closely related to housecats than either are to sabertooths.

Vocalization is driven by the larynx and soft tissue in the throat, not bones. However anatomists noticed that the bones responsible for anchoring those tissues in place called the hyoid bones differed in both number and size between purring and roaring cats.

“While humans have only one hyoid bone, purring cats have nine bones linked together in a chain and roaring cats have seven,” co-author and NC State Ph.D. student Ashley Deutsch said in a statement. “The missing bones are located toward the top of the hyoid structure near where it connects to the skull.”

According to the team, sabertooth tigers only have seven bones in their hyoid structure, but the shape and size look eerily similar to some purring cats’ bones. If vocalization is related to the number of bones in the hyoid structure, then the sabertooths roared. However, if it is about shape, they may have purred.

“You can argue that since the sabertooths only have seven bones they roared, but that’s not the whole story,” said Hartstone-Rose. “The anatomy is weird. They’re missing extra bones that purring cats have, but the shape and size of the hyoid bones are distinct. Some of them are shaped more like those of purring cats, but much bigger.

[Related: Orangutans can make two sounds at the same time.]

According to the team, if the missing bones (the epihyoid bones) were the key to different vocalizations, then the bones that are most closely connected to them should appear different between purrers and roarers. Those bones actually looked very similar in shape in the purring variety of cats.

The team saw more shape variation in the bones that are closer to the vocal apparatus, like the the thyrohyoid and basihyoid bones. Having these key hyoid bones shaped like those belonging to purring cats may indicate that they purred like a kitten instead of roaring like a lion, but it is still a bit of a prehistoric mystery.

“It is perhaps most likely that the size of the hyoids plays a role in the pitch of vocalization,” said Deutsch. “Although Smilodon wasn’t quite as big as the largest modern cats, its hyoid bones are substantially larger than those of any of their living relatives, so potentially they had even deeper vocalizations than the largest tigers and lions.”",https://www.popsci.com/uploads/2023/08/22/saber-tooth-vocalization.png?auto=webp,https://www.popsci.com/science/sabertooth-tiger-purr-roar/,Science
"['Tracey Peake', 'North Carolina State University']",,Did sabertooth tigers purr or roar? The answer may lie in a tiny string of bones,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Schematic of felid hyoid anatomy in situ in (a) Panthera tigris and (b) Caracal caracal. Stylohyoid is orange, epihyoid (* = ligamentous in Panthera) is purple, ceratohyoid is yellow, basihyoid is red, and thyrohyoid is cyan. Credit: Journal of Morphology (2023). DOI:10.1002/jmor.21627

When a sabertooth tiger called out, what noise did it make—a mighty roar or a throaty purr? A new study from North Carolina State University researchers has examined the data behind the arguments for each vocalization and found that the answer was more nuanced than they thought—and that it could depend on the shape of a few small bones. The work appears in the Journal of Morphology.

Modern cats belong to one of two groups: either the pantherine ""big cats,"" including the roaring lions, tigers and jaguars; or Felinae ""little cats,"" which include purring cats like lynxes, cougars, ocelots and domestic cats.

""Evolutionarily speaking, sabertooths split off the cat family tree before these other modern groups did,"" says Adam Hartstone-Rose, professor of biological sciences at NC State and corresponding author of the research. ""This means that lions are more closely related to housecats than either are to sabertooths.

""That's important because the debate over the kind of vocalization a sabertooth tiger would have made relies upon analyzing the anatomy of a handful of tiny bones located in the throat,"" Hartstone-Rose continues. ""And the size, shape and number of those bones differ between modern roaring and purring cats.""

Although vocalization is driven by the larynx and soft tissue in the throat, not bones, anatomists noticed that the bones responsible for anchoring those tissues in place—the hyoid bones—differed in size and number between roaring and purring cats.

""While humans have only one hyoid bone, purring cats have nine bones linked together in a chain and roaring cats have seven,"" says Ashley Deutsch, a Ph.D. student at NC State and lead author of the research. ""The missing bones are located toward the top of the hyoid structure near where it connects to the skull.""

""Because sabertooth tigers only have seven bones in their hyoid structure, the argument has been that of course they roared,"" Hartstone-Rose says. ""But when we looked at the anatomy of modern cats, we realized that there isn't really hard evidence to support this idea, since the bones themselves aren't responsible for the vocalization. That relationship between the number of bones and the sound produced hasn't ever really been proven."" Credit: North Carolina State University

The researchers looked at the hyoid structures of four species of roaring cats: lions, tigers, leopards and jaguars; and five species of purring cats: cougars, cheetahs, caracals, servals and ocelots. They compared these to 105 hyoid bones from the iconic sabertooth tiger Smilodon fatalis.

""You can argue that since the sabertooths only have seven bones, they roared, but that's not the whole story,"" Hartstone-Rose says. ""The anatomy is weird. They're missing extra bones that purring cats have, but the shape and size of the hyoid bones are distinct. Some of them are shaped more like those of purring cats, but much bigger.""

According to the researchers, if the missing bones (called epihyoid bones) were key to different vocalizations, the bones most closely connected to them should look different between the two groups. However, those bones looked very similar in shape whether they came from purring or roaring cats.

In fact, the researchers saw more shape variation in the bones closer to the vocal apparatus; i.e., the thyrohyoid and basihyoid bones. The uniformity of the upper bones between the two groups suggests that if the hyoid structure plays a role in vocalization, the lower bones are more important than the upper ones. So having these key hyoid bones shaped like those of purring cats could indicate that they purred rather than roared.

""We found that despite what history has told us about the number of bones in the hyoid structure, no one has validated the significance of that difference,"" Hartstone-Rose says. ""If vocalization is about the number of bones in the hyoid structure, then sabertooths roared. If it's about shape, they might have purred. Due to the fact that the sabertooths have things in common with both groups, there could even be a completely different vocalization.""

""It is perhaps most likely that the size of the hyoids plays a role in the pitch of vocalization,"" says Deutsch. ""Although Smilodon wasn't quite as big as the largest modern cats, its hyoid bones are substantially larger than those of any of their living relatives, so potentially they had even deeper vocalizations than the largest tigers and lions.""

Brian Langerhans, associate professor of biology at NC State, and former NC State undergraduate Deanna Flores also contributed to the work.

More information: Ashley R. Deutsch et al, The roar of Rancho La Brea? Comparative anatomy of modern and fossil felid hyoid bones Journal of Morphology (2023). DOI: 10.1002/jmor.21627. onlinelibrary.wiley.com/doi/10.1002/jmor.21627 Journal information: Journal of Morphology",https://scx2.b-cdn.net/gfx/news/2023/did-sabertooth-tigers.jpg,https://phys.org/news/2023-08-sabertooth-tigers-purr-roar-tiny.html,Science
['Kevin Hartnett'],2023-08-22 00:00:00,Quanta Magazine,"“I had heard rumors that this was coming up, and I didn’t know exactly what to expect,” said Vesna Stojanoska, a mathematician at the University of Illinois, Urbana-Champaign who attended the conference.

It was soon clear the rumors were true. Beginning on Tuesday, and over the next three days, Levy and his co-authors — Robert Burklund, Jeremy Hahn and Tomer Schlank — explained to the crowd of some 200 mathematicians how they’d proved that the telescope conjecture was false, making it the only one of Ravenel’s original conjectures not to be true.

The disproof of the telescope conjecture has wide-ranging implications, but one of the simplest and most profound is this: It means that in very high dimensions (think of a 100-dimensional sphere), the universe of different shapes is far more complicated than mathematicians anticipated.

Mapping the Maps

To classify shapes, or topological spaces, mathematicians distinguish between differences that matter and those that don’t. Homotopy theory is a perspective from which to make those distinctions. It considers a ball and an egg to be fundamentally the same topological space, because you can bend and stretch one into the other without ripping either. In the same way, homotopy theory considers a ball and an inner tube to be fundamentally different because you have to tear a hole in the ball to deform it into the inner tube.

Homotopy is useful for classifying topological spaces — creating a chart of all the kinds of shapes that are possible. It’s also important for understanding something else mathematicians care about: maps between spaces. If you have two topological spaces, one way to probe their properties is to look for functions that convert, or map, points on one to points on the other — input a point on space A, get a point on space B as your output, and do that for all the points on A.

To see how these maps work, and why they illuminate properties of the spaces involved, start with a circle. Now map it onto the two-dimensional sphere, which is the surface of a ball. There are infinitely many ways of doing this. If you imagine the sphere as Earth’s surface, you could put your circle at any line of latitude, for example. From the perspective of homotopy theory, they’re all equivalent, or homotopic, because they can all shrink down to a point at the north or south pole.

Next, map the circle onto the two-dimensional surface of an inner tube (a one-holed torus). Again, there are infinitely many ways of doing this, and most are homotopic. But not all of them. You could place a circle horizontally or vertically around the torus, and neither can be smoothly deformed into the other. These are two (of many) ways of mapping a circle onto the torus, while there is just one way to map it onto a sphere, reflecting a fundamental difference between the two spaces: The torus has one hole while the sphere has none.

It’s easy to count the ways we can map from the circle to the two-dimensional sphere or torus. They’re familiar spaces that are easy to visualize. But counting maps is much harder when higher-dimensional spaces are involved.

Dimensional Differences

If two spheres have the same dimension, there are always infinitely many maps between them. And if the space you’re mapping from is lower-dimensional than the space you’re mapping to (as in our example of the one-dimensional circle mapped onto a two-dimensional sphere), there is always only one map.

Partly for that reason, counting maps is most interesting when the space you’re mapping from has a higher dimension than the space you’re mapping to, like when you map a seven-dimensional sphere onto a three-dimensional sphere. In cases like those, the number of maps is always finite.

“The maps between spheres in general tend to be more interesting when the source has a larger dimension,” Hahn said.

Moreover, the number of maps depends only on the difference in the number of dimensions (once the dimensions get big enough compared to the difference). That is, the number of maps from a 73-dimensional sphere to a 53-dimensional sphere is the same as the number of maps from a 225-dimensional sphere to a 205-dimensional sphere, because in both cases, the difference in dimension is 20.

Mathematicians would like to know the number of maps between spaces of any difference in dimension. They’ve managed to compute the number of maps for almost all differences in dimension up to 100: There are 24 maps between spheres when the difference is 20, and 3,144,960 when it’s 23.",https://d2r55xnwy6nx47.cloudfront.net/uploads/2023/08/TelescopeConjecture-bySamuelVelasco-Social.webp,https://www.quantamagazine.org/an-old-conjecture-falls-making-spheres-a-lot-more-complicated-20230822/,Science
"['Dr. Russell Moul', 'Science Writer']",2023-08-22 14:52:56+00:00,"""New 167-Million-Year-Old Dinosaur In India Is Oldest Of Its Kind In The World""","Archaeologists from the Indian Institute of Technology and the Geological Survey of India have recovered the remains of a new dinosaur that has never been seen in India before. The new fossil belongs to a species of dicraeosaurid sauropod – a long-necked “veggiesaurus” that lived in the area during the Middle Jurassic era. The fossil is not only the first of its kind but also the earliest known diplodocoid found in the world.

The researchers have named the new species Tharosaurus indicus. According to their analysis, T. indicus has a long depression on the side of its neck bones and neural spines that are not seen in other members of the group. The team believe they are evidence of spikes, potentially similar to those that appear on Bajadasaurus pronuspinax, another member of the Dicraeosauridae family. The ancient animal also appears to have a frontal vertebra surface near its tail bone that is reminiscent of a heart shape.

Advertisement Advertisement

Sauropods are thought to have originated at some point in the Late Triassic or Early Jurassic era, but the origins of Neosauropoda, of which Diplodocoidea belong, is still unknown and quite contentious. However, the new spiny-dino could help address this issue.

Palaeobiogeographic consideration of T. indicus, in relation to other Indian Jurassic sauropods, suggests that it is a leftover from a lineage that appeared in India and then dispersed across the rest of the then supercontinent, Pangaea. From around 300-200 million years ago, the continents of North America, Africa, South America, and Europe were all one large landmass.

The fossil was discovered in the Thar Desert, not far from Jaisalmer in the state of Rajasthan. During the Mesozoic Era (between 252 and 66 million years ago), this part of the country was actually a shoreline along the Tethys Ocean. The researchers believe that this area possibly played an important role in the emergence of neosauropods – a subgroup of sauropods that also had long necks and fed off vegetation.

The researchers believe their find is likely just the first of many more to come, but other similar fossils discovered in the area suggest that the region played a role in the evolution of many vertebrates.

Advertisement Advertisement

More work is needed to identify other members of this species and to compare them to other sauropod species found in Asia. This will help fill in the gaps of how these animals became dispersed and where they originally came from.

The study is published in Scientific Reports.",https://assets.iflscience.com/assets/articleNo/70359/aImg/70155/caudal-vertebrae-of-tharosaurus-indicus-meta.jpg,https://www.iflscience.com/new-167-million-year-old-dinosaur-in-india-is-oldest-of-its-kind-in-the-world-70359,Science
['Sejal Sharma'],2023-08-22 19:22:00+00:00,Fossils of 167-million-year-old dinosaur are the oldest of its kind,"Dicraeosaurids were a family of small-bodied sauropod dinosaurs that diversified from the Middle Jurassic to the Lower Cretaceous. Their most distinctive features were their long spine and unusual walking. They also ate plants.

Mostly found in Africa and South America, besides a few occurrences in the USA and China, to date, no diplodocoid (a broader group encompassing the dicraeosaurids) sauropods have been traced in India. Until now.

A team of researchers from India has discovered fossils of a new dicraeosaurid from the Indian city of Jaisalmer in western India. These fossils, dating back to 167 million years, include bones separated at the joints but associated with specimens of the central body bones spread over an area of 270 square feet ( 25- square meters).",https://dnd2oi6izkvoi.cloudfront.net/2023/08/22/image/jpeg/HfMNh7WJmqqXn9UeMbKIHHl3GOowNjqYBaUUFK0H.jpg,https://interestingengineering.com/culture/fossils-of-167-million-year-old-dinosaur-are-the-oldest-of-its-kind,Science
['Bob Yirka'],,First ever remains of a dicraeosaurid sauropod unearthed in India,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Cervical vertebrae (CV6/8) of Tharosaurus indicus. (a) RWR-241-A, anterior cotyle in anterior view. (b–k) RWR-241-B, partial vertebra, photographs and line drawings in (b,c) right lateral view, red line indicates U-shaped ridge demarcating anterior and posterior halves of lateral pneumatic fossa; (d,e) left lateral view; (f,g) ventral view, red line indicates posteriorly bifurcated midline keel and arrow indicates accessory ridge; (h,i) posterior view, arrows and red arrowheads indicate deep bifurcation of neural arch and triangular facets below cotyle, respectively. (j,k) dorsal view, arrowhead indicates passage enclosed by bifid neural arch and ligament scars and striations marked in red and purple, respectively. Broken areas and artifacts in gray and pink, respectively. c centrum, cpof centropostzygapophyseal fossa, cpol centropostzygapophyseal lamina, lf lateral fossa, lvf lateroventral flange, mk midline keel, na neural arch, nc neural canal, pvf posteroventral fossa, tpol intrapostzygapophyseal lamina. Scale bars represent 50 mm. Credit: Scientific Reports (2023). DOI: 10.1038/s41598-023-39759-2

A team of archaeologists from the Indian Institute of Technology and the Geological Survey of India, has unearthed the first ever remains of a dicraeosaurid sauropod in India. In their paper published in the journal Scientific Reports, the group describes the fossil, its condition and where it fits in with other dinosaurs of the Middle Jurassic.

The fossil (a partial dorsal vertebra) was dug up at a site in the Thar Desert near the city of Jaisalmer, in the state of Rajasthan. Prior research has shown that during the Mesozoic Era, the area was a shoreline along the Tethys Ocean. The newly found fossil has been dated to approximately 167 million years ago and identified as a member of the dicraeosaurids, which were a group of dinosaurs with long necks that fed on vegetation. It is the first member of the group to have ever been found in India—and the oldest in the world.

The team has named their new find Tharosaurus indicus. They note that dicraeosaurids, such as T. indicus, are all part of a larger group called diplodocoids, which all had long bodies and necks and spikes on the backs of their necks. T. indicus., the researchers note, has some slight differences from others in its group, such as a long depression on the side of its neck bones and neural spines that are believed to indicate it had uniquely facing spikes. It also had a frontal vertebra surface reminiscent of a heart near its tail bone.

The research team suggest their find is likely just the first of many to come, and together such fossils hint at the possibility that the area where the fossil was found likely played an important role in the emergence of neosauropods—also long-necked, vegetation eating dinosaurs.

They note that other fossils have been found in the area that also suggest the region played an evolutionary role in the development of many vertebrate groups. They conclude by noting that work such as theirs is still limited in India, due to an inadequate supply of resources—much more needs to be done to find out just how rich the country might be in dinosaur fossils.

More information: Sunil Bajpai et al, Fossils of the oldest diplodocoid dinosaur suggest India was a major centre for neosauropod radiation, Scientific Reports (2023). DOI: 10.1038/s41598-023-39759-2 Journal information: Scientific Reports

© 2023 Science X Network",https://scx2.b-cdn.net/gfx/news/hires/2023/first-ever-remains-of.jpg,https://phys.org/news/2023-08-dicraeosaurid-sauropod-unearthed-india.html,Science
[],,"Wake up, new Rajasthani dinosaur just dropped. And she’s the world's oldest vegetarian dino","The scorching heat of the Thar Desert in Rajasthan, has revealed a paleontological treasure that sheds new light on the history of dinosaurs. A collaborative effort between the brainiacs at the Indian Institute of Technology Roorkee (IIT-Roorkee) and the dino detectives from the Geological Survey of India (GSI) has unveiled the fossilized remains of the world's oldest vegetarian dinosaur in Jaisalmer.

Advertisement

In the modern era, the Thar Desert is situated in western India's Rajasthan state, but during the Mesozoic Era, it was a tropical shoreline along the Tethys Ocean, teeming with dinosaurs and marine life.

Picture this: around 167 million years ago, when the Thar Desert was more of a tropical beach than a parched wasteland, there lived the original herbivore trendsetter – Tharosaurus indicus. This long-necked, plant-munching marvel is a dicraeosaurid dinosaur, part of the sauropod gang that ruled the Jurassic and Cretaceous scenes.

167 million yrs old fossil remains of a long-necked plant eating dicraeosaurid #dinosaurs has been recovered from #Jaisalmer. The remains are of new species that has been named as Tharosaurus Indicus.



reports @MohitaTOI



Read more about it here : https://t.co/WcVKNO3j7v https://t.co/c8hVJNTVtU pic.twitter.com/ZAtFKy5DxT — Arvind Chauhan 💮🛡️ (@Arv_Ind_Chauhan) August 19, 2023

The discovered specimen, named Tharosaurus indicus, is the first known dicraeosaurid from India and the oldest of its kind ever found globally. But what makes Tharosaurus indicus a true ""rock star"" (pun intended) is its debut in India's paleontological stage. Paleontologists have fittingly dubbed it ""Tharosaurus"" after its home, and ""indicus"" as a shoutout to its Indian roots.

An excitable friend told me that my recent book was now officially a dinosaur! I will now have to break the news to her that “Tharosaurus Indicus”, the new plant-eating dinosaur found in India, is actually named for the Thar Desert, where it was unearthed! https://t.co/ggaQs2nQiy — Shashi Tharoor (@ShashiTharoor) August 12, 2023

The researchers behind the discovery suggest that this finding underscores the vital importance of exploring fossils in the Indian subcontinent to gain a more comprehensive understanding of the planet's prehistory. The discovery of Tharosaurus indicus challenges earlier assumptions about dinosaur populations in India.

Advertisement

The scientists have named this newly discovered dinosaur species as #TharosaurusIndicus. They had long necks and elongated bodies. This is a pioneering discovery in #BharatRashtra,

Thar desert was a coastline to the Tethys Ocean, back then, that was inhabited by these herbivores. pic.twitter.com/U6k5vQVoWJ — BHĀRAT RĀSHTRA (@BHARAT__RASHTRA) August 20, 2023

It breaks the ancient stereotype that India was just a ""dino-free zone."" Contrary to popular belief, India was a happening hub for dino evolution.

This finding suggests that the Thar Desert, once a tropical hangout spot, hosted a lively lineup of vegetarian giants.

This finding also suggests a more diverse dinosaur population in the region during the Middle Jurassic to Early Cretaceous periods.

Tharosaurus indicus provides critical insights into the evolutionary history of sauropods, a diverse group of long-necked dinosaurs that dominated landscapes during the Mesozoic Era.

The fossil exhibits unique characteristics, including elongated depressions on the neck bones' sides, neural spines with deep divisions resembling upward spikes on the neck, and a heart-shaped front surface on its tail bones.

These features not only differentiate it from other dicraeosaurids but also contribute to our understanding of sauropod adaptations and evolution.

The discovery of the Tharosaurus, along with other primitive dinosaur findings such as the Barapasaurus and Kotasaurus, suggests that India played a crucial role in the emergence and diversification of neosauropods, a group of long-necked vegetarian dinosaurs that grew to become the largest land animals of their time.

Advertisement

This revelation dovetails with the broader narrative of India's significance in the evolution of various vertebrate groups. Tharosaurus indicus joins the ranks of India's fossil celebrities like Indohyus and Cambaytherium, offering vital clues about the origin stories of whales and horses.

Despite the importance of such discoveries, the field of vertebrate paleontology in India faces challenges.

Limited access to fossil sites due to mining activities, dense forest cover, insufficient funding, and a scarcity of job opportunities for paleontologists hinder comprehensive research.

However, recent federal proposals aimed at preserving geo-heritage sites, including critical fossil sites, offer hope for the advancement of paleontological exploration in the country.

This exciting new finding underscores the need for continued exploration and protection of paleontological sites in India to unravel the mysteries of our planet's past.",https://akm-img-a-in.tosshub.com/sites/dailyo//resources/202308/copy-of-g2-cover210823013854.png,https://www.dailyo.in/news/wake-up-new-rajasthani-dinosaur-just-dropped-and-shes-the-worlds-oldest-vegetarian-dino-41152,Science
[],,Mysterious Hackers Are Targeting Space Telescopes,"But why?

360 No Scope

For at least the last three weeks, hackers have been targeting major telescopes in Hawaii and Chile, forcing scientists to temporarily put ten observatories out of commission. Remote operations have also been shut down at a few others.

It's a mysterious development that has researchers hunting for answers, Science reports — let alone a motive. Why would somebody intentionally try to shut down astronomical research?

The suspension has already interrupted a number of international projects, including doctoral theses and other papers. Bewildered, researchers are now racing to find ways to tighten up cybersecurity and resume observations.

And for a lot of research, it may already be too late. Many observations are tightly scheduled, leaving researchers with narrow time windows, many of which have already closed.

Cyber Incident

The extent of the fallout is baffling. Earlier this month, NOIRLab, a federally supported research lab, announced that its Gemini North telescope in Hawaii had been shut down as a result of a ""cyber incident."" Its twin telescope, Gemini South, followed.

A week later, NOIRLab cut off astronomers from remotely accessing the controls of yet another network of telescopes called the Mid-Scale Observatories in Chile. Eight other telescopes in the country had to suspend operations as well.

Mysteriously, NOIRLab refused to elaborate on the nature of the cyberattack or clarify whether the attackers were asking for a ransom.

NOIRLab has since proposed to send out a team of graduate students to Chile with the hopes of resuming in-person observations.

Digital Fortress

Others questioned whether the hackers even know what they're doing.

""Quite possibly, the attacker doesn’t even know they are attacking an observatory,"" Von Welch, retired lead of the NSF Cybersecurity Center of Excellence, told Science.

It's an unusual situation for astronomers to find themselves in, as cyberattacks aren't usually part of their job description. But the incident will likely serve as motivation to batten down the hatches.

""When people are like, 'Oh, where’s the data?' Then I’ll have to say, 'Well, I don’t have any data because a hacker somewhere took down the computer,'"" Luis Welbanks, an astronomy postdoc at Arizona State University, who uses ground-based observations to study the atmospheres of exoplanets, told Science. ""I don’t know if any hiring committee will be sympathetic to that.""

More on cyberattacks: AI Knows What You're Typing Just By Hearing It Over a Zoom",https://wp-assets.futurism.com/2023/08/mysterious-hackers-targeting-space-telescopes.jpg,https://futurism.com/the-byte/mysterious-hackers-targeting-space-telescopes,Science
"['James Felton', 'Senior Staff Writer']",2023-08-22 11:55:01+00:00,"""Mysterious Cyberattack Shuts Down Yet More Telescopes For Weeks""","A cyberattack on the National Optical-Infrared Astronomy Research Laboratory (NOIRLab) research center for ground-based astronomy has left several large telescopes unable to operate for weeks.

The attack took place on August 1, when NOIRLab say they detected a ""cyber incident"" in their computer systems, requiring them to suspend astronomical observations at the Gemini North telescope on Mauna Kea in Hawai'i.

Advertisement Advertisement

""Quick reactions by the NOIRLab cyber security team and observing teams prevented damage to the observatory,"" NOIRLab said in a statement.

""Out of an abundance of caution we have decided to isolate the Gemini Observatory computer systems by shutting them down.""

Weeks later, 10 telescopes are still offline and remote control of many unavailable. Science attempted to find out more about the nature of the attack, but NOIRLab declined to say whether the hack was a ransomware attack. In ransomware attacks, users are denied access to their files or control over their systems and the hacker says they will only give it back once a ransom is paid.

Though NOIRLab have not confirmed it, a ransomware attack would be a likely candidate for an attack. In late October last year, the Atacama Large Millimeter Array (ALMA) Observatory in Chile announced that a hack had forced the telescope offline. The incident, which left the observatory offline for over a month, was confirmed to be a ransomware attack.

Advertisement Advertisement

Hackers may target telescopes, as well as other science facilities, due to the worth of their data and the cost to the facilities when they are forced to shut down operations. While ALMA was offline it was losing around a quarter of a million dollars a day, with hackers likely gambling that ALMA would pay up to avoid the expense. Though technicians were quickly able to isolate the systems affected by the hackers without paying a ransom, ALMA was only able to return to operations on December 21, after almost two months offline.

Another problem might be a lack of investment in cybersecurity. VP of technical account management EMEA at Tanium, Chris Vaughan, told Infosecurity Magazine at the time of the ALMA attack that these facilities likely had ""very limited"" IT budgets.

“A high level of network visibility should be utilized as part of a zero-trust approach. This is where implicit trust is eliminated and the principle of ‘never trust, always verify’ is used,” he told the magazine.

“This means that strong authentication methods, network segmentation and lateral movement prevention is key. If these practices are embedded within an organization’s culture along with effective staff training, then institutions like ALMA can carry on their fantastic work without costly interruptions caused by cyber-threats.”

Advertisement Advertisement

[H/T: Science]",https://assets.iflscience.com/assets/articleNo/70340/aImg/70140/gemini-north-meta.png,https://www.iflscience.com/mysterious-cyberattack-shuts-down-yet-more-telescopes-for-weeks-70340,Science
[],,Mysterious 'cyber incident' forces some telescopes to shut down,"National Science Foundation (NSF) telescopes are being targeted by mysterious cyber attacks, as per a new report by Science.org. Since the beginning of August, a major “cyber incident"" has disrupted the NSF centre which coordinates international astronomy efforts. The attacks have knocked out telescopes in Hawaii and Chile, further halting operations, and preventing the scientists from conducting research, the report said.

The apparent cyberattack was detected by NOIRLab, a coordinating centre run by NSF for ground-based astronomy.

“Quick reactions by the NOIRLab cyber security team and observing teams prevented damage to the observatory,” the centre said in a press release.

The first telescope to be affected was the Gemini North telescope in Hilo, Hawaii, which is operated by the International Gemini Observatory.

NOIRLab’s cybersecurity team and observing teams retracted quickly, which helped prevent physical damage to the observatory, but the attack forced operations at the Gemini North and Gemini South, located on Cerro Pachón mountain in Chile, to completely shut down.

As per the reports, the forced closure due to the incident impacted research as scientists missed out on significant observation windows, affecting international projects.

“We’re all in this together,” Science.org quoted Gautham Narayan, an astronomer at the University of Illinois Urbana-Champaign whose team is trying to save its chance to observe new supernovas using one of the affected Chilean telescopes, as saying.

The astronomy community has a “grim determination to press on, despite the trying circumstances,” he added.

On August 9, NOIRLab's computer systems, which usually permit astronomers to operate ground-based telescopes remotely, disconnected its computer network from the Mid-Scale Observatories (MSO) network on Cerro Tololo and Cerro Pachon, making the remote observations impossible at the Víctor M. Blanco 4-meter and SOAR telescopes.

According to the reports, the closure impacted eight other affiliated telescopes in Chile.

The NOIRLab team is making efforts to help find out temporary solutions in the absence of remote observing capabilities.

(With inputs from agencies)

WATCH WION LIVE HERE",https://cdn.wionews.com/sites/default/files/2023/08/22/374745-2023-08-20t000530z2lynxmpej7j000rtroptp4cyber-attack.JPG,https://www.wionews.com/science/mysterious-cyber-incident-forces-nsf-funded-telescopes-to-shut-down-627897,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
[],,A 9-minute journey inside a black hole,"If you were out in space exploring and you didn’t realize you were coming upon a black hole, you would not notice that anything terrible was about to happen. Eventually, however, you would succumb to a terrifying fate.

Black holes could have played a crucial role in the emergence of life. Ironically, the Solar System is in orbit around a supermassive black hole located in the center of our Milky Way galaxy. And one day, we might fall into a black hole.

Black holes should be thought of as “empty places” rather than “dense objects.” While they are indeed formed from incredibly dense objects (collapsed stars), the black hole itself is nothing.

Janna Levin: A very common misconception I think about black holes is that they're incredibly dense objects. They are indeed formed from incredibly dense objects: collapsed stars. But the black hole itself is nothing. Our sun is a million and a half kilometers across. But were we to crush the Sun to smaller and smaller scales, we would have to crush it to less than six kilometers across — the entire mass of the Sun.

At that point, the Sun itself is forced to continue to collapse, leaving behind nothing. There's no hard surface. There's no material from the Sun that made it — it's literally empty space. If you get close to a black hole, you might not even realize something truly terrible is about to happen. And so there's a deep sense in which we can think of a black hole as a place more than it is a thing.

I'm Janna Levin and I'm a professor of physics and astronomy at Barnard College of Columbia University, and my most recent book is ""Black Hole Survival Guide."" Maybe you wanna take a minute just to define 'curved space-time.' Let me just try something: So Einstein's equations describe how space and time respond to matter and energy. If I throw something around the Earth, I see that it travels along an arc — and if I throw it fast enough, I can put it into orbit.

Consider something like the International Space Station. It is launched at 17,500 miles an hour onto a curve that it is falling along freely. The engines are turned off, it is literally in free fall, and it's a perfect circle. That is an illustration of a shape in the curves around the Earth. These orbits, these arcs that things are falling along are the curves in spacetime.

So, if you were out in space exploring and you didn't realize you were coming upon a black hole, you could safely get very close to that black hole and not notice anything terrible was about to happen. The black hole is like a lens. You would see the light from around the black hole distorted by the curvature.

But if you realized very late that you were indeed near a black hole and you wanted very much to escape, you would have a real problem with your fuel rations. It's very expensive to launch things away from a gravitational object. It's very expensive to launch spacecraft off the Earth; it requires a tremendous amount of energy. If you were foolish enough to veer too close, there is no amount of thrust from your jet pack or fuel in the tank of your spacecraft that will actually be able to satisfy the requirements of escaping from a black hole.

If you get close to a black hole, you realize that not only is space curved, you also begin to notice that time has warped. We call it 'time dilation.' The pause between ticks on your clock, between breaths, between the firing of thoughts, all of these appear to slow down relative to somebody far from the black hole. For you, your experience of time is quite normal because you and your clock are synced. But for somebody far away, it appears that your clocks are slowing down. And as you edge closer and closer to the shadow, it will appear to somebody far away that your clocks have stopped ticking entirely. And as you cross and get further and further inside the black hole, the orbits that things can navigate on become smaller and smaller and smaller.

And eventually, you will get so close that there are no curves that lead outward. None. All paths lead inwards. And that defines a kind of ""shadow"" around this collapsed object, and that shadow determines what we call the 'event horizon,' the region beyond which no information will ever get out; not even light itself can ever escape.

It may surprise people to learn that the larger the black hole is, the safer you'll be for the longest period of time actually. You could cross the event horizon and you could watch the galaxy evolve behind you, and you could take notes and write poetry, and have a terrible sense of existential dread. You might be able to do that in the biggest black hole imaginable, maybe for a year if you had the supplies to keep yourself alive, before you hit your ultimate fate in the center.

Our story about the black hole leads, mathematically, to the prediction of a 'singularity,' which is a region in space and time where the curvature is responding to an infinite density. All of the matter is now crushed so catastrophically that it is creating an infinite curvature in space time. And as you race towards this singularity which you can't avoid, you will notice that space is trying to drive the atoms in your body closer together towards that singularity. It is also trying to pull you apart.

You would suddenly become aware that the curvature in space was stronger at your feet than it is at your head. You would feel your feet pulling away from your head. Eventually, you would break into pieces. So it's as though you're being squeezed and pulled apart. You're literally pulverized. Ultimately, even the atoms are broken apart to their fundamental quantum bits. And as you approach closer and closer to the singularity, you will in a finite time reach the end.

Now, if the singularity is real, it will be as though your quantum particles have spilled out of the Universe altogether, and essentially have ceased to exist. It's as though all of that matter is fundamentally lost. And that seems not only metaphysically terrifying, but also from the perspective of a scientist or a physicist, it seems wrong, and in violation of some of our core principles.

Now, it might be our core principles collapse and we have to just accept it for what it is: that things fall out of the Universe and cease to exist. Or it might be their principles are solid and strong, and that we should be using them to understand how to rewrite the ultimate fate of the material that falls into a black hole.

Black holes could be a really crucial link in the story that gets from the Big Bang to us, to the emergence of life. Not only that, we are in orbit around that supermassive black hole in our own Milky Way galaxy. And one day, we might fall into a black hole. That might be the ultimate fate of these atoms on this solar system. So, I think it should give us all pause to realize that we're all on this rock together that we're all progeny of this Universe — and that we may well all end up in the center of that black hole.","https://bigthink.com/wp-content/uploads/2023/08/A1-Web-Levin-1.jpg?resize=1200,630",https://bigthink.com/the-well/what-would-happen-if-we-fell-in-a-black-hole/,Science
['Brown University'],,Fluid dynamics researchers shed light on how partially submerged objects experience drag,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

In new study, Brown researchers describe how drag on a partially submerged object may be several times greater than drag on a fully submerged object. Image courtesy of the Harris Lab. Credit: Harris Lab.

One of the most common and practically useful experiments in all of fluid dynamics involves holding an object in air or submerging it fully underwater, exposing it to a steady flow to measure its resistance in the form of drag. Studies on drag resistance have led to technological advances in airplane and vehicle design and even advanced our understanding of environmental processes.

That's much tougher these days. As one of the most thoroughly studied aspects in fluid dynamics, it's become hard to glean or detail new information on the simple physics of drag resistance from these classic experiments. But a team of engineers led by Brown University scientists managed to do so by bringing this problem to the surface—the water surface, that is.

Described in an new paper in Physical Review Fluids, the researchers created a small river-like channel in the lab and lowered spheres—made of different water repellent materials—into the stream until they were almost fully submerged by the flowing water.

The results from the experiment illustrate the fundamental—and sometimes counterintuitive—mechanics of how drag on a partially submerged object may be several times greater than drag on a fully submerged object made of the same material.

For instance, the researchers—led by Brown engineers Robert Hunt and Daniel Harris—found that drag on the spheres increased the moment they touched the water, no matter how water repellent the sphere material was. Each time, the drag increased substantially more than what was expected and continued to increase as the spheres were lowered, beginning only to drop when the spheres were fully beneath the water.

""There's this intermediate period where the spheres going into the water are creating the biggest disturbances so that the drag is much stronger than if it were way below the surface,"" said Harris, an assistant professor in Brown's School of Engineering. ""We knew the drag would go up as the spheres were lowered because they are blocking more of the steady flow, but the surprising thing was how much it goes up. Then as you keep pushing the sphere deeper, the drag goes back down.""

The study shows drag forces on partially submerged objects can be three or four times greater than on fully submerged objects. The largest drag forces, for instance, were measured just prior to the sphere becoming fully submerged, meaning water is flowing all around it but there's still a small dry spot sticking out at the surface.

""You might expect how much of the sphere is in the water to correspond with how big the drag is,"" said Hunt, a postdoctoral researcher in Harris' lab and the study's first author. ""If so, then you might naively approximate the drag by saying that if the sphere is almost 100% in the water, the drag is going to be almost the same as if it was fully immersed beneath the surface. What we found is the drag can actually can be much larger than that—and not like 50% but more like 300% or 400%.""

The researchers also found that the sphere's level of water repellency plays a key role in the drag forces it experiences. This is where things get a bit counterintuitive. Drag forces on partially submerged objects can be three or four times greater than on fully submerged objects. The sphere coated with superhydrophobic material, making it very repellent to water, encountered more drag than the less water repellant spheres. Graph courtesy of the Harris Lab. Credit: Harris Lab

The experiment was done with three spheres that are otherwise identical except one was coated with a superhydrophobic material, making it very repellent to water, while the others were made of materials that are increasingly less water repellent.

Running the experiments, the researchers found that the superhydrophobic coating encountered more drag than the other two spheres. It was a surprise because they expected the opposite.

""Superhydrophobic materials are often proposed to reduce drag, but, in our case, we found that superhydrophobic spheres when almost fully immersed have a much larger drag than the sphere made of any other water repellency,"" Hunt said. ""In trying to decrease the drag, you might actually increase it substantially.""

The paper explains simple physics is the likely cause.

""The water wants nothing to do with this superhydrophobic sphere so it does anything that it can to, sort of, get out of the way of the sphere,"" Harris said. ""But what happens is much of it piles up in front of it, so there ends up being a wall of water that the sphere is hitting. Intuitively, you would think the water should slip by more freely. Physics actually conspires against that in this scenario.""

The findings from the paper may one day hold implications for designs and structures that operate at an air and water interface, like small autonomous vehicles. For now, the standalone physics of this basic research is interesting enough as studies on partially submerged objects aren't as currently well characterized or understood in the field.

""We were surprised no one had made these measurements,"" Harris said. ""It's such a simple idea but there's just a lot of rich physics here.""

The researchers chose spheres as the first three-dimensional objects because of how simple their geometry is. They only have one length scale—the radius. The sphere acts as a starting point to be able to strip the physical mechanics down to its most fundamental principles before moving on to more complicated shapes.

""Starting from the simplest point, we look at what are the physics here and then as a next step we begin to apply our knowledge to more realistic structures, whether it's emulating a biological structure or looking at manmade propulsive structures,"" Harris said.

Hunt and fellow lab member Eli Silver designed the flume apparatus for creating the water stream experiment and programmed the motorized lift that lowers the spheres into the water channel. The work started as a collaboration with Yuri Bazilevs, a professor at Brown's School of Engineering. It also included researchers from the University of Illinois Urbana-Champagne, who performed computer simulations.

More information: Robert Hunt et al, Drag on a partially immersed sphere at the capillary scale, Physical Review Fluids (2023). DOI: 10.1103/PhysRevFluids.8.084003",https://scx2.b-cdn.net/gfx/news/hires/2023/brown-fluid-dynamics-r.jpg,https://phys.org/news/2023-08-fluid-dynamics-partially-submerged.html,Science
['Eric Lagatta'],2023-08-22 00:00:00,NASA flew a spy plane into thunderstorms to help predict severe weather: How it works.,"NASA flew a spy plane into thunderstorms to help predict severe weather: How it works.

Storm-chasing NASA pilots recently spent weeks flying modified a spy plane directly into thunderstorms in an effort to gain new insights about lightning and severe weather.

Lightning has historically only been researched by low-flying aircraft or ground observers who are too far from thunderclouds to examine their detailed characteristics. Conversely, NASA's many satellites, such as the imaging sensor on the International Space Station, are attempting to measure lightning and related energy discharges from hundreds or even thousands of miles above.

But as the highest flying plane in the space agency's Airborne Science Program, the ER-2 aircraft was able to literally fly into the eye of the storm itself. The 60 hours of flight its pilots logged over the course of a month provided previously inaccessible observations that NASA hopes will help scientists better predict when storms could turn severe.

“This is a mission to go into the microphysics of what is going on in the enormous electric field above our heads,” principal investigator Nikolai Ostgaard from the University of Bergen said in a written statement.

To the moon and back: Astronauts get 1st look at Artemis II craft ahead of lunar mission

How often do lightning strikes occur?

About 40 million lightning strikes hit the ground in the United States each year, according to the Centers for Disease Control and Prevention.

The odds of being struck by lightning in a given year are less than one in a million, and almost 90% of all lightning strike victims survive, the CDC said.

Though it's rare that people are struck by lightning, the lingering threat is still a major cause of storm related deaths in the U.S. In the last three decades, the U.S. has averaged 43 reported lightning fatalities per year, according to the National Weather Service.

A lightning strike can result in a cardiac arrest, which can lead to irreversible brain damage for those who survive if they're not resuscitated in a timely manner, the weather service said.

How the experiment worked

Thunderstorms can emit two different types of gamma-ray radiation from their electric fields: terrestrial gamma-ray flashes and gamma-ray glows. While the flashes are brief (albeit intense) bursts of radiation that occur from specific points within the thundercloud, the glows are longer than the flashing and can last from minutes to hours.

In an effort to determine how long these glows last on average, an international group of scientists from the University of Bergen in Norway, the U.S. Naval Research Laboratory, and three NASA centers spent a month conducting and overseeing flights in thunderstorm hotspots.

With operations based in Tampa, Florida, researchers hoped to learn more about lightning and the vast energy fields around thunderclouds in Earth's atmosphere. As a result of their experiments, NASA said in a news release that researchers were able to capture the most detailed airborne analysis of gamma-rays and thunderclouds ever recorded.

The research was part of what's known as the ALOFT project, or Airborne Lightning Observatory for Fly’s Eye Simulator and Terrestrial Gamma Rays. The acronym may sound like a mouthful, but the mission was essentially to fly NASA's ER-2 aircraft above storms in Central America, the Caribbean, and off the coast of Florida.

The airplane is capable of flying at about 60,000 feet, an ideal altitude for flying in the proximity of thunderclouds. While airborne, the plane was fitted with instruments mounted on the aircraft to measure the brightness of gamma rays while flying as close as safely possible to thunderclouds as tall as 10 miles in altitude.

The ALOFT team on the ground was able to receive the data in real time, which allowed them to instruct pilots to circle and fly over any electrically glowing thundercloud detected for as long as possible.

The data collected allowed the team to understand more about under just what conditions terrestrial gamma-ray flashes are produced, as well as the behavior of gamma-ray glows in thunderclouds.

If that sounds hard to decipher, Timothy Lang, lead research aerospace technologist at NASA's Marshall Space Flight Center, put it this way: The data the program has gathered could ""help scientists see when storms are strengthening and provide extra lead time of information to keep the public safe from the threat of lightning.”

'Internet apocalypse:' How NASA's solar-storm studies could help save the web

About the aircraft

The high-altitude Lockheed ER-2 aircraft used in the study is one of two NASA operates as ""flying laboratories"" based at the agency's Armstrong Flight Research Center in Palmdale, California.

The craft were acquired in 1981 and 1989 to replace two Lockheed U-2 aircraft that NASA was using since 1971 to collect science data, according to a NASA fact sheet about the aircraft. Combined, the U-2s and ER-2s have flown more than 4,500 data missions and test flights since the Airborne Science Program's inaugural flight in 1971.

An invaluable tool for scientific research, the craft have been used to study Earth's oceanic processes, make celestial observation and now, to study weather.

“It will open doors to understanding lightning,"" Ostgaard said. ""We do not really understand how these gamma-ray flashes and glows are related to thunderclouds and lightning.""

Eric Lagatta covers breaking and trending news for USA TODAY. Reach him at elagatta@gannett.com.","https://www.gannett-cdn.com/authoring/authoring-images/2023/08/21/USAT/70643891007-nas-aplane.jpg?auto=webp&crop=984,556,x0,y50&format=pjpg&width=1200",https://www.usatoday.com/story/news/nation/2023/08/22/us-spy-plane-nasa-lightning-mission/70643651007/,Science
"['Daniel.Hani Sprylab.Com', 'Science Communicator']",,Something very weird is happening inside Earth’s core. Here's what means for the planet,"Take even a quick peak beneath Earth’s surface and you soon discover just how much we don’t know about what’s happening right under our feet.

We spend so much of our time focused on the world around us that we rarely give much thought to what’s going on at the core of our planet. If Earth were an apple, the crust that we live on would only be as thick as the apple’s skin.

The structure of the Earth

How hot is the Earth's core?

Like an apple, Earth also has a core tucked away within, buried beneath a layer called the mantle. The core formed early, just 200 million years after Earth itself coalesced, some 4.5 billion years ago. Earth’s core is large – almost equivalent to half the size of Mars – and there’s such extreme pressure crushing down on it that its temperature is as hot as the surface of the Sun.

To put that into numbers, that's around 6,000°C! Keep in mind, too, that Earth’s core is only around 3,000km from the surface – if the Sun were as close as that, it would melt us entirely.

What is the Earth's core made of?

There are two main parts to the Earth's core; an inner core and an outer core, followed by the mantle and the crust:

1. Inner Core

A solid, crystallised iron structure that’s under immense heat and pressure. Each layer of the crystal structure is thought to be hexagonal in shape, although there may actually be two separate crystalline structures present. The crystals are believed to align roughly north-south to match the orientation of the Earth’s rotation axis and its magnetic field.

2. Outer Core

This is the only truly liquid layer of Earth’s internal structure. Around 2,000km thick, the outer core is mostly iron and nickel, with between five and ten per cent made up of lighter elements. The transition between the inner core and outer core is located approximately 5,150km beneath Earth’s surface.

3. Mantle

Together, the crust and the top half of the mantle make up the lithosphere, which is broken into tectonic plates that shift. These shifts cause earthquakes and the continents to drift. The mantle is by far the largest part of the Earth, making up 84 per cent of its total volume.

4. Crust

The crust is split into the oceanic crust, which is a maximum of 10km (6.2 miles) thick, and the continental crust, which can be as much as 80km (49.7 miles) thick in places. The crust rises and falls by up to 25cm each day as the Moon pulls on it.

How do we know the composition of the core?

Earthquakes have played an indispensable role in our understanding of this internal structure. The modern seismometer, invented in 1880, measures the vibrations from earthquakes as they ripple through the planet. In the early 20th century, scientists assumed that Earth’s core was completely molten and the material’s movement was responsible for generating the planet’s magnetic field.

Then, in 1936, the Danish seismologist Inge Lehmann was able to determine, through the use of seismometers, that seismic waves were bouncing off something deep inside Earth. She correctly concluded that the planet’s core was composed of two parts: a solid inner core, nested Russian-doll-style, inside a molten outer core.

But more recent work is revealing that the reality could be a touch more complicated. Dr Thanh-Son Phạm and Prof Hrvoje Tkalčić from The Australian National University tried something different. “We claim the detection for the first time of ricocheting seismic waves, which propagate from the earthquake source to the other side of Earth, and back, up to five times,” Phạm says.

“The detection is significant because it allows a new way to probe the very centre of Earth, which was very unlikely in the past.” It’s a technique that’s often been used in the search for new minerals but not for probing Earth’s inner structure.

Publishing their findings in February 2023, Phạm and Tkalčić analysed data from the growing network of seismometers set up across the planet. The important part was getting data from close to the epicentre of the earthquakes and then from the exact opposite spots on the other side of the planet, known as the antipode.

The reason this has been tricky in the past is because earthquakes tend to cluster around an equatorial belt dominated by oceans and other remote areas.

When an earthquake strikes, the ensuing vibrations reverberate inside the planet for days. They take about 20 minutes to cross from one side of the Earth to the antipode. Phạm and Tkalčić saw up to five back-and-forth bounces from several magnitude-six earthquakes.

The waves got weaker with each bounce, so they used a technique called stacking to combine them. This helped the two scientists to draw out more information from the weaker signals. Only two bounces had been analysed prior to their work.

Seismic waves travel at different speeds

The scientists found that the seismic waves travelled differently through the innermost inner core than the outermost. The waves slowed down when they hit the solid core but they slowed down in different directions.

Phạm says that this suggests the crystals of iron that make up the core are arranged differently in the inner core. They estimate that the innermost inner core is 650km thick and takes up slightly more than half of the inner core.

There’s more work to be done, however. “The [question of the] nature of the transitional layer between the innermost region and the upper layer of the inner core remains to be answered,” Phạm says. “Hopefully, this question can be addressed in the near future.”

Understanding Earth's core could help us with Mars

Understanding its exact structure is important because Earth hasn’t always had a solid core – it’s believed to have formed between 600 million and 1.5 billion years ago. Insights into its structure could also help astronomers and planetary scientists to understand more about what happened to Mars.

An illustration of how the surface of Mars might have looked in the ancient past when its atmosphere was thicker and warmer

Data from Mars rovers hint at a warmer, wetter past for the Red Planet that would have made it a lot more like Earth. If Mars’s core solidified completely, its magnetic field would have switched off, leaving it unprotected from the ravages of the solar wind that gradually pecked away the majority of the Martian atmosphere.

What’s happening to its spin?

Our planet’s spin is slowing down and our days are getting longer as a result.

How long is a day? 24 hours? 86,400 seconds? The answer is no two days are ever the same. A day is defined by how long it takes Earth to complete one rotation on its axis and many factors affect the speed of our spin. The gravitational influence of the Moon has dragged on the day, lengthening it from just under 19 hours 1.4 billion years ago to the more familiar 24 hours today.

This is not only predicted by the physics of tidal forces but also backed up by studies of 430-million-year-old fossilised coral. As the coral grew, it laid down a new line of calcium each day. These lines are arranged in patterns that represent the seasons. There are 420 lines within those patterns, meaning 420 days annually. As the year is the fixed amount of time it takes Earth to orbit the Sun, more days mean fewer hours in each one and just under 21 hours at the point the coral stopped growing.

Counting the ridges in fossilised coral can be used to determine the number of days there were in a year when it was growing

The melting of the polar caps at the end of Earth’s regular ice ages has also played a halting role. These are long-term trends. More short-term effects include an earthquake in Chile in 2010 that sped up the planet and shortened the day by 1.26 microseconds. In fact, 29 June 2022 was the shortest day ever directly recorded.

But something strange appears to be occurring in the short-term trends. Since 2020, the average day has been getting longer – in other words, Earth is slowing down. This goes against a previous pattern of the average day shortening for the half-century before that.

So what’s going on? Prof Xiaodong Song and Yi Yang from Peking University in China believe they may have the answer and they think it’s Earth’s inner core.

The core spins differently from the mantle

The solid inner core sits inside the cocoon of the liquid outer core and so it’s not rigidly held in place. It’s free to spin at a different rate from the mantle and crust above. The inner core used to spin faster than the rest of the planet but Yang and Song suggest that it has slowed down recently and may even be rotating slower than the layers above.

The pair looked for seismic events that happened in the same location many years apart. In particular, they studied earthquakes erupting close to the South Sandwich Islands in the Atlantic and the resulting seismic detections in Alaska. Their paper, Multidecadal variation of the Earth’s inner-core rotation, also mentions seismic waves recorded in Montana, US, from two nuclear tests conducted at Novaya Zemlya, USSR, in 1971 and 1974.

An illustration showing how an earthquake that occurs in Alaska can send seismic waves down into the planet that are capable of passing through its core

If the core hasn’t changed, then it should reflect the seismic waves in the same way and they would look almost identical at the surface. Except that’s not what Song and Yang found. The differences they saw led them to conclude that, since 2009, the inner core has been slowing.

By comparing this data to older measurements stretching back to 1964, they conclude that this behaviour is “part of an approximately seven-decade oscillation, with another turning point in the early 1970s.” Perhaps the core speeding up and slowing down in a repeating pattern?

Why is the core slowing down?

It’s a tentative finding, one that needs more supporting data, and other researchers have put forward alternative explanations. It could be that the surface of the inner core isn’t as smooth as generally believed, for example. If it’s rougher then that could change how the inner core reflects seismic waves without needing a change in speed.

If the core does turn out to be slowing down, what could be behind it? Well, the inner core isn’t completely free to move – it’s partially pinned by the gravity of the mantle.

Some geophysicists argue that this sets up a cycle in which the inner core slows down and speeds up. Perhaps we’re just observing a short part of this cycle and it’ll speed up again very soon.

With an unprecedented number of seismometers scattered across the planet – and more being added all the time – we may not have to wait too long for answers.

What’s going on with our magnetic field?

Earth’s magnetosphere keeps us safe from the radiation pouring out of the Sun. But recent research suggests the whole thing could be about to turn upside down.

Earth’s magnetic field is a behemoth. It stretches some 65,000km towards the Sun but on the night side of the planet extends beyond six million kilometres. That means that for about a week of its month-long journey around Earth, the Moon is embedded within our magnetic field.

The core is behind all this. As heat escapes from the solid inner core it surges into the molten outer core and drives convection currents. Electrically charged material is moved around, which generates a magnetic field that flows up through the crust and out into space where it meets the solar wind – the high-energy stream of particles from the Sun. It’s this interaction that pushes our magnetosphere so far out on the night side of Earth.

The magnetosphere has kept life on Earth safe for billions of years. For centuries explorers relied on compasses aligned with it for navigation, while animals follow it to find their way too. And yet, it’s not as constant as it may seem.

Earth’s magnetic field protects us from the high-energy solar winds that burst forth from the Sun

In the 1970s scientists spotted a phenomenon called geomagnetic jerks – abrupt and unpredictable changes in our magnetic field. But they only began to understand them once we started looking down at ourselves from space.

Computer simulations can help scientists

Then, in 2019, Julien Aubert of the University of Paris and Prof Christopher Finlay of the Technical University of Denmark released the results of a supercomputer simulation of the outer core. They found that waves created in the inner core spread into the outer core and cause sharp changes in the flow of liquid beneath the magnetic field. It can take 25 years for a rising blob of metal to lead to a geomagnetic jerk.

Our magnetic field can also flip. When lava cools it preserves information about the direction of the Earth’s magnetic field at the time. By analysing layers of lava, researchers have shown that, on average, the direction of our magnetic field reverses every 200,000 years.

The last flip was 780,000 years ago... and there are signs another may be on the way.

How strong is Earth's magnetic field?

According to the European Space Agency, over the last 200 years, the global average strength of our magnetic field has dropped by nine per cent. Such drops have preceded previous reversals. In some spots, the reduction has unfolded at an even more dramatic pace. Take the so-called South Atlantic Anomaly (SAA), which sits over South America. “It’s a region where geomagnetic intensity is the lowest,” according to NASA geophysicists Weijia Kuang and Terence Sabaka. But it’s also changing.

“Observations have found that the SAA is expanding and moving westward,” Kuang and Sabaka say. The field strength of the SAA also dropped by eight per cent between 1970 and 2020. What’s causing it?

“The short answer is that the SAA is due to vigorous convection in Earth’s outer core,” say Kuang and Sabaka. It’s associated with a magnetic reversal in the outer core that works against the main magnetic field.

This has some downsides. Several satellites moving through the region have failed due to the intense radiation that leaks in from space. Astronauts can’t perform spacewalks if they’re in the vicinity. The former astronaut Terry Virts even said he saw a massive flash of light, while his eyes were closed, when passing over it.

But the SAA does help geophysicists to understand what’s going on in the bowels of the planet.

According to Kuang and Sabaka, the SAA can be used to map the flow of material in the topmost part of the outer core. “The SAA forecast accuracy can [also] be used to estimate the entire core state, which is not observable from Earth’s surface or in space,” they add.

What will happen in the future?

Will it stop spinning? Will it solidify completely? And what will it mean for those of us living above it?

Earth’s core can trace its history back to the formation of the planet.

When the Sun sparked out of a cloud of interstellar gas and dust, a band of leftover material formed around it. This protoplanetary disc was laced with the iron ejected into the Universe by the cataclysmic supernovae that mark the end of the lives of the most massive stars.

Gradually, gravity fashioned this material into lumps of rock and metal called planetesimals and they smashed together to form planets. The impacts were so forceful that the rock and metal melted and gravity could round out the new object into a sphere. The heavy iron sank to the middle and the lighter rock floated to the top.

As the planet cooled, a crust formed on the surface but the iron core remained molten. This was sustained by the immense gravitational pressure of the layers above crushing down on the core.

Earth in its earliest days as a protoplanet was a seething-hot mass, with molten rock near the surface and heavier liquified iron sinking down to form the planet’s core.

But all this happened billions of years ago and the core has been cooling ever since. “As the liquid iron in the outer core cools it slowly freezes into solid iron and becomes the inner core,” says Dr Dan Frost, a seismologist at the University of South Carolina.

How does the Earth cooling down affect the inner core?

This process adds 8,000 tonnes of iron to the inner core every second – the equivalent of the mass of the entire human population added daily. As the inner core cools, energy is transferred to the outer core, which drives convection and creates our global magnetic field.

Yet new research led by Frost is hinting that the growth of the inner core is uneven. The eastern part of the inner core lies beneath Asia and the Western Pacific, while the western part sits below the Americas and the Atlantic.

Frost’s team set about measuring the growth across these far-flung parts of the planet’s interior. It’s a tricky thing to do when all you’ve got to go on are measurements made from the surface.

“We can’t measure that the inner core is a little bit bigger today than it was yesterday, our measurements aren’t that sensitive,” Frost says. “We’re looking for evidence of movement within the inner core.”

Seismic waves can tell us what's going on

Seismic waves travelling through the inner core move faster when they move parallel to Earth’s rotation axis (roughly north-south) than when they travel parallel to the equator.

“We think this means that the crystals in the inner core are all aligned in a similar direction,” Frost says. “The way to get that alignment is if the inner core moves.” It’s similar to the way that sticks dropped into a river align with the direction of the flowing water.

Frost’s team found that the core below the Banda Sea near Indonesia is growing faster than the side beneath Brazil. The lop-sidedness doesn’t last, however. “Gravity forces [the wider part] back into the centre,” says Frost. “That flow of material would cause the crystal alignment that we see.”

Is there more to the core than meets the eye?

Frost’s work does assume that the inner core is only made up of one type of crystallised iron. We’ve already seen that other work hints at a difference between the outermost inner core and the innermost inner core.

Frost isn’t convinced of those conclusions. “There isn’t a sharp transition between an outermost and innermost inner core,” Frost says. “It’s more of a smooth transition.” Frost says that such a model is compatible with his findings.

It just goes to show that many mysteries surrounding Earth’s solid core remain unsolved. We’ve only known of its existence for less than a century. Perhaps the next century will bring more insights and a deeper understanding of the mechanism that keeps us all safe from the ravages of radiation being blasted at us from space?

Nor should we worry about the core completely solidifying any time soon. Its growth is slow. The inner core is only getting about 2mm wider every year. Although fast for a geological process, some estimates suggest it would take another 91 billion years for the molten outer core to disappear.

But don't worry; the dying Sun will fry Earth long before that happens.

Read more:",https://c02.purpledshub.com/uploads/sites/41/2023/08/earths-core.jpg,https://www.sciencefocus.com/earths-mysterious-core,Science
"['Studyfinds Research', ""View Studyfinds'S Article Archive""]",2023-08-20 19:00:17+00:00,Study of Earth’s inner core reveals a ‘planet within a planet’,"SALT LAKE CITY — Scientists are trying to go where no man has gone before, into the inner core of Earth! A team of scientists at the University of Utah has made significant progress in understanding the formation and structure of the planet’s enigmatic inner core. They believe seismic waves from natural earthquakes will help unravel the secrets of this hidden area.

The inner core, a solid metal ball within our planet, not only influences its magnetic field but also plays a crucial role in supporting life on Earth. The study reveals that the inner core is far from being a uniform mass, contrary to previous assumptions. Instead, it is more akin to a tapestry, composed of various “fabrics.”

“For the first time we confirmed that this kind of inhomogeneity is everywhere inside the inner core,” explains lead author Guanning Pang in a university release.

By examining seismic data from a global network of detectors initially established to detect nuclear blasts, the researchers gained insights into Earth’s deepest reaches.

Keith Koper, a seismologist involved in the study, likens the exploration of the inner core to a frontier area. He emphasizes that imaging the interior of Earth’s core is challenging due to its depth and unknown characteristics. The seismic waves generated by earthquakes provided valuable information, as they propagate through the planet’s crust, mantle, and core.

“The planet formed from asteroids that were sort of accreting [in space]. They’re running into each other and you generate a lot of energy. So the whole planet, when it’s forming up, is melting,” Koper explains. “It’s simply that the iron is heavier and you get what we call core formation. The metals sink to the middle, and the liquid rock is outside, and then it essentially freezes over time. The reason all the metals are down there is because they’re heavier than the rocks.”

The team’s analysis of seismic data, collected from 2,455 earthquakes, unveiled the structure and behavior of Earth’s inner core. They discovered that the inner core’s inhomogeneity strengthens as one goes deeper toward the center of the Earth. This observation provides insights into the growth process of the inner core over time. The inner core grew rapidly in the past, reaching an equilibrium, and then continued to grow at a slower rate. This growth process resulted in the presence of trapped liquid iron within the solid core.

The significance of this research extends beyond expanding our understanding of Earth’s core. It demonstrates the power of utilizing seismic data to unlock hidden information about our planet. The findings contribute to ongoing efforts to predict seismic activity, improve weather forecasting, and advance our knowledge of Earth’s atmosphere. The research team’s work opens the door to further exploration of Earth’s deep interior, paving the way for future discoveries.

The study is published in the journal Nature.",https://studyfinds.org/wp-content/uploads/2023/07/AdobeStock_130596002-scaled.jpeg,https://studyfinds.org/earth-core-planet-within-planet/,Science
['Pranjal Mehar'],2023-08-21 09:37:02+00:00,‘Planet within a planet’ revealed by research into Earth’s deep core,"Earth’s inner core acquires texture as it solidifies within the fluid outer core. It looks like a solid metal ball, a “planet within a planet.” Its existence makes life on the surface possible.

However, it remains a mystery: How Earth’s inner core formed, grew, and evolve?

A team of University of Utah-led researchers is seeking to uncover the answer.

Seismic waves from earthquakes can be used to image the texture, or fabric, of the inner core and gain insight into the history and evolution of Earth’s core. But, scientists suggest that the inner core is not the homogenous mass that was once assumed: it’s more like a tapestry of different “fabrics.”

This discovery opens a window into the deepest reaches of Earth.

Guanning Pang, a former doctoral student in the U’s Department of Geology & Geophysics, said, “For the first time, we confirmed that this inhomogeneity is everywhere inside the inner core.”

This study used a unique dataset from a global network of seismic arrays installed to find nuclear explosions. This information has aided investigations into meteor explosions, the location of a colony of pygmy blue whales, weather forecast advancements, and the formation of icebergs.

The interior of the earth is much more challenging to study. The finest tools for detecting this hidden region are seismic waves from earthquakes that go from the planet’s thin crust and vibrate through its rocky mantle and metallic core.

Koper said, “The planet formed from asteroids accreting [in space]. They’re running into each other, and you generate a lot of energy. So the whole planet, when it’s forming up, is melting. It’s simply that the iron is heavier, and you get what we call core formation. The metals sink to the middle, and the liquid rock is outside and freezes over time. All the metals are down there because they’re heavier than the rocks.”

Koper’s lab has examined seismic data sensitive to the inner core for the past few years. The duration of the day may have changed from 2001 to 2003 due to differences between Earth’s rotation and the inner core, according to a prior study led by Pang.

Iron, nickel, and a few other elements comprise most of the Earth’s core, around 4,300 miles across. The inner core is solid, and the outside body is still liquid.

Koper said, “It’s like a planet within a planet that has its rotation, and it’s decoupled by this big ocean of molten iron.”

“The protective field of magnetic energy surrounding Earth is created by convection within the liquid outer core, which extends 2,260 kilometers (1,795 miles) above the solid core. The molten metal rises above the solid inner core, cools as it approaches Earth’s rocky mantle, and sinks. This circulation generates the bands of electrons enveloping the planet. Without a solid inner core, this field would be much weaker, and the planetary surface would be bombarded with radiation and solar winds that would strip away the atmosphere and render the surface uninhabitable.”

The U team used seismic data collected from 20 seismometer arrays located around the globe, including two in Antarctica, for the new study. Outside of Pinedale, Wyoming, is where Utah is most nearby. As parabolic antennae work, these sensors are placed in holes up to 10 meters deep in granite formations and configured in patterns to focus the signals they receive.

Pang studied seismic waves from 2,455 earthquakes with magnitudes greater than 5.7, or around the same as the quake that shook Salt Lake City in 2020. How these waves reacted with the inner core mapped its interior structure. Smaller earthquakes don’t produce waves that are powerful enough for the study.

Koper said, “This signal that comes back from the inner core is tiny. The size is about on the order of a nanometer. What we’re doing is looking for a needle in a haystack. So these baby echoes, and reflections are very hard to see.”

Journal Reference:",https://www.techexplorist.com/wp-content/uploads/2023/08/earth-core.jpg,https://www.techexplorist.com/planet-within-planet-revealed-research-earths-deep-core/67373/,Science
"['Samantha Mathewson', 'Contributing Writer', 'Social Links Navigation']",2023-08-22 18:00:25+00:00,Hubble Space Telescope captures 'ghostly' glow of distant galaxy (photo),"A distant galaxy sparkles from the soft glow of its many tiny stars in a new photo from the Hubble Space Telescope .

The galaxy, named ESO 300-16, is located about 28.7 million light-years away from Earth in the Eridanus constellation and appears as a celestial cloud of sparkling stars against the dark backdrop of space. Other galaxies and stars are also featured in the new Hubble image, providing a captivating view of this cosmic neighborhood.

""The galaxy ESO 300-16 looms over this image,"" European Space Agency (ESA) officials said in a statement about the image on Monday (Aug. 21), adding that it ""is a ghostly assemblage of stars which resembles a sparkling cloud.""

Related: The best Hubble Space Telescope images of all time!

This recent view of ESO 300-16 was taken using the Advanced Camera for Surveys instrument on the Hubble Space Telescope, which is a joint mission led by NASA and ESA. It is part of a series aimed at surveying Earth 's galactic neighbors.

""Around three quarters of the known galaxies suspected to lie within 10 megaparsecs [32 million light-years] of Earth have been observed by Hubble in enough detail to resolve their brightest stars and establish the distances to these galaxies,"" ESA officials said in the statement. ""A team of astronomers proposed using small gaps in Hubble's observing schedule to acquaint ourselves with the remaining quarter of the nearby galaxies.""

ESO 300-16 is classified as an irregular galaxy due to its indistinct shape and lack of nuclear bulge or spiral arms. Instead, it resembles the shape of a cloud, comprised of many tiny stars all clumped together.

The stars give off a soft, diffuse light that surrounds a bubble of bright blue gas at the galaxy's core. The brighter, foreground objects represent nearby stars and galaxies, according to the statement.",https://cdn.mos.cms.futurecdn.net/84qQCJ7rpZPwXovHxHjgA6-1200-80.jpg,https://www.space.com/distant-galactic-neighbor-sparkles-hubble-photo,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
['Aditya Madanapalle'],2023-08-22 07:56:16+05:30,Hubble Space Telescope captures image of irregular galaxy ESO 300-16,"The Hubble Space Telescope has snapped a stunning image of a galaxy that defies classification. ESO 300-16 is an irregular galaxy, a type of galaxy that lacks a clear shape and structure. The galaxy is located in the constellation of Eridanus, contains a bubble of blue gas at its core and has a backdrop of many distant galaxies.

Hubble’s capture of ESO 300-16. (Image Credit: ESA/Hubble and NASA, R Tully).

The Hubble Space Telescope has captured an image of the irregular galaxy ESO 300-16 located at a distance of 28.7 million lightyears in the southern constellation of Eridanus. Irregular galaxies do not have a clearly defined shape, and appear as diffuse clouds. A bubble of bright, blue gas is visible towards the galaxy core.

ESO 300-16 was captured as part of an imaging campaign known as Every Known Nearby Galaxy, which aims to create a complete inventory of Hubble images of all galaxies within 10 megaparsecs of the Earth, or 32.6 million lightyears. Even the distance that light travels in a year is not convenient for measuring astronomical distances, which is why astronomers use parsecs. One parsec is equal to 3.26 lightyears, or 30.9 trillion kilometres. A megaparsec is one million parsecs.

Hubble has already observed around 75 per cent of the nearby galaxies within 10 parsecs in other observation campaigns. The Every Known Nearby Galaxy campaign aims to capture the remaining 25 per cent of the galaxies, using the spare time available on the telescope as it turns its gaze from one planned campaign to another. The observations conducted in the gaps of Hubble’s schedule allows scientists to maximise the science returns from the deep space observatory. Hubble has previously captured the lenticular galaxy NGC 6684 and the irregular dwarf galaxy NGC 1156 as part of the campaign.

Also Read | Hubble Space Telescope captures globular cluster NGC 6652

As with most images of Hubble, the target is sitting in a field of even more distant galaxies, of all shapes and sizes, some of which are interacting with each other. The image is also peppered with a few foreground stars that have prominent cross shaped diffraction spikes caused by the light from the stars interacting with the internal support structure of Hubble. The diffraction spikes can be considered as a signature of Hubble.

Also Read | Hubble tracks AU Mic b, a hiccupping exoplanet that is shedding its atmosphere",https://images.news9live.com/wp-content/uploads/2023/08/potw2334a-1-Cropped.jpg,https://www.news9live.com/science/hubble-space-telescope-captures-image-of-irregular-galaxy-eso-300-16-2257909,Science
[],2023-08-21 16:32:00.510000+00:00,Hubble Telescope Images Abell 3322,"The Hubble Space Telescope is no spring chicken, having operated in space for over 30 years. But the veteran observatory soldiers on. It recently imaged a massive galaxy cluster that could hold secrets about both dark and ordinary matter.

The cluster is Abell 3322. It sits in the constellation Pictor, about 2.6 billion light-years from Earth. Galaxy clusters are just what they sound like—groups of galaxies bound together by gravity. They can clue researchers into how dark matter interacts with regular matter, as well as fundamental questions about how galaxies form and evolve.

Advertisement

At the center of the recent Hubble shot of Abell 3322 is 2MASX J05101744-4519179, a particularly bright galaxy. The image was taken by Hubble’s Wide Field Camera 3 and its Advanced Camera for Surveys, third-generation instruments on the telescope that image at near-infrared and visible light wavelengths.

Three galaxies in the image are brighter than the rest (two in the center of the image and one in its upper right-hand corner). The alignment of those galaxies indicates to scientists that the galaxy cluster appears to be actively forming, according to a European Space Agency release.

Advertisement Advertisement

Dark matter is not literally “dark,” it’s just dark to us. In plainer terms, we don’t know what it is. It could be a lot of different things, or one vexing tough-to-spot particle. Dark matter hardly interacts with ordinary matter, making it difficult to learn about, and has never been directly observed.

But scientists know dark matter exists because of its gravitational effects. Haloes of dark matter manifest around some galaxies and galaxy clusters, and areas of gravitational lensing are happy hunting grounds for dark matter candidates.

Advertisement

Some of the galaxies in the recent image appear distorted or flattened; they are gravitationally lensed, meaning their light is being bent and refocused by the gravitational field between them and Hubble.

Advertisement

The two leading candidates for dark matter are Weakly Interacting Massive Particles, or WIMPs, and axions, a theorized particle named for a laundry detergent. Earlier this year, a team of astronomers found signs of axion-like dark matter in Einstein rings, particularly in lensed images of HS 0810+2554, a distant quasar. Einstein rings are spectacular circles or near-circles of light in space caused by intense gravitational lensing.

More observations of regions in space where dark matter appears to be at work will help researchers understand how the stuff comprising it interacts with the world we can see. Combined with laboratory investigations of dark matter candidates, we get closer to shining a light on some of the most hidden physics.

Advertisement

More: New Map of Dark Matter Validates Einstein’s Theory of Gravity","https://i.kinja-img.com/gawker-media/image/upload/c_fill,f_auto,fl_progressive,g_center,h_675,pg_1,q_80,w_1200/b3666c254c64255407c0c765e94a30ca.jpg",https://gizmodo.com/hubble-telescope-images-abell-3322-dark-matter-1850757510,Science
['Tibi Puiu'],2023-08-21 21:14:41+00:00,Zombie-ant fungi and dinosaur embryos: spectacular winning photos from nature competition,"Credit: Cornelia Sattler

A stunning photo capturing a vivid orange pore fungus (Favolaschia calocera) thriving on rotten wood has emerged as the victor of this year’s BMC Ecology and Evolution image competition. The photograph, taken by Cornelia Sattler from Macquarie University, Australia, is more than just a pretty picture though. Beyond the seemingly innocent beauty of the fungus, Sattler says that we must also recognize its invasive nature and the devastation it has caused to Australia's ecosystems.

Despite its alluring appearance, the orange pore fungus poses a threat by displacing other native fungi and encroaching upon the Australian rainforest. The fungus's spores can be carried by humans, which is why people traveling in protected natural areas should exercise extra vigilance to protect Australia's biodiversity.

Originally discovered in Madagascar, the orange pore fungus has spread across the globe, including Australia. However, it is not alone. Many invasive species, such as the European rabbit, root rot fungus, and feral pigs, are jeopardizing a significant portion of Australian species currently facing extinction.

Nature: stunning but fragile

The BMC Ecology and Evolution image competition offers a window into the diverse and captivating world of science through art. While the winning images are all visually engaging, they also underscore the importance of scientific vigilance and ecological preservation. Each photograph serves as a reminder that the natural world is not only awe-inspiring but also deeply interconnected and fragile.

Credit: Roberto García-Roa.

In the Protecting Our Planet category, Roberto García-Roa from the University of Lund, Sweden, won first place with his image of beekeepers caring for a hive within a sustainable beekeeping project in Guinea. The initiative, which encourages locals to cultivate honey, serves as a means to combat deforestation in the area that is currently threatening chimpanzee populations.

Credit: João Araújo.

João Araújo, representing the New York Botanical Garden, triumphed in the Plants and Fungi category. His photograph captures a different fungus parasitizing the fruiting body of a zombie-ant fungus.

Zombie-ant fungi possess the remarkable ability to manipulate the behavior of their insect hosts, coercing them to relocate to more favorable environments for their own growth. This unique phenomenon is observed across forests worldwide, ranging from tropical to temperate regions, where various Camponotini ants fall victim to this manipulation.

But, in this case, the zombie-ant fungus met its match: another parasitic fungus.

""The forests inhabited by these fungi also provide a habitat for mycoparasitic fungal lineages that exhibit the ability to parasitize, consume, and even castrate Ophiocordyceps. It is only recently that scientists have begun to document and describe these lesser-known fungi that possess the ability to eliminate other fungi,"" said Araújo.

Credit: Victor Huertas

Victor Huertas from James Cook University, Australia, seized the first spot in the Research in Action category. His winning image features an underwater remotely-operated vehicle deployed in the crystal-clear waters of the Coral Sea Marine Park in Australia, offering a glimpse into marine exploration. Thanks to these devices, the team has uncovered new species in reefs where they had not yet been documented, expanding the geographic range of multiple fish species.

Last but not least, an enthralling digital illustration portraying the embryonic development of a dinosaur within an egg claimed the Paleoecology category. It's based on the finding of a pair of hadrosauroid dinosaur eggs and embryos from China's Upper Cretaceous red beds from between 72 and 66 million years ago. This snapshot of prehistoric life was submitted by Jordan Mallon from the Canadian Museum of Nature and created by Wenyu Ren from Beijing, China.

“The relatively small size of the egg and the unspecialized nature of the dinosaur embryo developing within it suggests that the earliest hadrosaurs were born immature and helpless. Over time, hadrosaurs began to lay larger eggs, indicating that their young may have been born at more advanced stages of development and required less parental care than earlier hadrosaurs,” Mallon said.

Runner-up entries

Plants and fungi: runner-up. Defeated. A spider seemingly defeated by a parasitic fungus. Credit: Roberto García-Roa

Research in action: runner-up. Researchers from the University of Glasgow’s Scottish Marine Animal Stranding Scheme conduct a necropsy of a stranded humpback whale. Credit: Submitted by Professor Paul Thompson, photo captured by James Bunyan from Tracks Ecology",https://cdn.zmescience.com/wp-content/uploads/2023/08/Invasive-Orange-Pore-Fungus.webp,https://www.zmescience.com/science/news-science/amazing-nature-photos-bmc-ecology-evolution-competition/,Science
"['Stacy Liberatore', 'Stacy Liberatore For Dailymail.Com']",2023-08-21 18:00:48+01:00,Zombie fungus devouring an ant from the inside out wins Ecology and Evolution contest with 'wonder of nature' theme,"READ MORE: Zombie fungus is three steps away from infecting humans

There were four categories: 'Research in Action,' 'Protecting our planet,' 'Plants and Fungi' and 'Paleoecology'

An ant being devoured from the inside out by a deadly zombie fungus is a category winner in a contest focused on 'the wonder of nature.'

The BMC Ecology and Evolution competition invited anyone affiliated with a research institution to submit to one of the following four categories: 'Research in Action,' 'Protecting our planet,' 'Plants and Fungi' and 'Paleoecology.'

João Araújo from the New York Botanical Garden submitted the winning photo for the 'Plants and fungi' category, which captured cordyceps bursting from the ant's head.

The detailed image comes just months after the world was gripped by HBO's hit show 'The Last of Us,' with a plot about cordyceps evolving to infecting humans.

João Araújo from the New York Botanical Garden submitted the winning photo for the 'Plants and fungi' category, which captured cordyceps bursting from the ant's head

The overall winner was an image depicting bright orange fruiting bodies growing on deadwood in the Australian rainforest taken by Cornelia Sattler from Macquarie University, Australia.

Researchers from around the world submitted their best images to the journal, those images capturing the wonders of Earth and nature.

The photographs have also been used to understand nature and share a glimpse into 'long lost worlds,' the publication said.

Araújo's photo did not win overall, but it reminds people of HBO's hit series 'The Last of Us.'

The Last of Us tells the story of an apocalyptic world where cordyceps, the mind-controlling fungus, jumps from ants to humans due to climate change.

DailyMail.com spoke with Araújo in February about the fungus, which he said likely infected the first ant 45 million years ago.

Araújo continued to explain that around 35 ophiocordyceps fungi are known to turn insects into zombies, which are found in the US, Brazil, Japan and parts of Africa.

And now one of his images of the fungus devouring an insect has won a photography contest.

The overall winner was an image depicting bright orange fruiting bodies growing on deadwood in the Australian rainforest

Victor Huertas, a Postdoctoral Research Associate from the Hoey Reef Ecology Lab at James Cook University in Australia, captured the winning image for the 'Research in action' category

The winning photo, however, is a stunning display of brightly colored fungus littering a log in the Australian rainforest, which was first identified in Madagascar but is now found worldwide.

Previous research has reported that invasive species, such as the European rabbit, root rot fungus and feral pigs, threaten 82 percent of Australian species at risk of extinction.

As a result, Australia has particularly strict rules about bringing plants, animals, and organic matter into the country.

Sattler said: 'Despite its innocent and beautiful appearance, the orange pore fungus is an invasive species that displaces other fungi and is spreading throughout the Australian rainforest.

'It is important to closely monitor this fungus, whose spores are often transported by humans, in order to safeguard the biodiversity of Australia.'

Senior Editorial Board Member Arne Traulsen recommended the entry, saying: 'Cornelia Sattler's image allows us to peek into the world of fungi, organisms that are fascinating and yet underappreciated and understudied.'

Victor Huertas, a Postdoctoral Research Associate from the Hoey Reef Ecology Lab at James Cook University in Australia, captured the winning image for the 'Research in action' category.

The winner for 'Protecting our planet' went to Roberto García-Roa, an evolutionary biologist. The image features a sustainable beekeeping project launched by the Chimpanzee Conservation Center in Guinea

And the final category, 'Paleoecology,' was won by a stunning photo showing a pair of hadrosauroid dinosaur eggs and embryos from China's Upper Cretaceous red beds, dating back approximately 72 to 66 million years ago

The photo beautifully captures a moment as the team deploys an underwater Remotely Operated Vehicle (ROV) at Diamond Reef within the Coral Sea Marine Park. This advanced ROV, equipped with multiple photo and video cameras, serves as a vital tool enabling surveys at depths beyond the reach of divers.

The winner for 'Protecting our planet' went to Roberto García-Roa, an evolutionary biologist and conservation photographer affiliated with the University of Lund in Sweden.

The image features a sustainable beekeeping project launched by the Chimpanzee Conservation Center in Guinea.

Senior Editorial Board Member Josef Settele said: 'This photo shows how very different aspects of wildlife conservation can be combined into a win-win situation that helps simultaneously protect our planet and empower local communities.'

And the final category, 'Paleoecology,' was won by a stunning photo showing a pair of hadrosauroid dinosaur eggs and embryos from China's Upper Cretaceous red beds, dating back approximately 72 to 66 million years ago.

Jordan Mallon submitted the image from the Canadian Museum of Nature.

He said: 'The relatively small size of the eggs, and the unspecialized nature of the dinosaur embryos inside, suggest that the earliest hadrosaurs laid small eggs and hatched altricial young.

'More derived hadrosaurs eventually laid eggs nearly four times larger by volume and hatched correspondingly larger young.

'This digital image depicts an example of a 'primitive' hadrosaur developing within the safety of its small egg expertly crafted by Wenyu Ren.'",https://i.dailymail.co.uk/1s/2023/08/21/17/74563515-0-image-m-19_1692635321865.jpg,https://www.dailymail.co.uk/sciencetech/article-12429385/Zombie-fungus-devouring-ant-inside-wins-Ecology-Evolution-contest-wonder-nature-theme.html,Science
"['Bmc', 'Biomed Central']",2023-08-20 03:26:27-07:00,From Zombie-Ant Fungi to Hadrosauroid Embryos: Stunning Winners of BMC Ecology and Evolution Image Competition,"Cornelia Sattler’s image of the invasive orange pore fungus won the BMC Ecology and Evolution image competition. The competition celebrates nature’s wonders across various categories, blending art and science.

A captivating image of the invasive orange pore fungus (Favolaschia calocera), which highlights the potential threats the species may pose to Australian ecosystems, has won the third BMC Ecology and Evolution image competition. The competition showcases the wonder of the natural world — both past and present — and celebrates those working to understand it.

The overall winning image depicts bright orange fruiting bodies growing on deadwood in the Australian rainforest and was taken by Cornelia Sattler from Macquarie University, Australia. The orange pore fungus was first observed in Madagascar but is now found throughout the world. Previous research has reported that invasive species, such as the European rabbit, root rot fungus, and feral pigs, threaten 82% of Australian species at risk of extinction. As a result, Australia has particularly strict rules about bringing plants, animals, and organic matter into the country.

Cornelia Sattler said: “Despite its innocent and beautiful appearance, the orange pore fungus is an invasive species that displaces other fungi and is spreading throughout the Australian rainforest. It is important to closely monitor this fungus, whose spores are often transported by humans, in order to safeguard the biodiversity of Australia.”

Senior Editorial Board Member Arne Traulsen recommended the entry, saying: “Cornelia Sattler’s image allows us to peek into the world of fungi, organisms that are fascinating and yet underappreciated and understudied.”

Additional Award-Winning Entries

Beyond the main prize, the competition recognized victors and runners-up in four distinct categories: Research in Action, Protecting our Planet, Plants and Fungi, and Palaeoecology.

Victor Huertas from James Cook University, Australia took the winning image for the Research in Action category. The photograph depicts the deployment of an underwater remotely operated vehicle at Coral Sea Marine Park, Australia. The device is used to survey oceans at depths that are beyond the reach of divers and has been used to discover new species in reefs and expand the known geographic range of multiple fish species.

Senior Editorial Board Member Luke Jacobus said: “This photograph captures the essence of ecological study. It showcases sharp imaging and good storytelling and invites us to be curious about our dynamic world.”

The Protecting our Planet category winner was captured by Roberto García-Roa from the University of Lund, Sweden, and features a sustainable beekeeping project launched by the Chimpanzee Conservation Center in Guinea. The project aims to combat deforestation by encouraging locals to cultivate their own honey. A portion of the profits generated by the project go towards chimpanzee conservation activities.

Senior Editorial Board Member Josef Settele said: “This photo shows how very different aspects of wildlife conservation can be combined into win-win situation that helps simultaneously protect our planet and empower local communities.”

The Plants and Fungi category winner depicts a fungus parasitizing the fruiting body of a zombie-ant fungus — a fungus that can compel infected ants to migrate to locations that are more favorable for its growth — and was taken by João Araújo from the New York Botanical Garden, New York, USA.

João Araújo said: “Zombie-ant fungi are found in forests all over the world, however, the forests they inhabit are also shared with fungi that can parasitize, consume, and even castrate them. Scientists have only recently started to catalog and describe these fascinating fungi that can kill other fungi.”

The Paleoecology category winner was submitted by Jordan Mallon from the Canadian Museum of Nature, Canada, and was created by Wenyu Ren from Beijing, China. The image depicts an embryonic hadrosauroid — a dinosaur with a duck-like beak — developing within an egg from China’s Upper Cretaceous red beds, which date to between 72 and 66 million years ago.

Jordan Mallon said: “The relatively small size of the egg and the unspecialized nature of the dinosaur embryo developing within it suggests that the earliest hadrosaurs were born immature and helpless. Over time, hadrosaurs began to lay larger eggs, indicating that their young may have been born at more advanced stages of development and required less parental care than earlier hadrosaurs.”

Celebrating the Intersection of Art and Science

Now in its third year, the BMC Ecology and Evolution Image Competition was created to give ecologists, evolutionary biologists, and paleontologists the opportunity to use their creativity to celebrate their research and the intersection between art and science. The winning images are selected by the Editor of BMC Ecology and Evolution and senior members of the journal’s editorial board.

Editor Jennifer Harman said: “Judging the many remarkable images submitted to this year’s competition was a rewarding and challenging experience. The winning images were selected by our senior Editorial Board Members as much for the scientific stories behind them as for their artistic qualities. We thank all those who took part in this year’s competition and congratulate our winning entrants. We hope our readers enjoy viewing these images and exploring the stories behind them as much as we did.”",https://scitechdaily.com/images/Invasive-Orange-Pore-Fungus.jpg,https://scitechdaily.com/from-zombie-ant-fungi-to-hadrosauroid-embryos-stunning-winners-of-bmc-ecology-and-evolution-image-competition/,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
[],,NASA's Ingenuity helicopter performs test flight on Mars in rare footage,"NASA's Ingenuity helicopter remains functional after a small technical malfunction on its 54th flight mission at the beginning of August, as evidenced by a 46-second test flight in a video released by the space agency on Saturday.

Designed to use its four-foot rotor wings to fly under the unique Martian conditions, the Ingenuity was originally only meant for five flights, a target it has exceeded ten-fold.

“A key objective of Perserverance’s mission on Mars is astrobiology, including the search for signs of ancient microbial life,” NASA

According to NASA, the helicopter activated its flight-contingency program which automatically lands the craft if a problem is detected in aerial conditions during its flight in early August.

The test flight which followed was completed without any problems being detected and saw the craft hover at almost five meters above the surface before touching down as it was filmed by NASA’s Perseverance rover which searches the Martian surface alongside its smaller companion for signs of life-hospitable terrain.

“A key objective of Perserverance’s mission on Mars is astrobiology, including the search for signs of ancient microbial life,” NASA explained.

Members of NASA?s Ingenuity helicopter team in the Space Flight Operations Facility , April 19, 2021 (credit: REUTERS/NASA/JPL-CALTECH/HANDOUT)

Nothing has been found, yet

Unfortunately, signs of life on Mars elude scientists who continue to hope that some form of primitive life will confirm the existence of extraterrestrial life.","https://images.jpost.com/image/upload/f_auto,fl_lossy/c_fill,g_faces:center,h_407,w_690/549019",https://www.jpost.com/science/space/article-755476,Science
"['Georgina Torbet', 'August']",2023-08-20 15:31:43-07:00,See Ingenuity helicopter take to the air in video,"NASA has released a video taken by the Perseverance rover on Mars that shows its companion, the helicopter Ingenuity, in flight. Ingenuity performed a short flight into the air and back down to the martian surface on August 3, and the rover was near enough to capture footage of the flight using its Mastcam-Z imager.

The video shows Ingenuity’s 54th flight, which consisted of a simple takeoff, hover, and landing. The helicopter reached an altitude of 16 feet over a period of under 30 seconds, with the purpose of the flight being to check Ingenuity’s navigation system. This follows a recent incident in which NASA lost contact with the helicopter for one week due to issues sending signals over the area’s complex geography. Communications were established in time for flight 50, with the helicopter able to work as expected.

Fly into #NationalAviationDay with Ingenuity!@NASAPersevere captured this video during the #MarsHelicopter’s 54th flight as the rotorcraft hovered 16 feet (5 m) above the surface and rotated to the left before landing again. pic.twitter.com/y2ay2dKZa7 — NASA JPL (@NASAJPL) August 19, 2023

Ingenuity has proven remarkably hardy, even in the cold, dusty, inhospitable martian environment. The helicopter, which traveled inside the belly of the rover and touched down on the planet’s surface in 2020, was originally designed to perform just five flights as part of a test of the feasibility of flying on another planet. The helicopter exceeded all expectations, not only being able to fly and land accurately, but also continuing to work for an incredible 50-plus flights so far, despite challenges like the cold winter season, which limited the amount of power that could be collected by the helicopter’s solar panels.

Recommended Videos

Since the 54th flight shown in the video, Ingenuity performed its 55th flight on August 12. During that flight, the helicopter moved from its previous location called Airfield Omicron and traveled 866 feet over a period of around two-and-a-half minutes, taking it to a new location dubbed Airfield Pi. The helicopter is currently traveling close to the Perseverance rover and is scouting routes ahead to make driving easier and safer for the rover.

Editors' Recommendations",https://www.digitaltrends.com/wp-content/uploads/2023/08/PIA25970.width-12801.jpg?resize=1200%2C630&p=1,https://www.digitaltrends.com/space/ingenuity-video-perseverance-mars/,Science
[],2023-08-21 08:25:34+05:30,"In a special moment, NASA rover on Mars snaps Ingenuity Mars Helicopter in flight","In a special moment, NASA rover on Mars has captured remarkable video footage of its helicopter flying and landing. The Martian atmosphere is very thin, just around one percent of Earth's, which makes it hard for things to lift off. However, NASA's experimental helicopter called Ingenuity was built to lift off using its special rotor in these unusual conditions. The small robot, with its four-foot wingspan, has managed to fly more than 50 times, even though NASA initially thought it would only be able to fly five times.

Perseverance's Watchful Eye

Recently, NASA's big Perseverance rover filmed the whole 54th flight of the helicopter in early August. There was a small issue during the flight that made the helicopter come back down quickly, but NASA used this flight to check if its control system still worked well. And it did.

Flight Sequence Captured in Detail

In the video, Ingenuity starts its rotors at the very bottom, around 5 seconds into the video. Then, at 15 seconds, the robot takes off and hovers about 16 feet above the Martian ground before gently landing again.

Searching for Clues of Ancient Life

Perseverance, the rover, took this clear video from a distance of 180 feet. Perseverance is exploring rocks and soil on Mars along with its friend Ingenuity, the helicopter. They are looking for signs of life, like special patterns or substances that might suggest living things were there in the past.

One big goal for Perseverance on Mars is to learn about astrobiology, which is all about finding signs of ancient tiny life forms. NASA explained that they are looking for things that could only have been made by living things. So far, there is no proof that life existed on Mars, but there might have been simple life forms in hidden caves or far beneath the ground. Scientists also think that there might be a chance for life to exist in places like the oceans of Enceladus and Europa, which are moons of other planets, even farther out in space than Mars.",https://images.hindustantimes.com/tech/img/2023/08/21/1600x900/NASA_mars_helicopter_1692586293639_1692586294217.jpg,https://tech.hindustantimes.com/tech/news/in-a-special-moment-nasa-rover-on-mars-snaps-ingenuity-mars-helicopter-in-flight-71692586094919.html,Science
['Andy Corbley'],2023-08-22 15:00:45+00:00,Plant-Based Filter Removes Up to 99.9% of Microplastics from Water,"What do you get when you cross sawdust and polyphenols? A water filter that can remove 99.9% of microplastics; and that’s no joke.

The health of effects of ingesting microplastics are, predictably, not good, though the science is in its early stages. We already know that microplastics rain down over the world from potentially as high up as the jet stream, that they are present in the deepest ocean trenches, and some of the most remote mountain tops.

Researchers looking for better ways to filter microscopic particles of plastic from water sources investigated the properties of wood and other plant material and found they work extremely well, with very little cost and potentially unlimited scaling potential.

The water filter design, which the inventors called “bioCap” is made of sawdust, composed of cellulose, hemicellulose, and lignan but which itself isn’t a very good filter; removing just 10% of micro and nanoparticles of plastic. However, with the addition of polyphenols like tannic acid, a defense chemical found in almost all plants that lack underground root systems, that effectiveness became almost perfect.

The polyphenols create strong molecular interactions with polymer particles, including many microplastics, and which didn’t wear out even after repeated filtering trials.

All the commonly-found varieties of plastic polymer in packaging, artificial textiles, and building materials were run through the filter in micro or nano-sized particles.

“By taking advantage of the different molecular interactions around tannic acids, our bioCap solution was able to remove virtually all of these different microplastic types,” said Orlando Rojas, one of the study’s corresponding authors.

OTHER SUSTAINABLE SOLUTIONS: This Tower Filters 273 Hot Air Balloons-Worth of Pollution per Day in India City

He told his university press that in a test to remove particles just 110 nanometers in diameter, which are known to cross the blood-brain barrier, fewer were found accumulating in the internal organs of mice watered with microplastic-contaminated liquid.

“Most solutions proposed so far are costly or difficult to scale up,” Rojas said. “We’re proposing a solution that could potentially be scaled down for home use or scaled up for municipal treatment systems.”

He points out that bark, sawdust, and leaves are extremely easy to obtain essentially anywhere on Earth an entrepreneur would think to open a production line of these water filters.

SHARE This Great Yet Ridiculously Simple Idea With Your Friends…",https://www.goodnewsnetwork.org/wp-content/uploads/2023/08/credit-UBC-Public-Affairs-e1692695737257.jpg,https://www.goodnewsnetwork.org/plant-based-filter-removes-up-to-99-9-of-microplastics-from-water/,Science
[],,Scientists Say New Device Can Scrub 99.9 Percent of Microplastics From Water,"This simple, organic device sounds like it could be a seriously good solution to the growing microplastics problem.

Purification Station

Scientists have developed a new technique that filters out microplastics from drinking water — and its ingredients are all plant-based.

Crafted by researchers out of Canada's University of British Columbia and China's Sichuan University, the ""bioCap"" purifying filter is comprised of compounds from fruit and wood that are able to eliminate almost all microplastics in water.

Using fruit tannins — the chemicals that make under-ripe fruit taste bad — coated over sawdust, the researchers were able to create a cylindrical water filtration device that eliminates between 95.2 and 99.9 percent of microplastics depending on what they're made of.

That's a huge deal for anyone who's paid attention to the news in the past few years because microplastics are being found everywhere scientists look for them: in our bodies, our water, our food, and even the skies.

Organic Solution

To test the system, the team of forestry, chemistry, and biological engineering researchers gave groups of mice either drinking water purified with the bioCap or untreated water. In the mice that got the purified water, ""the process was proven to prevent the accumulation of microplastics in the organs,"" a press release claims.

What's perhaps most exciting about the bioCap device is that even at its least efficient, per a study published in the journal Advanced Materials earlier this year, it still managed to eliminate the vast majority of microplastic materials.

""There are [microfibers] from clothing, microbeads from cleansers and soaps, and foams and pellets from utensils, containers, and packaging,"" Dr. Orlando Rojas, the scientific director of UBC's BioProducts Institute, said in the school's press release. ""By taking advantage of the different molecular interactions around tannic acids, our bioCap solution was able to remove virtually all of these different microplastic types.""

Whether it needs to be scaled up for industrial use — or down for home use — Rojas said that the bioCap is an ideal solution because it's made of organic materials and does not lead to ""further pollution"" like plastic filters do.

It's an excellent proposal for a deceptively simple solution — and hopefully, people in power concerned about the alarming findings from microplastics research will listen.

More on microplastics: Scientists Puzzled to Find Plastic Fragments Inside Human Hearts",https://wp-assets.futurism.com/2023/08/organic-device-filters-microplastics.jpg,https://futurism.com/the-byte/organic-device-filters-microplastics,Science
"['University Of British Columbia', 'Ubc']",2023-08-21 01:28:37-07:00,Pollution Solution: New Device Can Capture 99.9% of Microplastics in Water Using Wood Dust,"UBC’s BioProducts Institute develops a plant-based filter, “bioCap,” that can capture nearly 99.9% of microplastic particles in water, offering a scalable and sustainable solution to microplastic pollution.

Could plants offer a solution to the looming threat of microplastic pollution? Scientists at UBC’s BioProducts Institute found that if you add tannins—natural plant compounds that make your mouth pucker if you bite into an unripe fruit—to a layer of wood dust, you can create a filter that traps virtually all microplastic particles present in water.

Although the technology is still in its experimental phase, the researchers believe it can be scaled up affordably and efficiently, given the right industrial collaborator.

The Challenge of Microplastics

Microplastics are minuscule fragments of plastic that originate from the deterioration of consumer goods and industrial waste. Keeping them out of water supplies is a huge challenge, says Dr. Orlando Rojas, the institute’s scientific director and the Canada Excellence Research Chair in Forest Bioproducts.

He noted one study which found that virtually all tap water is contaminated by microplastics, and other research which states that more than 10 billion tons of mismanaged plastic waste will be dispersed in the environment by 2025.

“Most solutions proposed so far are costly or difficult to scale up. We’re proposing a solution that could potentially be scaled down for home use or scaled up for municipal treatment systems. Our filter, unlike plastic filters, does not contribute to further pollution as it uses renewable and biodegradable materials: tannic acids from plants, bark, wood and leaves, and wood sawdust—a forestry byproduct that is both widely available and renewable.”

Effectiveness Across Plastic Types

In their research, the team analyzed microparticles shed from widely-used tea bags made of polypropylene. They observed that their technique, termed “bioCap,” captured between 95.2 percent and a staggering 99.9 percent of plastic particles in water, depending on the plastic type. When tested in mouse models, the process was proven to prevent the accumulation of microplastics in the organs.

Dr. Rojas, a professor in the departments of wood science, chemical and biological engineering, and chemistry at UBC, emphasizes that it’s difficult to capture all the different kinds of microplastics in a solution, as they come in different sizes, shapes, and electrical charges.

“There are microfibres from clothing, microbeads from cleansers and soaps, and foams and pellets from utensils, containers, and packaging. By taking advantage of the different molecular interactions around tannic acids, our bioCap solution was able to remove virtually all of these different microplastic types.”

Interdisciplinary Collaboration Towards Sustainability

The UBC method was developed in collaboration with Dr. Junling Guo, a professor at the Center of Biomass Materials and Nanointerfaces at Sichuan University in China. Marina Mehling, a PhD student at UBC’s department of chemical and biological engineering, and Dr. Tianyu Guo, a postdoctoral researcher at the BioProducts Institute, also contributed to the work.

“Microplastics pose a growing threat to aquatic ecosystems and human health, demanding innovative solutions. We’re thrilled that the BioProducts Institute’s multidisciplinary collaboration has brought us closer to a sustainable approach to combat the challenges posed by these plastic particles,” said Dr. Rojas.

Reference: “Flowthrough Capture of Microplastics through Polyphenol-Mediated Interfacial Interactions on Wood Sawdust” by Yu Wang, Mengyue Wang, Qin Wang, Taoyang Wang, Zhengming Zhou, Marina Mehling, Tianyu Guo, Hang Zou, Xiao Xiao, Yunxiang He, Xiaoling Wang, Orlando J. Rojas, Junling Guo, 6 June 2023, Advanced Materials.

DOI: 10.1002/adma.202301531",https://scitechdaily.com/images/Wood-Dust-Traps-Microplastic-Pollution-scaled.jpg,https://scitechdaily.com/pollution-solution-new-device-can-capture-99-9-of-microplastics-in-water-using-wood-dust/,Science
"['Monisha Ravisetti', 'Astronomy Channel Editor', 'Tom C', 'Ryan F. Mercer', 'Social Links Navigation']",2023-08-21 10:00:01+00:00,"We still don't know what dark matter is, but here's what it's not","Two views from Hubble of the massive galaxy cluster Cl 0024+17 (ZwCl 0024+1652) are shown. To the right, a blue shading has been added to indicate the location of invisible material called dark matter that is mathematically required to account for the nature and placement of the gravitationally lensed galaxies that are seen, shown as blueish smudges on the left-hand image.

The quest to find dark matter is a curious one. It is, quite literally, a shot in the dark. Even though scientists are certain that dark matter exists — as all our universe's normal matter simply can't account for the way galaxies are kind of held together — they don't know what it is. They also don't really know where it is (though they have some ideas). And they definitely don't know what it looks like.

Yet the physics community is keen on investigating these elusive particles because the dark side of our cosmos accounts for an unsettling 95% of our universe when taking into account dark energy, the unseen force accelerating space's expansion.

But how does one analyze something without truly knowing what to analyze? Well, there is one way. Despite not knowing what dark matter is yet, scientists can slowly figure out what it is not.

This is precisely what several researchers who are dedicated to the hunt recently did by sifting through data captured with a detector buried deep within a mine in Minnesota. While they did not find evidence of dark matter, they say they've created one of the tightest-ever limits for detecting the phenomenon someday. A full outline on their findings was published in June in the journal Physical Review D.

""It's all about mindset in science, where a null result can be as impactful as a positive result,"" Daniel Jardin, study co-author and a postdoctoral scholar at Northwestern University, told Space.com. ""Obviously it would have been fantastic to find dark matter, but we managed to rule out a new slice of dark matter parameter space.""

Related: 'Hidden' photons could shed light on mysterious dark matter

These latest revelations are associated with the Super Cryogenic Dark Matter Search (SuperCDMS) collaboration, which Jardin is a member of.

To put it briefly, SuperCDMS's experimental detector, the team concluded, can now rule out dark matter particles down to about a fifth of a proton's mass — and potentially even lower masses.

""I've always liked chasing the unknown, and that's as big as it gets,"" Jardin said. ""I'm very happy that my career has led me here and, however brief it may last, I can always say this result was the best in the world until other experiments inevitably catch up.""

This composite image shows the galaxy cluster 1E 0657-56, also known as the ""bullet cluster."" This cluster was formed after the collision of two large clusters of galaxies, the most energetic event known in the universe since the Big Bang. Most of the matter in the clusters (blue) is clearly separate from the normal matter (pink), giving direct evidence that nearly all of the matter in the clusters is dark. (Image credit: X-ray: NASA/CXC/CfA/M.Markevitch et al.; Optical: NASA/STScI; Magellan/U.Arizona/D.Clowe et al.; Lensing Map: NASA/STScI; ESO WFI; Magellan/U.Arizona/D.Clowe et al.)

Wait, what is SuperCDMS?

To capture proof of dark matter particles, the SuperCDMS collaboration works with an experiment referred to as, well, SuperCDMS.

This experiment basically harnesses the power of detectors that can identify if and when a dark matter particle (whatever that is) collides with the atomic nuclei of materials built into the detectors themselves, specifically either germanium or silicon.

""I've been interested in space since I was young because it makes everything on Earth feel so small and insignificant,"" Jardin said. ""Then I learned about dark matter and couldn't believe all of the stars and galaxies and things we see in the night sky make up less than 5% of the universe.""

Getting even more technical, SuperCDMS can pick out whether those dark matter particles partake in what are known as ""elastic collisions."" If they do, what would happen is any energy a dark matter particle loses upon its crash would get transferred to the motion of the impacted atomic nucleus. In turn, the two bits would recoil.

As study co-author Noah Kurinsky, a staff scientist at the SLAC National Accelerator Laboratory, puts it, it'd be like two billiard balls smashing into one another only to slightly bounce backward on the table.

But here's the thing.

SuperCDMS clearly hasn't found any elastic collisions yet — per Jardin, we'd have heard about that by now as such a discovery would probably earn a Nobel prize. However, this team of researchers, notably including Rob Calkins, a research assistant professor at Southern Methodist University, came up with an interesting question.

What if SuperCDMS had been capturing some other type of collision no one's been looking for all this time? Particularly, inelastic collisions.

And considering these new results, they were definitely on to something.

""Searching for elastic collisions is still the main thrust of SuperCDMS, but considering inelastic collisions opened an avenue to dark matter parameter space that the experiment was not previously sensitive to,"" Jardin explained.

There are two ways a potential dark-matter-inelastic collision may work. The first, according to the team, has to do with something called Bremsstrahlung radiation. In the detector, if this type of inelastic collision happened, the dark matter particle would transfer some of its energy to a light particle, or photon, rather than just recoiling like in the billiard ball example.

Though on the other hand, an inelastic collision may occur through something called the Midgal effect. If this version happened, the dark matter particle slamming into the nucleus would cause the nucleus itself to get knocked out of position, messing up its electron cloud distribution. Upon getting back into its original spot, some of those jostled electrons would get ejected.

At risk of simplification, this means the team was searching for SuperCDMS signals of either a flying photon or lonely electron straggler.

""It wasn't as easy as counting,"" Jardin noted. ""This analysis used spectral shapes to model the energy profile of the signal as well as the many known background sources.""

And after all that, the search turned up empty — but the story didn't end here.

""Then,"" Jardin continued, ""we used statistics to answer the question 'what is the probability that we see the signal over the known background?' That question is repeated hundreds of thousands of times and we rule out the parameter space where we should've been able to see the signal and didn't.""

Photo of a 3-inch germanium iZIP detector used in the SuperCDMS Soudan dark matter experiment (associated with the Minnesotan mine). (Image credit: Matthew Cherry/SuperCDMS Collaboration)

There's always a silver lining

""There are roughly 1 billion dark matter particles passing through you every second, but they interact so rarely that you can't tell,"" Jardin said. ""We're looking for a 1 in a billion billion billion billion chance of interaction.""

Even though that golden ticket was not found, however, other forms of treasure did come to light.

Foremost, all of those statistical studies on SuperCDMS signals ended up providing the team with their conclusion about dark matter particles' likely lower mass limits.

""Another dark matter experiment that wasn't sensitive to dark matter mass as low as SuperCDMS for elastic collisions published a similar analysis that extended their reach and leveled the playing field. Reading that, we wondered how much lower we could reach if we used the same method,"" Jardin said.

Plus, as he explained, the team also ""added more to the analysis such as more complex statistics and the inclusion of interactions with the Earth.""

Yes, the Earth

Perhaps even more impressive is how the team took into consideration that the entire Earth's position in space can affect these dark matter signals.

As they explain, if dark matter interacts strongly enough with stuff, it'd likely interact with literally everything in its path on the way to our little Earth-based detectors underground. One of those things ripe for interaction is our planet's atmosphere.

And if a dark matter particle did interact with our atmosphere, this planetary shield would take away some of the particle's energy by the time we captured its signals, the team reasoned.

""Dark matter is believed to be fairly ubiquitous in a big sphere around the galaxy,"" Jardin said. ""Our solar system is in a spiral arm of the Milky Way that is spinning, the Earth is orbiting the sun and the Earth rotates on its axis. This astronomical motion means the Earth is passing through the sea of dark matter particles, but from our perspective, that looks like dark matter particles are constantly bombarding the Earth and our detectors.""

Thus, the researchers realized there's likely an upper limit to the energy such reactive dark matter particles can hole — if they are this reactive, that is.

By modeling things like Earth's atmospheric density, working with geologists to figure out what types of rocks are above the Minnesotan mine where SuperCDMS is buried and tons of other variables, they indeed figured out those upper dark matter energy limits.

""When you fit a line to some data, there are 2 parameters: Slope and intercept,"" Jardin said. ""In this analysis, we had over 50 parameters being fit simultaneously.""

As for what's next, well, Jardin says this Sherlock Holmes-style deduction shall continue. And if any of that went over your head, he emphasized a visual way to look at the team's results that put everything into perspective.

This is what Jardin is referring to when he talks about parameter space. The black areas are the regions created with this new analysis. (Image credit: M. F. Albakry et al. )

""This result — the black lines — rules out some new parameter space that others haven't reached before, but there's a lot of open space to the left, representing lower masses and bottom, representing a lower chance of interacting,"" he said. ""Those are increasingly difficult to probe, but dark matter physicists are clever.""

These dark matter hunters surely reached for the stars and managed to softly land on the moon.",https://cdn.mos.cms.futurecdn.net/Gzeh3UHHySiPg6yBnWZmU3-1200-80.jpg,https://www.space.com/dark-matter-detector-tights-limits-inelastic-collisions,Science
[],,"Scientists Discover ""Demon"" Particle","Right in time for spooky season, scientists have discovered the existence of something called the ""demon"" particle. While the name of the material may strike terror in some, its discovery is actually far less sinister. Hidden from researchers for over seven decades, the ""composite"" of electrons was recently discovered according to a new study published in Nature.

""Demons have been theoretically conjectured for a long time, but experimentalists never studied them,"" paper senior author Peter Abbamonte said in the study. ""In fact, we weren't even looking for it. But it turned out we were doing exactly the right thing, and we found it.""

What is the demon particle?

The demon particle isn't a standard particle such as a proton or electron but rather, a composite of various electrons. A theory of the demon particle first circulated in the 1950s as a result of studies conducted by Dr. David Pines. While standard electrons have both a mass and a charge, Pines hypothesized a combination of electrons could potentially be massless and without a charge—and that's exactly what Abbamonte's team found.

""Pines' prediction of demons necessitates rather specific conditions, and it was not clear to anyone whether strontium ruthenate should have a demon at all,"" co-author Dr. Edwin Huang said. ""We had to perform a microscopic calculation to clarify what was going on. When we did this, we found a particle consisting of two electron bands oscillating out-of-phase with nearly equal magnitude, just like Pines described.""

""At first, we had no idea what it was,"" added first author Ali Husain. ""Demons are not in the mainstream. The possibility came up early on, and we basically laughed it off. But, as we started ruling things out, we started to suspect that we had really found the demon.""",https://sportshub.cbsistatic.com/i/2022/07/19/08516b05-0772-4c64-9e34-9db0b74b7bae/insidious-5-release-date-july-2023.jpg?width=1200,https://comicbook.com/irl/news/demon-particle-discovered-new-study/,Science
['Daniel Wu'],2023-08-20 00:00:00,NASA spacecraft reunites with Earth after 17-year trip around the sun,"Listen 5 min Share Comment on this story Comment

For nearly 17 years, NASA’s Solar Terrestrial Relations Observatory-A spacecraft drifted through space on a lonely mission. It traveled around the sun far ahead of Earth, conducting groundbreaking research on the solar system’s star. Tech is not your friend. We are. Sign up for The Tech Friend newsletter. ArrowRight Like many NASA spacecraft, STEREO-A outlived its mission life span of two years. Instead, it traveled further and further away from Earth on a journey that became fraught with uncertainty as it passed behind the sun in 2015, temporarily severing contact with NASA. The same year, the agency lost contact with STEREO-A’s sibling vessel, STEREO-B, which was traveling a similar path.

But STEREO-A kept going. And its orbital trajectory around the sun meant that it had a chance to do what very few other NASA spacecraft could: eventually make its way back toward home.

That came to fruition earlier this month, when STEREO-A passed between the sun and the Earth for the first time since its launch in 2006, NASA announced. The flyby marked a milestone for the spacecraft and the team that has monitored its progress — and a chance for STEREO-A to prove its relevance almost two decades later. As it continues to pass by Earth, STEREO-A will be used to perform new research on the sun, aided by newer NASA satellites that have been developed since its launch.

Advertisement

“This is a point in time for this mission to shine again,” Lika Guhathakurta, STEREO’s program scientist, told The Washington Post.

The two STEREO spacecraft launched in October 2006 with an ambitious mission: to generate a 360-degree view of the sun by observing the star from two vantage points as they circled it on orbits that diverged from the Earth in opposite directions. STEREO-A maneuvered into an orbit around the sun ahead of Earth, and STEREO-B began circling the sun in the opposite direction behind the Earth.

The difference in perspective was groundbreaking, Guhathakurta said. Earthbound instruments can only ever observe one Earth-facing slice of the sun at a time, while the rest of the rapidly changing solar surface remains obscured. The twin STEREO spacecraft, from their offset positions, allowed scientists to capture a 360-degree view of the sun for the first time, a feat that still awes Guhathakurta.

Advertisement

“Seeing the sun from the front and from the far side at the same time — extraordinary,” she said. “We are on planet Earth, human beings, and we are achieving that.”

Share this article Share

The STEREO craft also allowed scientists to better study the sun’s roiling surface and the hazards that erupt from it. The two craft, operating the same way two eyes create depth perception, provided a three-dimensional view of the sun and of coronal mass ejections — a phenomenon in which plumes of plasma and magnetic field shoot outward from the sun’s outer atmosphere at hundreds or thousands of miles per second, potentially threatening Earth’s power grid and satellites, as well as other planets and NASA spacecraft. That imagery allowed scientists to track the shape, density and velocity of coronal mass ejections as they rippled across the solar system.

As STEREO-A and STEREO-B continued on their orbits, they neared the far side of the sun in 2014. It was a testament to how far they’d traveled, but also a huge risk — moving directly behind the sun would sever communication between the spacecraft and NASA for a period of several months.

Advertisement

The two wayward spacecraft, years past their expiration dates, had not been designed to operate without communication from NASA for that long. While conducting tests in preparation for the downtime, the agency lost contact with STEREO-B. NASA briefly regained contact with the spacecraft in 2016 but determined that a malfunctioning component had sent it into an uncontrollable spin, leaving it unable to orient its antenna or solar panels properly, and the agency gave up on recovery efforts.

STEREO-A, however, emerged from the far side of the sun unscathed — and began the long trip back toward Earth. Earlier this month, the spacecraft passed between Earth and the sun, coming within around 5 million miles of Earth, according to NASA.

The spacecraft arrived back near Earth at an opportune time, Guhathakurta said. When STEREO-A was launched 17 years ago, it viewed the sun during a solar minimum, a low point in the sun’s 11-year cycle of high and low solar activity. That limited the number of coronal mass ejections and other phenomena that the spacecraft initially observed. This year, STEREO-A’s return has coincided with a period of intense solar activity.

Advertisement

And its flyby means it can finally return to the work it once performed with its lost sibling. A capable fleet of satellites and probes near Earth will help STEREO-A re-create the 3D imaging of the sun it once captured with STEREO-B, the agency said.

STEREO-A will continue to work on the edge of solar physics. Scientists hope to use the new data gathered during the spacecraft’s flyby to examine a recent theory that coronal loops — giant arcs of solar material that crisscross the sun’s surface when viewed in ultraviolet light — may be optical illusions.

For Guhathakurta, who began working on the STEREO mission in 1998, STEREO-A’s perseverance after such a long journey is heartening.

“It’s like seeing your children grow up and do extraordinary things,” Guhathakurta said. She added that STEREO-A’s mission may not be finished, depending on NASA’s budgeting decisions. Either way, STEREO-A will continue on its course for another orbit around the sun.

“They don’t stay home,” Guhathakurta added, laughing. “They drift away very quickly.”",https://www.washingtonpost.com/wp-apps/imrs.php?src=https://arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/QM46PWLB4REVNEZQ3Y6RZNHJ3Q.jpeg&w=1440,https://www.washingtonpost.com/nation/2023/08/20/nasa-stereo-a-earth-flyby/,Science
[],,NASA Flyby Spacecraft That Drifted Away For 17 Years Makes Trip Around Sun,"NASA’s STEREO-A spacecraft, which drifted away through space for nearly 17 years, has passed between the Sun and Earth in a landmark feat. The STEREO-A outlived its mission life span of approximately 2 years. It became the first Earth flyby of the nearly 17-year-old mission that has been able to make its way back home. The visit has led to a unique opportunity for the spacecraft to collaborate with NASA missions in Earth's vicinity. It is the first time that the spacecraft made contact with the sun since its launch in 2006.

The STEREO (Solar Terrestrial Relations Observatory) spacecraft was launched on Oct. 25, 2006, from the Cape Canaveral Air Force Station in Florida. STEREO-A (for “Ahead”) advanced into the space, leaving the Earth as STEREO-B (for “Behind”) trailed towards the Earth-like orbits to the sun. Since its launch, NASA scientific team has been monitoring the progress of the spacecraft. Almost two decades later, as STEREO-A made contact with the sun, it will now be used by NASA to perform new research on the sun aided by the newer satellites.

NASA’s STEREO-A spacecraft will cross the Sun-Earth line one day before Venus passes between the Sun and Earth. Credits: NASA's Goddard Space Flight Center/Scientific Visualization Studio.

This image made available by NASA shows an artist’s rendering of the Parker Solar Probe approaching the Sun. Credit: AP

STEREO-A and -B provided view of our closest star

During its initial years of launch, the dual-spacecraft mission was able to achieve the set target of providing the first stereoscopic, or multiple-perspective, view of our closest star. In 2011, STEREO-A and -B reached a 180-degree separation in their orbits achieving yet another landmark space endeavour. For the first time, the team at NASA could see the Sun as a complete sphere.

“Prior to that we were ‘tethered’ to the Sun-Earth line – we only saw one side of the Sun at a time,” Lika Guhathakurta, STEREO program scientist at NASA Headquarters in Washington, DC was quoted as saying in a NASA release. “STEREO broke that tether and gave us a view of the Sun as a three-dimensional object,"" he added.

This coronagraph image shows a coronal mass ejection escaping the Sun, which is occluded behind the black circle at the center of the image. STEREO-A imaged this Earth-directed CME eruption on July 17, 2023. The CME was captured by the COR2 instrument on STEREO-A at the highest cadence (2.5 mins) ever achieved by a coronagraph. Credit: NASA

Scientists at NASA were able to study the data transmitted by both spacecraft until 2014. Following that year, NASA lost most of the contact with the mission during the planned reset of the STEREO-B. STEREO-A, meanwhile continued its journey, capturing the solar flares but was unable to transmit the data to the space agency. Last week, on Aug. 12, STEREO-A completed one full revolution lapsing the Earth's orbit around the Sun. “This is a point in time for this mission to shine again,” Lika Guhathakurta, STEREO’s program scientist was reported as saying. STEREO-A will provide data about the surface of the sun and hazards erupting from the giant star.",https://img.republicworld.com/republic-prod/stories/promolarge/xhdpi/2tdfu0b3juksqlrz_1692584632.jpeg,https://www.republicworld.com/science/space/nasa-flyby-spacecraft-that-drifted-away-for-17-years-makes-trip-around-sun-articleshow.html,Science
"['Maya Pontone', 'More Maya Pontone']",2023-08-21 22:43:13+00:00,Is That a Question Mark in Deep Space?,"It’s a bird! It’s a plane! It’s a ???

Over the past week, a high-resolution image of two young orbiting stars captured by NASA’s James Webb Space Telescope has grabbed the attention of astronomical enthusiasts and punctuation aficionados alike for what appears to look like a galactic question mark.

The photo, originally taken in May and released in late June, gives viewers a detailed look at some of the fantastic cosmic phenomena happening light-years away from Earth. Spanning approximately three light-years across in the Vela Constellation, the composite near-infrared light image shows a pair of actively developing stars known as Herbig-Haro 46/47. The pair of stars, which are buried at the epicenter of the image behind the red light diffraction, are “just a few thousand years old,” reads a statement on the James Webb Space Telescope’s website.

“When the stars ‘eat’ too much material in too short a time, they respond by sending out two-sided jets along the opposite axis, settling down the star’s spin, and removing mass from the area,” the statement reads. “Over millennia, these ejections regulate how much mass the stars retain.”

The entire image captured by the Webb telescope shows a pair of actively forming stars known as Herbig-Haro 46/47, which NASA scientists say are only a mere few thousand years old.

While this image of Herbig-Haro 46/47 is fascinating in itself, as it gives researchers an idea of what our own sun may have looked like at the beginning, directly below the mass is what appears to be a mysteriously well-punctuated message from the universe. While it is unclear exactly what this question mark is, its color and shape give researchers a clue. Representatives of the Space Telescope Science Institute (STScI) told Space.com that the red fuzzy image is “probably a distant galaxy, or potentially interacting galaxies (their interactions may have caused the distorted question mark-shape).”

“This may be the first time we’ve seen this particular object,” STScI added in their statement to the media outlet, adding that “additional follow-up would be required to figure out what it is with any certainty.”

“Webb is showing us many new, distant galaxies — so there’s a lot of new science to be done!”",https://hyperallergic-newspack.s3.amazonaws.com/uploads/2023/08/question-mark-nasa.jpg,https://hyperallergic.com/840364/is-that-a-question-mark-in-deep-space/,Science
"['Smithsonian Magazine', 'Margaret Osborne', 'Daily Correspondent', 'Read More', 'Margaret Osborne Is A Freelance Journalist Based In The Southwestern U.S. Her Work Has Appeared In The']",,What Is This ‘Cosmic Question Mark’ Captured by the James Webb Space Telescope?,"The James Webb Space Telescope has captured a spectacular new image of a pair of actively forming stars about 1,470 light-years away. But beneath the breathtaking phenomenon, some viewers noticed a peculiar shape among the backdrop of celestial objects: a glowing question mark. The image quickly went viral on social media, with jokes about its origin ranging from aliens to a glitch in the Matrix.

So, what exactly is this strange cosmic figure?

“The very first thing you can rule out is that it’s a star in the Milky Way,” Matt Caplan, a physicist at Illinois State University, tells CNN’s Kristen Rogers and Ashley Strickland. “Stars always have these really big spikes, and that’s because stars are point-like. It’s called diffraction, from basically the edges of the mirrors and the struts that support the sort of camera in the middle.”

The object’s color indicates it is either very distant—billions of light-years away—or much closer and obscured by dust. The question mark also appears to be made up of at least two distinct bodies: the curve and the dot, David Helfand, an astronomer at Columbia University, tells National Geographic’s Allie Yang.

The bodies may be completely unrelated and just happened to line up at exactly the right angle, Helfand tells the publication. But another possible explanation is that the shining question mark represents two galaxies merging. The hooked portion of the shape may be what’s called a tidal tail—a thin, elongated stream of stars and gases that occurs as galaxies interact.

“The upper part of the question mark looks like a distorted spiral galaxy, maybe merging with a second galaxy,” Kai Noeske, communication program officer with the European Space Agency, tells NPR’s Rachel Treisman.

Such shapes in space have been captured before. In 2008, the Hubble Space Telescope snapped a picture of two merging galaxies that had a vaguely question-mark-shaped appearance. Another image taken by Hubble in 2009 shows an optical illusion made up of at least four galaxies that look to form a similar shape but are mostly unconnected.

The James Webb Space Telescope’s image, which was released in July, focused on the frequently observed stars known as Herbig-Haro 46/47. According to NASA, Herbig-Haro 46/47 is an important research focus because it is relatively young—only about a few thousand years old—and star systems take millions of years to fully form. Learning more about how these stars gather mass over time could reveal more about how our own sun came to be, per the agency.

While we may never know the exact cause behind the cosmic question mark, the James Webb image quite literally shows us how many more scientific questions we have yet to answer about space.

“I think we all enjoy finding familiar shapes in the sky; that creates a deep connection between our human experience and language in this case (a question mark!) and the beauty of the universe surrounding us,” Macarena Garcia Marin, Webb project scientist with the Space Telescope Science Institute, tells NPR in an email. “I think this exemplifies the human need for exploration and wonder, and to me it brings the question of how many other interesting objects are out there waiting to be explored with Webb.”

Get the latest stories in your inbox every weekday.",https://th-thumbnailer.cdn-si-edu.com/Sa0VkoodWvWIXtSAsj3Vt7mhRfg=/fit-in/1600x0/filters:focal(411x309:412x310)/https%3A%2F%2Ftf-cmsv2-smithsonianmag-media.s3.amazonaws.com%2Ffiler_public%2F36%2F17%2F3617dd90-0aa8-47cd-b259-25be06500388%2Ff3ktyf5xeaat_5.jpeg,https://www.smithsonianmag.com/smart-news/what-is-this-cosmic-question-mark-captured-by-the-james-webb-space-telescope-180982761/,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
[],,This Giant Star Creates Plasma Waves 3 Times Larger Than the Sun,"Astronomers recently used computer simulations to study the rise and fall of gargantuan tides on a distant massive star.

The highest tides on Earth happen in the Bay of Fundy on the southeastern coast of Canada, where high tides raise the water level by more than 38 feet. But on the massive star MACHO 80.7443.1718, high tides raise waves of plasma 2 million miles high. Harvard University astrophysicists Morgan MacLeod and Avi Loeb (yes, that Avi Loeb) recently used computer simulations to explore how plasma tidal waves behave when the star passes close to its smaller (but still ten times more massive than our Sun) companion.

They published their results in the journal Nature Astronomy.

Making Waves

160,000 light years away in the Large Magellanic Cloud, MACHO 80.7443.1718 is actually two stars: one about 35 times more massive than our Sun, and another that astronomers can only “see” from how it affects its larger, brighter companion. These two massive stars waltz around their shared center of gravity once every 33 days. Because their orbit is more of a stretched-out oval than a circle, the distance between them varies, and that creates massive tides that rise and fall in a dramatic but regular rhythm. Astronomers call pairs like this a “heartbeat” star.

“During each pass, each star’s huge gravitational forces create extreme tides on the other — so big, in fact, that they fly away ‘ringing,’ as their shapes wobble and shift around,” writes MacLeod in a blog post about his recent paper with Loeb. “Those wobbles affect the amount of light each star shines toward us here on Earth at a given time, and graphs of their brightness over time look a lot like a heart monitor’s output — earning them their name.”

The tides on most heartbeat stars are about 6,000 times higher than the more familiar tides in Earth’s oceans (and made of extremely hot plasma). But on MACHO 80.7443.1718, the tides are more than a million times higher than ocean tides here on Earth; their towering height is about a fifth of the star’s normal diameter. If you stacked three Suns on top of each other, they’d nearly be swallowed up by the plasma tidal wave. These plasma tidal waves are mind-bogglingly huge.

And according to MacLeod and Loeb’s simulations, they have profound effects on the star and its companion.

Breaking Waves

MACHO 80.7443.1718 spins extremely fast — so fast that centrifugal force has pushed the sides of the star outward, so it looks like a squashed sphere, wider than it is tall. When each wave breaks, the superheated plasma crashes back down to the surface of the star, sending up a turbulent spray. Because the star is spinning so fast, the spray of its breaking plasma waves gets picked up and flung into a glowing halo of material around the star, about 100 times brighter than our Sun.

Meanwhile, the rising, falling, and flowing of so much plasma with such tremendous momentum is enough to affect how fast the star spins and how it orbits its smaller companion. Every crashing wave adds a little momentum to the star’s rotation, making it spin faster and faster. And in the 25 years astronomers have been watching MACHO 80.7443.1718, they’ve noticed its orbit speeding up by about 11 seconds a year — which means the stars are falling just a tiny bit closer together every time they twirl around each other.

“Each breaking tidal wave releases nearly 1,000 times all the gravitational energy that holds Earth together,” writes MacLeod, “and the energy released by this process matches the stars’ decaying orbit — showing that the system’s orbit is decaying because of the energy released by the breaking tidal waves.”

Surf’s Up!

Astronomers have spotted about a thousand pairs of “heartbeat” stars so far, and about 20 of them may have extreme plasma tidal waves that swell and break on the blazing-hot surface of MACHO 80.7443.1718.

“MACHO 80.7443.1718 is likely just the first of a growing class of objects,” write MacLeod and Loeb.",https://imgix.bustle.com/uploads/image/2023/8/22/3eeaebd6-a5e1-4c5d-a558-f45080b0b7ff-081723_lk_star_tidal_waves_feat-1030x580.jpg?w=1200&h=630&fit=crop&crop=faces&fm=jpg,https://www.inverse.com/science/this-star-has-plasma-tidal-waves-that-could-swallow-our-sun,Science
['Purdue University'],2023-08-21 03:17:06-07:00,Superior Strength and Plasticity – A New Treatment for Steel Alloys,"A new treatment tested on a high-quality steel alloy results in remarkable strength and flexibility, qualities often seen as a trade-off rather than a combination. Ultra-fine metal grains that the treatment produced in the outermost layer of steel appear to stretch, rotate and then elongate under strain, conferring super-plasticity in a way that Purdue University researchers cannot fully explain.

The researchers treated T-91, a modified steel alloy that is used in nuclear and petrochemical applications, but said the treatment could be used in other places where strong, ductile steel would be beneficial, such as cars axles, suspension cables and other structural components. The research, which was conducted in collaboration with Sandia National Laboratories and has been patented, appeared Wednesday, May 31 in Science Advances.

More intriguing even than the immediate result of a stronger, more plastic variant of T-91 are observations made at Sandia showing characteristics of what the team is calling a “nanolaminate” of ultra-fine metal grains the treatment created in a region extending from the surface to a depth of about 200 microns. Microscopy images show an unexpected deformation of the treated steel –dubbed G-T91 (or gradient T91)— as it is subjected to increasing stress, said Xinghang Zhang, lead author and a professor in the School of Materials Engineering at Purdue.

“This is a complex process, and the research community has not seen this phenomenon before,” Zhang said. “By definition, the G-T91 is showing super-plasticity, but the exact mechanism that allows this is unclear.”

Metals like steel may look monolithic to the naked eye, but when greatly magnified, a metal bar reveals itself to be a conglomeration of individual crystals called grains. When a metal is subjected to strain, the grains are able deform in such a way that the metallic structure is maintained without rupturing, allowing the metal to stretch and bend. Larger grains can accommodate greater strain than smaller grains, the foundation to a fixed trade-off between large-grain deformable metals and small-grain strong metals.

In the Science Advances paper, lead author Zhongxia Shang, a former graduate student in Zhang’s lab, used compressive and shear stresses to break large grains at the surface of a T-91 sample into smaller grains. A cross-section of the sample shows that grain sizes increase from the surface, where the smallest ultra-fine grains are less than 100 nanometers in size, into the center of the material, where grains are 10 to 100 times larger.

The modified G-T91 sample had a yield strength of about 700 megapascals, a unit of tension stress, and withstood a uniform strain of about 10%, a significant improvement over the combined strength and plasticity that can be reached with standard T-91.

“This is the beauty of the structure, the center is soft so it can sustain plasticity but, by introducing the nanolaminate, the surface has become much harder,” said Shang, now a research staff scientist at Purdue’s Birck Nanotechnology Center. “If you then create this gradient, with the large grains in the center and nanograins in the surface, they deform synergistically. The large grains take care of the stretching, and the small grains accommodate the stress. And now you can make a material that has a combination of strength and ductility.”

While the research team had hypothesized that the gradient nanostructured G-T91 would perform better than standard T-91, scanning electron microscopy images taken at intervals during the tension testing reveal a mystery. Electron backscattered diffraction images taken at a scanning electron microscope at Sandia show how grains in the nanolaminate of the G-T91 change at increasing intervals of true strain, a measure of plasticity, from 0% to 120%. At the beginning of the process, the grains are vertical, with a shape the team describes as lenticular. But as strain increases, they appear to stretch into a more globular shape, then rotate, and finally elongate horizontally.

Zhang said the images show the interface between the grains – called the grain boundary –moving, allowing the grains to stretch and rotate and enabling the steel itself to deform plastically. The team has secured funding from the National Science Foundation to investigate the rules governing this movement in the grain boundaries, which could make it possible to understand the intriguing deformation behavior of gradient materials.

“If we know how they move and why they move, maybe we can find a better way to arrange the grains. We don’t know how to do it yet, but it’s opened a very interesting potential,” Zhang said.

Reference: “Gradient nanostructured steel with superior tensile plasticity” by Zhongxia Shang, Tianyi Sun, Jie Ding, Nicholas A. Richter, Nathan M. Heckman, Benjamin C. White, Brad L. Boyce, Khalid Hattar, Haiyan Wang and Xinghang Zhang, 31 May 2023, Science Advances.

DOI: 10.1126/sciadv.add9780

The study was made possible with support from National Science Foundation. Research conducted at Sandia was supported by a user proposal at the Center for Integrated Nanotechnologies, an Office of Science user facility operated by the U.S. Department of Energy, Office of Science. Zhang and Shang were joined by Tianyi Sun, Jie Ding, Nicholas A. Richter, and Haiyan Wang at Purdue, and by Sandia researchers Nathan M. Heckman, Benjamin C. White, Brad L. Boyce, and Khalid Hattar, who were supported by the U.S. Department of Energy Office of Basic Energy Sciences.

Zhang disclosed his innovation to the Purdue Research Foundation Office of Technology Commercialization, which applied for and received a patent to protect intellectual property. Industry partners seeking to further develop or commercialize the work can contact Parag Vasekar, [email protected], about 2019-ZHAN-68391.",https://scitechdaily.com/images/Steel-Pipes.jpg,https://scitechdaily.com/superior-strength-and-plasticity-a-new-treatment-for-steel-alloys/,Science
[],2023-08-21 16:52:15-04:00,Melting Permafrost Could Unleash Time Traveling Pathogens,"John Carpenter's 1982, science-fiction-horror classic The Thing centers on an Antarctic research facility and its encounter with an alien entity from beneath the ice. When the ice melts and an ancient organism is released, everyone at the facility is exposed and the whole of humanity is threatened.

For decades, the solution seemed simple: If you find something frozen in the ice, you leave it there. Now, though, the world is warming, the ice is melting, and ancient viruses are coming for us whether we like it or not. Figuring out how much trouble we might be in was the goal of a recent study published in the journal PLOS Computational Biology.

Ancient Viruses Waiting in the Permafrost

Permafrost is more or less what it sounds like, a layer of soil which has remained frozen for tens of thousands of years. There, scientists regularly find preserved organic material, like the mummified bodies of mammoths, so well preserved they seem as though they’ve only just died.

RELATED: Scientists Revive Worms Frozen for 46,000 Years in Siberian Permafrost

There’s little risk of a mammoth waking up after being thawed out, but smaller creatures are better at surviving full body freezing and walking away on the other side. Just ask these nematode worms who were frozen for 46,000 years before wiggling their way into the future.

And if you think worms are good at sleeping their way through the millennia, just wait until you hear about viruses. Researchers were interested not in any particular pathogen, but in the likelihood that one or more of them will infiltrate our ecosystem and muck everything up.

THE THING (1982) Photo: Universal/courtesy Everett Collection

Researchers modeled interactions between an ancient virus and modern bacteria in a computer simulation. Then they ran that simulation thousands of times to see what would happen. That way, they could crunch the probabilities that a killer virus frozen in the deep past might wake up and wipe out all life on Earth. In most cases, invading viruses had little if any effect on the simulated ecosystem. That’s the good news. The vast majority of invading viruses just aren’t very good at getting a foothold. Now the bad news.

In 1.1% of simulations, an invasive virus had a substantial impact on its new environment. Importantly, not all impacts were negative, at least when looking at the whole ecosystem. In the worst cases, biodiversity in the ecosystem dropped by 32%, nearly a third. In the best cases, species biodiversity actually increased by about 12%. To be clear, that does not mean that the viruses wiped out 32% of life in their simulated ecosystem, just that there was significantly lower genetic and species diversity in the ecosystem.

Is an Ancient Virus Coming For Us or Not?

While a 1.1% risk might seem low, we need to know what our sample size is. Scientists estimate that ordinary melting releases roughly 4 sextillion cells from the permafrost each year. To be clear, that is a 4 with 21 zeros following it. Even if we reduce to just 1.1% of that total, we’re looking at a number of potential exposures that you can’t really get your head around. It’s more than the number of stars in the Milky Way, and it’s not even close.

RELATED: Band-aids not helping with that infection? Try putting a virus on it

Credit: Universal Pictures

The point is, there are a staggering number of opportunities for an upstart virus hoping to make up for lost time. The good news is that people don’t tend to group in places covered with permafrost. It is, sort of by definition, not an awesome place to live. Consequently, if and when dangerous pathogens are released, they’ll at least be in one of the least populated places on Earth.

The point is, ancient viruses are probably not waiting to emerge from the permafrost and turn us into tentacled monsters. But if you do find one, it’s your job to destroy the helicopter and make sure it never gets out.

For further instructions, catch The Thing, available from Universal Pictures.",https://www.syfy.com/sites/syfy/files/2022/06/gettyimages-607397920_0.jpg,https://www.syfy.com/syfy-wire/melting-permafrost-could-unleash-time-traveling-pathogens,Science
['Katie Hawkinson'],2023-08-20 00:00:00,"Ancient viruses could re-emerge as permafrost melts, posing 'unpredictable threats' to our communities, new study says","Scientists are studying a new threat emerging from melting permafrost: ancient viruses.

A new study says these pathogens could pose significant risks to modern-day humans.

The authors say the chances of a catastrophic re-emergence are low but worrisome.

Sign up for our newsletter to get the latest on the culture & business of sustainability — delivered weekly to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy Policy

Advertisement

Advertisement

As permafrost thaws across the world due to a warming climate, scientists are researching a potential new threat: The emergence of ancient viruses trapped in the frost for tens of thousands of years.

The authors of the study — published in PLOS Computational Biology, a peer-reviewed scientific journal — used computer simulations to model how ancient viruses could survive, evolve, and persist in our modern-day communities. This research marks the first ""extensive exploration of the ecological risk"" these viruses pose, according to the authors.

Melting permafrost is already revealing organisms that have been trapped beneath the ice for millennia. In a study published last month, scientists said they discovered a 46,000-year-old microscopic worm trapped in Siberian permafrost that was still capable of producing offspring. And earlier this year, a French scientist identified a 48,000-year-old virus in Siberian permafrost that could still infect single-celled organisms.

In many of the simulations conducted in the study of the ancient viruses, researchers found that they could thrive in modern communities without making a catastrophic impact, but still caused ""non-negligible ecological change.""

Advertisement

Advertisement

The simulations found that just 1% of cases resulted in major ecological damage. But within this small percentage, the simulations found that the pathogens would either increase species diversity by 12% or decrease species diversity by 32%, according to the authors.

That 1% is important, the authors warn, and these low-probability yet catastrophic re-emergence scenarios require further attention.

""Risk does not emerge solely from the chance of the event occurring, but from the combination of probability and the magnitude of the event's potential effects,"" the authors wrote. ""From that perspective, our results are worrisome, as they point to an actual risk deriving from the rare events where time-traveling invasions produce severe ecological impacts.""

Plus, the pathogens that were most successful in the past are the most likely to successfully re-establish themselves today, according to the researchers. This means the viruses most likely to re-emerge successfully could also be the most likely to pose an ecological risk.

Advertisement

Advertisement

Experts have been sounding the alarm on melting permafrost for years, identifying it as just one of countless reasons to slow carbon emissions. Not only is the thawing permafrost a sign that global climate change is worsening, vast swaths of melting ice also pose a significant threat to human infrastructure.",https://i.insider.com/64e22a14b698ac0019dd8406?width=1200&format=jpeg,https://www.businessinsider.com/ancient-viruses-may-reemerge-as-permafrost-melts-climate-change-study-2023-8,Science
['Quincy Jon'],2023-08-20 00:00:00,Climate Change Threat: Melting Permafrost Could Unleash Ancient Viruses That May Harm Modern Humans,"Scientists worry that increasing temperatures would melt permafrost, resurrecting tens of thousands of year-old viruses.

A recent PLOS Computational Biology study used computer models to study the survival, evolution, and consequences of ancient viruses that may reappear due to permafrost melting, as reported by Business Insider.

The permafrost's melting revealed long-frozen creatures. Experts unearthed a 46,000-year-old reproducing worm last month, and a 48,000-year-old virus that infects single-celled creatures was uncovered in Siberian permafrost by a French researcher this year.

The study models demonstrated that most old viruses could persist in modern cultures without damaging them, although they had a ""non-negligible ecological change."" According to the research, only 1% of instances resulted in significant ecological disturbances. The calculations showed that, within this tiny fraction, diseases would either increase or decrease species diversity by 12% or 32%.

Ancient Diseases Threaten the Modern World

Although this 1% may seem minor, the study's authors emphasized low probability, but catastrophic events need careful thought. They underlined that the likelihood of the occurrence and its possible impacts constitute the actual risk, and their findings indicate that uncommon events pose real ecological concerns.

The research indicated the ancient viruses that were most effective in the past are the ones that are most likely to reappear in the present. This suggests that the viruses that provide the most remarkable ecological harm also have the highest likelihood of successfully returning.

Experts have long been concerned about permafrost melting because of what it may mean for infrastructure and climate change. In permafrost, the 1918 pandemic influenza strain and smallpox virus genetic material have been detected.

Read Also: Coffee Health Effects: How Much Is Too Much?

A 2016 anthrax epidemic in Siberia was attributed to deep permafrost melting brought on by extremely hot summers, which allowed Bacillus anthracis spores from ancient graves and animal corpses to resurface. The epidemic impacted more than 2,000 reindeers and several humans, according to a CNN report.

More Research Being Conducted to Understand Potential 'Zombie' Viruses

The danger and effects of more sophisticated permafrost viruses are still being explored, even though scientists have primarily examined single-celled viruses. According to an article from LiveScience, researchers are wary about doing more research that may unintentionally result in the release of ancient viruses capable of infecting contemporary animals.

Researchers looked at soil and lake sediment samples in a different investigation to find viral fingerprints and the genomes of possible hosts in the Arctic. It was discovered that the risk of viruses spreading to new hosts was greater close to areas with large glacier meltwater, a tendency made worse by climate change.

Understanding the broader threats that permafrost melt poses to the Arctic environment requires measuring thaw rates, depths, and the release of greenhouse gases like methane and carbon dioxide. Identifying the dangers present in permafrost thaw is an essential first step.

There are worries about hidden garbage, radioactive substances, and ""Methuselah microorganisms"" that might disturb existing ecosystems and have unknown repercussions due to the fast melting of permafrost.

Although it is still improbable that ancient viruses would directly infect people, ongoing monitoring and study are needed to understand the broader ecological effects of permafrost melting.

Related Article: Oetzi the Iceman's DNA Unveils Fresh Insights Into His 5,300-Year-Old Story

ⓒ 2023 TECHTIMES.com All rights reserved. Do not reproduce without permission.",https://1734811051.rsc.cdn77.org/data/images/full/434483/climate-change-threat-melting-permafrost-could-unleash-ancient-viruses-that-may-harm-modern-humans.jpg,https://www.techtimes.com/articles/295370/20230820/climate-change-threat-melting-permafrost-unleash-ancient-viruses-harm-modern.htm,Science
[],,"Ancient viruses could re-emerge as permafrost melts, posing 'unpredictable threats' to our communities, new study says","Scientists are studying a new threat emerging from melting permafrost: ancient viruses.

A new study says these pathogens could pose significant risks to modern-day humans.

Advertisement

As permafrost thaws across the world due to a warming climate, scientists are researching a potential new threat: The emergence of ancient viruses trapped in the frost for tens of thousands of years.

The authors of the study — published in PLOS Computational Biology, a peer-reviewed scientific journal — used computer simulations to model how ancient viruses could survive, evolve, and persist in our modern-day communities. This research marks the first ""extensive exploration of the ecological risk"" these viruses pose, according to the authors.

Melting permafrost is already revealing organisms that have been trapped beneath the ice for millennia. In a study published last month, scientists said they discovered a 46,000-year-old microscopic worm trapped in Siberian permafrost that was still capable of producing offspring. And earlier this year, a French scientist identified a 48,000-year-old virus in Siberian permafrost that could still infect single-celled organisms.

In many of the simulations conducted in the study of the ancient viruses, researchers found that they could thrive in modern communities without making a catastrophic impact, but still caused ""non-negligible ecological change.""

The simulations found that just 1% of cases resulted in major ecological damage. But within this small percentage, the simulations found that the pathogens would either increase species diversity by 12% or decrease species diversity by 32%, according to the authors.

Advertisement

That 1% is important, the authors warn, and these low-probability yet catastrophic re-emergence scenarios require further attention.

""Risk does not emerge solely from the chance of the event occurring, but from the combination of probability and the magnitude of the event's potential effects,"" the authors wrote. ""From that perspective, our results are worrisome, as they point to an actual risk deriving from the rare events where time-traveling invasions produce severe ecological impacts.""

Plus, the pathogens that were most successful in the past are the most likely to successfully re-establish themselves today, according to the researchers. This means the viruses most likely to re-emerge successfully could also be the most likely to pose an ecological risk.

Experts have been sounding the alarm on melting permafrost for years, identifying it as just one of countless reasons to slow carbon emissions. Not only is the thawing permafrost a sign that global climate change is worsening, vast swaths of melting ice also pose a significant threat to human infrastructure.",https://www.businessinsider.in/photo/102879762/ancient-viruses-could-re-emerge-as-permafrost-melts-posing-unpredictable-threats-to-our-communities-new-study-says.jpg?imgsize=815784,https://www.businessinsider.com/ancient-viruses-may-reemerge-as-permafrost-melts-climate-change-study-2023-8,Science
['Elizabeth A. Thomson'],,"Machine-learning system based on light could yield more powerful, efficient large language models","ChatGPT has made headlines around the world with its ability to write essays, email, and computer code based on a few prompts from a user. Now an MIT-led team reports a system that could lead to machine-learning programs several orders of magnitude more powerful than the one behind ChatGPT. The system they developed could also use several orders of magnitude less energy than the state-of-the-art supercomputers behind the machine-learning models of today.

In the July 17 issue of Nature Photonics, the researchers report the first experimental demonstration of the new system, which performs its computations based on the movement of light, rather than electrons, using hundreds of micron-scale lasers. With the new system, the team reports a greater than 100-fold improvement in energy efficiency and a 25-fold improvement in compute density, a measure of the power of a system, over state-of-the-art digital computers for machine learning.

Toward the future

In the paper, the team also cites “substantially several more orders of magnitude for future improvement.” As a result, the authors continue, the technique “opens an avenue to large-scale optoelectronic processors to accelerate machine-learning tasks from data centers to decentralized edge devices.” In other words, cellphones and other small devices could become capable of running programs that can currently only be computed at large data centers.

Further, because the components of the system can be created using fabrication processes already in use today, “we expect that it could be scaled for commercial use in a few years. For example, the laser arrays involved are widely used in cell-phone face ID and data communication,” says Zaijun Chen, first author, who conducted the work while a postdoc at MIT in the Research Laboratory of Electronics (RLE) and is now an assistant professor at the University of Southern California.

Says Dirk Englund, an associate professor in MIT’s Department of Electrical Engineering and Computer Science and leader of the work, “ChatGPT is limited in its size by the power of today’s supercomputers. It’s just not economically viable to train models that are much bigger. Our new technology could make it possible to leapfrog to machine-learning models that otherwise would not be reachable in the near future.”

He continues, “We don’t know what capabilities the next-generation ChatGPT will have if it is 100 times more powerful, but that’s the regime of discovery that this kind of technology can allow.” Englund is also leader of MIT’s Quantum Photonics Laboratory and is affiliated with the RLE and the Materials Research Laboratory.

A drumbeat of progress

The current work is the latest achievement in a drumbeat of progress over the last few years by Englund and many of the same colleagues. For example, in 2019 an Englund team reported the theoretical work that led to the current demonstration. The first author of that paper, Ryan Hamerly, now of RLE and NTT Research Inc., is also an author of the current paper.

Additional coauthors of the current Nature Photonics paper are Alexander Sludds, Ronald Davis, Ian Christen, Liane Bernstein, and Lamia Ateshian, all of RLE; and Tobias Heuser, Niels Heermeier, James A. Lott, and Stephan Reitzensttein of Technische Universitat Berlin.

Deep neural networks (DNNs) like the one behind ChatGPT are based on huge machine-learning models that simulate how the brain processes information. However, the digital technologies behind today’s DNNs are reaching their limits even as the field of machine learning is growing. Further, they require huge amounts of energy and are largely confined to large data centers. That is motivating the development of new computing paradigms.

Using light rather than electrons to run DNN computations has the potential to break through the current bottlenecks. Computations using optics, for example, have the potential to use far less energy than those based on electronics. Further, with optics, “you can have much larger bandwidths,” or compute densities, says Chen. Light can transfer much more information over a much smaller area.

But current optical neural networks (ONNs) have significant challenges. For example, they use a great deal of energy because they are inefficient at converting incoming data based on electrical energy into light. Further, the components involved are bulky and take up significant space. And while ONNs are quite good at linear calculations like adding, they are not great at nonlinear calculations like multiplication and “if” statements.

In the current work the researchers introduce a compact architecture that, for the first time, solves all of these challenges and two more simultaneously. That architecture is based on state-of-the-art arrays of vertical surface-emitting lasers (VCSELs), a relatively new technology used in applications including lidar remote sensing and laser printing. The particular VCELs reported in the Nature Photonics paper were developed by the Reitzenstein group at Technische Universitat Berlin. “This was a collaborative project that would not have been possible without them,” Hamerly says.

Logan Wright, an assistant professor at Yale University who was not involved in the current research, comments, “The work by Zaijun Chen et al. is inspiring, encouraging me and likely many other researchers in this area that systems based on modulated VCSEL arrays could be a viable route to large-scale, high-speed optical neural networks. Of course, the state of the art here is still far from the scale and cost that would be necessary for practically useful devices, but I am optimistic about what can be realized in the next few years, especially given the potential these systems have to accelerate the very large-scale, very expensive AI systems like those used in popular textual ‘GPT’ systems like ChatGPT.”

Chen, Hamerly, and Englund have filed for a patent on the work, which was sponsored by the U.S. Army Research Office, NTT Research, the U.S. National Defense Science and Engineering Graduate Fellowship Program, the U.S. National Science Foundation, the Natural Sciences and Engineering Research Council of Canada, and the Volkswagen Foundation.",https://news.mit.edu/sites/default/files/images/202308/Optical-Neural-Network.png,https://news.mit.edu/2023/system-could-yield-more-powerful-efficient-llms-0822,Science
['Brown University'],2023-08-22 09:49:01-07:00,Melting Mysteries on Mars: Gullies May Have Formed by Recent Periods of Liquid Meltwater,"In a new study, scientists how gullies on the slopes of Martian craters could have formed by on-and-off periods of meltwater from ice on and beneath the planet’s surface.

A study led by Brown University researchers offers new insights into how water from melting ice could have played a recent role in the formation of ravine-like channels that cut down the sides of impact craters on Mars.

Recently published in the journal Science, the study focuses on Martian gullies, which look eerily similar to gullies that form on Earth in the Dry Valleys of Antarctica and are caused by water erosion from melting glaciers. The scientists, including Brown planetary scientist Jim Head, built a model that simulates a sweet spot for when conditions on Mars allow the planet to warm above freezing temperatures, leading to periods of liquid water on Mars when ice on and beneath the surface melts.

The researchers discovered that when Mars tilts on its axis to 35 degrees, the atmosphere becomes dense enough for brief episodes of melting to occur at gully locations. They then matched the data from their model to periods in Mars history when the gullies in the planet’s Terra Sirenum region are believed to have expanded rapidly downhill from high elevation points — a phenomenon that could not be explained without the occasional presence of water.

Historical Context and Findings

“We know from a lot of our research and other people’s research that early on in Mars history, there was running water on the surface with valley networks and lakes,” said Head, a professor of geological sciences at Brown. “But about 3 billion years ago, all of that liquid water was lost, and Mars became what we call a hyper-arid or polar desert. We show here that even after that and in the recent past, when Mars’ axis tilts to 35 degrees, it heats up sufficiently to melt snow and ice, bringing liquid water back until temperatures drop and it freezes again.”

The findings help fill in some of the missing gaps on how these gullies formed, including how high they start, how severe the erosion is, and how far they extend down the side of craters.

Comparison With Previous Theories

Previous theories suggest Martian gullies were carved by carbon dioxide frost, which evaporates from soil, causing rock and rubble to slide down slopes. The height of the gullies made many scientists theorize that meltwater from glaciers had to be involved because of the distance they traveled down the slopes and how eroded the gullies looked. Proving liquid water could exist on Mars since it disappeared so long ago has been difficult because temperatures typically hover about 70 degrees below freezing.

The results from the new study suggest that gully formation was driven by periods of melting ice and by CO2 frost evaporation in other parts of the year. The researchers found this has likely occurred repeatedly over the past several million years with the most recent occurrence about 630,000 years ago.

They say that if ice was present at gully locations in the areas they looked at when Mars’ axis tilted to about 35 degrees, the conditions would have been right for the ice to melt because temperatures rose above 273 degrees Kelvin, equivalent to about 32 degrees Fahrenheit.

Implications of the Study

“Our study shows that the global distribution of gullies is better explained by liquid water over the last million years,” said Jay Dickson, the study’s lead author and a former researcher at Brown who’s now at California Institute of Technology. “Water explains the elevation distribution of gullies in ways that CO2 cannot. This means that Mars has been able to create liquid water in enough volume to erode channels within the last million years, which is very recent on the scale of Mars geologic history.”

Despite doubts about meltwater being possible and scientists never being able to model the right conditions on Mars for ice to melt, the researchers were convinced that the meltwater theory was accurate because they had seen similar features firsthand in Antarctica. There, despite the cold temperatures, the sun is able to heat ice just enough for it to melt and for gully activity to occur.



A time-lapse of gullies forming in the Upper Wright Valley of the Antarctic Dry Valleys. Credit: Video courtesy of Jim Head, Brown University

The new study is a continuation of previous research the team started decades earlier looking at Martian gullies. In a 2015 study, for instance, the researchers showed it was possible that there may have been past periods on Mars when water was available to form gullies if Mars tilted on its axis enough. The findings encouraged them to model what that tilt was and match it with the locations and altitudes of gullies that have formed.

Potential for Life and Future Exploration

The paper raises anew the fundamental question of whether life could exist on Mars. This is because life, as it’s known on Earth, goes hand in hand with the presence of liquid water. Mars will eventually tilt to 35 degrees again, the researchers said.

“Could there be a bridge, if you will, between the early warm and wet Mars and the Mars that we see today in terms of liquid water?” Head said. “Everybody’s always looking for environments that could be conducive to not just the formation of life but the preservation and continuation of it. Any microorganism that might have evolved in early Mars is going to be in places where they can be comfortable in ice and then also comfortable or prosperous in liquid water. In the frigid Antarctic environment, for example, the few organisms that exist often occur in stasis, waiting for water.”

The study also introduces the importance of these gullies in terms of potential targets to visit during future exploration missions on Mars.

Reference: “Gullies on Mars could have formed by melting of water ice during periods of high obliquity” by J. L. Dickson, A. M. Palumbo, J. W. Head, L. Kerber, C. I. Fassett and M. A. Kreslavsky, 29 June 2023, Science.

DOI: 10.1126/science.abk2464

The study included funding from the NASA Mars Data Analysis Program. Other Brown-affiliated authors include former graduate students Ashley Palumbo and Laura Kerber, former graduate student and postdoctoral researcher Caleb Fassett and visiting researcher Mikhail Kreslavsky, a planetary scientist at University of California, Santa Cruz.",https://scitechdaily.com/images/Mars-Gullies.jpg,https://scitechdaily.com/melting-mysteries-on-mars-gullies-may-have-formed-by-recent-periods-of-liquid-meltwater/,Science
['Leonard David'],2023-08-21 17:31:21+00:00,Perchlorate on the Red Planet: How a Toxin in Martian Soil Can Fuel Future Exploration,"The NASA Phoenix Mars Lander assessed the history of water in the Martian arctic, searched for evidence of a habitable zone, and appraised the biological potential of the ice-soil boundary. Image credit: NASA/JPL-Caltech.

One finding from Mars exploration is that the Red Planet is a haven of pervasive perchlorate.

On one hand, the carpet of perchlorate chemistry found on Mars may boost the chances that microbial life exists on the Red Planet. However, perchlorates are also perilous to the health of future crews destined to explore that way-off world.",https://media2.spaceref.com/wp-content/uploads/2023/08/21132754/PHOTO-1-mars-phoenix-Cropped-scaled.jpg,https://spaceref.com/science-and-exploration/perchlorate-red-planet-toxin-martian-soil-fuel-future-exploration/,Science
[],2023-08-20 22:01:59+00:00,"Study: Ancient Mars May Have Had Wet, Dry Periods","Researchers say they have found evidence that ancient Mars experienced both wet and dry climate cycles.

The new evidence is based on data collected by an exploring vehicle on Mars, called Curiosity. The explorer, or rover, is operated by the American space agency NASA.

Scientists say the finding suggests Mars may have once held the right conditions to support life. They describe their findings in a study appearing this month in the publication Nature.

Today, Mars is a dusty, cold desert. But past research has shown the planet was once home to a large system of rivers and lakes. Many studies have suggested the presence of water billions of years ago may have created conditions to support life. But there has been no clear evidence Mars also experienced dry periods.

The Curiosity rover has been exploring Mars’ huge Gale crater since 2012. The area is believed to have contained a lake at one time and has a large mountain of sediment nearly six kilometers high.

The researchers said that while climbing the side of the sediment mountain in 2021, Curiosity found salt remains that formed a hexagonal shape in soil that dated back nearly four billion years. The rover's instruments identified the shape as cracks in dried mud.

""When a lake dries up the mud cracks, and when it fills back up, the cracks heal,"" said William Rapin. He is a researcher at France’s National Centre for Scientific Research (CNRS) and the lead writer of the study.

Rapin said when this process is repeated, the cracks position themselves in hexagons, or six-sided shapes. This hexagonal evidence suggests there were long dry periods in the Gale Crater area. NASA said the evidence that rivers and lakes on ancient Mars began to dry up at times provides evidence that climate cycles repeatedly happened.

Rapin said the finding is ""the first tangible proof” that Mars had a wet-dry climate."" The researchers say having both wet and dry seasons, as we have on Earth, could have provided the right conditions for life to form on Mars.

Curiosity and another rover operating on Mars, Perseverance, have already identified evidence of organic compounds that could suggest the presence of past life forms.

But Rapin noted these building blocks need the right mix of conditions in order to support life. ""In a world that's too dry, these molecules never have the (chance) to form – nor do they in a world that's too wet,"" he said.

Ashwin Vasavada is a project scientist at NASA's Jet Propulsion Laboratory in California. He said in a statement, ""Over 11 years, we've found ample evidence that ancient Mars could have supported microbial life. Now, the mission has found evidence of conditions that may have promoted the origin of life, too.""

Such evidence would never have been found on Earth, Rapin said. This is because tectonic plates on our planet repeatedly recycle the surface, burying evidence from before the time life formed.

Rapin noted this means that studying Mars – which does not have tectonic plates – could help scientists solve the mystery of how life began on Earth. ""It's pretty lucky of us to have a planet like Mars nearby that still holds a memory of the natural processes which may have led to life,"" he said.

I’m Bryan Lynn.

Bryan Lynn wrote this story for VOA Learning English, based on reports from NASA, Agence France-Presse, the French National Centre for Scientific Research and Nature.

Quiz - Study: Ancient Mars May Have Had Wet and Dry Periods Start the Quiz to find out Start Quiz

______________________________________________

Words in This Story

crater – n. a big hole left in the ground or an object by a force of impact

sediment – n. materials that collect at the bottom of a liquid

crack – n. a line on the surface of something that is damaged

mud –n. soft, wet soil or clay

tangible – adj. something that is real and can be seen, touched or measured

organic – adj. chemicals known to contain carbon

ample – adj. enough, or more than enough

origin – v. where something begins or comes from

_________________________________________________

What do you think of this story? We want to hear from you. We have a new comment system. Here is how it works:

Write your comment in the box. Under the box, you can see four images for social media accounts. They are for Disqus, Facebook, Twitter and Google. Click on one image and a box appears. Enter the login for your social media account. Or you may create one on the Disqus system. It is the blue circle with “D” on it. It is free.

Each time you return to comment on the Learning English site, you can use your account and see your comments and replies to them. Our comment policy is here.",https://gdb.voanews.com/01000000-0aff-0242-4bc1-08dba01b042a_cx1_cy9_cw26_w1200_r1.jpg,https://learningenglish.voanews.com/a/study-ancient-mars-may-have-had-wet-dry-periods/7229813.html,Science
['Jennifer Ouellette'],,In the (convection) zone: Astronomers eavesdrop on stars’ innate “twinkle”,"Science 101 tells us that the twinkling appearance of stars from our vantage point on Earth is due to atmospheric effects: winds and varying temperatures and densities in the air bend and distort the light. But stars have another sort of ""twinkle"" produced by how gases ripple in waves across their surface, an effect that could provide astronomers with a handy means of exploring the interior of massive stars to learn more about how they form and evolve. But the effect is much too small to be readily detected by telescopes.

So scientists have now developed the first 3D simulations of that innate twinkle, according to a recent paper published in the journal Nature Astronomy. As a bonus, the researchers converted the data from those rippling waves of gas into an audible sound, so now we can all take a moment to listen to ""Twinkle, Twinkle, Little Star"" (see video above) and Gustav Holst's ""Jupiter"" (see video below) in the ""language"" of the stars.

“Motions in the cores of stars launch waves like those on the ocean,” said co-author Evan Anders of Northwestern University. “When the waves arrive at the star’s surface, they make it twinkle in a way that astronomers may be able to observe. For the first time, we have developed computer models which allow us to determine how much a star should twinkle as a result of these waves. This work allows future space telescopes to probe the central regions where stars forge the elements we depend upon to live and breathe.”

The critical feature for this latest research is the so-called ""convection zone,"" typically found near the surface, although it can also persist deeper into the star. (Stars can also develop convection zones near the core.) Our Sun, for instance, has a convective envelope ranging from its surface to about one-third of the way toward its core. Stellar convection is what moves matter from the star's deeper and hotter layers outward to the cooler outer layers, and material from those outer layers to the inner hotter layers.

Advertisement

Convection is also one proposed mechanism for the so-called ""red noise"" signals astronomers have observed in the photometric light curves of hot, massive stars—a mysterious pulsing that causes fluctuations in the stars' brightness. Specifically, it's been suggested that core convection, or turbulence from subsurface convection zones, could produce gravity waves that ripple outward to the surface. Those waves would compress and decompress the plasma, producing the brightness fluctuations in the star's light. Anders and his colleagues developed their simulations in part to test that hypothesis. The challenge: while some waves make it to the surface, others are trapped below and bounce around. So they needed some means of distinguishing between the two kinds of waves.

To do so, they turned to an acoustic analogy. ""The character of music depends both on the sound waves produced by musicians and on the acoustics of the environment where is played,"" the authors wrote. ""Music is recorded in special studios with walls that absorb or diffuse waves to minimize the influence of the environment on the sound and retrieve the 'pure sound' of the musicians. To experience music in a different environment, it is not necessary to physically transport the musicians; instead, one can apply a filter to the recording, mimicking the effects of the new environment.""

The team adopted a similar strategy, running short simulations of waves generated by convection and recording the waves as they moved beyond the convection zone. First, they built a model to calculate the basic ""song"" of those convection waves—technically, the photometric variability from the gravity waves—and then they applied a filter to replicate the star's acoustical properties, akin to the damping filters used in a recording studio. Once this approach had been validated, Anders et al. ran convection simulations for stars with masses of three, 15, and 40 times our Sun. These showed what those waves should look like when viewed through a telescope.

Advertisement

As for the sonification, a star's convection produces waves that correspond to different sounds. “The smaller stars in our study are more like the violin, where they have some more high-pitched noises because they have a smaller wave cavity, just like a violin has a smaller wave cavity,” Anders told New Scientist. “And our larger stars have a bigger wave cavity, just like a cello has a bigger wave cavity, so they have some deeper noises.” They used their model to find out what a song would sound like if we heard to propagated through a star by applying it to real music. ""The stars change the music and, correspondingly, change how the waves would look if we saw them twinkling on the star's surface,"" said Anders.

The simulations also revealed that the twinkling attributable to core convection is simply too weak to fully explain the observed red noise effect in massive stars. It's possible that convection nearer to the star's surface could account for the red noise, but according to co-author Matteo Cantiello of the Flatiron Institute's Center for Computational Astrophysics in New York, this would tell astronomers less about the processes occurring deep in the star's interior. The next step is to improve their simulations to take other effects into account, such as a star spinning rapidly around its axis, which might produce a flickering strong enough to be detected by telescopes.

DOI: Nature Astronomy, 2023. 10.1038/s41550-023-02040-7 (About DOIs).

Listing image by E.H. Anders et al., 2023",https://cdn.arstechnica.net/wp-content/uploads/2023/08/twinkle2-760x380.jpg,https://arstechnica.com/science/2023/08/in-the-convection-zone-astronomers-eavesdrop-on-stars-innate-twinkle/,Science
['University Of Texas At Austin'],2023-08-22 13:01:56-07:00,First-Ever Jurassic Vertebrate Fossils Discovered in Texas,"A team led by scientists from The University of Texas at Austin has unveiled the first-ever Jurassic vertebrate fossils discovered in Texas, filling a significant gap in the state’s fossil history.

These ancient bone remnants, found to be from the extremities and spine of a plesiosaur, offer a glimpse into the prehistoric times when this extinct marine creature navigated the shallow waters that once spanned present-day northeastern Mexico and the far west of Texas around 150 million years ago.

The bones were discovered in the Malone Mountains of West Texas during two fossil hunting missions led by Steve May, a research associate at UT Austin’s Jackson School of Geosciences Museum of Earth History.

Before the discovery, the only fossils from the Jurassic that had been collected and described from outcrops in Texas were from marine invertebrates, such as ammonites and snails. May said that the new fossil finds serve as solid proof that Jurassic bones are here.

“Folks, there are Jurassic vertebrates out there,” May said. “We found some of them, but there’s more to be discovered that can tell us the story of what this part of Texas was like during the Jurassic.”

A paper describing the bones and other fossils was published in Rocky Mountain Geology on June 23.

The Jurassic was an iconic prehistoric era when giant dinosaurs walked the Earth. The only reason we humans know about them, and other Jurassic life, is because of fossils they left behind.

But to find Jurassic-aged fossils, you need Jurassic-aged rocks. Because of the geological history of Texas, the state hardly has any outcrops from this time in Earth’s history. The 13 square miles of Jurassic-aged rocks in the Malone Mountains make up most of those rocks in the state.

In 2015, when May learned while researching a book that there were no Jurassic bones in the Texas fossil record, he decided to go to the Malone Mountains to explore.

“You just don’t want to believe that there are no Jurassic bones in Texas,” May said. “Plus, there was a tantalizing clue.”

The clue was a mention of large bone fragments in a 1938 paper on the geology of the Malone Mountains by Claude Albritton, who later became a geology professor at Southern Methodist University (SMU). It was enough of a lead to get May and his collaborators out to West Texas to see for themselves. Large bone fragments are what they found. The plesiosaur fossils are eroded and broken up.

But it’s a start that could lead to more science, said co-author Louis Jacobs, a professor emeritus at SMU.

“Geologists are going to go out there looking for more bones,” Jacobs said. “They’re going to find them, and they’re going to look for the other things that interest them in their own special ways.”

Today, the Malone Mountains rise above the dry desert landscape. During the Jurassic, the sediments were deposited just below sea level probably within miles of the shoreline.

The team found several other specimens that give a look into the ancient shallow marine environment, such as petrified driftwood filled with burrows from marine worms and the shells of clams, snails, and ammonites. The researchers found a range of plant fossils, including a pinecone, and wood with possible growth rings.

Globally, Jurassic plant fossils from lower latitudes close to the Earth’s equator are relatively rare, said co-author and paleobotanist Lisa Boucher, the director of the Jackson School’s Non-Vertebrate Paleontology Lab. She said the plant finds should make the Malones a place of interest to other paleobotanists and those interested in paleoenvironmental reconstruction.

Scientists have been conducting research in the Malones for over 100 years. So, why did it take so long to bring back Jurassic bones? May has several ideas – from remoteness of the area and permitting, to the research interests of past scientists. Whatever the reasons, Boucher said that the team’s discovery of a Texas first shows the value of fieldwork – simply traveling to a place to see what’s there.

“It’s frequently part of the scientific process,” Boucher said. “There’re a few lines buried in an old publication, and you think ‘surely somebody has already looked at that,’ but often they haven’t. You need to delve into it.”

Reference: “A record of Late Jurassic vertebrates from Texas” by Steven R. May, Kenneth S. Bader, Lisa D. Boucher, Louis L. Jacobs, Joshua R. Lively, Timothy S. Myers and Michael J. Polcyn, 1 June 2023, Rocky Mountain Geology.

DOI: 10.24872/rmgjournal.58.1.19

The study’s additional co-authors are Kenneth Bader, a laboratory manager at the Jackson School Museum of Earth History; Joshua Lively, the curator of paleontology at Utah State University and a Jackson School alumnus; and Timothy Myers and Michael Polcyn, both researchers at Southern Methodist University.",https://scitechdaily.com/images/Styxosaurus-Plesiosaur.jpg,https://scitechdaily.com/first-ever-jurassic-vertebrate-fossils-discovered-in-texas/,Science
"['Sam Buckberry', 'I Am A Biologist Who Works At The Intersection Of Epigenetics', 'Genomics', 'Bioinformatics', 'Medical Research', 'Public Health.', 'I Currently Lead The Epigenetics Program In Indigenous Genomics At The Telethon Kids Institute. Here', 'My Research Is Focused Using Epigenetics', 'Cutting-Edge Data Analytics To Advance Chronic Disease Prediction', 'Prevention']",2023-08-21 00:00:00,A ‘Memory Wipe’ for Stem Cells May Be the Key to Better Regenerative Therapies,"Stem cells are special kinds of cells in our bodies that can become any other type of cell. They have huge potential for medicine, and trials are currently under way using stem cells to replace damaged cells in diseases like Parkinson’s.

One way to get stem cells is from human embryos, but this has ethical concerns and practical limitations. Another way is to turn adult cells from the skin or elsewhere into what are called “induced pluripotent stem cells” (iPS cells).

However, these cells sometimes carry a “memory” of the kind of cell they used to be, which can make them less predictable or efficient when we try to turn them into other types of cells.

In a study published in Nature, my colleagues and I have found a way to erase this memory, to make iPS cells function more like embryonic stem cells.

Great Promise for Regenerative Medicine

Mature, specialized cells like skin cells can be reprogrammed into iPS cells in the lab. These “blank slate” cells show great promise in regenerative medicine, a field focused on regrowing, repairing, or replacing damaged or diseased cells, organs, or tissues.

Scientists can make iPS cells from a patient’s own tissue, so there’s less risk the new cells will be rejected by the patient’s immune system.

To take one example, iPS cells are being tested for making insulin-producing pancreas cells to help people with diabetes. We’re not there yet, but it’s an example of what might be possible.

Research using iPS cells is a rapidly advancing field, yet many technical challenges remain. Scientists are still figuring out how to better control what cell types iPS cells become and ensure the process is safe.

One of these technical challenges is overcoming “epigenetic memory,” where the iPS cells retain traces of the cell type they once were.

Epigenetic Memory and How It Can Impair the Use of iPS Cells

To understand “epigenetic memory,” let’s first talk about epigenetics. Our DNA carries sequences of instructions known as genes. When various factors influence gene activity (turning them on or off) without changing the DNA sequence itself, this is known as epigenetics—literally meaning “above genetics.”

A cell’s epigenome is a collective term to describe all the epigenetic modifications in a cell. Each of our cells contains the same DNA, but the epigenome controls which genes are turned on or off, and this determines whether it becomes a heart cell, a kidney cell, a liver cell, or any other cell type.

You can think of DNA as a cookbook and the epigenome as a set of bookmarks. The bookmarks don’t alter the recipes, but they direct which ones are used.

Similarly, epigenetic marks guide cells to interpret the genetic code without changing it.

When we reprogram a mature cell into an iPS cell, we want to erase all its “bookmarks.” However, this doesn’t always work completely. When some bookmarks remain, this “epigenetic memory” can influence the behavior of the iPS cells.

An iPS cell made from a skin cell can retain a partial “memory” of being a skin cell, which makes it more likely to turn back into a skin-like cell and less likely to turn into other cell types. This is because some of the DNA’s epigenetic marks can tell the cell to behave like a skin cell.

This can be a hurdle for using iPS cells because it can impact the process of turning iPS cells into the types of cells you want. It might also affect the function of the cells once they’re created. If you want to use iPS cells to help repair a pancreas, but the cells have a “memory” of being skin cells, they might not function as well as true pancreatic cells.

How to Clear iPS Cell Epigenetic Memory and Improve Function

Overcoming the issue of epigenetic memory in iPS cells is a widely recognized challenge for regenerative medicine.

By studying how the epigenome transforms when we reprogram adult skin cells into iPS cells, we discovered a new way to reprogram cells that more completely erases epigenetic memory. We made this discovery by reprogramming cells using a method that imitates how the epigenome of embryo cells is naturally reset.

During the early development of an embryo, before it is implanted into the uterus, the epigenetic marks inherited from the sperm and egg cells are essentially erased. This reset allows the early embryo cells to start fresh and become any cell type as the embryo grows and develops.

By introducing a step during the reprogramming process that briefly mimics this reset process, we made iPS cells that are more like embryonic stem cells than conventional iPS cells.

More effective epigenetic memory erasure in iPS cells will enhance their medical potential. It will allow the iPS cells to behave as “blank slates” like embryonic stem cells, making them more likely to transform into any desired cell type.

If iPS cells can forget their past identities, they can more reliably become any type of cell and help create specific cells needed for therapies, like new insulin-producing cells for someone with diabetes, or neuronal cells for someone with Parkinson’s. It could also reduce the risk of unexpected behaviors or complications when iPS cells are used in medical treatments.

This article is republished from The Conversation under a Creative Commons license. Read the original article.

Image Credit: NIH",https://singularityhub.com/wp-content/uploads/2023/08/colony-of-induced-pluripotent-stem-cells-3.jpeg,https://singularityhub.com/2023/08/21/a-memory-wipe-for-stem-cells-may-be-the-key-to-better-regenerative-therapies/,Science
['Monash University'],2023-08-20 14:15:09-07:00,Scientists Discover “Dynamite” Way To Wipe a Cell’s Memory To Better Reprogram It as a Stem Cell,"A new method to reprogram human cells to better mimic embryonic stem cells.

In a groundbreaking study published on August 16 in the journal Nature, Australian scientists have resolved a long-standing problem in regenerative medicine. They developed a new method to reprogram human cells to better mimic embryonic stem cells, with significant implications for biomedical and therapeutic uses. The team of researchers was led by Professor Ryan Lister from the Harry Perkins Institute of Medical Research and The University of Western Australia and Professor Jose M Polo from Monash University and the University of Adelaide.

History and Challenges of Cell Reprogramming

In a revolutionary advance in the mid-2000s, it was discovered that the non-reproductive adult cells of the body, called ‘somatic’ cells, could be artificially reprogrammed into a state that resembles embryonic stem (ES) cells which have the capacity to then generate any cell of the body.

The transformative ability to artificially reprogram human somatic cells, such as skin cells, into these so-called induced pluripotent stem (iPS) cells provided a way to make an essentially unlimited supply of ES-like cells. This has widespread applications in disease modeling, drug screening, and cell-based therapies.

“However, a persistent problem with the conventional reprogramming process is that iPS cells can retain an epigenetic memory of their original somatic state, as well as other epigenetic abnormalities,” Professor Lister said. “This can create functional differences between the iPS cells and the ES cells they’re supposed to imitate, and specialized cells subsequently derived from them, which limits their use.”

Introducing the TNT Reprogramming Technique

Professor Jose Polo, who is also with the Monash Biomedicine Discovery Institute, explained that they have now developed a new method, called transient-naive-treatment (TNT) reprogramming, that mimics the reset of a cell’s epigenome that happens in very early embryonic development.

“This significantly reduces the differences between iPS cells and ES cells and maximizes the effectiveness of how human iPS cells can be applied,” he said.

Dr. Sam Buckberry, a computational scientist from the Harry Perkins Institute, UWA, and Telethon Kids Institute, and co-first author of the study, said by studying how the somatic cell epigenome changed throughout the reprogramming process, they pinpointed when epigenetic aberrations emerged, and introduced a new epigenome reset step to avoid them and erase the memory.

Dr. Xiaodong Liu, a stem cell scientist who also spearheaded the research said the new human TNT-iPS cells much more closely resembled human ES cells – both molecularly and functionally – than those produced using conventional reprogramming.

Improved Results With TNT Method

Dr. Daniel Poppe, a cell biologist from UWA, the Harry Perkins Institute, and co-first author, said the iPS cells generated using the TNT method differentiated into many other cells, such as neuron progenitors, better than the iPS cells generated with the standard method.

Monash University student and co-first author Jia Tan said the team’s TNT method was dynamite.

“It solves problems associated with conventionally generated iPS cells that if not addressed could have severely detrimental consequences for cell therapies in the long run,” he said.

Future Implications and Research

Professor Polo said that despite their breakthrough, the precise molecular mechanisms underlying the iPS epigenome aberrations and their correction are not fully known. Further research is needed to understand them.

“We predict that TNT reprogramming will establish a new benchmark for cell therapies and biomedical research, and substantially advance their progress,” Professor Lister said.

Reference: “Transient naive reprogramming corrects hiPS cells functionally and epigenetically” by Sam Buckberry, Xiaodong Liu, Daniel Poppe, Jia Ping Tan, Guizhi Sun, Joseph Chen, Trung Viet Nguyen, Alex de Mendoza, Jahnvi Pflueger, Thomas Frazer, Dulce B. Vargas-Landín, Jacob M. Paynter, Nathan Smits, Ning Liu, John F. Ouyang, Fernando J. Rossello, Hun S. Chy, Owen J. L. Rackham, Andrew L. Laslett, James Breen, Geoffrey J. Faulkner, Christian M. Nefzger, Jose M. Polo and Ryan Lister, 16 August 2023, Nature.

DOI: 10.1038/s41586-023-06424-7

The collaborative research project also included researchers from the Australian National University, Westlake University, Queen Mary University of London, Mater Research Institute, University of Queensland, Queensland Brain Institute, South Australian Health & Medical Research Institute, Duke-NUS Medical School, and CSIRO.",https://scitechdaily.com/images/Human-iPS-Cells.jpg,https://scitechdaily.com/scientists-discover-dynamite-way-to-wipe-a-cells-memory-to-better-reprogram-it-as-a-stem-cell/,Science
"['Sam Buckberry', 'The Conversation']",,A 'memory wipe' for stem cells may be the key to better therapies,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Credit: Pixabay/CC0 Public Domain

Stem cells are special kinds of cells in our body that can become any other type of cell. They have huge potential for medicine, and trials are currently under way using stem cells to replace damaged cells in diseases like Parkinson's.

One way to get stem cells is from human embryos, but this has ethical concerns and practical limitations. Another way is to turn adult cells from the skin or elsewhere into what are called ""induced pluripotent stem cells"" (iPS cells).

However, these cells sometimes carry a ""memory"" of the kind of cell they used to be, which can make them less predictable or efficient when we try to turn them into other types of cells.

We have found a way to erase this memory, to make iPS cells function more like embryonic stem cells. Our study is published in Nature.

Great promise for regenerative medicine

Mature, specialized cells like skin cells can be reprogrammed into iPS cells in the lab. These ""blank slate"" cells show great promise in regenerative medicine, a field focused on regrowing, repairing or replacing damaged or diseased cells, organs or tissues.

Scientists can make iPS cells from a patient's own tissue, so there's less risk the new cells will be rejected by the patient's immune system.

To take one example, iPS cells are being tested for making insulin-producing pancreas cells to help people with diabetes. We're not there yet, but it's an example of what might be possible.

Research using iPS cells is a rapidly advancing field, yet many technical challenges remain. Scientists are still figuring out how to better control what cell types iPS cells become and ensure the process is safe.

One of these technical challenges is ""epigenetic memory"", where the iPS cells retain traces of the cell type they once were.

Epigenetic memory and how can it impair the use of iPS cells

To understand ""epigenetic memory"", let's first talk about epigenetics. Our DNA carries sequences of instructions known as genes. When various factors influence gene activity (turning them on or off) without changing the DNA sequence itself, this is known as epigenetics—literally meaning ""above genetics"".

A cell's epigenome is a collective term to describe all the epigenetic modifications in a cell. Each of our cells contains the same DNA, but the epigenome controls which genes are turned on or off, which determines whether it becomes a heart cell, a kidney cell, a liver cell, or any other cell type.

You can think of the DNA as a cookbook and the epigenome as a set of bookmarks. The bookmarks don't alter the recipes, but they direct which ones are used.

Similarly, epigenetic marks guide cells to interpret the genetic code without changing it.

When we reprogram a mature cell into an iPS cell, we want to erase all its ""bookmarks"". However, this doesn't always work completely. When some bookmarks remain, this ""epigenetic memory"" can influence the behavior of the iPS cells.

An iPS cell made from a skin cell can retain a partial ""memory"" of being a skin cell, which makes it more likely to turn back into a skin-like cell and less likely to turn into other cell types. This is because some of the DNA's epigenetic marks can tell the cell to behave like a skin cell.

This can be a hurdle for using iPS cells because it can impact the process of turning iPS cells into the types of cells you want. It might also affect the function of the cells once they're created. If you want to use iPS cells to help repair a pancreas, but the cells have a ""memory"" of being skin cells, they might not function so well as true pancreatic cells.

How we managed to clear iPS cell epigenetic memory and improve their function

Overcoming the issue of epigenetic memory in iPS cells is a widely recognized challenge for regenerative medicine.

By studying how the epigenome transforms when we reprogram adult skin cells into iPS cells, we discovered a new way to reprogram cells that more completely erases epigenetic memory. We made this discovery by reprogramming cells using a method that imitates how the epigenome of embryo cells is naturally reset.

During the early development of an embryo, before it is implanted into the uterus, the epigenetic marks inherited from the sperm and egg cells are essentially erased. This reset allows the early embryo cells to start fresh and become any cell type as the embryo grows and develops.

By introducing a step during the reprogramming process that briefly mimics this reset process, we made iPS cells that are more like embryonic stem cells than conventional iPS cells.

More effective epigenetic memory erasure in iPS cells will enhance their medical potential. It will allow the iPS cells to behave as ""blank slates"" like embryonic stem cells, making them more likely to transform into any desired cell type.

If iPS cells can forget their past identities, they can more reliably become any type of cell and help create specific cells needed for therapies, like new insulin-producing cells for someone with diabetes, or neuronal cells for someone with Parkinson's. It could also reduce the risk of unexpected behaviors or complications when iPS cells are used in medical treatments.

This article is republished from The Conversation under a Creative Commons license. Read the original article.",https://scx2.b-cdn.net/gfx/news/hires/2022/cell-1.jpg,https://medicalxpress.com/news/2023-08-memory-stem-cells-key-therapies.html,Science
"['Deborah Padgett', ""Opgs Task Lead At Nasa'S Jet Propulsion Laboratory"", 'Written Deborah Padgett']",,"Sols 3923-3925: Approaching the Ridgetop – ""Bermuda Triangle"" Ahead! – NASA Mars Exploration","Earth planning date: Friday, August 18, 2023

The Gediz Vallis Ridge has been a long-term, and, at times, seemingly impossible goal of the Curiosity Rover mission. Our path to it has repeatedly been diverted from our first difficult climb onto the Greenhugh Pediment way back in 2020, our dead-end foray onto and across the pediment through a steep side ravine of the Gediz Vallis, ultimately blocked by the potentially wheel-eating “Gatorback” ridges in 2022, and finally to our recent slip-and-slide circuitous climb out of the Marker Band Valley onto the Gedis Vallis ridge itself. The team today called GV Ridge the “Bermuda Triangle” of Mt. Sharp. We are now just a few meters away from being able to reach the arm out and get contact science on some of the ridge material, and anticipation is growing.

The drive on Sol 3921 ended a few meters short of our destination cluster of boulders due to some sideways sliding en-route. The uncertain footing also left our wheels unsafe to support a deployment of Curiosity’s arm, so all of our weekend science activities will be via targeted remote sensing rather than use of the arm’s instruments for more detailed study. Mastcam is taking this opportunity to perform a 360 degree panorama, which should be spectacular! Mastcam will also have large mosaics targeted at the transition between the dark “float” rock ridge material and the underlying sulfate-bearing bedrock, as well as multispectral imaging of the nearby “Skiathos” and “Skopelos” boulders. ChemCam will zap those same rocks with its laser to study a possible surface coating and compositional variations between rock layers. ChemCam will also use the telescopic mode of its RMI camera to zoom in on a light colored bedrock wall adjacent to a basin of dark sand and to continue its characterization of the amazing layering on Kukenan Butte. Meanwhile, Navcam will take some dust devil movies and a measurement of dust in the air across Gale Crater, as well as imaging of clouds and their shadows on the beautiful peaks around us.

Another short 2 m drive, which the team calls a “bump,” will finally place Curiosity within arm’s reach of the boulder collection on Sol 3924. Following our usual set of post-drive observations, Curiosity will perform AEGIS and MARDI imaging on Sol 3925 to further document the geology of our new location. We end the plan in the early morning of Sol 3926 with a set of atmospheric observations, including a dust measurement and a Navcam 360 phase function sky survey.

With Monday’s plan, Curiosity will hopefully be able to finally perform contact science on a diverse cluster of GV Ridge boulders, presuming that our drive is successful and doesn’t leave our wheels perched on any of the abundant rocks on this steep slope. Another remaining challenge is a very tiny decisional downlink on Monday, giving us very little data to decide on our next steps. In addition, on Monday, JPL is in the bullseye of the very first tropical storm watch to ever be posted in Southern California by the National Hurricane Center. Fingers crossed that the “GV Ridge Triangle” will not claim another MSL plan before Curiosity reaches the top!",https://mars.nasa.gov/system/news_items/main_images/9465_msl-raw-image-web.jpg,https://mars.nasa.gov/msl/mission-updates/9465/sols-3923-3925-approaching-the-ridgetop-bermuda-triangle-ahead,Science
"['University Of Science', 'Technology Of China']",,Study discovers tunable van Hove singularity without structural instability,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Evolution of CsTi 3 Bi 5 electronic structure with Cs doping. Credit: Physical Review Letters (2023). DOI: 10.1103/PhysRevLett.131.026701

A team led by Prof. He Junfeng from University of Science and Technology of China (USTC) of the Chinese Academy of Sciences (CAS), together with domestic and international collaborators, discovered that the energy level of the van Hove singularity (VHS) in the novel Ti-based kagome metal CsTi 3 Bi 5 can be tuned without lattice structural instability. Their work was published in Physical Review Letters on July 12 as the cover article.

In kagome metal, the electronic instabilities provided by VHS usually coexist with lattice structural instabilities, making it difficult to distinguish the effect of different instabilities on charge density waves (CDW).

To understand the effect of different instabilities on CDW, the team conducted research on the novel Ti-based kagome metal CsTi 3 Bi 5 . CsTi 3 Bi 5 has the same lattice structure as AV 3 Sb 5 (A=K, Rb, Cs) but does not have charge density wave states.

The team first studied the electronic structure of CsTi 3 Bi 5 using high-resolution angle-resolved photoemission spectroscopy and found it in good agreement with the results of first-principles calculations. The energy position of the VHS in pristine CsTi 3 Bi 5 was well above the Fermi level and cannot bring about electronic instability. First-principles calculations and low-temperature X-ray diffraction measurements showed no lattice instability in CsTi 3 Bi 5 .

Researchers went on to find that electrons can be introduced by Cs surface doping, enabling the modulation of the VHS in CsTi 3 Bi 5 in a wide energy range. When the VHS approaches Fermi level, it can generate electronic instabilities. At the same time, first-principles calculations showed no lattice structural instability in CsTi 3 Bi 5 after electron doping. In this way, the team realized the decoupling of the two instabilities. CsTi 3 Bi 5 can be a unique platform where the electronic instabilities can be modulated solely without being affected by the structural instabilities.

The researchers also found that even if the VHS is tuned to introduce electronic instability near the Fermi energy level, it still can't generate the energy gap in CDW in CsTi 3 Bi 5 . Thus, the electronic instability itself can't generate charge density waves in CsTi 3 Bi 5 .

First-principles calculations further showed that during the evolution from CsV 3 Sb 5 to CsTi 3 Bi 5 , the appearance of CDW directly corresponds to the change in the total energy of the system. CDW phase transition occurs only when the corresponding crystal structure has the lowest total energy. Therefore, lattice structural instability plays an important role in CDW phase transition in kagome metals.

This work is instructive for the further understanding of the effects of electronic instability and lattice structural instability on CDW in kagome metals.

More information: Bo Liu et al, Tunable Van Hove Singularity without Structural Instability in Kagome Metal CsTi3Bi5, Physical Review Letters (2023). DOI: 10.1103/PhysRevLett.131.026701 Journal information: Physical Review Letters

Provided by University of Science and Technology of China",https://scx2.b-cdn.net/gfx/news/2023/researchers-reveal-tun.jpg,https://phys.org/news/2023-08-tunable-van-hove-singularity-instability.html,Science
[],,Van Hove Singularity Uncovered in Kagome Superconductor,"A team led by Prof. HE Junfeng from University of Science and Technology of China (USTC) of the Chinese Academy of Sciences (CAS), in collaboration with Academician GAO Hongjun's team from CAS and other domestic and international research teams, discovered the van Hove singularity (VHS) at Fermi level in kagome superconductors, and revealed its relationship with superconductivity. Their work was published in Nature Communications on June 28th.

VHS is a saddle point connecting electron-like and hole-like energy bands which can generate divergent electron density of states. On the one hand, the luge electron density of states near VHS can cause strong instability in the electronic structure. On the other hand, hole-like and electron-like conduction can coexist at VHS, giving rise to unconventional electronic pairing.

However, in reality, VHS tend to deviate from the Fermi level of the material, resulting in very little effect on the low-energy states of the material. Therefore, it is important to find the suitable kagome material to explore the effect of VHS on superconductivity.

The researchers investigated Ta-doped CsV 3 Sb 5 samples, and the use of Ta atoms instead of V atoms can increase the superconducting transition temperature from 2.5 K in CsV 3 Sb 5 to 5.5 K in CsV 3-x Ta x Sb 5 (x~0.4). Angle-resolved photoemission spectroscopy was used to investigate the electronic structures of both CsV 3 Sb 5 and Ta-doped CsV 3-x Ta x Sb 5 samples.

The results showed that the VHS in CsV 3 Sb 5 lies below the Fermi level before entering the superconducting state due to the reconfiguration of energy bands by the electron density wave and contributes almost nothing to superconductivity, whereas in CsV 3-x Ta x Sb 5 , the VHS is located exactly at the Fermi level, in agreement with first-principles calculations. Further experiments demonstrated that there is a strong correlation between the superconducting transition temperature and the energy position of the VHS relative to the Fermi energy level, revealing the feasibility of VHS-enhanced superconductivity in kagome superconductors.

In addition, the researchers found that the superconducting state in CsV 3-x Ta x Sb 5 has significantly different characteristics from the superconducting state in CsV 3 Sb 5 through scanning tunneling microscopy experiments, indicating the possibility of unconventional pairing superconductivity in the van Hove scenario.",https://cdn1.miragenews.com/tmp_cache?cdn=images.unsplash.com/photo-1578496479939-722d9dd1cc5b?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=750&q=80,https://www.miragenews.com/van-hove-singularity-uncovered-in-kagome-1069777/,Science
"['University Of Science', 'Technology Of China']",,Researchers reveal van Hove singularity at Fermi level in kagome superconductor,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

The existence of VHS perfectly aligned with the Fermi level in CsV 2.6 Ta 0.4 Sb 5 . a Photoelectron intensity plot along Γ-K-M-Γ of CsV 2.6 Ta 0.4 Sb 5 measured with 21.2 eV photons at 200 K. This photon energy probes the electronic structure in the Γ-K-M plane of the 3D BZ . The red dashed lines are a guide for the eye. b EDCs near M point extracted from the photoemission raw spectrum in the momentum region marked by the blue arrow in (a). c Same as the raw EDCs in (b), but symmetrized to show the absence of an energy gap. d EDCs near M point extracted from the photoemission raw spectrum in the momentum region marked by the yellow arrow in (a). The red triangles and circles in (b), (d) indicate the EDC peaks. e Band dispersion near K and M points (along the Γ-K-M-Γ direction) extracted from the EDC peaks measured at 200 K (red empty circles) and 25 K (magenta solid circles), respectively. f Extracted band dispersion of CsV 2.6 Ta 0.4 Sb 5 and CsV 3 Sb 5 in the momentum region near M, indicated by the black dotted box in (e). The error bars in (e) and (f) represent the uncertainties in the determination of EDC peak positions. g Superconducting T c (right axis) and superconducting gap (left axis) as a function of the energy position of the VHS in doped CsV 3 Sb 5 samples . The error bars in (g) represent the uncertainties in the determination of the VHS (bottom axis), superconducting T c (right axis), and superconducting gap (left axis). Credit: Nature Communications (2023). DOI: 10.1038/s41467-023-39500-7

A team led by Prof. He Junfeng from University of Science and Technology of China (USTC) of the Chinese Academy of Sciences (CAS), in collaboration with Academician Gao Hongjun's team from CAS and other domestic and international research teams, has discovered the van Hove singularity (VHS) at Fermi level in kagome superconductors and revealed its relationship with superconductivity. Their work was published in Nature Communications on June 28.

VHS is a saddle point connecting electron-like and hole-like energy bands that can generate divergent electron density of states. On the one hand, the luge electron density of states near VHS can cause strong instability in the electronic structure. On the other hand, hole-like and electron-like conduction can coexist at VHS, giving rise to unconventional electronic pairing.

However, in reality, VHS tends to deviate from the Fermi level of the material, resulting in very little effect on the low-energy states of the material. Therefore, it is important to find the suitable kagome material to explore the effect of VHS on superconductivity.

The researchers investigated Ta-doped CsV 3 Sb 5 samples, and the use of Ta atoms instead of V atoms can increase the superconducting transition temperature from 2.5 K in CsV 3 Sb 5 to 5.5 K in CsV 3-x Ta x Sb 5 (x~0.4). Angle-resolved photoemission spectroscopy was used to investigate the electronic structures of both CsV 3 Sb 5 and Ta-doped CsV 3-x Ta x Sb 5 samples.

The results showed that the VHS in CsV 3 Sb 5 lies below the Fermi level before entering the superconducting state due to the reconfiguration of energy bands by the electron density wave and contributes almost nothing to superconductivity, whereas in CsV 3-x Ta x Sb 5 , the VHS is located exactly at the Fermi level, in agreement with first-principles calculations.

Further experiments demonstrated that there is a strong correlation between the superconducting transition temperature and the energy position of the VHS relative to the Fermi energy level, revealing the feasibility of VHS-enhanced superconductivity in kagome superconductors.

In addition, the researchers found that the superconducting state in CsV 3-x Ta x Sb 5 has significantly different characteristics from the superconducting state in CsV 3 Sb 5 through scanning tunneling microscopy experiments, indicating the possibility of unconventional pairing superconductivity in the van Hove scenario.

More information: Yang Luo et al, A unique van Hove singularity in kagome superconductor CsV3-xTaxSb5 with enhanced superconductivity, Nature Communications (2023). DOI: 10.1038/s41467-023-39500-7 Journal information: Nature Communications

Provided by University of Science and Technology of China",https://scx2.b-cdn.net/gfx/news/2023/researchers-reveal-van.jpg,https://phys.org/news/2023-08-reveal-van-hove-singularity-fermi.html,Science
['News Staff'],2023-08-21 19:57:32+00:00,Triassic Apex Predator Had Much Weaker Bite than Previously Thought,"Saurosuchus galilei, a large loricatan pseudosuchian archosaur that lived in South America 230 million years ago (Late Triassic epoch), was thought to be an apex predator due to its size and diet, standing at between 5-8 m (16-26 feet) in length and weighing over 250 kg. However, the new analysis of Saurosuchus galilei’s skull and comparisons with the later well-known dinosaur Allosaurus found that despite their similar skull strengths, Saurosuchus galilei had a much weaker bite than the dinosaurs that followed it. Saurosuchus galilei would have had a bite with the force of 1015-1885 N, equivalent to modern crocodiles called gharials (for comparison, Allosaurus had a bite force of 3,572 N; saltwater crocodiles have a bite force of 16,000 N; Tyrannosaurus rex: 17,000-35,000 N).

“We found that Saurosuchus galilei actually had an incredibly weak bite for its size and thus predated animals in very different ways compared to later evolving dinosaurs,” said University of Birmingham vertebrate paleobiologist Dr. Jordan Bestwick.

“In fact, despite being one of the bigger lizards and an apex predator, Saurosuchus galilei had a bite that was on a par with the relatively measly bite of the gharial, and much less powerful than more fearsome crocs and alligators around today.”

“You would still have liked to leave Saurosuchus galilei well alone, but they likely fed only on the soft fleshy bits of their kills as their bite wouldn’t have enabled them to crunch up bones.”

Despite their relative size, Saurosuchus galilei would have been a careful diner that used their back teeth to remove the flesh from their kills.

In contrast to later dinosaurs, the feeding behavior of Saurosuchus galilei is likely due to a weak bite and a more rectangular skull shape.

Also these earlier reptiles had thinner bones in their noses compared to the later Allosaurus.

“Saurosuchus galilei would certainly have been a fearsome reptile until it sat down to eat its prey, and we can see how evolutionary details in the skulls of these massive apex predators necessitated significant differences in eating behavior,” said University of Birmingham paleobiologist Dr. Stephan Lautenschlager.

“While dinosaurs that followed in the Jurassic period would have eaten the vast majority of their kills, Saurosuchus galilei may have left more complete carcasses, which would have provided a secondary meal for carrion-feeding animals too.”

“It is truly amazing how similar the skulls of top predators in the Triassic period (the time before the domination of the dinosaurs) look compared to the well-known carnivorous dinosaurs such as Tyrannosaurus rex,” said University of Birmingham paleontologist Molly Fawcett.

“However, unexpectedly we found that the bite power of these Triassic predators were far weaker compared to the post-Triassic dinosaurs.”

The study was published in The Anatomical Record.

_____

Molly J. Fawcett et al. Functional morphology of the Triassic apex predator Saurosuchus galilei (Pseudosuchia: Loricata) and convergence with a post-Triassic theropod dinosaur. The Anatomical Record, published online August 16, 2023; doi: 10.1002/ar.25299",https://cdn.sci.news/images/2023/08/image_12197-Saurosuchus-galilei.jpg,https://www.sci.news/paleontology/saurosuchus-galilei-bite-12197.html,Science
[],2023-08-22 09:12:46+00:00,What next for ISRO after Chandrayaan-3 mission?,"August 22, 2023 02:42 pm | Updated 02:42 pm IST - Bengaluru

A mission to study the Sun, and launching a climate observation satellite, a test vehicle as part of Gaganyaan human space flight programme and an Indo-US synthetic aperture radar — ISRO has a packed schedule following the highly anticipated landing of Chandrayaan-3 Lander.

In addition, XPoSat (X-ray Polarimeter Satellite), the country's first dedicated polarimetry mission to study various dynamics of bright astronomical X-ray sources in extreme conditions, is also ready for launch, an ISRO official said on Tuesday.

Aditya-L1, the first space-based Indian observatory to study the Sun, is getting ready for the launch, most likely in September first week.

According to ISRO Chairman, Somanath S, the space agency has also lined up the launch of a climate observation satellite INSAT-3DS.

The launch of a test vehicle mission, for the validation of the crew escape system for Gaganyaan, the country's maiden human space flight mission, is also expected soon.

NISAR

""(Then) we have to launch NISAR, the India-U.S. built Synthetic Aperture Radar,"" Mr. Somanath said in his independence day address at ISRO headquarters here on August 15. ""So, our hands are full.""

""We are going to build a large number of satellites for our security purpose as well in the coming days,"" Mr. Somanath had said.

According to ISRO officials, NASA-ISRO SAR (NISAR) is a Low Earth Orbit (LEO) observatory being jointly developed by U.S. space agency NASA and ISRO.

NISAR will map the entire globe in 12 days and provide spatially and temporally consistent data for understanding changes in Earth's ecosystems, ice mass, vegetation biomass, sea level rise, ground water and natural hazards including earthquakes, tsunamis, volcanoes and landslides, they said.

""It carries L and S dual band Synthetic Aperture Radar (SAR), which operates with Sweep SAR technique to achieve large swath with high resolution data. The SAR payloads mounted on Integrated Radar Instrument Structure (IRIS) and the spacecraft bus are together called an observatory"", an ISRO official noted.

Unmanned missions ahead of Gaganyaan

Before undertaking the Gaganyaan human space (manned) flight mission, ISRO has planned two unmanned missions.

""We are getting ready for the (first of the two) unmanned crew module mission by the beginning of next year"", an ISRO official said.

The objective of the Gaganyaan mission is to demonstrate the capability of conducting human space flight mission to LEO on-board Indian Launch vehicle. The Orbital module consists of a Crew module and a Service module.

Crew module, which is a pressurised module, acts as living quarters for the crew. The orbital module will be positioned in approximately 400 km circular orbit around earth for one to 3 days and the crew module will return at the designated location at sea.",https://th-i.thgim.com/public/incoming/r0a8f2/article67141506.ece/alternates/LANDSCAPE_1200/IMG_ISRO_s_PSLV-C56_DS-S_2_1_5LBI7UNM.jpg,https://www.thehindu.com/sci-tech/science/what-next-for-isro-after-chandrayaan-3-mission/article67222472.ece,Science
['Dan Robinson'],2023-08-22 00:00:00,Student project shows sails can de-orbit satellites quickly,"A prototype satellite built to test a deployable drag sail to de-orbit satellites appears to have fulfilled its purpose, burning up on re-entry earlier this month after spending just 445 days in orbit.

SBUDNIC, an acronym chosen to be a play on ""Sputnik,"" was put together by students at Brown University, Rhode Island, using low-cost off-the-shelf commercial components. The CubeSat design featured a drag sail made from Kapton polyimide film, and with structural supports of thin aluminum tubing, which deployed once the satellite was in orbit.

The project was intended to demonstrate a potential solution to the problem of low Earth orbit becoming a graveyard for more and more defunct satellites that have reached the end of their life, as The Register detailed previously. If proved successful, the idea is that future satellites could incorporate a similar mechanism to help de-orbit them at the end of their life span.

SBUDNIC was sent up aboard the SpaceX Transporter 5 launch in May last year as part of a payload comprising a number of other small satellites. Its sail ""popped open like an umbrella"" at a height of about 520 kilometers above the Earth's surface, according to the project team, to create drag and cause its orbit to decay.

The project appears to have been successful in this respect, according to tracking data the team obtained from US Space Command. It indicated that SBUDNIC was about 470 kilometers (292 miles) above the Earth in early March, while other comparably sized satellites deployed to a similar orbit as part of the same mission were still at altitudes of 500 kilometers (310 miles) or more.

The decay of the CubeSat's orbit accelerated as it dropped lower, such that its last known altitude was just 146 kilometers (90 miles) on August 8, shortly after which it is assumed to have been destroyed by burning up in the atmosphere.

Previous predictions had suggested that the drag device would reduce the orbital lifetime of SBUDNIC from over 20 years to as few as 6.5 years, but in reality it was brought down in about a year and a quarter.

""We were trying to prove that there are ways of de-orbiting space junk after mission life has ended that are not super costly,"" said Selia Jindal, one of the project leads who graduated from Brown University this year. ""This showed that we can do that. We were successfully able to de-orbit our satellite so that it's no longer taking up space in Earth's orbit.""

The sail concept is orders of magnitude less costly than rival ideas for tackling orbital junk such as space tow trucks or nets to capture the junk and pull it out of orbit, according to Dheraj Ganjikunta, SBUDNIC's lead program manager who graduated last year.

""Rather than taking junk out of space after it becomes a problem, we have this $30 drag device you can just throw onto satellites and radically reduce how long they're in space,"" Ganjikunta said.

Of course, this requires future satellites to be designed to have a similar mechanism built in, and so does not help to address existing space junk, but every little presumably helps.

SBUDNIC was a 3U CubeSat, meaning it was effectively the size of three 10cm cubes combined. It was based around a $10 Arduino system plus 65 AA lithium batteries and included a variety of 3D-printed parts produced with consumer-grade printers. ®",https://regmedia.co.uk/2019/01/16/burn_shutterstock.jpg,https://www.theregister.com/2023/08/22/student_satellite_sail_project/,Science
"['Frid Kvalpskarmo Hansen', 'Norwegian University Of Science']",,Rare Stone Age discovery in mid-Norway,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Flint objects with completely straight and parallel side edges told archaeologists that what they had found was extra exciting. Credit: Silje Elisabeth Fretheim

When archaeologists recently carried out an excavation at Vinjeøra in southern Trøndelag County, they made a surprising discovery that they had only dreamed of finding.

Archaeologist and Project Manager Silje Elisabeth Fretheim made a bold claim: She said she would eat her hard hat if the settlement they were excavating at Vinjeøra wasn't a Stone Age discovery from some of the first people to settle along the Norwegian coast, around 11,500 to 10,000 years ago.

The first discoveries to make it to the surface seemed very promising, large pieces of flint that were highly reminiscent of early, pioneer settlements.

However, it soon became clear that Silje would be closer to eating her hard hat than expected. What they had found was something else entirely and much more exciting.

The people from the east

When the excavations in Vinjeøra got under way properly, the researchers suddenly discovered artifacts that looked nothing like would be expected from a pioneer settlement, but had completely different characteristics.

""We found small and medium-sized flint objects that we refer to as lithics and microlithics. Several had sharp edges that were so straight and parallel that they could have been made using a ruler,"" says Fretheim, an archaeologist at the NTNU University Museum.

""We also came across a conical lithic core and there was little doubt that we had discovered a different type of stone technology than we associate with pioneer culture,"" she said.

Instead, the researchers found evidence from people who came to Finnmark from the east around 9000 BC.

Archaeologists don't just dig with a shovel. Here, the top layer of soil in the excavation area is removed before the ""fine digging"" begins. Credit: Silje Elisabeth Fretheim

Two waves of migration

The ice remained the longest in Scandinavia compared to the rest of Europe during the last Ice Age. The Norwegian coast only became free of ice around 12,500 years ago. The first people arrived in what we now know as Norway and Sweden about 1,000 years later.

Skeletal analyses have previously shown that Scandinavia experienced two major waves of migration in the time after the ice had started to retreat. The first came from the southwest. It was made up of people who had lived in modern-day Spain and Portugal during the last Ice Age and who later moved north as the ice melted away. They were blue-eyed, but their skin was darker than today's Scandinavians.

""They populated the entire Norwegian coast up to Finnmark in just a few centuries,"" Fretheim explains.

A thousand years later, there was another major wave of migration, this time from the northeast. These were people who had traveled from areas around the Black Sea or Ukraine, heading north through Russia and Finland to the coast of Finnmark. They had lighter skin and their eye colors varied.

They had their own technique for creating stone tools, which clearly differed from the techniques used by the migrants from the south. This technique eventually took over and became dominant.

""It looks as though the two cultures met and both had something teach the other. The people from the east brought new technology, while the people from the south knew the landscape and way of life along the coast, which must have been unknown to the people who arrived from the inland areas to the east,"" Fretheim says.

It appears that the people from the east absorbed the lifestyle of those who were already here and, during the early centuries, they lived a nomadic life in lightweight housing structures, perhaps tents. Their food came from the sea and boats were likely key, just as they were for the pioneers from the south.

""DNA studies also show that the two groups mixed,"" Fretheim said.

This is a type of stone hammer, a tool flint smiths used to shape tools. The technique used by the eastern immigrants was quite difficult. It’s something you have to be trained in, it’s not something you can copy just by looking at a tool, Fretheim said. Credit: Silje Elisabeth Fretheim

An unusual find

So why is it so exciting to discover artifacts from the eastern wave of immigrants?

""While we have found lots of artifacts from southern migrants—the pioneer culture —along the outer coast of Central Norway to south of Trondheim Fjord, there have been virtually no discoveries in that region that can be confidently traced back to the earliest migrants from the east,"" Fretheim says.

""One exception is a small settlement near Foldsjøen in Malvik, which was excavated in the 1980s,"" Fretheim said.

There is nothing mysterious about the lack of evidence from the eastern immigrants on the outer coast. Changes in sea level in the centuries that followed the Ice Age mean that most of the evidence of settlers along western coast of Norway during the 8500–7000 BC period have disappeared, washed away, eroded or buried in beach sediment.

""For this reason, there are very few discoveries from these people to be made between Finnmark and Eastern Norway,"" Fretheim says.

""Deep in the fjords, however, the uplift progressed differently and settlements here were consequently preserved,"" she said.

However, the archaeologists can't decide on their own where to excavate, so they haven't been able to focus their search for settlements from the people from the east. The reason for this is that archaeological excavations are usually carried out in connection with new infrastructure or buildings. This excavation, for example, is being carried out because the Norwegian Public Roads Administration is developing the new E39 road through Vinjeøra.

""We have dreamed of finding this for a long time and we were dealt a perfect hand here,"" Fretheim said.

This map shows what the sea level—and shoreline—was like 10,200 years ago. The red ring shows the excavation area at Skardbekken. Credit: Silje Elisabeth Fretheim

Hard hat for dinner?

This author takes her responsibilities as a journalist seriously, so I had to put Fretheim on the spot. Will she have to eat her hard hat?

""We are currently dating the settlement as being around 10,200 to 10,300 years old, based on the local beach displacement curve. So I have narrowly avoided having to eat my hard hat, even though the settlement turned out to be something other than what I first thought,"" she said.",https://scx2.b-cdn.net/gfx/news/2023/rare-stone-age-discove.jpg,https://phys.org/news/2023-08-rare-stone-age-discovery-mid-norway.html,Science
"['Posted By', 'View Articles']",2023-08-22 12:21:49+00:00,NASA is ‘all eyes’ on the ice giants … and you can help!,"Are you an amateur astronomer? Would you like to help NASA with one of its deep space missions? Well now’s your chance! The New Horizons spacecraft is now in the outer fringes of the solar system, much farther than Pluto. But in September, it will look back to observe the two ice giants, Uranus and Neptune. The Hubble Space Telescope will help out, too. And as NASA announced earlier this month, you can observe these distant worlds at the same time and share your images with the mission team and on social media.

Looking back at the ice giants

New Horizons is in the Kuiper Belt, more than five billion miles (eight billion km) from Earth. That is even farther away than Pluto, which the spacecraft flew past and studied in 2015. From that vantage point, New Horizons will look back toward the solar system. For these observations, all eyes will be on Uranus and Neptune. Mission scientists say that by looking at them “from behind,” New Horizons can observe them in a way that we never can on Earth. The images and other data will provide new insight into the atmospheres of the two giant worlds. And indeed they are two different and unique worlds, despite looking superficially similar.

The observations will help provide new details about both the planets’ atmospheres themselves and how heat is transferred from the their cores to the deep atmospheres that envelope those cores.

Amateur astronomers needed

New Horizons and Hubble will be able to study a lot of details in the planets’ atmospheres. But NASA also wants help from amateur astronomers. They can supplement the observations in ways that New Horizons and Hubble cannot do.

Alan Stern is the New Horizons principal investigator from the Southwest Research Institute (SwRI) in Boulder, Colorado. He stated:

By combining the information New Horizons collects in space with data from telescopes on Earth, we can supplement and even strengthen our models to uncover the mysteries swirling in the atmospheres of Uranus and Neptune. Even from amateur astronomer telescopes as small as 16 inches, these complementary observations can be extremely important.

In particular, the astronomers can help track bright features in the planets’ atmospheres. And they can do that for longer periods of time.

Later, you can post your images on X (formerly Twitter) and Facebook. You can include details such as time and date and what filter passbands you used. Be sure to include the hashtag #NHIceGiants in your posts. That way, the New Horizons mission team can collect the images as part of the campaign.

More information available soon

NASA says that additional details about the campaign will be posted soon, including website URL, finder charts and observation tables.

As for New Horizons and Hubble, those images will be publicly available later this year. The Hubble images will be posted in late September on the Mikulski Archive for Space Telescopes (MAST) website. The New Horizons images will be published separately by the end of 2023.

Previous images from Hubble in 2019 showed bright and dark storms on both planets. And in a new study of images from the past 30 years from Hubble and the W.M. Keck Observatory, scientists have found that Neptune’s clouds have almost completely disappeared. They are expected to reappear over the next few years, however. It will be interesting to see what New Horizons and Hubble see next month!

Bottom line: NASA’s New Horizons spacecraft and Hubble Space Telescope will turn their eyes to the ice giants – Uranus and Neptune – in September. And NASA wants your help!

Via NASA

Read more: Why Neptune and Uranus are different

Read more: New Hubble images show storms on Uranus and Neptune",https://earthsky.org/upl/2023/08/Uranus-Neptune-Voyager-2-1986-1989.jpg,https://earthsky.org/space/ice-giants-uranus-neptune-new-horizons-amateur-astronomers/,Science
"['Kantaro Komiya Rocky Swift', 'Kantaro Komiya', 'Rocky Swift', 'Thomson Reuters', ""Kantaro Writes About Everything Japan'S Economic Indicators To North Korea'S Missiles To Global Regulation On Ai Companies. His Previous Stories Have Been Published In The Associated Press"", 'Bloomberg', 'The Japan Times', 'Rest Of World. A Tokyo Native', 'Kantaro Graduated Depauw University In The United States', 'Was The Recipient Of The Overseas Press Club Foundation Scholar Award.']",2023-08-28 00:00:00,Japan suspends H-IIA rocket launch for moonshot because of strong winds,"H-IIA launch vehicle number 47 is seen on the launching pad at Tanegashima Space Center on the southwestern island of Tanegashima, Japan in this photo taken by Kyodo on August 28, 2023. Kyodo/via REUTERS Acquire Licensing Rights

Summary

Companies Launch operator MHI suspends launch because of high-altitude winds

New launch date to be decided, but will be no sooner than Aug. 31 -MHI

Moon lander SLIM on board to defy Japan's recent space development setbacks

TOKYO, Aug 28 (Reuters) - Japan's space agency suspended a planned launch on Monday of a rocket carrying what would be the country's first spacecraft to land on the moon, with operator Mitsubishi Heavy Industries (MHI) (7011.T) citing high winds.

Although the H-IIA rocket, the Japanese flagship launch vehicle, has a 98% launch success rate, unsuitable wind conditions in the upper atmosphere forced a suspension 27 minutes before the planned liftoff.

""High-altitude winds hit our constraint for a launch... which had been set to ensure no impact from debris falling outside of pre-warned areas,"" said MHI H-IIA launch unit chief Tatsuru Tokunaga.

Strong winds of nearly 108 kph (67 mph) were observed at an altitude of 5,000-15,000 metres (16400-49200 ft), Japan Aerospace Exploration Agency (JAXA) safety manager Michio Kawakami said. Multiple typhoons around Japan could have affected the wind conditions, he added.

The new launch date has not been decided, but will be no sooner than Thursday because of necessary processes such as re-fuelling, Tokunaga said. MHI and JAXA have said a launch could take place as late as Sept. 15.

The rocket was to be launched from JAXA's Tanegashima Space Center in southern Japan on Monday morning; it had already been postponed twice since last week because of bad weather. It will mark the 47th H-IIA Japan has launched.

'MOON SNIPER' MISSION

The rocket is carrying JAXA's Smart Lander for Investigating Moon (SLIM), which would be the first Japanese spacecraft to land on the moon. Tokyo-based startup ispace's (9348.T) Hakuto-R Mission 1 lander crashed on the lunar surface in April.

JAXA was planning to start SLIM's landing from lunar orbit in January-February 2024 after Monday's launch, aiming to follow the success of India's Chandrayaan-3 moon exploration mission this month.

Dubbed the ""moon sniper"", the SLIM mission seeks to achieve a high-precision landing within 100 metres of its target on the moon's surface - a technological leap from conventional lunar-landing accuracy of several kilometres, according to JAXA.

The rocket is also carrying an X-Ray Imaging and Spectroscopy Mission (XRISM) satellite, a joint project of JAXA, NASA and the European Space Agency.

H-IIA, jointly developed by JAXA and MHI, has been Japan's flagship space launch vehicle, with 45 successful launches in 46 tries since 2001. However, after JAXA's new medium-lift H3 rocket failed on its debut in March, the agency postponed the launch of H-IIA No. 47 for several months to investigate the cause.

Despite its goal to send astronauts on the lunar surface in the late 2020s, Japan's space missions have faced recent setbacks, with the launch failure of the Epsilon small rocket in October 2022, followed by an engine explosion during a test last month.

(This story has been refiled to restore deleted 'a' in paragraph 1)

Reporting by Kantaro Komiya and Rocky Swift; Editing by Kim Coghill and Gerry Doyle

Our Standards: The Thomson Reuters Trust Principles.",https://www.reuters.com/resizer/bqJDlo-G_7b9QmF9L4Gr3Obce4U=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/NY4XDCEQLZN53P34OXCSVUSL5M.jpg,https://www.reuters.com/technology/space/japan-space-agency-suspends-launch-attempt-rocket-carrying-moon-lander-2023-08-28/,Science
"['Joe Rao', 'Skywatching Columnist', 'Social Links Navigation']",2023-08-28 10:00:01+00:00,"August's Blue Moon, the biggest full moon of 2023, rises this week","On Wednesday, Aug. 30, you'll no doubt hear the mainstream media proclaiming that on that night we will have an opportunity to witness a ""supermoon."" It's a term, or more specifically, a branding, of relatively recent origin. It originated not from astronomy, but astrology; first coined by an astrologer, who arbitrarily defined it as ""a full moon which occurs with the moon at or near (within 90-percent of) its closest approach to Earth in a given orbit (perigee).""

Indeed, at 12 noon ET on that fifth Wednesday of August, the moon will arrive at perigee, its closest point in its orbit relative to Earth at 221,942 miles (357,181 km) away. And 9 hours and 36 minutes later, the moon will officially turn full. Although a full moon theoretically lasts just a moment, that moment is imperceptible to ordinary observation, and for a day or so before and after, most will speak of seeing the nearly full moon as ""full"": The shaded strip is so narrow, and changing in apparent width so slowly, that it is hard for the naked eye to tell whether it's present or which side it is.

And in addition to its ""supermoon"" status, this particular full moon will be the second to occur in the month of August, the first having occurred on Aug. 1. As a result, the second full moon of August on the 30th, will be also branded as a ""Blue"" moon. So, for what it's worth, what we'll have will be a ""Super Blue Moon.""

However, unless there is some unusual atmospheric condition present such as airborne dust, ash or smoke, the moon will not appear blue but its normal yellow-white self. Nonetheless, thanks to mainstream media hyperbole, many will likely look forward to getting a view of this big late summer moon.

Related: Full moon calendar 2023: When to see the next full moon

TOP TELESCOPE PICK: (Image credit: Celestron) Want to see the moon up close? We recommend the Celestron Astro Fi 102 as the top pick in our best beginner's telescope guide.

If you are hoping to catch a look at the full moon, our guide to the best binoculars could help you find some nice wide-angle optics for taking in larger areas of the lunar surface. Or, if you want to take a closer look at the features of the moon, our guide to the best telescopes can help you find the gear you need.

And if you're looking to take photos of our natural satellite or the night sky in general, check out our guide on how to photograph the moon, as well as our best cameras for astrophotography and best lenses for astrophotography.

This flood's for you

But there is also a drawback: A full moon nearly coinciding with perigee means that for several days around Aug. 30, the range of tides will be much larger than normal; low tides will be unusually low while high tides will run unusually high, perhaps even resulting in minor coastal flooding.

Such an extreme tide is known as a perigean spring tide, the word spring being derived from the German springen — to ""spring up,"" and is not — as is often mistaken — a reference to the spring season. Every month, spring tides occur when the moon is full and new. At these times the moon and the sun form a line with the Earth, so their tidal effects add together. (The sun exerts a little less than half the tidal force of the moon.) ""Neap tides,"" on the other hand, occur when the moon is at first and last quarter and works at cross-purposes with the sun. At these times tides are weak.

Tidal force varies as the inverse cube of an object's distance. On Wednesday the moon is 14 percent closer at perigee than at apogee. Therefore, it exerts 48 percent more tidal force during the spring tides of Aug. 30 than the spring tides near apogee two weeks earlier on Aug. 16.

And if a significant storm or a hurricane is offshore, working in concert with the already high-water levels, the consequences could lead to rough seas, beach erosion and major flooding.

We can only hope that such meteorological conditions do not materialize this year, though it should be pointed out that the traditional peak of the Atlantic hurricane season comes less than two weeks later, on Sept. 10.

Supermoon branding ""watered down""

For years, astronomers classified a full moon that coincided with perigee as a ""perigean full moon."" A term that received little or no fanfare.

Now, it seems that every time a full moon coincides with perigee, it is referred to as a ""supermoon."" Some newscasters — in an apparent effort to hold your attention — refer to this occurrence as ""rare,"" even though, in actuality, the moon turning full within hours of it arriving at perigee is not really such a rare occurrence.

In fact, on average, it occurs at an interval of once about every 413 days.

After next Wednesday, the next time this will happen will be on Oct. 17, 2024.

And yet the full moon of Aug. 1, which occurred about 11 and a half hours before perigee, as well as next month's full moon on Sept. 29 which comes nearly 33 hours after perigee, are also being branded as supermoons, seemingly because they fall within 90-percent of moon's closest approach to Earth. Or in other words, within the top 10-percent of the closest full moons for a given year.

So now in most years we have not just one but four ""supermoons."" In some years, there might be as few as two while in other years there could be as many as five!

But just how ""rare"" or ""super"" is that?

An illustration of the full moon as it will appear on Aug. 30, 2023. (Image credit: Chris Vaughan/Starry Night)

Unrealistic expectations: Bigger?

And while Wednesday's moon will be — as the Observer's Handbook of the Royal Astronomical Society of Canada suggests — the ""largest full moon of 2023,"" (14% larger in apparent size compared to a full moon at apogee — its farthest from Earth) the variation of the moon's distance is not readily apparent to observers viewing the moon directly.

So, if you step outside and look at the moon on Wednesday night and expect to see something special, you'll likely be disappointed. There are always many images published on the internet in advance of a ""Supermoon,"" displaying exceedingly large full moons, all taken with telephoto lenses, all implying that the moon is going to look amazingly large in the sky.

In fact, with no advance knowledge of the closeness of the full moon, it's likely most people would not notice any difference between Wednesday's full moon and any other full moon. However, once the ""supermoon"" concept is suggested, these same people will step outside, look up and declare that the moon does look much larger than normal; similar to the way the phrase ""emperor's new clothes"" has become an idiom about logical fallacies.

Brighter?

Then there is the issue regarding the moon's brightness. Websites speak of the ""supermoon"" appearing ""30 percent brighter than other full moons."" But that actually corresponds to a minuscule increase of less than three tenths of a magnitude; so, the moonlight on Wednesday night will not be exceptionally bright.

Yet, there are likely those who think that they will be seeing an exceptionally dazzling full moon that night. In June 2013, a friend of mine told me that she was expecting that year's version of the ""supermoon"" to look 'radically brighter,' ""Like with those 3-way light bulbs; I thought it was going to be like turning the moonlight up a notch.""

Instead, the moon's brightness looked no different compared to previous nights.

The full moon looks massive as it sets behind the Very Large Telescope in Chile's Atacama Desert, in this photo release on Jun 7, 2010. Why do observers report that the moon looks larger near the horizon than it does high in the sky? It may be nothing more than a trick of perspective. (Image credit: Gordon Gillet/ESO)

The moon illusion

Wednesday's moon might still appear enormous, but for a different reason.

When the perigee moon lies close to the horizon it can appear absolutely enormous. That is when the famous ""moon illusion"" combines with reality to produce a truly stunning view. For reasons not fully understood by astronomers or psychologists, a low-hanging moon looks incredibly large when hovering near to trees, buildings and other foreground objects.

The fact that the moon will be much closer than usual on Wednesday will only serve to amplify this strange effect.

So, a perigee moon, either rising in the east at sunset or dropping down in the west at sunrise might seem to make the moon appear so close that it almost appears that you could touch it. You can check out this out for yourself by first noting the times for moonrise and moonset for your area by going to this U.S. Naval Observatory website .

Don't overlook Saturn!

A full moon is positioned opposite to the sun in the sky. As it turns out, three days before the moon reaches this point in the sky, the planet Saturn will arrive at opposition to the sun, when it too is opposite to the sun in the sky. So, on Wednesday night, Saturn will ""photobomb"" the moon, being situated about 5 and a half degrees to its upper right.

Saturn of course is much farther than our nearest neighbor; it will be situated 814.6 million miles (1.31 billion km) or 73 light minutes from Earth. The ringed wonder will shine like a sedate yellow-white ""star."" The famous rings will be tilted 9-degrees toward Earth and are visible in high powered binoculars or small spotting scopes magnifying at least 25-power.

And so, regardless of exactly how you perceive Wednesday's full moon, we here at Space.com wish all of you clear, moonlit skies.",https://cdn.mos.cms.futurecdn.net/KGHeqZGe3t88vgf92Py9Ja-1200-80.jpg,https://www.space.com/biggest-full-moon-of-2023,Science
['Gordon Johnston'],2023-08-28 01:36:01-07:00,Don’t Miss: Super Blue Moon,"The Next Full Moon is a Supermoon, a Blue Moon, and Rakhi Purnima.

The next full Moon will be Wednesday night, August 30, 2023, appearing opposite the Sun (in Earth-based longitude) at 9:36 p.m. EDT. The planet Saturn, just a few days from its closest and brightest for the year, will appear near the Moon. As evening twilight ends (at 8:42 p.m.) Saturn will be 5 degrees to the upper right of the Moon, and will appear to swing clockwise around the Moon as the evening progresses. The Moon will appear full for 3 days around the peak of the full Moon, from Tuesday night to Friday morning.

This will be a supermoon. Publications use different thresholds for deciding which Moons qualify as “super,” but all agree that in 2023 the two full Moons in August qualify.

Have questions? See the Super Blue Moon FAQ.

This full Moon will be the second full Moon in August, making it a Blue Moon by the newer definition introduced by Sky & Telescope magazine in 1946. The older definition of Blue Moon, dating back to at least the 1500s, is the name for the third full Moon in a season that has four Moons. By this definition, the full Moon in August 2024 will be the Blue Moon and this full Moon, as the last full Moon of summer, shares some of the seasonal names from my posting for the August 1 full Moon. Neither of these definitions has anything to do with the color of the Moon, so the Blue Moon will not actually look blue. See this article to learn about a time when the Moon actually turned blue!

This full Moon corresponds with the Hindu festival Raksha Bandhan, also called Rakhi or Rakhi Purnima, celebrating the bond between brothers and sisters. One of the traditions is for sisters of all ages to tie a rakhi (a cotton bracelet) around their brother’s wrist, receiving a gift from the brother in return, as a sign of the continuing bond between them. The term “Raksha Bandhan” translates as “the bond of protection, obligation, or care.”

In many traditional lunisolar and lunar calendars the full Moons fall near the middle of the lunar months. This full Moon is in the middle of the seventh month of the Chinese calendar, Safar in the Islamic calendar, and Elul in the Hebrew calendar. Elul is a time of preparation for the High Holy Days of Rosh Hashanah and Yom Kippur. Customs include granting and asking others for forgiveness as well as beginning or ending all letters with the wish that the recipient will have a good year.

As usual, the wearing of suitably celebratory celestial attire is encouraged in honor of the full Moon. Take care of your siblings, let go of grudges, and here’s wishing you a good year!

As for other celestial events between now and the full Moon after next (with specific times and angles based on the location of NASA Headquarters in Washington, DC):

As summer ends and fall begins, the daily periods of sunlight continue to shorten, changing at their fastest around the autumnal equinox.

On Wednesday, August 30, 2023 (the day of the full Moon), morning twilight will begin at 5:35 a.m. EDT, sunrise will be at 6:35 a.m., solar noon will be at 1:09 p.m. when the Sun will reach its maximum altitude of 60.0 degrees, sunset will be at 7:42 p.m., and evening twilight will end at 8:42 p.m.. The autumn equinox will be on Saturday, September 23, with sunrise at 6:57 a.m. and sunset at 7:04 p.m.. By Friday, September 29 (the day of the full Moon after next), morning twilight will begin at 6:04 a.m., sunrise will be at 7:02 a.m., solar noon will be at 12:58 p.m. when the Sun will reach its maximum altitude of 48.6 degrees, sunset will be at 6:54 p.m., and evening twilight will end at 7:52 p.m..

No major meteor showers are predicted to peak during this lunar cycle. Three minor showers will peak at 6 or fewer visible meteors per hour under ideal conditions (effectively not visible from our brightly lit urban environments).

Evening Sky Highlights:

On the evening of Wednesday, August 30, 2023 (the night of the full Moon), as evening twilight ends (at 8:42 p.m. EDT), the rising Moon will be 8 degrees above the east-southeastern horizon with the planet Saturn 5 degrees to the upper right. The planet Mars will be setting on the western horizon. The bright star appearing closest to overhead will be Vega at 85 degrees above the eastern horizon. Vega, the brightest star in the constellation Lyra the lyre, is one of the three bright stars in the Summer Triangle (along with Deneb and Altair). Vega is the 5th brightest star in our night sky, about 25 light-years from Earth, has twice the mass of our Sun, and shines 40 times brighter than our Sun.

As this lunar cycle progresses, the background of stars and the planet Saturn will appear to shift westward each evening (as the Earth moves around the Sun), while the planet Mars will shift more slowly on the western horizon. After September 1 Mars will be below the horizon as evening twilight ends. The waxing Moon will pass by Spica on September 17 (hard to see as they will set shortly after evening twilight ends), Antares on September 20, and Saturn on September 26.

By the evening of Thursday, September 28 (the start of the night of the full Moon after next), as evening twilight ends (at 7:53 p.m. EDT), the rising Moon will be 12 degrees above the east-southeastern horizon. The planet Saturn will be 23 degrees above the southeastern horizon. The bright star appearing closest to overhead still will be Vega at 83 degrees above the western horizon.

Morning Sky Highlights:

On the morning of Thursday, August 31, 2023 (the morning of the night of the full Moon), as morning twilight begins (at 5:36 a.m. EDT), the setting Moon will be 14 degrees above the west-southwestern horizon. The planet Saturn will be to the lower right of the Moon at 7 degrees above the west-southwestern horizon. The other two visible planets will be bright Jupiter at 66 degrees above the southern horizon and even brighter Venus at 9 degrees above the eastern horizon. At 66 degrees Jupiter will be the bright object closest to overhead (with the bright star Capella a close second at 65 degrees above the east-northeastern horizon).

As this lunar cycle progresses, Venus, Jupiter, Saturn, and the background of stars will appear to shift westward each evening. September 8 will be the last morning Saturn will be in the sky as morning twilight begins. Beginning September 14, Mercury will rise before morning twilight begins, joining Venus and Saturn. Initially, Mercury will be difficult to see but will brighten quickly each morning. Venus will reach its greatest brilliancy on September 19 (when Venus is near its brightest it can be seen in the daytime). Mercury will reach its greatest angular separation from the Sun on September 22 and will appear at its highest above the horizon as morning twilight begins the next morning, September 23. The waning Moon will pass near Jupiter on September 4, Pollux on September 10, Venus on September 11 and 12, and Regulus on September 13.

On the morning of Friday, September 29, (the morning of the full Moon after next), as morning twilight begins (at 6:04 a.m. EDT), the setting full Moon will be 11 degrees above the western horizon. The three visible planets will be Venus (the brightest) at 29 degrees above the eastern horizon, Jupiter at 48 degrees above the west-southwestern horizon, and Mercury (the faintest) at 4 degrees above the eastern horizon. The bright star appearing closest to overhead will be Capella at 83 degrees above the north-northwestern horizon). Capella is the brightest star in the constellation Auriga the charioteer. Although we see Capella as a single star (the 6th brightest in our night sky), it is actually four stars (two pairs of stars orbiting each other). Capella is about 43 lightyears from us.

Detailed Daily Guide:

Here for your reference is a day-by-day listing of celestial events between now and the full Moon after next. The times and angles are based on the location of NASA Headquarters in Washington, DC, and some of these details may differ for your location (I use parentheses to indicate times specific to the DC area).

On Thursday night, August 24, 2023, the bright star Antares will appear near the half-full Moon, so close that for much of Canada, the US, and northern Mexico the Moon will pass in front of Antares. For the Washington, DC area, as evening twilight ends (at 8:52 p.m. EDT), Antares will be a degree to the left of the Moon. Antares will disappear behind the dark side of the Moon about an hour later (at 10:53 p.m.). Antares will reappear from the bottom of the Moon about 45 minutes after that (around 11:41 p.m.) but the bright limb of the Moon will at first mask this reappearance. Antares will set first on the west-southwestern horizon about 14 minutes later (at 11:55 p.m.). See this data for details on this occultation for your area.

Saturday morning, August 27, 2023, the planet Saturn will be at its closest and brightest for the year, called “opposition” because it will be opposite the Earth from the Sun, effectively a “full” Saturn. Saturn will be 10 degrees above the east-southeastern horizon as evening twilight ends Friday, August 26 (at 8:48 p.m. EDT), will reach its highest in the sky early Saturday morning (at 1:13 a.m.), and will be 11 degrees above the west-southwestern horizon as morning twilight begins (at 5:32 a.m.). Only planets that orbit farther from the Sun than the Earth can be seen at opposition from the Earth.

Wednesday morning, August 30, 2023, at 11:55 a.m. EDT, the Moon will be at perigee, its closest to the Earth for this orbit.

Wednesday night into Thursday morning, August 30 to 31, 2023, the planet Saturn, just a few days from its closest and brightest for the year, will appear near the full supermoon. As evening twilight ends (at 8:42 p.m. EDT), the Moon will be 8 degrees above the east-southeastern horizon with Saturn 5 degrees to the upper right. Saturn will appear to shift clockwise around the Moon as the night progresses. The Moon will reach its highest in the sky 4.5 hours later (Thursday morning at 1:23 a.m.) with Saturn 7 degrees to the right. By the time morning twilight begins (at 5:36 a.m.) the Moon will be 14 degrees above the west-southwestern horizon with Saturn 8 degrees to the lower right.

As mentioned above, the next full Moon will be Wednesday night, August 30, 2023, appearing opposite the Sun (in Earth-based longitude) at 9:36 p.m. EDT. The Moon will appear full for 3 days around the time of the full Moon, from Tuesday night to Friday morning. This full Moon will be the second full Moon in August, making it a Blue Moon by the newer definition introduced by Sky & Telescope magazine in 1946. Since this full Moon occurs near when the Moon is closest to the Earth (perigee), this will be a supermoon.

Friday evening, September 1, 2023, will be the last evening that the planet Mars will be above the western horizon as evening twilight ends (at 8:38 p.m. EDT), setting a minute later.

Sunday night into Monday morning, September 3 to 4, 2023, the planet Jupiter will appear near the waning gibbous Moon. As Jupiter rises above the east-northeastern horizon (at 10:16 p.m. EDT) it will be 8 degrees to the lower left of the Moon. The Moon will reach its highest in the sky for the night 6.5 hours later (at 4:45 a.m.) with Jupiter 6 degrees to the left of the Moon. Morning twilight will begin about an hour later (at 5:40 a.m.).

By Monday evening, September 4, 2023, the waning gibbous Moon will have shifted to the other side of Jupiter. As the Moon rises on the east-northeastern horizon (at 10:14 p.m. EDT) Jupiter will be 6 degrees to the right. The pair will separate as the night progresses.

Wednesday morning, September 6, 2023, the planet Mercury will be passing between the Earth and the Sun as seen from the Earth, called inferior conjunction. Planets that orbit inside of the orbit of Earth can have two types of conjunctions with the Sun, inferior (when passing between the Earth and the Sun) and superior (when passing on the far side of the Sun). Mercury will be shifting from the evening sky to the morning sky and will begin emerging from the glow of dawn on the eastern horizon in mid-September (depending upon viewing conditions).

Wednesday evening, September 6, 2023, the waning Moon will appear half-full as it reaches its last quarter at 6:21 p.m. EDT.

Friday morning, September 8, 2023, will be the last morning that the planet Saturn will be above the horizon as morning twilight begins.

Sunday morning, September 10, 2023, the bright star Pollux will appear above the waning crescent Moon. As the Moon rises on the northeastern horizon (at 2:10 a.m. EDT) Pollux will be 3 degrees above the Moon. Bright Venus will rise on the east-northeastern horizon 2 hours later (at 4:07 a.m.), appearing about 20 degrees below the Moon, with Pollux 4 degrees above the Moon. By the time morning twilight begins 1.5 hours after that (at 5:46 a.m.), Pollux will have shifted to 5 degrees above the Moon with Venus 19 degrees below the Moon. The bright star Regulus will be 18 degrees to the lower left of Venus.

Monday morning, September 11, 2023, the thin, waning crescent Moon will have shifted to 12 degrees to the upper left of Venus.

Tuesday morning, September 12, 2023, the thin, waning crescent Moon will have shifted to 13 degrees to the lower left of Venus, with the bright star Regulus 10 degrees below the Moon.

Tuesday mid-day, September 12, 2023, at 11:43 a.m. EDT, the Moon will be at apogee, its farthest from the Earth for this orbit.

Wednesday morning, September 13, 2023, the bright star Regulus will be 5 degrees to the right of the very thin, waning crescent Moon. The planet Mercury will be 8 degrees to the lower right of the Moon, but will be difficult to see, as it will rise a few minutes after morning twilight begins and will not be very bright (a crescent that is only 11% illuminated).

Thursday morning, September 14, 2023, will be the first morning the planet Mercury will be above the horizon as morning twilight begins. It will be difficult to see at first, only 14% illuminated, but will brighten each morning as the Sun illuminates more of its Earth-facing surface.

Thursday night, September 14, 2023, at 9:40 p.m. EDT, will be the new Moon, when the Moon passes between the Earth and the Sun and will not be visible from the Earth. The day of or the day after the New Moon marks the start of the new month for many lunisolar calendars. The eighth month of the Chinese calendar will start on September 15.

Sundown on Friday, September 15, 2023, will be the start of Rosh Hashanah (the Head of the Year), the two-day Jewish New Year celebration that will end at sundown on Sunday, September 17. Rosh Hashanah is the first of a series of holidays in Tishrei, the first month of the Hebrew calendar. The tenth day of Tishrei is Yom Kippur, the Day of Atonement. The 10 days from Rosh Hashanahâ€¯to Yom Kippur, called theâ€¯Days of Awe, are a time to reflect on the mistakes and lessons of the past, and to make resolutions for the new year. The fifteenth day of Tishrei (close to the full Moon after next) is the start of the 7-day Sukkot holiday.

In the Islamic calendar, the months traditionally start with the first sighting of the waxing crescent Moon. Many Muslim communities now follow the Umm al-Qura Calendar of Saudi Arabia, which uses astronomical calculations to start months in a more predictable way. Using this calendar, sundown on Friday evening, September 15, 2023, will probably mark the beginning of Rabi’ al-Awwal, the third month of the Islamic calendar. During this month some Muslims celebrate Mawlid, the birthday of Muhammad.

Sunday evening, September 17, 2023, if you have a very clear view of the west-southwestern horizon, you might be able to see the bright star Spica 3 degrees to the lower right of the thin, waxing crescent Moon. They may be difficult to see. You would need to look before evening twilight ends, as when twilight ends (at 8:11 p.m. EDT) Spica will be close to setting and the Moon will be only 2 degrees above the horizon. The Moon will set 17 minutes later (at 8:28 p.m.).

Solar noon to solar noon from Monday, September 18, to Tuesday, September 19, 2023, will be the shortest solar day of the year. At 23 hours, 59 minutes, 38.6 seconds long, it will be 21.4 seconds shorter than the 24 hour average our modern clocks use.

On Tuesday, September 19, 2023, the planet Venus will be at its greatest brilliancy for the year, a good estimate of when Venus will be at its brightest. Greatest brilliancy is calculated based on the distances and angles between the Sun, Venus, and the Earth, making a simplifying assumption on how Venus scatters sunlight. When bright, Venus can be seen during the day (if the skies are clear enough and you know where to look). Greatest brilliancy occurs about 36 days before and after inferior conjunction.

On Wednesday evening, September 20, 2023, the bright star Antares will appear to the upper left of the waxing crescent Moon. Antares will be 5 degrees from the Moon as evening twilight ends (at 8:06 p.m. EDT). By the time the Moon sets on the west-northwestern horizon less than 2 hours later (at 9:57 p.m.) Antares will be 4 degrees from the Moon. For parts of East Asia the Moon will actually pass in front of Antares, blocking it from view (see http://www.lunar-occultations.com/iota/bstar/0921zc2366.htm for more information).

By Thursday evening, September 21, 2023, as evening twilight ends, the Moon will have shifted to 8 degrees on the other side of Antares. The pair will separate as the evening progresses.

Friday morning, September 22, 2023, will be when the planet Mercury reaches its greatest angular separation from the Sun as seen from the Earth for this apparition (called greatest elongation). Because the angle of the line between the Sun and Mercury and the horizon changes with the seasons, the date when Mercury and the Sun appear farthest apart as seen from the Earth is not always the same as when Mercury appears highest above the eastern horizon as morning twilight begins, which occurs the next morning, Saturday, September 23.

On Friday afternoon, September 22, 2023, the Moon will appear half-full as it reaches its first quarter at 3:32 p.m. EDT.

Early Saturday morning, September 23, 2023, at 2:50 a.m. EDT, will be the autumnal equinox, the astronomical end of summer and start of fall. The Sun will be shifting from the Northern to the Southern Hemisphere, this year passing across the Earth’s equator over the Indian Ocean.

On Sunday, September 24, 2023, a mission I worked on before retiring from NASA, OSIRIS-REx, will deliver to Earth a sample from the surface of the asteroid Bennu. NASA’s Live coverage of the capsule landing is scheduled to start at 10 a.m. EDT.

Tuesday evening into Wednesday morning, September 26 to 27, 2023, the planet Saturn will appear near the waxing gibbous Moon. Saturn will be 4 degrees to the upper left of the Moon as evening twilight ends (at 7:56 p.m. EDT). By the time the Moon reaches its highest in the sky for the night a little over 3 hours later (at 11:07 p.m.) Saturn will be 3 degrees to the upper right. As Saturn sets below the west-southwestern horizon a little over 5 hours after that (at 4:24 a.m.) it will be 4 degrees to the lower right of the Moon.

Wednesday evening, September 27, 2023, at 9:06 p.m. EDT, the Moon will be at perigee, its closest to the Earth for this orbit.

The full Moon after next will be Friday morning, September 29, 2023, appearing opposite the Sun (in Earth-based longitude) at 5:58 a.m. EDT. This will be late Thursday night from the time zone of Hawaii and the Cook Islands westward to the International Date Line. The Moon will appear full for 3 days around this time, from Wednesday evening to Saturday morning.",https://scitechdaily.com/images/Blue-Moon.jpg,https://scitechdaily.com/dont-miss-super-blue-moon/,Science
"['Aliza Chasan', 'Aliza Chasan Is A Digital Producer At Minutes', 'Cbs News.']",,A rare super blue moon arrives this week. Here's how to see it.,"A rare super blue moon will shine in the sky as August wraps up.

The month already featured a supermoon as it began, but the second full supermoon of the month — which will appear on Aug. 30 — will also be a blue moon. A blue moon is not actually blue in color; the term signifies a second full moon within a single month.

August's first full moon rose on Aug. 1 and was the second of four consecutive supermoons. On average, supermoons are about 16% brighter than an average moon. They also appear bigger than the average full moon. According to NASA, it's similar to the size difference between a quarter and a nickel. The phenomenon occurs when the moon's orbit is closest to Earth at the same time the moon is full.

The Aug. 30 supermoon will appear to be even closer than the full moon at the beginning of the month. The last of the four consecutive supermoons this year will be the Sept. 28 ""Harvest Moon.""

The silhouette of treetops on a hill seen in front of the ""Sturgeon Moon"" supermoon on Aug. 2, 2023 in Turin, Italy. Stefano Guidi/Getty Images

Those who miss out on the blue moon will have quite a wait before the next one. While around 25% of full moons are supermoons, just 3% of full moons are blue moons, according to NASA. The next blue moon after the one on Aug. 30 will be in May 2026. Astronomy fans will be in for a special treat come 2037, which will feature super blue moons in January and March.

This Wednesday's super blue moon will reach its peak at 9:36 p.m. EDT. Those looking to the skies may also spot Saturn, which will be visible near the moon around 8:42 p.m. EDT and appear to swing clockwise around the moon as the evening progresses, according to NASA. Saturn should be visible just by looking up, but binoculars or a telescope will help viewers make out some of the planet's distinguishing features.

Saturn moved directly opposite the sun on Saturday night and will stay there through Sunday night, with the sun's illumination allowing the ringed planet to appear bigger and brighter in the sky, according to NASA. It will remain visible until February of next year.",https://assets1.cbsnewsstatic.com/hub/i/r/2023/08/27/5d3f85f9-97b5-4ab1-855a-7f46fb07a218/thumbnail/1200x630/1076d9a6051014486b2af8937d5a58a6/gettyimages-1589369186.jpg?v=85153828b1c3c07a041ab8e73ff87e39,https://www.cbsnews.com/news/rare-super-blue-moon-august-30-how-to-see-it/,Science
['Stuart Clark'],2023-08-28 00:00:00,Starwatch: August’s second supermoon the largest this year,"The second full moon of the month occurs this week. The first took place on 1 August, but this second coming will grace the skies on 31 August.

Because it is the second full supermoon in the month, it is also called a blue moon – although definitions for blue moons vary. The above definition is known as a monthly blue moon but some prefer what is known as a seasonal blue moon. This is the third full moon in a season that contains four full moons – so the blue moon may not be the second of the month.

But whether you think the one on 31 August is a blue moon or not, it is definitely a supermoon, the largest of the four supermoons occurring this year. The moon will be 222,043 miles (357,344km) away from Earth, hence the full moon will appear larger than average, earning it the title of supermoon. The day before the full moon occurs, the almost full moon will join Saturn in the evening sky. The silvery moonlight will make a subtle contrast to Saturn’s ochre glow. The chart shows the view looking south-east from London at 22.30 BST on 30 August 2023. The conjunction is much higher in the sky when viewed from the southern hemisphere.",https://i.guim.co.uk/img/media/b2a905832a511514d27d0f5cd14647ffa93f42f7/284_451_1404_842/master/1404.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=d68808cf48ecea022322546606cc6431,https://www.theguardian.com/science/2023/aug/28/starwatch-august-second-supermoon-largest-blue-moon,Science
[],,"Aditya-L1 mission to study the Sun to be launched on September 2, announces ISRO","The Bengaluru-based Indian Institute of Astrophysics (IIA) is the lead institute for the development of Visible Emission Line Coronagraph (VELC) payload while Inter-University Centre for Astronomy and Astrophysics, Pune, has developed the Solar Ultraviolet Imaging Telescope (SUIT) payload for the mission.

According to ISRO, VELC aims to collect the data for solving how the temperature of the corona can reach about a million degrees while the Sun's surface itself stays just over 6000 degrees Centigrade.

Aditya-L1 can provide observations on the corona, and on the solar chromosphere using the UV payload and on the flares using the X-ray payloads. The particle detectors and the magnetometer payload can provide information on charged particles and the magnetic field reaching the halo orbit around L1.

The satellite, developed by U R Rao Satellite Centre here, arrived at ISRO's spaceport of Sriharikota in Andhra Pradesh, earlier this month.

It is planned to be placed in a halo orbit around the L1 point of the Sun-Earth system.

A satellite placed in the halo orbit around the L1 point has the major advantage of continuously viewing the Sun without any planets obstructing the view or causing eclipses, ISRO noted. ""This will provide a greater advantage of observing the solar activities and its effect on space weather in real time,"" it said.

Using the special vantage point L1, four payloads would directly view the Sun and the remaining three payloads are expected to carry out in-situ studies of particles and fields at the L1 point, thus providing important scientific studies of the propagatory effect of solar dynamics in the interplanetary medium.

""The SUITs of Aditya L1 payloads are expected to provide the most crucial information to understand the problem of coronal heating, coronal mass ejection (CME), pre-flare and flare activities and their characteristics, dynamics of space weather, propagation of particle and fields etc,"" ISRO said.

The major science objectives of the Aditya-L1 mission are: study of solar upper atmospheric (chromosphere and corona) dynamics; study of chromospheric and coronal heating, physics of the partially ionised plasma, initiation of the coronal mass ejections, and flares; observe the in-situ particle and plasma environment providing data for the study of particle dynamics from the Sun; and physics of solar corona and its heating mechanism.

Besides, the mission aims to study diagnostics of the coronal and coronal loops plasma: temperature, velocity and density; development, dynamics and origin of CMEs; identify the sequence of processes that occur at multiple layers (chromosphere, base and extended corona) which eventually leads to solar eruptive events; magnetic field topology and magnetic field measurements in the solar corona; and drivers for space weather (origin, composition and dynamics of solar wind).

The instruments of Aditya-L1 are tuned to observe the solar atmosphere, mainly the chromosphere and corona. In-situ instruments will observe the local environment at the L1 point.",https://images.deccanherald.com/deccanherald%2F2023-08%2F131cd3da-4a3a-4c14-855d-3c3ef3ea12d1%2FF4m_Sb1bMAAFjz7.png?rect=0%2C0%2C1166%2C612&w=1200&ar=40%3A21&auto=format%2Ccompress&ogImage=true&mode=crop,https://www.deccanherald.com/science/space/aditya-l1-mission-to-study-the-sun-to-be-launched-on-september-2-announces-isro-2663492,Science
[],2023-08-28 00:00:00,India sets September launch date for mission to study the sun,"A security guard stands behind the logo of Indian Space Research Organisation (ISRO) at its headquarters in Bengaluru, India, June 12, 2019. REUTERS/Francis Mascarenhas//File Photo Acquire Licensing Rights

BENGALURU, Aug 28 (Reuters) - India's first space-based observatory to study the sun will be launched on Sept. 2, the country's space agency said on Monday.

The announcement, in a post on messaging platform X, formerly known as Twitter, comes days after India became the first country to land a spacecraft on the unexplored south pole of the moon.

The Aditya-L1, India's first space-based solar probe, aims to study solar winds, which can cause disturbance on earth and are commonly seen as ""auroras"".

The craft, named after the Hindi word for the sun, will be launched from the country's main spaceport in Sriharikota using India's heavy-duty launch vehicle, the PSLV, which will travel about 1.5 million km (932,000 miles), the agency said.

""The total travel time from launch to L-1 (Langrange point) would take about four months for Aditya-L1,"" the Indian Space Research Organisation (ISRO) said in a post on X.

The government sanctioned the equivalent of about $46 million for the mission in 2019.

ISRO has not given an official update on costs and did not immediately respond to a call seeking comment.

India has achieved a reputation for successful space launches at cut-throat costs. It's latest moon mission had a budget of about $75 million- less than that of Hollywood space thriller ""Gravity"".

Reporting by Nivedita Bhattacharjee in Bengaluru; Writing by Sakshi Dayal; Editing by Louise Heavens and Mike Harrison

Our Standards: The Thomson Reuters Trust Principles.",https://www.reuters.com/resizer/9cjEUeaua0_SVwd09oYb5vpRfuo=/1200x628/smart/filters:quality(80)/cloudfront-us-east-2.images.arcpublishing.com/reuters/CX6IDBDRWRKGJDDHV7UVRLFSCE.jpg,https://www.reuters.com/world/india/indias-first-space-based-observatory-study-sun-be-launched-sept-2-space-agency-2023-08-28/,Science
[],2023-08-27 14:38:12+05:30,What is Aditya L-1 mission? All you need to know about ISRO’s solar quest,"The Indian Space Research Organisation's (ISRO) Aditya L-1 mission is a ground-breaking effort aimed at researching the Sun's corona, solar storms, and other solar phenomena. The goal of this enormous mission is to improve our understanding of the Sun and its impact on the Earth's space environment. Let's go into the specifics and goals of the Aditya L-1 Mission.

Aditya L-1 Mission's purpose and objectives

The Aditya L-1 Mission's major goal is to examine the dynamics of the Sun's outermost layers, notably the corona, and to explore the processes that contribute to the creation of solar storms and their impact on interplanetary space and the Earth's climate. Its goal is to better understand coronal mass ejections (CMEs), solar flares, and other solar events, as well as their relationship to geomagnetic storms that disrupt communication and power systems on Earth.

ALSO READ: Where to watch FIBA World Cup 2023? TV details, streaming options, and other avenues explored

Launch and Orbit

The Polar Satellite Launch Vehicle (PSLV-XL) will launch Aditya L-1 from India's Satish Dhawan Space Centre in 2023. The spacecraft will be positioned at Lagrange Point 1 (L1), which is approximately 1.5 million kilometers (about 932056.79 mi) from Earth. This excellent location will provide Aditya L-1 with an uninterrupted view of the Sun, giving critical data for extensive solar observations.

Payloads and Instruments

Aditya L-1 will be outfitted with a set of instruments designed to capture and analyze various features of the Sun's atmosphere and magnetic field. Among the important payloads are:

Visible Emission Line Coronagraph (VELC): It will use spectro-polarimetry to investigate the magnetic field and dynamic processes of the solar corona.

Solar Ultraviolet Imaging Telescope (SUIT): The chromosphere and transition region emissions in the Solar Ultraviolet (UV) band will be observed by this device.

Aditya Solar Wind Particle Experiment (ASPEX): It will measure the properties of solar wind plasma as well as variations in composition.

Solar Low Energy X-ray Spectrometer (SoLEXS): SoLEXS will measure solar X-ray spectra to study solar flares and coronal heating.

Collaboration with International Space Agencies

Collaboration with other international space agencies, including NASA and the European Space Agency (ESA), has occurred on the Aditya L-1 project. These collaborations attempt to increase scientific output by combining data from many satellites and devices throughout the world, allowing for complete insights into solar processes. The collaboration also makes it easier to acquire supplementary datasets, which improves our understanding of the Sun and its impact on Earth's space environment on a global scale.

Advertisement

The Aditya L-1 mission marks a significant advancement in solar study, paving the path for a better knowledge of the Sun's influence on our planet. This ambitious mission by ISRO will contribute to space weather forecasting and a broader understanding of our cosmic neighbor by researching the Sun's corona, magnetic field, solar storms, and their influence on Earth, helping science, technology, and society.

ALSO READ: What is the new season of Fortnite? All you need to know about Battle Royale Chapter 4 Season 4",https://www.pinkvilla.com/images/2023-08/1298399047_screenshot-2023-08-27-122236-2.jpg,https://www.pinkvilla.com/trending/india/what-is-aditya-l-1-mission-all-you-need-to-know-about-isros-solar-quest-1238853,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
[],2023-08-28 00:00:00,International crew arrive at space station aboard SpaceX Dragon Endurance – Spaceflight Now,"A SpaceX Crew Dragon ferry ship docked at the International Space Station Sunday after a 29-hour rendezvous, bringing four fresh crew members to the lab to replace four others wrapping up a six-month stay in orbit.

Crew-7 commander Jasmin Moghbeli, European Space Agency astronaut Andreas Mogensen, Japanese astronaut Satoshi Furukawa and cosmonaut Konstantin Borisov docked at the lab at 9:16 a.m. EDT. After extensive leak checks, hatches were opened and the crew was welcomed aboard by the station’s seven crew members.

“Expedition 69 is very glad to greet new crewmates,” said ISS commander Sergey Prokopyev. He noted that space veterans Mogensen and Furukawa were making their second visit to the station while Moghbeli and Borisov were making their first flight.

“My extreme congratulations for Jasmin and Konstantin, this your first flight, you became now real astronaut and cosmonaut, and I believe this will be (a) very significant event of your life. Welcome aboard. Looking forward to working together.”

Moghbeli, a Marine Corps helicopter test pilot, said “it’s so good to see all your smiling faces. As you know, we’ve been training together for a while for this exact moment where we could join you and continue the amazing work that’s done on the International Space Station.

“I want to echo the thanks to all the teams … for preparing us for this moment. I think we represent a good crew to be coming to the International Space Station.”

Moghbeli and her Crew-7 colleagues blasted off from the Kennedy Space Center early Saturday atop a SpaceX Falcon 9 rocket. It was NASA’s seventh operational Crew Dragon flight to the space station and the first featuring crew members from four different space agencies.

Their addition to the station crew, which includes United Arab Emirates Crew-6 astronaut Sultan Alneyadi, means five nations are represented aboard the appropriately named lab complex — the United States, Russia, Japan, Denmark and United Arab Emirates.

But not for long.

The Crew-7 fliers are replacing Crew-6 commander Stephen Bowen, pilot Woody Hoburg, cosmonaut Andrey Fedyaev and Alneyadi They plan to undock and return to Earth in a little less than a week to close out a six-month mission.

Two weeks after the Crew-6 departure, on Sept. 15, a Russian Soyuz spacecraft will take off from the Baikonur cosmodrome in Kazakhstan carrying cosmonauts Oleg Kononenko, Nikolai Chub and NASA astronaut Loral O’Hara.

That crew, in turn, will replace Prokopyev, Dmitri Petelin and NASA astronaut Frank Rubio. They’re scheduled to return to Earth on Sept. 27 to wrap up a marathon 371-day stay in orbit, setting a new U.S. record for longest single spaceflight.",http://spaceflightnow.com/wp-content/uploads/2023/08/20230827-Crew-Welcome.jpg,https://spaceflightnow.com/2023/08/28/international-crew-arrive-at-space-station-aboard-spacex-dragon-endurance/,Science
[],,NASA’s SpaceX Crew-7 Flight Day 2 Highlights,,https://i.ytimg.com/vi/kAofb-vIxRM/maxresdefault.jpg,https://www.youtube.com/watch?v=kAofb-vIxRM,Science
['Jackie Wattles'],2023-08-27 00:00:00,"SpaceX, NASA mission with international crew docks with space station","Sign up for CNN’s Wonder Theory science newsletter. Explore the universe with news on fascinating discoveries, scientific advancements and more.

CNN —

Astronauts aboard a SpaceX Crew Dragon capsule docked Sunday at the International Space Station, concluding a one-day trip to rendezvous with the orbiting laboratory after launching from Florida.

The capsule made first contact with the space station at 9:16 a.m. ET Sunday and its hatches opened at 10:58 a.m. ET.

Hailing from four countries — making this mission, called Crew-7, the most nationally diverse SpaceX mission to date — the astronauts include NASA’s Jasmin Moghbeli, the mission commander; Danish astronaut Andreas Mogensen of the European Space Agency; Satoshi Furukawa of the Japan Aerospace Exploration Agency, or JAXA; and Russian cosmonaut Konstantin Borisov of Roscosmos.

The four launched aboard the Crew Dragon spacecraft atop a SpaceX Falcon 9 rocket from NASA’s Kennedy Space Center in Florida at 3:27 a.m. ET Saturday, and they’ve spent the last day free-flying aboard the 13-foot-wide capsule as it slowly maneuvered toward the space station.

Crew-7’s mission

Moghbeli, Mogensen, Furukawa and Borisov are joining the seven astronauts already on the orbiting laboratory.

The Crew-7 astronauts will spend about five days taking over operations from the SpaceX Crew-6 astronauts, who have been on the space station since March.

The new team will then bid farewell to the SpaceX Crew-6 astronauts, who will return home aboard their spacecraft, the Crew Dragon Endeavour, in the coming days.

This mission marks the eighth flight operated by NASA and SpaceX as part of the agency’s commercial crew program, which has been ferrying astronauts to the space station since SpaceX’s first crewed mission in 2020.

During their stay on the space station, which is expected to last about 180 days, the Crew-7 astronauts will pore through a slate of experiments. The research will include investigating the potential risk of dispersion of bacteria and fungi from human-led space missions. The team will analyze whether the microorganisms can be expelled from the space station’s vents and spewed into the vacuum of space.

Another project, from the ESA, will investigate how sleeping in the microgravity environment differs from Earth by analyzing astronauts’ brain waves while they doze off. Yet another experiment will look at the formation of biofilms in wastewater on the space station, which could be key to finding better ways to recycle water for drinking and hygiene while in space. (Yes, astronauts have long used recycled sweat and urine to drink and shower on the station.)

Furukawa, one of only two crew members who has flown to space, said during a news conference this month that he looks forward to reinhabiting the microgravity environment on the space station and delving into scientific pursuits, including research that could aid the development of new medicine and projects that could help inform how humans can one day explore the moon.

Mogensen is the other veteran of spaceflight on this mission. Borisov and NASA’s Moghbeli are both on their first.

“This is something I’ve wanted to do for as long as I can remember,” Moghbeli said during a July 25 news conference. “One of the things I’m most excited about is looking back at our beautiful planet. Everyone I’ve talked to who has flown already has said that was kind of a life-changing perspective.”","https://media.cnn.com/api/v1/images/stellar/prod/230826032147-03-spacex-crew-7-launch-082623.jpg?c=16x9&q=w_800,c_fill",https://www.cnn.com/2023/08/27/world/spacex-nasa-crew-7-dock-space-station-scn/index.html,Science
[],,SpaceX launches new crew to international space station | GMA,,https://i.ytimg.com/vi/9J7dpjwlxmo/maxresdefault.jpg,https://www.youtube.com/watch?v=9J7dpjwlxmo,Science
"['Vitaly Egorov', 'Vitaly Egorov Is A Journalist', 'Science Communicator. He Runs The Telegram Channel Zelenyikot', 'Focusing On News About Space.', 'Ivan Fomin', 'Joshua R. Kroeker', 'Harold Chambers', 'Robert Jenkins', 'Aug.']",2023-08-28 00:00:00,How Russia’s Lunar Ambitions Came Crashing Down,"The crash of Russia’s Luna-25 spacecraft on the surface of the Moon on Aug. 19 marked the Roscosmos space agency’s latest unsuccessful attempt to explore interplanetary space. While the causes of the accident are still being investigated, it is already clear that it was brought on by a series of problems afflicting the Russian space program: a lack of funding and engineering personnel, dependence on the political interests of the state, and vulnerability to Western sanctions in procuring crucial electronic components. Launching a research probe to the Moon has been a goal of Russian scientists since the 90s. The modern Russian state’s first interplanetary mission, Mars-96, failed in 1996. As a result, scientific organizations decided to moderate their ambitions and take up an apparently easier goal — landing a probe on the Moon. At that time, the Russian space program was in a different situation compared to today. While the industry was seriously underfunded, it had highly professional personnel who in Soviet times orchestrated successful research missions to Venus. The Soviet Union had less luck reaching Mars, but this was due to the imperfection of Soviet electronics, and not from a lack of professionalism. Financing for the project only became stable in 2005, when Roscosmos included it in the Federal Space Program for 2005-2015. Subsequently, the project had to be repeatedly revised, primarily due to this lack of funding. In the 2000s, the space program suffered a financial crisis, and within the industry there was constant competition for money between different projects. Their supporters were labeled the ""Martians"" — those who wanted to research Mars; ""Lunatics"" — those who prioritized the Moon; and ""Astrophysicists"" — who wanted to probe further into deep space. Priority was given to projects which enjoyed the support of international partners or promised ambitious discoveries. Much depended on the authority of the key lobbyists of each persuasion. At first, the Astrophysicists won, and they were able to get money for the Integral space telescope project in collaboration with the European Space Agency. When it came to exploring the solar system, Roscosmos' interest remained with Mars, so preference was given to the Phobos-Grunt project. The mission promised a more ambitious achievement: retrieving soil from Mars’ largest moon, Phobos. The Moon has always been peripheral to the state’s interests, and was thus funded on a residual basis. The prospects for a mission to the Moon increased in 2011, when the Spektr-R space telescope was launched in the summer, pleasing astrophysicists. But the Phobos-Grunt craft suffered a mechanical fault that winter, breaking apart while re-entering Earth’s atmosphere. Plans for a lunar craft were based on the design of Phobos-Grunt. Its failure forced engineers back to the drawing board. Also at that time, the makeup of the space industry itself was changing significantly; experienced scientists were leaving, with younger specialists coming in their place. They needed new ambitious projects with a high degree of risk to gain experience and prestige.

Several factors affected the implementation of the Luna program at once. One of the most significant was Russia's seizure of Crimea in 2014, which prompted U.S. sanctions blocking the export of high-tech electronic components to Russia. Many critical electronic elements had to be refurbished or procured from new suppliers. One of these devices — the navigation inertial unit Bius-L — could no longer be imported, so had to be produced domestically. The success of Luna-25 depended on its proper function when it crashed. The second difficulty was again created by competition between the Martians and Astrophysicists. Although funding for space research in Russia improved through the 2010s, missions were left to compete for engineering personnel. The state-owned Lavochkin Association dominates the production of components for the space program. However, its manufacturing capacity was split between producing parts for weather-monitoring satellites and the Mars mission and space telescope programs. Because these missions were given higher priority, work on Lunar-25 was delayed. Finally, in 2019, the Lavochkin Association completed its part in these projects, leaving more time for the lunar program. The latest delays and postponements of the launch, first to 2022 and then to 2023, were again linked to import-substituted control units. These would control the spacecraft’s position, determining its speed and distance to the surface of the Moon. On Aug. 11, 2023, Luna-25 was finally launched from the Vostochny Cosmodrome in Russia’s Far East. A month earlier, India launched its lunar vehicle, Chandrayaan 3, which was supposed to land relatively close to its Russian counterpart. An unspoken race unfolded between the two probes. India had a head start, but its craft was moving along a more conservative trajectory. According to the plan, Chandrayaan 3 was supposed to land two days later than Russia’s spacecraft, on Aug. 23. Eventually, Luna-25 was able to get closer to the Moon than Chandrayaan 3, but by that time Russian experts noticed ""alarming signs."" An error occurred during the first correction of the craft’s trajectory to the Moon, which required the engines to be restarted. It had already become clear that the Luna-25’s flight was not going according to plan, although this was not officially reported. Once it started orbiting the Moon, nothing prevented the scientists from leaving the device for a few days, or even months, so they could study its shortcomings and try to fix them. Luna-25 was expected to operate on the Moon for up to a year, so the station could have stayed in orbit for a long time in the event of a malfunction. But if that happened, India would have beaten Russia in the race to become the first conqueror of the Moon’s circumpolar region. In addition, on Aug. 22, Russia celebrates Flag Day. The flag of Russia had been placed on board the Luna-25 before its launch — perhaps Roscosmos wanted to debut a photo of the Russian flag planted on the Moon to mark the holiday.

news Putin Congratulates India on Moon Landing After Own Probe Crashed Read more",https://static.themoscowtimes.com/image/og/83/82246__83f0e5b0ed01b824894c5cfed80385e9.jpg,https://www.themoscowtimes.com/2023/08/28/how-russias-lunar-ambitions-came-crashing-down-a82246,Science
['The Conversation'],2023-08-27 22:00:00+09:30,Russia declares new space race but China’s not competing,"Richard de Grijs, Macquarie University

This week, the Russian space agency Roscosmos had hoped to return to the Moon after an absence of nearly 50 years. Instead, on Saturday it lost control of its Luna-25 lander. The agency explained the spacecraft “switched to an off-design orbit and ceased to exist as a result of a collision with the lunar surface”.

Yet, in an interview aired on state television, the agency’s chief, Yuri Borisov, pledged his nation’s unwavering commitment to lunar exploration: “This is not just about the prestige of the country and the achievement of some geopolitical goals. This is about ensuring defensive capabilities and achieving technological sovereignty.”

Roscosmos had been keen to beat a rival Indian spacecraft, Chandrayaan-3, to achieve a soft landing near the lunar south pole. The Indian mission landed softly as hoped.

Despite the Luna-25 failure, the head of Russia’s space agency also declared a “new race to exploit the Moon’s resources has begun”, and there would be a potential crewed Russian-Chinese mission in the future, as reported by Reuters. His statement sounds like it is less about the scientific exploration of the lunar surface, and more about geopolitical posturing.

I recently spent the better part of a decade as a senior academic at Peking University, and in July 2023 was appointed as Executive Director of the International Space Science Institute–Beijing. These appointments have allowed me to gain unique insights into the processes driving China’s space science program.

A lunar outpost

The lunar south pole region is thought to contain significant water reservoirs locked in grains of ice. That makes the area interesting as a potential staging post for future missions to Mars and beyond, as lunar explorers can use the water for survival.

In early 2021, Roscosmos and the China National Space Administration signed a memorandum of understanding to jointly establish an International Lunar Research Station by the mid-2030s.

The lunar south pole may well be a prime site for such a robotic base, which might also involve the European Space Agency and other international partners.

Yet human involvement in Sino-Russian space missions is not anticipated any time soon. Therefore, Borisov’s assertion that Russia would explore a joint crewed mission came as an unlikely surprise. He may well have been speaking to a domestic audience, in an attempt to salvage his agency’s credentials.

Despite an impressive number of collaboration agreements, high-profile Sino-Russian space projects remain few and far between. If joint human exploration of the Moon is not currently on the cards, it is highly unlikely the Chinese space authorities will take the bait.

No need for a space race

China has always carefully planned its approach to Solar System exploration and human spaceflight, navigating a succession of clearly defined technological benchmarks. China will unlikely be coerced into rushing its planned milestones. As such, the notion of a “space race” involving China seems a moot point.

Chinese scientists and engineers have become highly adept at developing homegrown capabilities. They no longer require international assistance. If anything, in the Sino-Russian relationship, Russia is now well and truly the junior partner. Its ageing technology pales in comparison with the leaps of modernisation we have witnessed in relation to China’s progress in space.

Although the country only joined the league of space-faring nations in 1970 with the launch of its first satellite, Dong Fang Hong 1 (The East is Red 1), it has since made massive strides in technology readiness.

China’s lunar exploration program has gradually built on proven capabilities, from entering the Moon’s orbit on its first lunar missions (Chang’e 1 and Chang’e 2; named after the Chinese Moon goddess) to achieving soft landings (Chang’e 3 and Chang’e 4) and a successful sample return mission, Chang’e 5.

Venturing out to the planets

Solar System exploration is now firmly on China’s agenda, not least because of the recent Tianwen 1 (Heavenly Questions) mission to Mars. That mission successfully deployed the Zhurong rover (named after a Chinese mythological god of fire), a major technological feat in its own right.

Similarly, China’s human spaceflight program is starting to yield impressive results. As the country’s scientists and engineers are banned from collaborating with their federally funded US counterparts by the 2011 Wolf Amendment, the China Manned Space program has been pursuing construction of a sovereign space station, Tiangong (Heavenly Palace).

Future plans include the development of a next-generation crewed spacecraft to replace the workhorse Shenzhou (Divine Vessel on the Heavenly River) series. We are told it will be capable of carrying taikonauts to the Moon, but that does not mean Russian cosmonauts will be invited to come along.

Although China can no longer boast the economic successes of the past and external cash injections might be seen as helpful, Russia’s financial losses due to its ongoing war in Ukraine may well make any such overtures merely wishful thinking.

Russia’s prowess in space appears to have become just a dim reflection of its Soviet precursor.

Richard de Grijs, Professor of Astrophysics / Executive Director, International Space Science Institute-Beijing, Macquarie University

This article is republished from The Conversation under a Creative Commons license. Read the original article.",https://cosmosmagazine.com/wp-content/uploads/2023/08/chandrayaan-3-concept-nasa.jpg,https://cosmosmagazine.com/space/russia-declares-new-space-race/,Science
"['Tony Ho Tran', 'Deputy Editor', 'Innovation']",2023-08-27 00:06:46.637000+00:00,Are We Watching the End of Russia’s Space Ambitions?,"It was a tale of two space programs. On Sunday, Russia’s Luna-25 lander malfunctioned as it prepared to touch down on the moon’s south pole the following day—eventually crashing into the lunar surface. If it had landed, it would have been the country’s first return to the moon since 1976, when it was known as the Soviet Union. Instead, it ended up being another black eye for a beleaguered space program.

Then, a few days later, India’s Chandrayaan-3 lander successfully touched down on the moon’s south pole—making India the fourth country to land on the lunar surface after the Soviet Union, the U.S., and China. There, researchers hope to deploy a rover to search for and study ice and soil in the region—which many suspect holds valuable and vital resources for future lunar missions.

While it was a resoundingly successful mission, the Chandrayaan-3 lander underscored the relatively decline of Russia’s civilian space agency, Roscosmos. It’s seen its stature on the world stage take a beating in the wake of the invasion of Ukraine, and had already been suffering from a string of embarrassing news ranging from the bloviating smack talk of its former chief Dmitry Rogozin to the multiple life-threatening incidents it caused for astronauts on the International Space Station. The failure of Luna-25 calls into question the long term ambitions of Roscosmos—and whether or not we’re witnessing the death rattle of Russia’s space ambitions.

“The problems with Roscosmos existed certainly prior to the invasion of Ukraine,” John Logsdon, founder of the Space Policy Institute at George Washington University, told The Daily Beast. The issues that have plagued Russia’s space program, he said, mirror the very issues that have mired the country for decades including a downright Kafkaesque bureaucracy and financial malfeasance.

“They have not had adequate funding or adequate priority—but they have had a lot of corruption,” Logsdon explained.

Indeed, lack of funding has significantly crippled the once-proud space program. In 2015, the Russian government slashed spending on Roscosmos by more than a third due to a financial crisis caused by western economic sanctions in response to its 2014 invasion of Ukraine. This greatly delayed the agency’s plans to create its own space station by 2023—which has clearly not happened and hasn’t gained much development since its announcement.

In 2018, Roscosmos faced budget cuts yet again to the tune of roughly $2.4 billion. The cuts caused further delays to its spacefaring ambitions along with the construction of its spaceports. This is despite Russian president Vladimir Putin saying that same year: “It is necessary to drastically improve the quality and reliability of space and launch vehicles […] to preserve Russia’s increasingly threatened leadership in space.”

More recently, in 2021, Putin announced yet another cut in funding for the following three years to Roscosmos due to a financial crisis caused by western economic sanctions in response to its invasion of Ukraine (stop us if you’ve heard this one before). Also in the backdrop of all this was the space agency’s announcement that it had lost an eye-watering $262.4 million in revenue in 2020 due to a variety of issues stemming from the COVID-19 pandemic.

Despite this, Putin still expressed his wishes that Roscosmos return the country’s space ambitions to its former dominance—expressing concern that it would be rapidly outstripped by western competition from the likes of SpaceX. However, much of this can likely be attributed to Putin’s wish that the country dominate space for geopolitical purposes rather than scientific ones.

Logsdon explained that this can be seen through Moscow’s focus on the Russian Space Forces, their answer to the U.S. Space Force. Not only has this branch received the majority of the focus when it comes to Russia’s space ambitions, but it also controls the necessary resources for space exploration.

“The Russian equivalent of the Space Force in the military has gotten priority funding over the last 10 years or so,” he said. “They’ve developed a wide range of military capabilities that are viewed by the U.S. as rather threatening.”

Logsdon added: “The military controls all the launch vehicles.” This means that Roscosmos lacks independence and autonomy to conduct missions when compared to the likes of NASA.

There’s also the rampant corruption that has occurred throughout Roscosmos—exacerbated by its former head Rogozin. While he has since left the role following the Ukraine invasion, many space experts blame Rogozin for the current state of the agency.

Under his wing, Roscosmos had a series of failed and embarrassing launches and suffered from widespread corruption. Funds meant for the construction of the Vostochny cosmodrome in eastern Russia—the same space port from which the ill-fated Luna-25 was launched—were embezzled, resulting in prison terms for four former construction company executives in 2021.

That brings us to today, where Roscosmos’ latest space-faring plan came crashing down to the lunar surface. This failure represents a massive setback for the agency’s hopes to establish a foothold on the moon, which has become a shining prize for the world’s spacefaring nations.

This is due to the fact that the moon—and, in particular, its south pole—is thought to abound in resources and materials that future lunar colonies can rely on, like water and minerals. It’s why China and India have recently sent rovers to the moon. It’s also why the U.S. and NASA have poured billions of dollars into the Artemis program to return American astronauts to the moon and establish a permanent base.

“There’s pretty firm speculation that there are resources in the craters of the [lunar] south pole that have technical and economic values in addition to scientific interest,” Logsdon said. “There is a ‘race’ to be the first to the south pole region.”

However, with Roscosmos now performing with seemingly both hands tied behind its back, it’s now well behind the competition, whatever Putin might say. The Russian space industry is not nearly as advanced or well-funded as it is in the West, which boasts such private-sector heavy hitters as SpaceX and Blue Origin.

Logsdon cautioned that this doesn’t mean that Roscosmos should be written off quite yet. “It depends on how the Russian leadership reacts to this failure,” he said. “They could say—as the U.S. has after shuttle failures, or the Apollo 1 fire, or some of our Mars failures—that it’s not acceptable and we gotta get back to where we want to be. Or they could say, ‘Let’s not throw good money after bad,’ and de-emphasize the civilian program.”

For now, though, things look bleak for Roscosmos. The storied Soviet-Russian space program once projected near-total dominance when it came to space. It produced heroes like Yuri Gagarin, and groundbreaking events like the first satellite into orbit and interplanetary probes to Venus and Mars.

Now, despite its sky-high ambition, it’s a shadow of its former self—the victim of its own corruption, incompetence, and greed.","https://img.thedailybeast.com/image/upload/c_crop,d_placeholder_euli9k,h_1688,w_3000,x_0,y_0/dpr_2.0/c_limit,w_740/fl_lossy,q_auto/v1693014003/082723-russia-hero_h5fjrn",https://www.thedailybeast.com/are-we-watching-the-end-of-russias-roscosmos-space-ambitions,Science
[],2023-08-28 00:00:00,"Protesters, armed with traffic cones, are immobilizing driverless cars","WUSF 89.7 depends on donors for the funding it takes to provide you the most trusted source of news and information here in town, across our state, and around the world. Support WUSF now by giving monthly, or make a one-time donation online.",https://wusfnews.wusf.usf.edu/apple-touch-icon.png,https://wusfnews.wusf.usf.edu/2023-08-28/protesters-armed-with-traffic-cones-are-immobilizing-driverless-cars,Science
[],,Videos capture bright meteor falling above Colorado,,https://i.ytimg.com/vi/-7b6NLbx8lw/maxresdefault.jpg,https://www.youtube.com/watch?v=-7b6NLbx8lw,Science
['Jon Hamilton'],,How scientists engineered a see-through squid with its brain in plain view,How scientists engineered a see-through squid with its brain in plain view,https://media.npr.org/assets/img/2023/08/25/hummingbird-bobtail-squid-euprymna-berryi-albino-on-the-left-and-wild-type-on-the-right-ba00a6971bbbf425b5a9d7924edd7db22afae644.jpg?s=5,https://www.wbur.org/npr/1196073961/how-scientists-engineered-a-see-through-squid-with-its-brain-in-plain-view,Science
['Jamie Groh'],2023-08-26 00:00:00,Updates: SpaceX boosted another Falcon 9 Starlink mission from Cape Canaveral Saturday,"Updates: SpaceX boosted another Falcon 9 Starlink mission from Cape Canaveral Saturday

Show Caption Hide Caption SpaceX Starlink 6-11 Mission from Cape Canaveral Space Force Station A SpaceX Falcon 9 rocket launches the company's latest batch of Starlink satellites from Cape Canaveral Space Force Station on August 26, 2023. SpaceX

Update: Liftoff of Falcon 9 with 22 Starlink satellites at 9:05 p.m. EDT Saturday from Cape Canaveral Space Force Station in Florida visible by fans at both Daytona International Speedway at the Coke Zero Sugar 400 and at Exploria Stadium in Orlando during the Orlando City MLS soccer game. The successful launch was followed shortly by a booster landing aboard a drone ship stationed in the Atlantic Ocean. Read our full post-launch story here.

Follow live updates below as SpaceX targets 9:05 p.m. EDT Saturday night for the launch of a Falcon 9 rocket and 22 Starlink internet satellites from Launch Complex 40 at Cape Canaveral Space Force Station in Florida.

Space Force forecasters last reported weather conditions to be 95% ""go.""

After liftoff and a flight toward the southeast, Falcon 9 will fly along a southeastern trajectory and land on the Just Read the Instructions drone ship in the Atlantic Ocean.

If schedules hold, this would become the Space Coast's 44th launch this year and the second to liftoff from the Space Coast in less than 18 hours following this morning's early Crew-7 launch to the International Space Station from Kennedy Space Center.

For the latest, visit floridatoday.com/launchschedule.

Updates from Saturday's event below:

9:14 p.m. EDT: The Falcon 9 first stage has landed aboard the Just Read the Instructions drone ship, completing its 3rd mission.

Falcon 9’s first stage has landed on the Just Read the Instructions droneship pic.twitter.com/7AXYbB63Vw — SpaceX (@SpaceX) August 27, 2023

— Jamie Groh

9:05 p.m. EDT: SpaceX launched a Falcon 9 with 22 Starlinks satellites from Cape Canaveral Space Force Station. This marks the second flight of the day for the company, which just under 18 hours ago launched NASA's Crew-7 mission with three astronauts and one cosmonaut to the International Space Station from nearby Kennedy Space Center. That mission is expected to dock at the space station at 8:50 a.m. EDT Sunday after a 30-hour trip in orbit.

Here's the post-launch timeline:

T-plus:

00:01:12 minutes Max Q (moment of peak mechanical stress on the rocket)

00:02:30 minutes 1st stage main engine cutoff (MECO)

00:02:33 minutes 1st and 2nd stages separate

00:02:40 minutes 2nd stage engine starts (SES-1)

00:03:07 minutes Fairing deployment

00:06:13 minutes 1st stage entry burn begins

00:06:33 minutes 1st stage entry burn ends

00:08:05 minutes 1st stage landing burn begins

00:08:28 minutes 1st stage landing

00:08:44 minutes 2nd stage engine cutoff (SECO-1)

00:54:06 minutes 2nd stage engine starts (SES-2)

01:05:15 Starlink satellites deploy

— Jamie Groh

8:55 p.m. EDT: Now inside 10 minutes until liftoff of the Falcon 9 with 22 Starlink satellites from Cape Canaveral Space Force Station at 9:05 p.m. EDT. Here's a look at the last few remaining milestones to get through:

T-minus:

00:07:00 minutes Falcon 9 begins engine chill prior to launch

00:01:00 minute Command flight computer to begin final prelaunch checks

00:01:00 minute Propellant tank pressurization to flight pressure begins

00:00:45 seconds SpaceX Launch Director verifies go for launch

00:00:03 seconds Engine controller commands engine ignition sequence to start

00:00:00 Falcon 9 liftoff

— Jamie Groh

8:30 p.m. EDT: SpaceX has started loading kerosene and liquid oxygen into the Falcon 9 rocket's first stage at Launch Complex 40. Teams are still counting down to a 9:05 p.m. EDT liftoff. Weather conditions remain favorable.

Propellant load is underway for tonight’s Falcon 9 launch of 22 @Starlink satellites. Weather is 95% favorable and all systems are go for liftoff → https://t.co/bJFjLCiTbK — SpaceX (@SpaceX) August 27, 2023

— Jamie Groh

8:15 p.m. EDT: Here's a look at the countdown milestones left in tonight's mission:

T-minus:

00:38:00 minutes SpaceX Launch Director verifies go for propellant load

00:35:00 minutes RP-1 (rocket grade kerosene) loading begins

00:35:00 minutes 1st stage LOX (liquid oxygen) loading begins

00:16:00 minutes 2nd stage LOX loading begins

00:07:00 minutes Falcon 9 begins engine chill prior to launch

00:01:00 minute Command flight computer to begin final prelaunch checks

00:01:00 minute Propellant tank pressurization to flight pressure begins

00:00:45 seconds SpaceX Launch Director verifies go for launch

00:00:03 seconds Engine controller commands engine ignition sequence to start

00:00:00 Falcon 9 liftoff

— Jamie Groh

8:05 p.m. EDT: Now inside one hour to launch. All signs indicate that SpaceX is continuing to target 9:05 p.m. EDT this evening for liftoff of the Starlink 6-11 mission from Cape Canaveral Space Force Station. Tonight's flight will mark the third for this particular Falcon 9 first-stage booster. After flying a trajectory to the southeast, it will target a drone ship landing in the Atlantic Ocean. No local sonic booms with this mission.

— Jamie Groh

8/26/23 7:50 PM: We have activated our launch operations support team in preparation for the #SpaceX #Falcon9 launch. Window: 8:47-11:05 PM pic.twitter.com/qXDkhxw68B — Brevard EOC (@BrevardEOC) August 26, 2023

7:00 p.m. EDT: SpaceX teams are still counting down to launch of this Starlink mission, known as 6-11, from Launch Complex 40. A quick check of the weather shows conditions are favorable around the spaceport for an on-time liftoff tonight. Stay tuned for more frequent updates as we progress through countdown milestones.

— Jamie Groh

6:00 p.m. EDT: Good evening! Welcome to our live coverage of today's second mission to target liftoff from the Space Coast. SpaceX teams at Cape Canaveral Space Force Station are counting down to the liftoff of a Falcon 9 rocket with 22 Starlink satellites at 9:05 p.m. EDT.

Weather conditions were last reported to be 95% ""go."" If needed, launch teams have a window tonight that extends until 11:04 p.m. EDT.

Stay tuned for more frequent updates throughout the night as we get closer to the start of fueling, which should begin 38 minutes ahead of liftoff.

— Jamie Groh

Space is important to us and that's why we're working to bring you top coverage of the industry and Florida launches. Journalism like this takes time and resources. Please support it with a subscription here.","https://www.gannett-cdn.com/presto/2022/09/15/PBRE/cc2c1b04-afce-43b6-b8bb-c68821015690-SpaceX_Starlink_Falcon_.jpg?auto=webp&crop=839,472,x0,y362&format=pjpg&width=1200",https://www.floridatoday.com/story/tech/science/space/2023/08/26/updates-spacex-falcon-9-starlink-mission-cape-canaveral-space-force-florida/70623583007/,Science
['Joe Fisher'],2023-08-27 00:00:00,"SpaceX launches 5,000th Starlink satellite into orbit","A Falcon 9 rocket launches from Space Launch Complex 40 at Cape Canaveral Space Force Station in Florida, launching 22 Starlink satellites into low-earth orbit on Saturday. Photo courtesy of SpaceX/ Twitter

Aug. 27 (UPI) -- SpaceX has launched 5,000 Starlink satellites into orbit after sending 22 into space on Saturday night. A Falcon 9 rocket launched from Space Launch Complex 40 at Cape Canaveral Space Force Station in Florida at 9:05 p.m. EDT, Florida Today reports. It was the agency's second launch of the day. Advertisement

The first stage booster separated about 8 minutes after launch and landed on the Just Read the Instructions droneship in the Atlantic Ocean for recovery.

Falcon 9 launches 22 @Starlink satellites from Florida pic.twitter.com/b1Zf78Qzxn— SpaceX (@SpaceX) August 27, 2023

It was the booster's third launch and landing.

The 22 Starlink satellites were deployed into low-earth orbit about 65 minutes after launch, according to Space.com, following a second stage burn.

SpaceX has been approved to deploy 12,000 Starlink satellites and has requested clearance for an additional 30,000.

Starlink satellites deliver high-speed broadband access at relatively low latency compared to other satellite internet services, according to the company. Service is commercially available

Eighteen hours prior to the launch, NASA's Crew-7 mission launched from Launch Complex 39A at the Kennedy Space Center in Florida. The SpaceX Dragon, carrying a four-person crew, docked with the International Space Station at 9:16 a.m. EDT, Sunday.

Advertisement

The mission is slated for six months on the space station. During that time, the crew will conduct a variety of scientific experiments, demonstrations and maintenance.",https://cdnph.upi.com/sv/ph/og/i/4091693152302/2023/1/16931529432919/v1.5/SpaceX-launches-5000th-Starlink-satellite-into-orbit.jpg,https://www.upi.com/Science_News/2023/08/27/spacex-starlink-5000-satellites-falcon/4091693152302/,Science
['Ramish Zafar'],2023-08-27 04:43:52+00:00,SpaceX Might Miss Its Goal Of 100 Rocket Launches In 2023,"This is not investment advice. The author has no position in any of the stocks mentioned. Wccftech.com has a disclosure and ethics policy.

In less than a day after launching NASA's Crew 7 mission to the International Space Station (ISS), SpaceX flew its Falcon 9 rocket from the Cape Canaveral Space Force Station in Florida. The launch was SpaceX's 59th for 2023 and its 258th overall mission, indicating that it is unlikely that the firm will meet its self-set target of launching 100 rockets this year. SpaceX's Falcon 9 rocket was already vertical on the pad yesterday at the time of the Crew 7 launch, and if the company is to launch 100 missions this year, then it will have to launch one more mission this year and at least ten missions per month for the remainder of 2023.

SpaceX Has Launch Nearly As Many Launches In 2023 So Far As It Did In Full Year 2022

Even though SpaceX might not launch 100 missions this year, the firm has grown its launch cadence this year compared to the last. In 2022, the company had launched 61 missions, and with potentially two more launches left before August closes, it appears that SpaceX will have met its 2022 cadence by the end of this month.

A large portion of SpaceX's launch manifest is made of Starlink launches, and recent trends indicate that the firm will have to step up the pace of these launches, too. This is because the number of satellites that SpaceX launches with each mission has rapidly dropped since the firm finished building out the first generation portion of its constellation. The satellites part of the second generation constellation are significantly bigger than their predecessors and naturally take more space inside the Falcon 9 rocket.

SpaceX's plans for its second-generation constellation have penned in using Starship for the launches, and so far, there are few signs that the rocket will be operational by the end of this year.

The Falcon 9 lifted off from the Cape yesterday as part of SpaceX's latest Starlink launch. Image: SpaceX/X

The Falcon 9 lifted off at 9:05 pm local time and within a minute of the launch, it was traveling faster than the speed of sound. The booster for yesterday's mission was a relatively new one by SpaceX's standards, as it was flying for the third time. It was the booster's first Starlink flight. Before today's mission, the rocket had flown a satellite for the European Space Agency (ESA) and a private astronaut mission for Axiom Space.

SpaceX's Crew Dragon is on its way to the International Space Station (ISS) right now, and it is expected to dock at the station later today. The Crew Dragon is currently flying NASA's Crew 7 mission, and the launch took place yesterday after a day's delay. This delay took place because SpaceX had to verify all of the spaceship's valves due to some problems on a Cargo Dragon that came back to Earth earlier this year. Its journey to the station has been smooth so far, apart from a minor problem with one of its GPS sensors. These sensors are responsible for orienting the ship with the ISS, and more details about this anomaly should be clear once the Dragon approaches the ISS to dock.

SpaceX also conducted a static fire test of the Starship Super Heavy booster earlier this week. This was one of the most successful tests of the rocket so far, as all 33 of its Raptor engines successfully ignited. However, the test, which ran for a full duration of six seconds, still saw two Raptor engines shut down, indicating that SpaceX still faces some problems when handling close to three dozen rocket engines on a single rocket.",https://cdn.wccftech.com/wp-content/uploads/2023/08/SPACEX-FALCON-9-STARLINK-AUGUST-26-2023-LAUNCH-HEADER-scaled.jpeg,https://wccftech.com/spacex-might-miss-its-goal-of-100-rocket-launches-in-2023/,Science
[],,SpaceX launches another batch of Starlink satellites from Florida’s Space Coast,,https://i.ytimg.com/vi/R-1kywJgC98/maxresdefault.jpg,https://www.youtube.com/watch?v=R-1kywJgC98,Science
[],,Kennedy Space Center Visitor Complex,"A United Launch Alliance (ULA) Atlas V rocket is launching the SILENTBARKER/NROL-107 mission, a joint National Reconnaissance Office (NRO) and U.S. Space Force (USSF) capability to improve space domain awareness. The launch window opens at 8:34 AM and concludes at 9:32 AM.",https://www.kennedyspacecenter.com:443/-/media/DNC/KSCVC/Global-Images/favicon.ashx,,Science
['Jamie Groh'],2023-08-26 00:00:00,SpaceX's weekend launch doubleheader sets stage for ULA Atlas V liftoff Tuesday morning,"SpaceX's weekend launch doubleheader sets stage for ULA Atlas V liftoff Tuesday morning

Show Caption Hide Caption SpaceX Starlink 6-11 Mission from Cape Canaveral Space Force Station A SpaceX Falcon 9 rocket launches the company's latest batch of Starlink satellites from Cape Canaveral Space Force Station on August 26, 2023. SpaceX

The second of SpaceX's two Falcon 9 launches this week vaulted away from Cape Canaveral Space Force Station Saturday night, less than 18 hours after the liftoff of NASA's Crew-7 mission to the International Space Station from nearby Kennedy Space Center.

That mission was set to dock with the space station at 8:50 a.m. EDT Sunday after a 30-hour trip in orbit.

At 9:05 p.m. EDT, the 230-foot rocket packed with another batch of 22 Starlink internet satellites soared away from Launch Complex 40 on a southeasterly trajectory, skirting between the Florida coast and the Bahamas. It was visible across the state by fans at both Daytona International Speedway at the Coke Zero Sugar 400 and at Exploria Stadium in Orlando during the Orlando City MLS soccer game.

The rocket's first stage landed aboard the Just Read the Instructions drone ship about eight minutes after liftoff, completing its third mission to date.

Meanwhile, the Space Coast's next launch, a United Launch Alliance Atlas V slated for liftoff Tuesday morning, may have to contend with poor weather conditions. A storm system brewing off the southwest coast of Florida could impact the area by early week.

When's the next launch from Florida?

The next launch slated for liftoff from Florida's Space Coast is United Launch Alliance's second of the year.

Teams at the Cape's Launch Complex 41 are preparing an Atlas V rocket with a classified payload for the U.S. Space Force and National Reconnaissance Office to launch early next week.

The payload is part of the Space Force's Silent Barker satellite constellation network intended to provide space situational awareness, orbital surveillance, and tracking.

Liftoff of the NROL-107 mission is slated for 8:34 a.m. EDT, Tuesday, Aug. 29, that will arc over the Atlantic Ocean on an easterly trajectory.

Weather outlook iffy for next liftoff:

A weather report released Saturday by the Space Force's 45th Weather Squadron projected conditions to be 70% ""go"" for ULA's liftoff from the Cape Tuesday morning.

""An area of low pressure is currently developing in the northwest Caribbean Sea and will push northwards into the Gulf of Mexico early next week,"" the report said. ""While there is still some disagreement among the global models regarding the position, timing, and intensity of this potential storm, by Tuesday morning, most of the models have the system well to our southwest, somewhere in the southeastern Gulf.""

The primary concerns for launch day were listed at cumulus and anvil clouds around the spaceport, as well as a likelihood of some shower development. Conditions deteriorate to 35% ""go"" for a backup opportunity 24 hours later on Wednesday.

If schedules hold, this mission would become the Space Coast's 45th launch this year. Follow FLORIDA TODAY's Space Team live launch coverage beginning 90 minutes before liftoff.

NASA's SpaceX Crew-7: Falcon 9 soared from KSC early Saturday sending a crew of four to the International Space Station

Space Perspective: Company building balloons in Titusville to elevate tourists to the edge of space

What was the payload of Saturday's SpaceX launch?

Starlink is SpaceX's space-based internet service, primarily for hard-to-reach locations. The constellation, which operates about 340 miles above Earth, delivers coverage to most of North and South America, Europe, Japan, and Australia.

All told, the company has sent more than 5,000 of the flat-packed satellites to orbit since 2019.

Last year, SpaceX also inked a deal with cellular service provider T-Mobile to allow users to access Starlink internet services to send text messages. The plan, called ""Coverage Above & Beyond,"" is expected to be available to T-mobile customers by the end of this year.

For the latest updates, visit floridatoday.com/launchschedule.

Contact Jamie Groh at JGroh@floridatoday.com and follow her on X.com at @AlteredJamie.

Space is important to us and that's why we're working to bring you top coverage of the industry and Florida launches. Journalism like this takes time and resources. Please support it with a subscription here.

Launch Tuesday, August 29","https://www.gannett-cdn.com/authoring/authoring-images/2023/08/27/PBRE/70693097007-crb-082623-1-spacex.jpg?auto=webp&crop=1732,979,x0,y97&format=pjpg&width=1200",https://www.floridatoday.com/story/tech/science/space/2023/08/26/spacex-falcon-9-starlink-launch-saturday-crewed-space-station-mission-cape-canaveral-ksc-florida/70623621007/,Science
['Danielle Haynes'],2023-08-25 00:00:00,ULA rolls out Atlas V rocket for classified government launch at Cape Canaveral,"1/4

The United Launch Alliance Atlas V rocket with the National Reconnaissance Office payload, NROL-107 Silentbarker, rolls to Launch Complex 41 at the Cape Canaveral Space Force Station on Friday. Photo by Joe Marino/UPI | License Photo

Aug. 25 (UPI) -- United Launch Alliance rolled out an Atlas V rocket Friday in preparation for next week's planned launch of a classified space surveillance mission from Cape Canaveral Space Force Station in Florida. The ULA conducted Friday's movements in partnership with the U.S. Space Force and the National Reconnaissance Office. The NRO contracted ULA in 2019 to produce the Atlas V rocket and carry out mission integration, mission launch operations and other activities. Advertisement

The launch is scheduled to take place at 8:34 a.m. EDT on Tuesday.

""Our Atlas V rocket has arrived at its Cape Canaveral pad for Tuesday's launch of a new national security capability, called SILENTBARKER/NROL-107, that will advance our Space Domain Awareness against threats in orbit,"" ULA said in a statement on its website.

""Surveillance from space augments and overcomes existing ground sensor limitations with timely 24-hour above-the-weather collection of satellite metric data only possible with a space-based sensor and then communicates its findings to satellite operators, analysts, and other mission users.""

Because the mission is classified, the government hasn't provided many details about the contents of the payload or the scope of its capabilities.

Advertisement

The NRO describes Silentbarker/NROL-107 as ""a joint NRO and U.S. Space Force space domain awareness mission to meet Department of Defense and intelligence community space protection needs.""

The ULA has launched 17 Atlas V rockets as part of NRO missions, with Tuesday's planned event being the 18th and final from Cape Canaveral, according to the NRO. In addition to the powerful Atlas V rocket, the mission will include the Centaur upper stage, a liquid hydrogen/liquid oxygen-fueled vehicle that produces 106 kilo-Newtons of thrust.",https://cdnph.upi.com/sv/ph/og/upi/8701692997593/2023/1/f81deecace99c6526e05e4851c7849fc/v1.5/ULA-rolls-out-Atlas-V-rocket-for-classified-government-launch.jpg,https://www.upi.com/Science_News/2023/08/25/ULA-NRO-silentbarker/8701692997593/,Science
"['Mike Wall', 'Senior Space Writer', 'Social Links Navigation']",2023-08-25 20:30:56+00:00,Atlas V rocket rolled to pad for 'Silent Barker' spysat launch (photos),"A United Launch Alliance Atlas V rocket rolls to its launch pad at Cape Canaveral Space Force Station on Aug. 25, 2023.

United Launch Alliance (ULA) rolled its Atlas V rocket to the pad today (Aug. 25) to gear up for the launch of a hush-hush mission next week.

The Atlas V made the trek to Space Launch Complex-41 at Florida's Cape Canaveral Space Force Station, ULA representatives announced today via X (formerly Twitter).

The Atlas V is carrying a payload for ""Silent Barker,"" a joint mission of the U.S. Space Force and the National Reconnaissance Office (NRO) that's scheduled to launch on Tuesday (Aug. 29) at 8:34 a.m. EDT (1234 GMT). You can watch the liftoff live here at Space.com when the time comes, courtesy of ULA.

Related: Declassified US spy satellite photos & designs (gallery)

Another look at the Atlas V, which is scheduled to launch the Silent Barker mission for the U.S. Space Force and the National Reconnaissance Office on Aug. 29, 2023. (Image credit: ULA)

The Silent Barker mission, also known as NROL-107, aims to provide ""the capability to search, detect and track objects from a space-based sensor for timely custody and event detection,"" according to a ULA mission description.

""Silent Barker/NROL107 will strengthen the NRO's ability to provide a wide range of timely intelligence information to national decision makers, warfighters and intelligence analysts to protect the nation's vital interests and support humanitarian efforts worldwide,"" the description adds.

That's pretty much all we know about the mission. The lack of detail isn't surprising; it's the norm for the NRO, which builds and operates the United States' fleet of spy satellites.

Silent Barker will be the 18th Atlas V launch for the U.S. National Reconnaissance Office. (Image credit: ULA)

The Atlas V has 97 launches under its belt to date, all of which have been successful. Seventeen of those flights have lofted NRO payloads, ULA representatives said via X today.

The workhorse rocket has launched a number of NASA spacecraft as well, including the Curiosity and Perseverance Mars rovers, the OSIRIS-REx asteroid-sampling probe and New Horizons, which performed the first-ever flyby of Pluto in July 2015.

ULA plans to phase out the Atlas V, however; the company is developing a new rocket called Vulcan Centaur, which will replace its older counterpart.",https://cdn.mos.cms.futurecdn.net/7KYeftzRjNZWXWVh2SiruZ-1200-80.jpg,https://www.space.com/atlas-v-rocket-rollout-silent-barker-photos,Science
['Keith Cowing'],2023-08-27 18:39:06+00:00,NASA Shares First Images from US Pollution-Monitoring Instrument,"This image shows nitrogen dioxide levels over the DC/Philadelphia/New York region at 12:14 p.m. on August 2, as measured by TEMPO. Credits: Kel Elkins, Trent Schindler, and Cindy Starr/NASA’s Scientific Visualization Studio NASA

On Thursday, NASA released the first data maps from its new instrument launched to space earlier this year, which now is successfully transmitting information about major air pollutants over North America. President Biden and Vice President Harris believe that all people have a right to breathe clean air. Data from the TEMPO mission will help decision makers across the country achieve that goal and support the Biden Administration’s climate agenda — the most robust climate agenda in history.

From its orbit 22,000 miles above the equator, NASA’s TEMPO, or Tropospheric Emissions: Monitoring of Pollution, is the first space-based instrument designed to continuously measure air quality above North America with the resolution of a few square miles.

“Neighborhoods and communities across the country will benefit from TEMPO’s game-changing data for decades to come,” said NASA Administrator Bill Nelson. “This summer, millions of Americans felt firsthand the effect of smoke from forest fires on our health. NASA and the Biden-Harris Administration are committed to making it easier for everyday Americans and decisionmakers to access and use TEMPO data to monitor and improve the quality of the air we breathe, benefitting life here on Earth.”

Observations by TEMPO will significantly improve studies of pollution caused by rush-hour traffic, the movement of smoke and ash from forest fires and volcanoes, and the effects of fertilizer application on farmland. In addition, TEMPO data will help scientists evaluate the health impacts of pollutants and aid in the creation of air pollution maps at the neighborhood scale, improving understanding of disparities in air quality within a community. Data will be shared with partner agencies that monitor and forecast air quality, such as the Environmental Protection Agency and the National Oceanic and Atmospheric Administration.

Launched in April aboard a Maxar Intelsat 40e satellite on a SpaceX Falcon 9 rocket, TEMPO makes hourly daytime scans of the lower atmosphere over North America from the Atlantic Ocean to Pacific coast and from roughly Mexico City to central Canada. The primary instrument is an advanced spectrometer that detects pollution normally hidden within reflected sunlight.

The science mission is a collaboration between NASA and the Smithsonian Astrophysical Observatory (SAO) in Cambridge, Massachusetts.

The first pollution maps released by NASA from the mission show concentrations of nitrogen dioxide gas from pollution around cities and major transportation arteries of North America. TEMPO measures sunlight reflected and scattered off Earth’s surface, clouds, and atmosphere. Gases in the atmosphere absorb the sunlight, and the resulting spectra are then used to determine the concentrations of several gases in the air, including nitrogen dioxide.

The visualizations show six scans made between 11:12 a.m. and 5:27 p.m. EDT on Aug. 2. Closeup views focus on the southwestern U.S. from Los Angeles to Las Vegas; from central and eastern Texas to New Orleans; and the Interstate 95 corridor between New York and Washington. The data were gathered during TEMPO’s “first light” period from July 31 to Aug. 2, when mission controllers opened the spectrometer to look at the Sun and Earth and start a variety of tests and solar calibrations.

“TEMPO is beginning to measure hourly daytime air pollution over greater North America,” said Kelly Chance, SAO senior physicist and TEMPO principal investigator. “It measures ozone, nitrogen dioxide, formaldehyde, aerosols, water vapor, and several trace gases. There are already almost 50 science studies being planned that are based around this new way to collect data.”

The TEMPO instrument was built by Ball Aerospace and integrated with the Maxar-built Intelsat 40e. Since launch, teams from NASA, Ball Aerospace, and SAO have been checking and calibrating the satellite’s systems and components. The instrument will begin full operations in October, collecting hourly daytime scans, the first instrument to observe pollution over North America in this way.

“We are excited to see the initial data from the TEMPO instrument and that the performance is as good as we could have imagined now that it is operating in space,” said Kevin Daugherty, TEMPO project manager at NASA’s Langley Research Center in Hampton, Virginia. “We look forward to completing commissioning of the instrument and then starting science research.”

TEMPO is part of NASA’s Earth Venture Instrument program, which includes small, targeted science investigations designed to complement NASA’s larger research missions. The instrument also forms part of a virtual constellation of air pollution monitors for the Northern Hemisphere which also includes South Korea’s Geostationary Environment Monitoring Spectrometer and ESA’s (European Space Agency) Sentinel-4 satellite.

For more information on NASA’s Earth science research, visit: https://www.nasa.gov/earth",https://media2.spaceref.com/wp-content/uploads/2023/08/27143813/NASAShares.jpg,https://spaceref.com/newspace-and-tech/nasa-shares-first-images-from-us-pollution-monitoring-instrument/,Science
[],,NASA releases first pollution map images,,https://i.ytimg.com/vi/9IeSJ5yxXkM/hqdefault.jpg,https://www.youtube.com/watch?v=9IeSJ5yxXkM,Science
['Amal Jos Chacko'],2023-08-27 12:59:24+00:00,NASA reveals first images of US air quality and pollution,"NASA's groundbreaking mission to monitor air pollutants from space, TEMPO (Tropospheric Emissions: Monitoring of Pollution), has started bearing fruit with the release of its first data maps, according to a press release by the agency.

Launched earlier this year on a SpaceX Falcon 9 rocket, TEMPO is already transmitting vital information about major air pollutants over North America, marking a significant step towards achieving clean air for all citizens.

President Biden and Vice President Harris have strongly advocated for improved air quality as a fundamental right, aligning with TEMPO's mission to support the administration's ambitious climate agenda.

Game-changing insights

Perched at an orbit of 22,000 miles above the equator, TEMPO holds the distinction of being the inaugural space-based instrument tailored to continually gauge air quality across North America at a resolution of a few square miles.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/27/image/jpeg/6hg2hpUW2jZLCZGn2bEtlyXMv6U7EAAQjTKXKtp1.jpg,https://interestingengineering.com/health/nasa-reveals-first-images-of-us-air-quality-and-pollution,Science
"['Georgina Torbet', 'August']",2023-08-26 16:56:43-07:00,Pollution-tracking NASA satellite shares its first images,"A new NASA satellite designed to monitor pollution from space has shared its first images, showing how it will be able to track air pollution across North America. The TEMPO, or Tropospheric Emissions: Monitoring of Pollution, instrument was launched earlier this year in April and has been observing the Earth from its orbit 22,000 miles above the equator.

TEMPO is able to measure air pollution with high resolution, down to a few square miles, and can show changes in pollution occurring in short time frames. That will allow it to gather data on factors affecting air pollution like rush hour traffic or smoke from wildfires.

Recommended Videos

“Neighborhoods and communities across the country will benefit from TEMPO’s game-changing data for decades to come,” said NASA Administrator Bill Nelson in a statement. “This summer, millions of Americans felt firsthand the effect of smoke from forest fires on our health. NASA and the Biden-Harris Administration are committed to making it easier for everyday Americans and decision-makers to access and use TEMPO data to monitor and improve the quality of the air we breathe, benefitting life here on Earth.”

The first images from TEMPO are available in a series of visualizations, including two pollution maps showing the region around Los Angeles between midday and 4 p.m. on the same day. The maps below show the levels of nitrogen dioxide in the air on August 2, with darker colors representing higher levels. Other visualizations show pollution around major urban areas such as New York and Washington or Houston and New Orleans.

“TEMPO is beginning to measure hourly daytime air pollution over greater North America,” said TEMPO principal investigator Kelly Chance. “It measures ozone, nitrogen dioxide, formaldehyde, aerosols, water vapor, and several trace gases. There are already almost 50 science studies being planned that are based around this new way to collect data.”

This early data was collected as part of the calibration process for the primary TEMPO instrument, a spectrometer that measures pollution by seeing what wavelengths of light are absorbed by gases in the atmosphere. In its full operations, the satellite will take hourly scans during daylight hours, covering an area from central Canada down through the U.S. and down to Mexico City.

Editors' Recommendations",https://www.digitaltrends.com/wp-content/uploads/2023/08/TEMPO_AutoB1.jpeg?resize=1200%2C630&p=1,https://www.digitaltrends.com/space/tempo-pollution-first-data/,Science
"['Https', 'Gothamist.Com Staff Giulia-Heyward']",,NY native leads latest NASA trip to International Space Station,"A native New Yorker and NASA astronaut was among the SpaceX crew members who docked at the International Space Station on Sunday.

The weekend space trip was the first for Long Island native Jasmin Moghbeli. As the trip’s mission commander, Moghbeli “is responsible for all phases of the flight, from launch to re-entry,” NASA said on Sunday.

The SpaceX Crew-7 mission to the ISS – a multi-national lab nearly 300 miles from the planet and situated in Earth’s lower orbit – launched at 3:27 a.m. on Saturday. NASA announced the following day that its crew successfully docked at the site on Sunday at 8:39 a.m., according to a release from the agency.

NASA selected Moghbeli as an astronaut just six years earlier, in 2017. Moghbeli — who studied at M.I.T., in Cambridge, and the Naval Postgraduate School, in California, also worked as a helicopter and Marine Corps test pilot.",https://cms.prod.nypr.digital/images/340388/fill-1200x650|format-webp|webpquality-85,https://gothamist.com/news/ny-native-leads-latest-nasa-trip-to-international-space-station,Science
['Dandan Zou'],2023-08-27 17:42:55.435000+00:00,Long Island's Jasmin Moghbeli is aboard the International Space Station after successful SpaceX docking,"Long Island's Jasmin Moghbeli and three other astronauts of NASA’s SpaceX Crew-7 floated aboard the International Space Station Sunday morning, marking the beginning of a long-dreamed-of trip to space for the Baldwin-raised pilot.

“It's so good to see all your smiling faces,” said Moghbeli, surrounded by 10 other crew members crammed into three rows inside the station. “As you know, we've been training together for a while for this exact moment where we could join you and continue the amazing work that's done on the International Space Station.”

Moghbeli, a Marine pilot serving as commander, is joined on the six-month mission by the European Space Agency’s Andreas Mogensen, Japan’s Satoshi Furukawa and Russia’s Konstantin Borisov. The international crew of four joined the space station’s Expedition 69 crew of seven.

It’s Moghbeli’s first trip to space.

The flight from the Kennedy Space Center to the weightless station took nearly 30 hours after their spacecraft lifted off before dawn Saturday. But for Moghbeli, her journey to space began much earlier.

Get the Breaking News newsletter! Get the latest breaking news as it happens. By clicking Sign up, you agree to our privacy policy.

Born in Germany to parents who fled Iran after its 1979 revolution, Moghbeli, in a sixth-grade book report, wrote about Soviet cosmonaut Valentina Tereshkova. In 1963, Tereshkova was the first woman to go to space.

With her mother’s help, Moghbeli also made a makeshift spacesuit constructed of white windbreakers and a plastic container that served as the helmet.

“I still wake up and go, 'I can’t believe that I’m actually a NASA astronaut,’” Moghbeli said during a trip back to Lenox Elementary School and Baldwin High School in March.

Now dressed in her blue flight suit, Moghbeli flashed big smiles and high-fived with crewmates during the nine-minute-long welcome ceremony after SpaceX Dragon, the spacecraft that carried the astronauts, docked onto the station at 9:16 a.m. The crew on board greeted the new members with smiles and handshakes after hatches opened at 10:58 a.m. to allow Crew-7 to float in.

“I think we represent a good crew to be coming to the International Space Station,” Moghbeli said in her remarks, which were livestreamed through NASA’s website.

The number of crew members aboard the space station increased to 11 Sunday until the four Crew-6 members return to Earth in a few days, NASA said.

Crew-7 will conduct more than 200 science experiments and technology demonstrations to prepare for missions to the Moon, Mars and beyond, NASA said.

Moghbeli graduated from the Massachusetts Institute of Technology with a bachelor’s degree in aerospace engineering. She earned a master’s degree of science in aerospace engineering from the Naval Postgraduate School in Monterey, California, according to her bio on NASA’s website.

She was also a helicopter and Marine Corps test pilot, logging more than 150 combat missions and 2,000 hours of flight time, NASA said.

Even in space, Moghbeli keeps her Long Island alma mater close. She said in March that three Lenox items — a ""Lenox strong"" bracelet, a pin about Lenox pride and a drawing from a fifth-grader — would be among the roughly shoebox-sized personal items she’s allowed to carry with her.",https://cdn.newsday.com/ace/c:ZDMzNjU4NWQtMWUyZC00:N2RiMjVj/landscape/1280,https://www.newsday.com/news/nation/space-x-dragon-international-space-station-astronaut-qew1oufb,Science
[],,MIT alum serving as commander on latest SpaceX mission,,https://i.ytimg.com/vi/5r9tfcfVUDI/maxresdefault.jpg,https://www.youtube.com/watch?v=5r9tfcfVUDI,Science
[],,Life on Mars was discovered 50 years ago and then eradicated,"While the ongoing quest to detect life on Mars continues, NASA's plan to retrieve samples from the planet is set to conclude in the early next decade. However, one scientist proposes an intriguing notion: that we potentially encountered life on the Red Planet nearly five decades ago, an encounter that may have ended tragically.

Before the Curiosity rover's historic journey, two preceding landers played a vital role. NASA's Viking program, launched in 1975, not only offered the first glimpses of Mars' landscape but also performed biological analyses of its soil, with the primary aim of unearthing indications of life.

A paradigm shift

The data from these probes prompted a paradigm shift among Earth's scientific community regarding the presence of water on Mars. The explorations unveiled numerous geological formations consistent with the effects of substantial water flows. Vast river channels were revealed in various regions, and evidence emerged of catastrophic water surges that breached dams, carved extensive valleys, gouged rock formations, and traversed thousands of kilometers. Extensive networks of branching channels and streams were prevalent across the southern hemisphere, underscoring the likelihood of past rainfall on Mars. Notably, the slopes of Martian volcanoes bore resemblances to those in Hawaii, hinting at their prior exposure to rain. Certain craters even displayed characteristics akin to impacts on muddy terrain.

The experiments

Nevertheless, a series of experiments yielded perplexing outcomes that confounded scientists. The landers conducted three distinct experiments. The first produced affirmative results hinting at metabolic processes. However, the adverse effects of the subsequent two experiments, which failed to detect organic substances, led researchers to speculate that the initial positive result might have been due to non-biological chemical reactions. In simpler terms, the first experiment detected traces of organic materials combined with chlorine, likely contaminants inadvertently transported from Earth.

Another aspect of the experiment involved introducing water infused with nutrients and radioactive carbon (carbon-14) to the Martian soil. The hypothesis was that potential microorganisms on Mars would consume the nutrients and release radioactive carbon as a gas. Although the initial experiment indicated this radioactive gas's emission (absent in a control experiment), the remaining results remained inconclusive. According to an explanation on the scientific platform ""iflscience,"" the presence of bacteria should have resulted in increased gas production with additional nutrient injections and prolonged incubation. However, successive injections failed to trigger more gas emissions. The likely culprit for the initial positive reading was perchlorate, a compound utilized in rocket fuel, which could have altered nutrient processing.

The other theory

Yet, an alternative theory exists. Professor Dirk Schulz-McKoch, an authority on planetary habitation and astrobiology at the Technical University of Berlin, posits that including water in the experiment might have been an oversight, potentially leading to the demise of the very bacteria being sought.

In a June publication in BigThink magazine, he cites Earth-based life thriving in extreme environments, such as bacteria within salt rocks that draw moisture from the air. Submerging these bacteria in water could prove fatal, potentially explaining the absence of radioactive gas detection despite additional nutrient injections. Prof. Schultz-McKoch had previously proposed the possibility of Martian life containing hydrogen peroxide within their cells. In a 2007 study, he outlined the advantages of such a configuration for Martian life, including a low freezing point, a source of oxygen, and hygroscopicity.

He suggests, ""If we consider the hypothesis that Martian life evolved to incorporate hydrogen peroxide into its cells, it could elucidate the outcomes of the Viking program's experiments."" He adds, amusingly, that the gas chromatograph mass spectrometer subjected samples to heating before analysis. ""If Martian cells contained hydrogen peroxide, this could have proven fatal. Additionally, it might have triggered a reaction between the hydrogen peroxide and organic molecules, generating substantial carbon dioxide—precisely what the device detected.""

Although speculative, this notion posits that humanity possibly encountered life on Mars nearly five decades ago, inadvertently terminating it shortly after the discovery.","https://images.jpost.com/image/upload/f_auto,fl_lossy/c_fill,g_faces:center,h_407,w_690/549950",https://www.jpost.com/omg/article-756389,Science
['Deseret Digital Media'],,Scientists solve the genetic puzzle of men,"Scientists have taken an important step forward in understanding the human genome — our genetic blueprint — by fully deciphering the enigmatic Y chromosome present in males. (Phil Noble, Reuters)

Estimated read time: 3-4 minutes

WASHINGTON — Scientists have taken an important step forward in understanding the human genome — our genetic blueprint — by fully deciphering the enigmatic Y chromosome present in males, an achievement that could help guide research on infertility in men.

Researchers on Wednesday unveiled the first complete sequence of the human Y chromosome, which is one of the two sex chromosomes — the X chromosome being the other — and is typically passed down from male parent to male offspring. It is the last of the 24 chromosomes — threadlike structures that carry genetic information from cell to cell — in the human genome to be sequenced.

People have a pair of sex chromosomes in each cell. Males possess one Y and one X chromosome while females have two X chromosomes, with some exceptions.

The Y chromosome's genes help govern crucial reproductive functions including sperm production, formally called spermatogenesis, and are even involved in cancer risk and severity. But this chromosome had proven difficult to crack owing to its exceptionally complex structure.

""I would credit new sequencing technologies and computational methods for this,"" said Arang Rhie, a staff scientist at the U.S. National Human Genome Research Institute and lead author of a research paper detailing the achievement in the journal Nature.

""It finally provides the first complete view of a Y chromosome's code, revealing more than 50% of the chromosome's length that was previously missing from our genome maps,"" said University of California, Santa Cruz biomolecular engineering professor and study co-author Karen Miga, co-leader of the Telomere-to-Telomere consortium behind the research.

The complete X chromosome sequence was published in 2020. But until now, the Y chromosome part of the human genome had contained big gaps.

""This is especially important because the Y chromosome has been traditionally excluded from many studies of human diseases,"" UCSC genomicist and study co-author Monika Cechova said.

""The Y chromosome is the smallest and the fastest-evolving chromosome in the human genome, and also the most repetitive, meaning that its DNA contains stretches of DNA repeated many times over,"" Cechova added.

The work revealed features of medically relevant regions of the Y chromosome including a stretch of DNA — the molecule that carries genetic information for an organism's development and functioning — containing several genes involved in sperm production. The new fuller understanding of the Y chromosome's genes offers promise for practical applications including in fertility-related research, according to the researchers.

""Many of these genes are important for fertility and reproduction, and especially spermatogenesis, so being able to catalog normal variation as well the situations when, for example, azoospermia (an absence of sperm in semen) occurs, could be helpful for IVF (in vitro fertilization) clinics as well as further research into activity of these genes,"" Cechova said.

Geneticist Karen Miga is seen at a laboratory, used in research involving the human Y chromosome, at the University of California, in Santa Cruz, Calif., Feb. 10, 2022. (Photo: Carolyn Lagattuta via Reuters)

In addition to identifying some additional Y chromosome genes, the researchers found that some DNA from the chromosome had been mistaken in previous studies as bacterial in nature.

Scientists continue to broaden the understanding of human genetics. A first accounting of the human genome was unveiled in 2003. The first complete human genome — albeit with the Y chromosome partial — was published last year. In May, researchers published a new version of the genome that improved on its predecessor by including a rich diversity of people to better reflect the global population of 8 billion.

Fully sequencing the Y chromosome adds to this.

""We now have a recipe on how to assemble the Y chromosome fully, which, while expensive at the moment, can translate into personalized genomics in the future,"" Cechova said.

×

Most recent Science stories

Related topics Science",https://img.ksl.com/slc/2944/294439/29443996.JPG?filter=kslv2/responsive_story_lg,https://www.ksl.com/article/50715428/scientists-solve-the-genetic-puzzle-of-men,Science
[],,"India makes it to the moon, 'Y' chromosome fully sequenced and more | Science Buzz",,https://i.ytimg.com/vi/L5AzgrKEl4Q/hqdefault.jpg,https://www.youtube.com/watch?v=L5AzgrKEl4Q,Science
[],2023-08-27 13:39:03.018820+00:00,Eureka: Scientists decode mysterious male Y chromosome,"American scientists have successfully managed to decode the male Y chromosome, marking a crucial advancement that could pave the way for important discoveries about diseases, fertility issues, and more. The researchers announced this milestone in an article published last week in the Nature Scientific Journal.

<< Follow Ynetnews on Facebook | Twitter | Instagram | TikTok >>

More stories:

The Y chromosome is one of the two sex chromosomes, alongside the X chromosome. It is passed from father to son and is the last of the chromosome pairs present in our bodies. Each person has a pair of sex chromosomes in every cell. Females have a pair of X chromosomes, while males have the XY pair. Abnormal combinations of chromosomes, due to birth defects, result in unique genetic variations.

4 View gallery ( Photo: Shutterstock )

The Y chromosome’s genes are responsible for crucial functions, including sperm production, and they’re also involved in the risk of developing cancer and in its severity. Over the years, the Y chromosome has proven challenging to study due to its intricate structure, and until a few years ago, more than half of its genes remained unidentified.

In 2020, the complete X chromosome sequence was published. However, so far, efforts to sequence the Y chromosome have faced significant gaps in knowledge. The complexity of unraveling the structure of the male chromosome has led to limited research on diseases in humans.

""The Y chromosome is the smallest and the fastest-evolving chromosome in the human genome, and also the most repetitive, meaning that its DNA contains stretches of DNA repeated many times over,"" explained Monika Cechova, a geneticist specializing in genomics from the University of California’s UCSC Genomics Institute.

""Many of these genes are important for fertility and reproduction, and especially spermatogenesis, so being able to catalog normal variation as well the situations when, for example, azoospermia (an absence of sperm in semen) occurs, could be helpful for IVF (in vitro fertilization) clinics as well as further research into activity of these genes,"" she added.

4 View gallery ( Photo: Shutterstock )

The research was led by Monika Cechova, along with Karen Miga, an assistant professor of bio-molecular engineering from the T2T collaborative research group, and Arang Rhie, a member of the Institute for Human Genomic Research in the United States.

Since 2003, when the complete human genome was first revealed, excluding parts of the Y chromosome, scientists have continued to strive to expand our understanding of human genetics.

Back in May, an updated map of the human genome was published, now encompassing a more diverse range of individuals across the globe and providing a more accurate reflection of the world's population, which amounts to approximately eight billion people.

The Human Genome Project began in 1990, initiated by the U.S. Department of Energy and the National Institutes of Health in the United States. In 2001, a draft of the genome was published, and after five years, the final version was completed, featuring Chromosome Number 1, the last of the 23 pairs of chromosomes found in every cell.

4 View gallery ( Photo: Shutterstock )

The ""Book of Life,"" or by its scientific name, the Human Genome Project - marked the beginning of a growing wave of personalized medicine approaches. These aim to examine genetic changes and predispositions within body cells, thereby tailoring personalized treatments. Genome mapping also enables the development of tests for faster disease diagnosis, even before birth.

One of the surprising outcomes of the project was the discovery of a lower number of genes in the human genome than initially expected. While estimates previously suggested around 80,000 to 100,000 genes, containing approximately three billion pairs of nucleotides (encodings on DNA), it was found the human genome contains only 20,000 to 25,000 genes, close to that of a worm's genome.

""Not long ago, we finished mapping the entire human genome, and the completion of the Y chromosome fills in the missing pieces,"" explained Prof. Idit Maya, Director of the Neuropsychiatric Genetic Services and Director at the Rabin Medical Center.

4 View gallery ( Photo: Shutterstock )

""Understanding the sequence, which we thought we had completed 20 years ago, allows us first and foremost to understand what’s considered normal. This will enable us to find causes for diseases and protect ourselves against their symptoms or risk factors.”

Photo: Rabin Medical Center

“We know that there’s no universal genetic sequence, as each of us differs from one another by 0.01%. But changing just 10,000 DNA sequences out of the six billion we have is enough to make a significant difference and cause a defect or disease,” she added.",https://ynet-pic1.yit.co.il/picserver5/crop_images/2023/08/26/Bk11c75EPph/Bk11c75EPph_0_30_1000_563_0_large.jpg,https://www.ynetnews.com/health_science/article/hjwdr9oa2,Science
[],,Scientists fully sequence human Y chromosome for the first time | Latest News | WION,,https://i.ytimg.com/vi/YXRCbY2jtYo/maxresdefault.jpg,https://www.youtube.com/watch?v=YXRCbY2jtYo,Science
['Posted'],,Atoms Aren't Empty,"Can you explain quantum mechanics to me?Well, this glass, this drink, this counter top, uhh.. our bodies, all of it. It's mostly empty space. Groupings of tiny energy waves bound together.By what?Forces of attraction strong enough to convince us [that] matter is solid, to stop my body passing through yours.Flash forward to 2023, where Mario Barbatti is a theoretical chemist and physicist researching light and molecule interactions. He's also a professor of chemistry at Aix Marseille University in France. Writing this week for Aeon, Barbatti argues that "" there are no empty spaces within the atom ""The empty atom picture is likely the most repeated mistake in popular science.""",https://a.fsdn.com/sd/topics/science_64.png,https://science.slashdot.org/story/23/08/26/234246/atoms-arent-empty,Science
"['David Pogue', 'David Pogue Is A Six-Time Emmy Winner For His Stories On', 'Cbs Sunday Morning', ""Where He'S Been A Correspondent Since He'S Also A New York Times Bestselling Author"", 'A Five-Time Ted Speaker', 'Host Of Nova Science Specials On Pbs. For Years', 'He Wrote A New York Times Tech Column Every Week', 'For Years', 'A Scientific American Column Every Month.']",,The science and art of lightning,"It's not easy to photograph something that's visible for only a few millionths of a second. So, when Arizona photographer Lori Bailey is tracking a lightning storm, she relies on sensors for her cameras: ""'Cause Lori's brain is just too slow to say, 'There's the lightning!'"" she said.

But there's more to this profession than automated camera triggers and a lot of patience. You also need luck. She said, ""You can do everything right and still not have the cards fall in your favor.

""I have to admit, I enjoy feeling that atmospheric energy when you get close to lightning. It's kind of a natural high, you know, when the bolts are striking and they're really close.""

When conditions do go her way, the results (which she posts online) are spectacular.

Beautiful and dangerous, lightning bolts are one of nature's most captivating and misunderstood phenomena. Lori Bailey

Inside a storm cloud, millions of tiny ice crystals collide with slushy hail-like droplets. The ice crystals blow upward with a positive charge; the slush droplets drift downward with a negative charge. Eventually, the charges equalize in a bolt of lightning. It usually stays inside the cloud, or hops from cloud to cloud. But the bolts that most interest people are the ones that shoot down to the ground.

Or seem to. Phillip Bitzer, a lightning physicist at the University of Alabama at Huntsville, said, ""We talk about misconceptions – does lightning go up or down? And it starts with stuff that comes out of the cloud, but that stuff that comes out of the cloud, it's so dim, you don't make it out with your eye. The part that you see actually comes from the ground and goes up to the cloud.""

The lightning bolt is about the width of your thumb, as bright as a hundred million light bulbs, and five times as hot as the surface of the sun. ""It will superheat the air right around it,"" Bitzer said, ""and eventually that superheat will cool off and relax into this acoustical wave that we all know as thunder. So, you can't have thunder without the lightning.""

We asked Bitzer about some traditional lightning tropes. Like, ""Lightning never strikes twice in the same place""? ""So, it absolutely does,"" he said. ""And often what will happen is a single lightning flash, it can hit three to five times in the same place.""

Or, ""Lightning always hits the tallest point""? ""That's another misnomer,"" he said. ""It doesn't have to hit the tallest object. Lightning has already traveled a couple of miles from the cloud to the ground. At that point, it's going to go where it wants to go.""

Or that lightning strikes are rare (almost as rare as winning the lottery)? ""There's a lot of lightning that happens,"" Bitzer said. ""Around 45 times every second around the world, you'll get lightning.""

All told, that's about 1.4 billion bolts hitting the Earth each year – numbers that are expected to rise as the planet warms. And about 250,000 times a year, lightning hits people.

In 2015, a sudden storm interrupted a school soccer game in North Carolina. Teacher Shana Turner sought shelter in the doorway of a shed. But when lightning struck a nearby light pole, millions of volts coursed through the ground and into her body. ""I remember the sound,"" she said. ""It just sounded like it was a bomb going off. It was almost deafening. In my vision, [it] was slow motion.""

Like the vast majority of human lightning strikes, it was an indirect hit. Turner was thrown to the ground. ""Within about a minute, my arm, it felt like it was boiling, in my arm. It eventually went to where my feet were tingling.""

Lightning strikes often lead to memory issues, heart problems, and even personality changes; after all, your brain and heart are electrical systems. Turner said that, within the first couple of weeks of class, she couldn't remember some of her students' names. ""There was one instance where I went to call on a student's name and I couldn't come up with it,"" she said. ""So, I just turned to the board and, you know, tears rolling – I was trying to keep it away so my students couldn't see it, trying to choke it back. And he came up to me and he hugged me and he said, 'You can call me anything you want.'""

There wasn't much doctors could do. ""All I kept hearing was, 'This is the strangest thing I've ever seen,' or, 'What you're describing doesn't make sense,'"" she said.

Eventually, Turner found a group of lightning survivors on Facebook. ""That's when I started to figure out that I wasn't alone,"" she said. ""I wasn't the only one having these symptoms. I wasn't crazy.""

The group gets together twice a year, and Turner has never missed a meeting.

CBS News

If you want to minimize your chances of getting hit by lightning, go indoors or stay in your car. Bitzer said, ""'When thunder roars, go indoors.' There's a reason why we say that.""

Still, the biggest threat isn't lightning hitting people; it's lightning starting fires. ""Most forest fires are caused by humans, but most damage is done by lightning-caused wildfires,"" Bitzer said. ""Usually because, when lightning happens, it's not near a campground where you know it happened; it happens in some remote location that you might not know that the fire started right away.""

We may no longer believe that Zeus hurls lightning down from Mount Olympus when he's irritated. But there's still a lot we don't know. Bitzer said, ""Everybody thinks, 'Lightning, well, you must understand it, happens all the time!' And yet, we don't. The stuff that we see only lasts for, you know, maybe a millisecond.""

Our best hope is to build instruments. In fact, Bitzer himself helped developed a lightning camera that's on the International Space Station at this moment.

Pogue asked, ""Is there any practical value for mapping the lightning and how it happens? Or is it just kind of neat?""

""We know that [often] lightning will ramp up as a precursor to severe weather,"" Bitzer said. ""And so, we can watch the lightning activities start to increase or start to jump. We've also been able to use it to help aviation; we can route planes around storms that are electrically active.""

Back here on Earth, Shana Turner is still fighting to recover from her lightning strike eight years ago. ""Obviously the brain damage will never get any better,"" she said, ""but I've learned how to do other things to assist with it. I'm not going to let it stop me. If I let it stop me, it wins.""

A tattoo Shana Turner got, holding a lightning bolt. CBS News

And in Arizona, two days after our visit, photographer Lori Bailey got some of that good luck she'd been chasing: ""Oh, my goodness! This is where you feel alive, where you feel the energy of Mother Nature!"" she said.

Lori Bailey



For more info:



Story produced by Robert Marston. Editor: Steven Tyler.",https://assets2.cbsnewsstatic.com/hub/i/r/2023/08/27/852c4647-8a33-437b-a3a1-71059e757bcd/thumbnail/1200x630g8/43ea3ee81f66bdd0ae84f44e2d98e80e/lightning-lori-bailey-a-1280.jpg?v=85153828b1c3c07a041ab8e73ff87e39,https://www.cbsnews.com/news/the-science-and-art-of-lightning/,Science
['Esa Hubble'],2023-08-27 21:22:16-07:00,Maser Mystique: Hubble’s Gaze Into a Stellar Cradle,"The NASA/ESA Hubble Space Telescope has captured an entrancing dust-filled image of the protostellar object OH 339.88-1.26. Located 8,900 light-years away in the constellation Ara. This image showcases winding lanes of dark dust intertwined with bright stars, their brilliance emphasized by crisscrossing diffraction spikes.

Unveiling the Secrets of OH 339.88-1.26

The dark vertical streak in the center of the image conceals OH 339.88-1.26, which is an astrophysical maser. A maser — which is an acronym for “microwave amplification by stimulated emission of radiation” — is essentially a laser that produces coherent light at microwave wavelengths. These intriguing phenomena naturally arise in a range of astrophysical contexts, from the north pole of Jupiter to star-forming regions like the one depicted here.

Hubble’s Deep Dive into Star Formation

This image comes from a set of Hubble observations that peer into the hearts of regions where massive stars are born, with the goal of constraining the nature of massive protostars and testing theories of their formation. Astronomers turned to Hubble’s Wide Field Camera 3 (WFC3) to explore five intermediate-mass protostars at infrared wavelengths.

The Hubble observations were supported by other state-of-the-art observatories including ALMA, the Atacama Large Millimeter/submillimeter Array. ALMA is composed of 66 moveable high-precision antennas that can be arranged over distances of up to 16 kilometers (10 miles) on a plateau perched high in the Chilean Andes. Further data were contributed by the Stratospheric Observatory For Infrared Astronomy (SOFIA), which is a telescope that — until recently — operated out of a converted 747 aircraft.",https://scitechdaily.com/images/Protostellar-Object-OH-339-88-1-26.jpg,https://scitechdaily.com/maser-mystique-hubbles-gaze-into-a-stellar-cradle/,Science
"['Georgina Torbet', 'August']",2023-08-26 16:29:57-07:00,Hubble captures a sparkling cloud galaxy located next door,"An image from the Hubble Space Telescope shared this week by NASA shows a nearby galaxy, ESO 300-16. Unlike our Milky Way, which is a type called a spiral galaxy with a clear central bulge and defined spiral arms reaching out from its center, this neighborhood galaxy is loose and diffuse, looking more like a spattering of stars than anything with a clear structure. Hubble scientists describe it as a “sparkling cloud.”

The galaxy is a type called an irregular galaxy, due to its lack of clear shape. Its stars clump together in a soft bubble form, and it is located nearly 29 million light-years away in the direction of the constellation Eridanus.

“This observation is one of a series which aims to get to know our galactic neighbors,” Hubble scientists explain in a statement. “Hubble has observed around three-quarters of known galaxies within about 10 megaparsecs of Earth in enough detail to resolve their brightest stars and establish distances to these galaxies. A team of astronomers proposed using small gaps in Hubble’s observing schedule to acquaint ourselves with the remaining quarter of these nearby galaxies.”

Recommended Videos

The project is called Every Known Nearby Galaxy and is designed to maximize Hubble’s observing time. Time on Hubble is in high demand, so astronomers have to submit proposals for how and why they want to use Hubble for their observations far in advance. This is a competitive process, with experts deciding what the best of use Hubble’s limited time would be and filling out the schedule as much as they can. However, there are some small gaps between observations, such as when the telescope has to move to point to different parts of the sky for different observations.

Researchers make use of this 2-3% of time on Hubble which isn’t going toward primary observations to make other smaller observations like the Every Known Nearby Galaxy project. This has resulted in a series of images of our galactic neighbors, including ghostly galaxy NGC 6684, fuzzy galaxy LEDA 48062, and dwarf galaxy UGCA 307.

Editors' Recommendations",https://www.digitaltrends.com/wp-content/uploads/2023/08/hubble_eso300-16_potw2334a1.jpg?resize=1200%2C630&p=1,https://www.digitaltrends.com/space/hubble-eso-300-16/,Science
[],,"Glimpsing the Unknown: Captured Image 2,000 Light Years Away Holds Potential Key to Dark Matter Mysteries","For many of us, the Hubble Space Telescope is one of the most iconic elements of space exploration. We can’t envision capturing stars without its signature at the bottom of the image. Without the Hubble, the James Webb wouldn’t exist.

NASA App DOWNLOAD

The Hubble Space Telescope should have been retired for about 13 years by now, as it has been functioning in space for over 30 years, and NASA itself confirmed that it has been experiencing issues since 2010. And it’s not its fault; it wasn’t designed to work for such a long period.

However, the veteran telescope soldiers on. Recently, it has captured images of a massive galaxy cluster that could hold secrets about both dark and ordinary matter.

SA/Hubble & NASA, H. Ebeling

A bright galaxy full of secrets

At the heart of the recent image captured by the Hubble of Abell 3322 lies 2MASX J05101744-4519179, an exceptionally bright galaxy. The image was taken by Hubble’s Wide Field Camera 3 and its Advanced Camera for Surveys, third-generation instruments that capture images in near-infrared and visible light wavelengths.

Three galaxies in the image shine brighter than the rest (two at the center and one in the upper-right corner). The alignment of these galaxies indicates to scientists that the galaxy cluster appears to be actively forming, according to a statement from the European Space Agency.

This week's #HubbleFriday view takes us 2.6 billion light-years away, to the galaxy cluster Abell 3322!



Seen here in this new image, Abell 3322 is helping astronomers learn more about dark matter in galaxy clusters: https://t.co/pmZEUonBPo pic.twitter.com/Vo8DMNK64o — Hubble (@NASAHubble) August 18, 2023

Dark matter isn’t literally ‘dark’; it’s only dark to us. In simpler terms, we don’t know what it is. It could be various things or a challenging-to-detect particle. Dark matter barely interacts with ordinary matter, making its understanding difficult, and it has never been observed directly.

However, scientists are aware of its existence due to its gravitational effects. Halos of dark matter manifest around some galaxies and galaxy clusters, and regions with gravitational lensing serve as fertile hunting grounds for dark matter candidates.

In the recent image, some galaxies appear distorted or flattened; these are gravitational lenses, which means their light is bent and refocused by the gravitational field between them and the Hubble.

The two primary candidates for dark matter are Weakly Interacting Massive Particles (WIMPs) and axions, a theoretical particle named after a laundry detergent.

At the beginning of this year, a team of astronomers found indications of dark matter resembling axions in Einstein rings, particularly in images of HS 0810+2554, a distant quasar. Einstein rings are striking circles or near-circles of light in space caused by intense gravitational lenses.

A greater number of observations of regions in space where dark matter appears to be at work will assist researchers in understanding how the matter that composes it interacts with the observable world.

Combined with laboratory investigations of dark matter candidates, we are edging closer to shedding light on some of the most concealed physics of space… and one step closer to comprehending the universe.

Dark matter is something we have considered real for the past 100 years, but its study is exceedingly challenging and elusive. The ability to obtain clear images that aid in the study of this matter could be pivotal for the future of physics and astronomy. If we aim to reach for the stars, there’s no other way.

NASA App DOWNLOAD

Some of the links added in the article are part of affiliate campaigns and may represent benefits for Softonic.","https://articles-img.sftcdn.net/f_auto,t_article_cover_xl/auto-mapping-folder/sites/3/2023/08/Telescopio-Hubble-en-el-espacio-1024x579-1.jpeg",https://en.softonic.com/articles/the-secrets-of-dark-matter-could-be-in-this-image-captured-more-than-2000-thousands-of-light-years,Science
"['Linnea Pedersen', 'Marlowe Hood']",,Tropical forests nearing critical temperatures thresholds,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

The new research suggests that leaf death could become a new factor in the predicted ""tipping point"" where tropical forests transition due to climate change and deforestation into savannah-like landscapes.

Global warming is driving leafy tropical canopies close to temperatures where they can no longer transform sunlight and CO 2 into energy, threatening total collapse if the thermometer keeps climbing, according to a study Thursday.

A tiny percentage of upper canopy leaves have already crossed that threshold, reaching temperatures so high—above 47 degrees Celsius—as to prevent photosynthesis, the study published in Nature reported.

Currently, some leaves exceed such critical temperatures only 0.01 percent of the time, but impacts could quickly scale up because leaves warm faster than air, the researchers said.

""You heat the air by two to three degrees and the actual upper temperature of these leaves goes up by eight degrees,"" lead author Christopher Doughty of Northern Arizona University told journalists.

If tropical forest's average surface temperature warms 4C above current levels—widely considered a worst-case scenario—""we're predicting possible total leaf death,"" he said.

The new research suggests that leaf death could become a new factor in the predicted ""tipping point"" whereby tropical forests transition due to climate change and deforestation into savannah-like landscapes.

If air temperatures increase unabated by 0.03 C per year, the study projected, mass mortality among the canopies could happen in a little more than a century.

Doughty and his team used data from the NASA ECOSTRESS satellite—designed to measure plant temperatures—validated with ground observations, based in part on sensors attached to individual leaves.

Increased tree death

There remain uncertainties as to how high leaf temperatures might impact the forest as a whole, the scientists cautioned.

""Believe it or not, we don't know terribly much about why trees die,"" said co-author Gregory Goldsmith of Chapman University.

It doesn't take a scientist to know that when a tree loses its roots it dies, he said.

But the interactions and feedbacks between heat and drought—and water and temperature—on overall tree health aren't as clear.

Map showing the current forest area in the Amazon and the deforestation since 2000.

Total leaf death might not necessarily mean total tree death.

The critical temperature at which leaves turn brown and die might also differ by species, depending on the size and thickness of their leaves and the breadth of their canopy.

But there are already concerning signs. In the Amazon, where temperatures are higher than in other tropical forests, the rate at which trees are dying has increased in recent decades.

""The Amazon is currently experiencing higher levels of mortality than Central Africa and that could possibly be due to the high temperatures we've seen there,"" said Doughty.

Increased fragmentation of the forests from deforestation has also been shown to make the remaining forest areas warmer.

Tropical biomes contain 45 percent of the Earth's forests, and play an outsized role in absorbing human-caused carbon pollution.

They also harbor half or more of the world's plant biodiversity, with at least 40,000 different tree species, according to the Intergovernmental Panel on Climate Change (IPCC).

The fact that a few leaves are overheating at current temperatures is a ""canary in the coal mine,"" said senior author Joshua Fisher of Chapman University.

""You want to be able to detect something happening before it's widespread,"" he said.

""The fact that we can do that now gives us that ability to actually do something as a collective society.""

Scientists not involved in the study said it should serve as a warning that nature's capacity to adapt to climate change has limits.

""It is true that trees and other kinds of vegetation can soak up emissions and provide cooling,"" commented Leslie Mabon, a lecturer in environmental systems at The Open University.

""However, this study illustrates that without concerted action by humans to reduce emissions and limit global heating at the same time as protecting and enhancing nature, some functions of nature may start to break down at higher temperatures.""

More information: Christopher E. Doughty et al, Tropical forests are approaching critical temperature thresholds, Nature (2023). DOI: 10.1038/s41586-023-06391-z Journal information: Nature

© 2023 AFP",https://scx2.b-cdn.net/gfx/news/2023/tropical-forests-neari.jpg,https://phys.org/news/2023-08-tropical-forests-nearing-critical-temperatures.html,Science
[],2023-08-26 15:45:00+00:00,Tropical forests may be getting too hot for photosynthesis,"August 26, 2023 09:15 pm | Updated 09:15 pm IST

A small percentage of leaves on trees in tropical forests may be approaching the maximum temperature threshold for photosynthesis to work, suggests a study published in Nature. An estimated 0.01% of all leaves currently surpass this critical temperature but there are uncertainties in the range of potentially critical temperatures in tropical trees. Modelling suggests that tropical forests can withstand up to a 3.9 degree C increase over current air temperatures before a potential tipping point, therefore action is needed to protect the fate of tropical forests under future climate change. “But the uncertainty in the plasticity and range of critical temperature in tropical trees and the effect of leaf death on tree death could drastically change this prediction,” the authors warn.

“The 4 degree C estimate is within the ‘worst-case scenario’ of climate change predictions for tropical forests and therefore it is still within our power to decide the fate of these critical realms of carbon, water and biodiversity,” the authors write.

Recent studies have indicated a resilience of tropical forests to how warming impacts carbon uptake and long-term drought. “However, the critical temperature acts as an absolute upper limit and it seems that, if our assumptions in the model are correct, crossing such a threshold is within the range of our most pessimistic future climate change scenarios,” they note. In addition to temperature increase caused by global warming, deforestation and fragmentation can amplify local temperature changes. “The combination of climate change and local deforestation may already be placing the hottest tropical forest regions close to, or even beyond, a critical thermal threshold” they add. “Therefore, our results suggest that the combination of ambitious climate change mitigation goals and reduced deforestation can ensure that these important realms of carbon, water and biodiversity stay below thermally critical thresholds.”

Tropical forests serve as critical carbon stores and host most of the world’s biodiversity and may be particularly sensitive to increasing temperatures. The critical temperature beyond which photosynthetic machinery in tropical trees begins to fail averages at about 46.7 degrees C. However, whether leaf temperatures experienced by tropical vegetation approach this threshold, or soon will under climate change, remains unclear.",https://www.thehindu.com/theme/images/og-image.png,https://www.thehindu.com/sci-tech/science/tropical-forests-may-be-getting-too-hot-for-photosynthesis/article67235279.ece,Science
['Maiya Focht'],2023-08-26 00:00:00,"Extreme heat could make photosynthesis impossible for tropical trees and plants that may all die as a result, a new study found.","Trees stop making food for themselves when they get too hot, a new study shows.

If tropical air temperatures reach 116 degrees Fahrenheit, a lot of the rainforest could die.

This is the first study to narrow in on a threshold that we need to avoid.

Sign up for our newsletter to get the latest on the culture & business of sustainability — delivered weekly to your inbox. Loading Something is loading. Thanks for signing up! Access your favorite topics in a personalized feed while you're on the go. download the app Email address By clicking ‘Sign up’, you agree to receive marketing emails from Insider as well as other partner offers and accept our Terms of Service and Privacy Policy

Advertisement

Advertisement

When trees get hot, their leaves begin to sweat. If they stay hot for too long, they deplete their water supply, exhausting themselves.

It's then that photosynthesis, the backbone of plant life, breaks down.

The plant stops being able to care for itself, and begins to die, scientist Gregory Goldsmith, an assistant professor of biology at Chapman University, said in a press briefing.

So what happens in a world that by all signs, will continue to get warmer?

Advertisement

Advertisement

For a new Nature study, scientists across the country found that photosynthesis begins to fail in tropical trees at 116 degrees Fahrenheit (46.7 degrees Celsius).

The researchers also found that a small percentage of leaves — .01% — have already surpassed this limit at least once per season.

If the world continues to grow warmer, massive amounts of the tropical canopy could die off. However, in the paper, researchers state that ""it is still within our power to decide the fate of these critical realms of carbon, water, and biodiversity.

What we didn't know

Chloroplasts carry chlorophyll which makes them green. These chloroplasts actually circulate around within each cell. NNehring/ Getty Images

Scientists already knew extreme heat makes leaves unable to photosynthesize, said Goldsmith, a co-author of the study. But ""this study is really the first study to establish how close tropical forest canopies may be to these limits,"" he said.

Advertisement

Advertisement

To determine the threshold for what too hot really means, the researchers used data from climate monitoring satellites, temperature towers in tropical forests, and countless sensors they taped onto individual leaves in the canopy.

They studied five forests in Brazil, Puerto Rico, Panama, and Australia, ScienceAlert reported.

These three perspectives combined to give them an idea of when the leaves, which are harbingers of health for the rest of the tree, begin to malfunction.

A Cruise self-driving car in the middle of traffic in San Francisco. Justin Sullivan/Getty Images Without change, we're headed toward disaster

The nutrients a tree needs to sustain itself are created when it photosynthesizes. So if photosynthesis is interrupted, a plant will essentially starve to death.

Advertisement

Advertisement

Since plants take in carbon dioxide when they photosynthesize, they can help moderate the amount of greenhouse gases in the air.

But if a plant dies, all the carbon it's stored in its body gets released into the atmosphere.

Tropical forests make up about 12% of the Earth's land surface. So if this heat threshold is reached, that whole chunk of Earth's surface might begin to die off, releasing greenhouse gases into the air with it, said Christopher Doughty, a professor of ecoinformatics at Northern Arizona University.

If all the trees in the tropical rainforests died off, that would release an estimated 228.7 petagrams of carbon into the atmosphere, according to a 2012 study.

Advertisement

Advertisement

One petagram of carbon is equal to 1 Gigaton (or a billion metric tons), so 228 petagrams are equivalent to six times the amount of carbon emissions emitted worldwide in 2022, alone.

""If that all went into the atmosphere, that would accelerate climate change,"" Doughty said. He was the one up in the trees, taping each sensor delicately to the tropical canopy.

Though the researchers found that .01% of the leaves in the tropical rainforest have reached their heat-induced limit, there is room for error in the measurements, Doughty cautioned.

They arrived at their measurements based on the data they were able to gather from key areas globally, but they weren't able to actually measure all the tropical leaf temperatures across the globe.

Advertisement

Advertisement

A photo of the canopy of the Amazon rainforest. Ignacio Palacios/Getty Images

They estimated them by combining their ground data with satellite data, but there might be slight deviations from their estimation.

Even so, if no action is taken to prevent further climate change, Doughty said it's possible their predictions will come true.

But making even moderate changes, like enforcing our current climate agreements and reducing tropical deforestation, would help.

These sorts of changes could give us a good chance of avoiding what would be a tragic loss of some of Earth's most biologically-rich ecosystem. This makes Doughty hopeful.

Advertisement

Advertisement

""I feel optimistic,"" he said.",https://i.insider.com/64e617d8912f290019a98637?width=1200&format=jpeg,https://www.businessinsider.com/extreme-heat-climate-change-stop-tropical-trees-photosynthesis-kill-plants-2023-8,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
"['Jeanette Kazmierczak', 'Nasa S Goddard Space Flight Center']",2023-08-27 05:25:36-07:00,"X-Ray Vision to the Cosmos: JAXA, NASA XRISM Mission Ready for Liftoff!","The XRISM satellite, a collaborative effort between JAXA, NASA, and ESA, aims to offer unprecedented insights into the X-ray universe, exploring stellar phenomena and black hole activities. Launching alongside JAXA’s SLIM, its instruments, Resolve and Xtend, promise advanced X-ray detection and analysis.

A powerful satellite called XRISM (X-ray Imaging and Spectroscopy Mission) is set to provide astronomers with a revolutionary look at the X-ray sky.

XRISM, led by JAXA (Japan Aerospace Exploration Agency) in collaboration with NASA and with contributions from ESA (European Space Agency), is scheduled to launch on an H-IIA rocket from Japan’s Tanegashima Space Center at 8:26 p.m. EDT on Sunday, August 27 (9:26 a.m. on Monday, August 28, in Japan). JAXA will stream the launch live on YouTube, with a broadcast in both English and Japanese starting at 7:55 p.m. EDT.



Watch this video to learn more about XRISM (X-ray Imaging and Spectroscopy Mission), a collaboration between JAXA (Japan Aerospace Exploration Agency) and NASA. Credit: NASA’s Goddard Space Flight Center

“Some of the things we hope to study with XRISM include the aftermath of stellar explosions and near-light-speed particle jets launched by supermassive black holes in the centers of galaxies,” said Richard Kelley, NASA’s XRISM principal investigator at NASA’s Goddard Space Flight Center in Greenbelt, Maryland. “But of course, we’re most excited about all the unexpected phenomena XRISM will discover as it observes our cosmos.”

Companion Launch and XRISM’s Capabilities

Also on this launch is JAXA’s SLIM (Smart Lander for Investigating Moon), designed to demonstrate accurate, “pinpoint” lunar landing techniques by a small explorer. NASA provided a laser retroreflector array for SLIM, as both agencies cooperate in the international effort to further explore the Moon and, ultimately, human exploration of Mars.

XRISM detects X-rays with energies ranging from 400 to 12,000 electron volts. (For comparison, the energy of visible light is 2 to 3 electron volts.)

This range will provide astrophysicists with new information about some of the universe’s hottest regions, largest structures, and objects with the strongest gravity.

Instruments Onboard XRISM

The mission has two instruments, Resolve and Xtend.

Resolve is a microcalorimeter spectrometer developed in collaboration between JAXA and NASA. When an X-ray hits Resolve’s 6-by-6-pixel detector, its energy causes a tiny increase in temperature. By measuring each individual X-ray’s energy, the instrument provides information about the source, such as its composition, motion, and physical state.

To detect these tiny temperature changes, Resolve must operate at just a fraction of a degree above absolute zero. It reaches this state in orbit after a multistage mechanical cooling process inside a refrigerator-sized container of liquid helium.

“Resolve leverages technologies developed for previous X-ray missions like Suzaku and Hitomi,” said Lillian Reichenthal, NASA’s XRISM project manager at Goddard. “It represents the culmination of years of collaborative work between JAXA, NASA, and other partners from around the globe.”

XRISM’s second instrument, Xtend, was developed by JAXA. It will give XRISM one of the largest fields of view of any X-ray imaging satellite flown to date, observing an area about 60% larger than the average apparent size of the full moon. The images it collects will complement the data collected by Resolve.

XRISM’s Unique X-ray Imaging

Each instrument is at the focus of an XMA (X-ray Mirror Assembly) designed and developed at Goddard.

X-ray wavelengths are so short, they can pass straight between the atoms of the dish-shaped mirrors used to capture visible, infrared, and ultraviolet light.

Instead, X-ray astronomers use nested curved mirrors turned on their sides. The X-rays skip off the surfaces like stones across a pond and into the detectors.

Each of XRISM’s XMAs houses hundreds of concentric, precisely shaped aluminum shells built in quadrants and assembled into a circle. In all, there are over 3,200 individual mirror segments in the two mirror assemblies.

After launch, XRISM will begin a months-long calibration phase, during which Resolve will reach its operating temperature.

“Once XRISM begins collecting data, scientists will have the opportunity to propose sources for the mission to study,” said Mihoko Yukita, an astrophysicist at Goddard and Johns Hopkins University in Baltimore who works for NASA’s Guest Observer Facility for XRISM. “Researchers from around the world will have access to the cutting-edge work XRISM will be doing.”

XRISM is a collaborative mission between JAXA and NASA, with participation by ESA. NASA’s contribution includes science participation from the Canadian Space Agency.",https://scitechdaily.com/images/XRISM-X-Ray-Imaging-and-Spectroscopy-Mission-Spacecraft-Left-Front-View-scaled.jpg,https://scitechdaily.com/x-ray-vision-to-the-cosmos-jaxa-nasa-xrism-mission-ready-for-liftoff/,Science
"['Dr. Alfredo Carpineti', 'Senior Staff Writer', 'Space Correspondent']",2023-08-25 16:08:18+00:00,"""New X-Ray Observatory Will Launch This Weekend""","X-ray light is used to study the cosmos at its most extreme. The hottest plasma around stars and between galaxies, the behavior of black holes, and even energetic aurorae on the gas giant planets are all topics that require X-ray observations. And from tomorrow there will be a new telescope in orbit to do just that.

It is called XRISM (pronounced ""krizz-em"") and it is a collaboration between JAXA, the Japanese Space Agency, and NASA, with support from the European Space Agency (ESA). The name stands for X-Ray Imaging and Spectroscopy Mission and it is a direct successor of the failed Hitomi telescope that failed in orbit about a month after launch.

Advertisement Advertisement

The telescope has two instruments. Xtend is an X-ray camera that behaves similarly to a standard digital camera. The difference is the ability to measure the “color” of each X-ray directly from the interaction with the camera without the need for filters.

The second instrument is called Resolve. It is a spectrometer, an instrument that measures the wavelength of a photon very precisely. The instrument is a marvel of engineering and it will allow measurements that have not been possible so far.

“Resolve will give us a new look into some of the universe’s most energetic objects, including black holes, clusters of galaxies, and the aftermath of stellar explosions,” Richard Kelley, NASA’s XRISM principal investigator at NASA’s Goddard Space Flight Center, said in a statement. “We’ll learn more about how they behave and what they’re made of using the data the mission collects after launch.”

XRISM follows in the footsteps of NASA’s Chandra X-ray Observatory and ESA’s XMM-Newton, which were both launched in 1999. While they continue to work, they are aging and it is unclear how long they will still be around. XRISM will also demonstrate new tech that will be used by ESA’s Advanced Telescope for High Energy Astrophysics (ATHENA) telescope, scheduled to launch in the middle of next decade.

Advertisement Advertisement

But don’t think XRISM is just bridging a gap. It will deliver new insights into the formation of the universe, the center of active galaxies, and maybe even major unsolved problems like dark matter. This and so much more will be achieved by the telescope.

“The spectra XRISM collects will be the most detailed we’ve ever seen for some of the phenomena we’ll observe,” added Brian Williams, NASA’s XRISM project scientist at Goddard. “The mission will provide us with insights into some of the most difficult places to study, like the internal structures of neutron stars and near-light-speed particle jets powered by black holes in active galaxies.”

The launch is expected for 09:26 am Japan Standard Time on Monday 28, which is 8:26 pm EST on Sunday 27. You can follow the launch in the live stream above.",https://assets.iflscience.com/assets/articleNo/70417/aImg/70243/xrism-meta.png,https://www.iflscience.com/new-x-ray-observatory-will-launch-this-weekend-70417,Science
['Jeanette Kazmierczak'],,"JAXA, NASA XRISM Mission Ready for Liftoff",,http://www.nasa.gov/sites/default/files/thumbnails/image/xrism_s2_113.png,https://www.nasa.gov/feature/goddard/2023/jaxa-nasa-xrism-mission-ready-for-liftoff,Science
"['Iain.Todd Ourmedia.Co.Uk', 'Science Journalist']",,How to watch tonight's live launch of Japan's XRISM spacecraft,"This weekend, space fans will be able to watch the launch of the XRISM mission, a new spacecraft that will observe the hottest, most chaotic known places in the Universe.

XRISM (X-ray Imaging and Spectroscopy Mission) is scheduled to launch from Tanegashima Space Center in Japan on Saturday 26 August at 20:30 EDT (27 August 00:15 UTC / 01:15 BST), which is 09:30, Tokyo time.

The mission is a joint venture between the Japan Aerospace Exploration Agency (JAXA) and NASA, with participation from the European Space Agency (ESA).

JAXA is livestreaming the event, which you can watch at the bottom of this article.

Artist's impression of the Japanese XRISM spacecraft, which is tasked with studying some of the hottest places in the Universe. Credit: JAXA

What will XRISM do?

“X-ray astronomy enables us to study the most energetic phenomena in the Universe,"" says Matteo Guainazzi, ESA project scientist for XRISM.

""It holds the key to answering important questions in modern astrophysics

""How the largest structures in the Universe evolve, how the matter we are ultimately composed of was distributed through the cosmos.

""And how galaxies are shaped by massive black holes at their centres.""

Credit: JAXA/ESA

“With current instruments, we’re only capable of seeing these fingerprints in a comparatively blurry way,” says Brian Williams, NASA’s XRISM project scientist.

“Resolve will effectively give X-ray astrophysics a spectrometer with a magnifying glass.”

XRISM is expected to shed light on exploding stars (supernovae), black holes and their host galaxies, and galaxy clusters.

You can find out more about the science behind the spacecraft in our guide to the XRISM mission.

And you can watch the livestream of the XRISM launch below.

What the XRISM launch live

Find out more via the JAXA XRISM webpage.",https://c02.purpledshub.com/uploads/sites/48/2023/08/Artist_impression_of_XRISM.jpg,https://www.skyatnightmagazine.com/news/watch-xrism-launch,Science
['Pacific Northwest National Laboratory'],2023-08-27 17:47:18-07:00,Peeling Back the Chemical Unknown: Scientists Are on the Hunt for the Other 99 Percent,"New mass spectrometry technique holds the potential for exploring nature’s unknown chemical universe.

The universe is awash in billions of possible chemicals. Despite the arsenal of advanced technology at their disposal, researchers have only identified the molecular makeup of a minuscule portion, perhaps around 1 percent, of these compounds.

Scientists at the Department of Energy’s Pacific Northwest National Laboratory (PNNL) are taking aim at the other 99 percent, creating new ways to learn more about a vast sea of unknown compounds. There may be cures for disease, new approaches for tackling climate change, or new chemical or biological threats lurking in the chemical universe.

The work is part of an initiative known as m/q or “m over q”—shorthand for mass divided by charge, which signifies one of the ways that scientists measure chemical properties in the world of mass spectrometry.

“Right now, we can take a sample from soil, where, depending on soil type, there may be thousands of chemical compounds in just a teaspoon’s worth,” said Thomas Metz, who leads the m/q Initiative. “And we don’t know what most of them are in terms of their chemical structures. We simply have no idea what’s in there.”

Scientists typically rely on reference libraries that contain information about thousands of molecules to identify substances. Researchers sort their samples from soil, the body, or elsewhere and compare what they have measured experimentally to what’s in the library. While that’s helpful, it limits scientists to only structurally identifying molecules that have been seen before—for example, through analysis of standard compounds purchased from chemical suppliers.

m/q scientists are taking aim at the other 99 percent that haven’t been identified—yet.

In the latest development, a team led by scientist Adam Hollerbach has combined two high-resolution instruments into one system to size up molecules in unprecedented detail. The results were published online June 12 in the journal Analytical Chemistry.

Now, scientists can make several important measurements about chemical compounds in one experiment, gaining important information faster, more conveniently, and more accurately than before.

Hollerbach’s technique applies to ions—molecules that have either a positive or negative charge. That makes them easier to control and possible to detect using mass spectrometry.

Mass spectrometry: tool of the ion whisperers

Like the people who study them, ions have many features that distinguish one from another. In people, weight, hair color, size, shape, eye color, and many other characteristics help us know who’s who. For ions, identifying characteristics include mass, shape, size, electric charge, and chemical composition. Those not only serve as identifiers but also as guides to the associated molecules’ behavior—clues to their potential to cure disease or sop up pollutants, for example.

That understanding should help the efforts of scores of scientists at PNNL who focus on understanding the effect of microbes on climate. Microbes play a key role in transforming elements like carbon into other forms that are important for the planet. Their impact on warming or cooling the planet is mighty. But scientists have much to learn.

“There may be millions of microbes in just a gram of soil, and we don’t know who most of them are or what they do. There’s a lot of discovery still to happen,” said Metz. “From the viewpoint of challenging science, it’s either a worst-case scenario or one of our greatest opportunities, depending on how you look at it.”

m/q scientists are seizing the opportunity. Instead of framing their questions within the relatively small number of compounds that can be identified in conventional mass spectrometry measurements, they’re trying to leapfrog current limitations and create a whole new way of identifying what is unknown today. It’s a bit like when a new telescope is deployed and reveals several distinct stars where before, just one blurry hodgepodge of celestial bodies was visible.

The work is both experimental, putting molecules through their paces in the laboratory, and on computers, where scientists model what they are seeing and predict what they will likely see.

In the experiments described in the Analytical Chemistry paper, Hollerbach and colleagues made sensitive measurements of peptides and lipids. The experiments combined two instruments with similar names but that provided different details about ions. Both are used in mass spectrometry, a field whose history is interwoven with discoveries by PNNL scientists.

The first instrument is a mass spectrometer, which measures an ion’s mass, electric charge, and how the ion breaks apart. In this study, the team used an Orbitrap developed by Thermo-Fisher Scientific. Such instruments sort molecules of different masses well, but two molecules with the same mass are difficult to separate. Think of two people, each weighing 180 lbs.—one is tall and thin while the other is short and stocky. On a scale alone, they would be impossible to separate.

A SLIM approach: ion mobility spectrometry brings hefty results

The second instrument is known as SLIM: structures for lossless ion manipulations. SLIM, created by PNNL scientist Richard D. Smith and colleagues, is an ion mobility spectrometer that measures an ion’s size and electric charge.

SLIM, which is about the size of a laptop and stands at just one-quarter of an inch thick, is a hothouse of molecular activity. Dozens of long, winding paths transform the small device into a 42-foot-long molecular racetrack, with ions that are controlled tightly by electric fields racing round and round an oval obstacle course.

The “obstacles” are other, known molecules such as helium or nitrogen molecules. As the ions under study race through the SLIM device, they navigate around or through the other molecules, tumbling and swerving much like a football running back runs through and around opposing blockers. The term “ion mobility spectrometry” truly captures the action.

By recording how long it takes for the ions to complete the course—how deftly they navigate the blocking ions—scientists learn all kinds of things about ions’ shape and size. That information, which isn’t available from a standard mass spec instrument, is combined with data about the ion’s mass, electric charge, and fragmentation pattern. Altogether, the data yields the ion’s collision cross section, its molecular formula, and its fragmentation pattern, properties that are central to understanding a molecule’s structure.

“Two different molecules can have the same number of atoms, and the same mass and charge, but they could have very different structures and activity. That’s where SLIM comes in to tell the difference,” said Hollerbach. “Just one small change can mean the difference between a molecule that is indicative of a disease and one that’s not.”

The key to Hollerbach’s experiment was getting the two different instruments to play nicely together. While both standard mass spectrometry and ion mobility spectrometry analyze ions, they work on different time scales. Ions make their journey through SLIM and arrive at the Orbitrap faster than they can be processed.

So Hollerbach drew on an old technique, deploying “dual-gated ion injection.” He added gates to control the intake of ions into the system and to control their arrival at the Orbitrap, choosing to send some of the ions from SLIM into oblivion to keep the flow at a manageable rate.

“Really, the questions we ask are very simple,” said Hollerbach. “What is this, and how much is there? But the techniques we use are complex.”

Other m/q scientists are working on additional ways to identify or exploit unknown molecules. Some are creating ways to use data like that from Hollerbach’s experiment to predict an ion’s structure automatically, so drug makers and other scientists would know exactly what they’re working with. Others are scouting out the millions of possibilities for forms of compounds such as fentanyl, sorting out what’s unlikely from what might show up on the street one day. Then they predict how those compounds would behave inside a mass spectrometer—creating a way to identify them if and when they do show up.

Reference: “A Dual-Gated Structures for Lossless Ion Manipulations-Ion Mobility Orbitrap Mass Spectrometry Platform for Combined Ultra-High-Resolution Molecular Analysis” by Adam L. Hollerbach, Yehia M. Ibrahim, Vanessa Meras, Randolph V. Norheim, Adam P. Huntley, Gordon A. Anderson, Thomas O. Metz, Robert G. Ewing and Richard D. Smith, 12 June 2023, Analytical Chemistry.

DOI: 10.1021/acs.analchem.3c00881

The work described in the Analytical Chemistry paper was funded by the m/q Initiative at PNNL. The mass spectrometry measurements were made at EMSL, the Environmental Molecular Sciences Laboratory, a DOE Office of Science user facility at PNNL.

In addition to Hollerbach and Metz, PNNL authors of the paper are Yehia M. Ibrahim, Vanessa Meras, Randolph V. Norheim, Adam P. Huntley, Robert G. Ewing, and Richard D. Smith. Gordon Anderson, formerly of PNNL, with GAA Custom Engineering LLC in Benton City also contributed.",https://scitechdaily.com/images/Molecules-Chemicals-Chemistry.jpg,https://scitechdaily.com/peeling-back-the-chemical-unknown-scientists-are-on-the-hunt-for-the-other-99-percent/,Science
['Taylor'],,Auckland wastewater pipe dig reveals 'fossil treasure trove',"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Credit: CC0 Public Domain

A new New Zealand Journal of Geology and Geophysics paper out today describes the 266 fossil species as one of the richest and most diverse groups of three-million-year-old fauna ever found in New Zealand. At least ten previously unknown species will be described and named in future research.

In 2020, when Auckland's Watercare were excavating two huge vertical shafts for a major upgrade of the major pipeline that brings raw sewage for treatment from the central city they dug through an ancient shell bed. Auckland paleontologist Bruce Hayward likened it to ""finding gold right on your door step.""

Once they were informed of the fossil deposit's significance, Watercare and their contractors were eager to help and a huge heap of shelly sand was dumped in a nearby paddock so that paleontologists could search through it over many months. Watercare also funded two paleontology graduate students, working under the supervision of Auckland Museum curator Dr. Wilma Blom, to painstakingly sift through the heap for many weeks.

As a result, it is estimated that over 300,000 fossils were examined and several thousand have been returned in the museum as a record of this ""once-in-a-lifetime find.""

""Detailed identification of the fossils shows that they were deposited between 3 and 3.7 million years ago in a subtidal channel in an early version of the modern Manukau Harbour,"" said Dr. Hayward.

""At that time, sea level was slightly higher than it is today as the world was also several degrees warmer than now. As a result, the fossils include a number of subtropical species, whose relatives today live in the warmer waters around the Kermadec and Norfolk islands. At least ten previously unknown species are present and will be described and named in future work.""

In their paper that appeared this week in the New Zealand Journal of Geology and Geophysics, the five authors record 266 different fossil species, making it the richest and most diverse fauna of its age ever found in New Zealand. ""What is surprising,"" says lead author Dr. Hayward ""is that the fauna contains fossils that lived in many different environments that have been brought together in the ancient marine channel by wave action and strong tidal currents.""

""It includes ten specimens of the iconic NZ flax snail that must have lived on the adjacent land and been washed down into the sea by storm runoff. These are by far the oldest known flax snails in the world. Most of the fossils lived on the sea floor, some in brackish estuaries, others attached to hard rocky shorelines and still more have been carried in from offshore of the exposed west coast at the time.""

""Rare finds have included isolated baleen whale vertebrae, a broken sperm whale tooth, the spine of an extinct sawshark, dental plates of eagle rays and a number of great white shark teeth."" The work has been dedicated to Dr. Alan Beu, New Zealand's leading molluscan fossil expert, who was working on the fossils when he passed away earlier this year.

More information: A diverse Late Pliocene fossil fauna and its paleoenvironment at Māngere, Auckland, New Zealand, New Zealand Journal of Geology and Geophysics (2023). DOI: 10.1080/00288306.2023.2243234",https://scx2.b-cdn.net/gfx/news/2018/fossil.jpg,https://phys.org/news/2023-08-auckland-wastewater-pipe-reveals-fossil.html,Science
['Loukia Papadopoulos'],2023-08-27 17:01:46+00:00,Fossil treasure trove found in wastewater pipe dig,"Researchers in New Zealand have stumbled on 266 fossil species in an Auckland wastewater pipe dig, an area that was completely hidden from paleontologists making the discovery a very pleasant surprise. The find is notably one of the richest and most diverse groups of three-million-year-old fauna ever found in the small nation and will likely lead to at least ten previously unknown species being discovered.

This is according to a press release published on Sunday.

An unexpected find

The rare finds date from 2020 when Auckland’s Watercare workers were doing construction for a significant upgrade of the major pipeline that brings raw sewage for treatment from the central city. The workers accidentally hit an ancient shell bed and once informed of the fossil deposit’s significance proceeded to provide a huge heap of shelly sand so that paleontologists could search through it uncovering precious finds.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/27/image/jpeg/iAvMQ9qeBb7TBWejalOYClQJBq0kYp7en9trYZQI.jpg,https://interestingengineering.com/science/fossil-treasure-trove-found-in-wastewater-pipe-dig,Science
"['Laura Baisas', 'Laura Is A Science News Writer', 'Covering A Wide Variety Of Subjects', 'But She Is Particularly Fascinated All Things Aquatic', 'Paleontology', 'Nanotechnology', 'Exploring How Science Influences Daily Life. Laura Is A Proud Former Resident Of The New Jersey Shore', 'A Competitive Swimmer', 'A Fierce Defender Of The Oxford Comma.']",2023-08-28 08:00:00-04:00,Fossils of 10 unknown species found by sewage plant,"Fossils and ancient relics of the past turn up in some weird places, from the stretches of the New Jersey shore and random Walmarts to Swedish lakes and even the moon. They are also common finds during major excavations. More than 200 fossil species were found in a mound of sand beneath Mangere Wastewater Treatment Plant in Auckland, New Zealand.

[Related from PopSci+: The ghosts of the dinosaurs we may never discover.]

The fossils include some of the world’s oldest known flax snails, an extinct sawshark spine, great white shark teeth, and at least 10 previously known species. They are described in a study published on August 28 in the New Zealand Journal of Geology and Geophysics. According to the team, this treasure trove represents one of the richest and most diverse groups of three-million-year-old animal fossils ever found in New Zealand.

They were first uncovered in 2020 by Watercare, Auckland’s water and wastewater service. The company was excavating two large vertical shafts as part of an upgrade to the major pipeline that brings raw sewage from the center of the city to a plant for treatment. While digging, they came upon the ancient shell bed dating back at least three million years. Geologist and study co-author Bruce Hayward from Auckland-based research group Geomarine Research said that the discovery was similar to “finding gold right on your doorstep.”

Watercare and their contractors brought the shelly sand over to a nearby field so that Hayward and a team of paleontologists led by Auckland Museum curator Wilma Blom could carefully sift through it. The team examined more than 300,000 fossils of 266 species, and several thousand specimens have been brought to this museum.

The fossils were likely deposited between 3 and 3.7 million years ago into a subtidal channel that would become present-day Manukau Harbour. “At that time, sea level was slightly higher than it is today as the world was also several degrees warmer than now,” Hayward said in a statement. “As a result, the fossils include a number of subtropical species, whose relatives today live in the warmer waters around the Kermadec and Norfolk islands.”

In the study, the team describes 266 different fossil species and some rare finds, including a baleen whale vertebrae, dental plates of eagle rays, and a broken sperm whale tooth. The roughly 10 previously unknown species described and named in future research.

[Related: Fossil trove in Wales is a 462-million-year-old world of wee sea creatures.]

One aspect of this fossil bed that surprised the team is that the fossilized remains belong to animals that lived in many different environments that were eventually brought together in the ancient marine channel through strong currents and waves. Ten specimens of an iconic mollusk called the New Zealand flax snail likely lived on the land next to the ancient subtidal channel and were washed out to sea by storm runoff, according to the team. Other specimens were likely attached to hard rocky shorelines, while others were washed into the channel from areas further offshore.

The team dedicated the work to New Zealand’s leading molluscan fossil expert Alan Beu, who was working on the fossils before he died earlier this year.",https://www.popsci.com/uploads/2023/08/28/new-zealand-fossils.png?auto=webp,https://www.popsci.com/science/fossils-unknown-species/,Science
[],,Auckland wastewater pipe dig reveals 'fossil treasure trove',"Fossils of the world's oldest known flax snails, an extinct sawshark spine, and great white shark teeth have all been found in a mound of sand excavated from beneath Mangere Wastewater Treatment Plant in 2020

A new New Zealand Journal of Geology and Geophysics paper out today describes the 266 fossil species as one of the richest and most diverse groups of three-million-year-old fauna ever found in New Zealand. At least ten previously unknown species will be described and named in future research.

Fossil treasure trove from Auckland’s Mangere Wastewater Treatment Plant

In 2020, when Auckland’s Watercare were excavating two huge vertical shafts for a major upgrade of the major pipeline that brings raw sewage for treatment from the central city they dug through an ancient shell bed. Auckland paleontologist Bruce Hayward likened it to “finding gold right on your door step”. Once they were informed of the fossil deposit’s significance, Watercare and their contractors were eager to help and a huge heap of shelly sand was dumped in a nearby paddock so that paleontologists could search through it over many months. Watercare also funded two paleontology graduate students, working under the supervision of Auckland Museum curator Dr Wilma Blom, to painstakingly sift through the heap for many weeks. As a result, it is estimated that over 300,000 fossils were examined and several thousand have been returned in the museum as a record of this “once-in-a-lifetime find”.

“Detailed identification of the fossils shows that they were deposited between 3 and 3.7 million years ago in a subtidal channel in an early version of the modern Manukau Harbour”, said Dr Hayward. “At that time, sea level was slightly higher than it is today as the world was also several degrees warmer than now. As a result, the fossils include a number of subtropical species, whose relatives today live in the warmer waters around the Kermadec and Norfolk islands. At least ten previously unknown species are present and will be described and named in future work.”

In their scientific paper that appeared this week in the New Zealand Journal of Geology and Geophysics, the five authors record 266 different fossil species, making it the richest and most diverse fauna of its age ever found in New Zealand. “What is surprising,” says lead author Dr Hayward “is that the fauna contains fossils that lived in many different environments that have been brought together in the ancient marine channel by wave action and strong tidal currents. It includes ten specimens of the iconic NZ flax snail that must have lived on the adjacent land and been washed down into the sea by storm runoff. These are by far the oldest known flax snails in the world. Most of the fossils lived on the sea floor, some in brackish estuaries, others attached to hard rocky shorelines and still more have been carried in from offshore of the exposed west coast at the time.”

“Rare finds have included isolated baleen whale vertebrae, a broken sperm whale tooth, the spine of an extinct sawshark, dental plates of eagle rays and a number of great white shark teeth.” The work has been dedicated to Dr Alan Beu, New Zealand’s leading molluscan fossil expert, who was working on the fossils when he passed away earlier this year.",https://earimediaprodweb.azurewebsites.net/Api/v1/Multimedia/4655c523-517d-4257-9de9-b011ea25a0dd/Rendition/thumbnail/Content/Public,https://www.eurekalert.org/news-releases/999615,Science
[],,Skywatchers alert! Saturn will make its brightest and biggest appearance this weekend. Here's how to watch it,"Skywatchers assemble! Saturn, the giant ringed planet might make its best appearance of 2023 this weekend. The sixth planet will be the brightest and best placed (as seen from Earth) during this time, which will be a delight to skywatchers’ eyes.

This weekend, Saturn will be situated directly opposite the Sun with Earth in the middle. According to NASA, the gas-giant will also reach its perigee, that is, it will be closest to Earth. The combination of these two celestial events will make Saturn appear at its brightest and biggest this weekend.

The planet will remain visible through February 2024.

Here is everything you need to know to see Saturn at its brightest and best in 2023:

When will Saturn be at its biggest and brightest?

Saturn’s best view can be seen on Sunday (Aug 27), as per Space.com. On Sunday, the planet will reach its highest point around midnight in North America, while the exact moment of its appearance will occur a few hours later, around 4:20 am EDT (8:20 GMT or 1:50 pm IST) on Sunday.

At the moment of opposition, Saturn will reach magnitude 0.4, its brightest for 2023. Brighter objects have a lower magnitude; the full moon, by comparison, has a magnitude of around -12.6, according to NASA. This means Saturn should be easily visible to the unaided eye as a bright, non-flickering orb in the sky.

How to watch Saturn at its brightest and biggest?

Though on Sunday, Saturn can be viewed with the naked eye, but binoculars will reveal more detail and bring out the pale yellow colour of the planet. Under the right conditions, some high-power binoculars could even begin to bring out faint traces of Saturn's rings or even its largest moon, Titan.

Through a telescope, however, Saturn's rings should be clearly apparent. The gas giant's rings are currently beginning to tilt more on-edge toward Earth and will continue to do so through 2025, according to NASA. That makes this weekend an optimal time to catch a glimpse of one of the best night sky targets available to most backyard skywatchers.

The best way to find Saturn in the night sky

The ringed planet is currently within the constellation of Aquarius, which is visible in the northern sky as seen from the northern hemisphere. It would be perfect to find a clear view of the southern horizon to spot Saturn easily.

(With inputs from agencies)





WATCH WION LIVE HERE",https://cdn.wionews.com/sites/default/files/2023/08/27/375800-untitled-design-2023-08-27t124429254.png,https://www.wionews.com/science/skywatchers-alert-saturn-will-make-its-brightest-and-biggest-appearance-this-weekend-heres-how-to-watch-it-629648,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
"['Lauren Perkins', 'Nasa Marshall Space Flight Center']",2023-08-27 01:46:10-07:00,Ring Side Seats: Three Ways To Witness Saturn’s 2023 Opposition,"Saturn will be in opposition on August 26-27, 2023, appearing brighter. With the right equipment, viewers can discern its rings. Additionally, a Super Blue Moon will occur on August 30, 2023.

Saturn will be located directly opposite of the Sun – at opposition – on August 26-27, 2023, as the Earth orbits between the two. From our vantage point, the Sun’s illumination will allow Saturn to appear bigger and brighter in the sky in the weeks leading up to and after the opposition. In fact, Saturn remains visible until February 2024, so don’t worry if your local weather doesn’t cooperate with your viewing plans on any particular day.

Unaided Eye

Saturn is the farthest planet from Earth easily visible by the unaided human eye. It will appear on the southeastern horizon at sunset and you can spot the bright yellowish “star” all through the night until sunrise. Although you won’t be able to view any distinguishing features, like the famed icy rings without an aid, opposition is the brightest the planet will appear – pretty good for something over 800 million miles away!

Binoculars

Viewing Saturn through binoculars will enhance its golden color and depending on your binoculars, allow you to make out a hint of the telltale rings, appearing more like “ears”. If you have dark, clear viewing conditions, you may also be able to observe Saturn’s largest moon Titan through your binoculars.

Telescope

As is true with other celestial objects, a telescope will vastly improve what and how much you are able to see. Even a small telescope will allow you to see more details of Saturn’s rings. Of all the planets that can be observed, many astronomers encourage a Saturn-viewing in everyone’s lifetime. Even a modest magnification can provide a unique experience.

Bonus Viewing

Opposition not only makes for a slightly bigger and brighter appearing planet, but as you watch the skies over the next week, you’ll also be treated to a waxing gibbous moon leading up to the Super Blue Moon on August 30, 2023. A supermoon occurs when the Moon’s orbit is closest (perigee) to Earth at the same time the Moon is full, causing the Moon to appear slightly larger and brighter than a regular full moon. A blue moon is the second full moon in a month.

Happy skygazing!",https://scitechdaily.com/images/Saturn-Rings-Close-Illustration.jpg,https://scitechdaily.com/ring-side-seats-three-ways-to-witness-saturns-2023-opposition/,Science
['Oregon Coast Beach Connection'],,"Saturn at its closest and brightest now for Washington, Oregon, the coast","Saturn at its closest and brightest now for Washington, Oregon, the coast

Published 08/26/23 at 3:27 p.m.

By Oregon Coast Beach Connection staff

(Portland, Oregon) – If you like looking up at the stars, you're going to love the evenings in August in Washington, Oregon and along the coastlines. Jupiter has been the standout for months and still is: that extremely bright star that has even been cutting through some of the thin clouds and wildfire haze. Saturn, however, will be making a grand appearance in the south and southeast skies, as it reaches opposition on Sunday. Photo credits: NASA, ESA, and Amy Simon (NASA-GSFC); Image Processing: Alyssa Pagan (STScI))

According to Jim Todd of OMSI in Portland, Oregon, opposition lets Saturn become the biggest we'll see it all year, though it will tend to drop below the horizon by 1 a.m. Also, it won't be nearly as bright as Jupiter, but still at its brightest of the year.

“For stargazers and astrophotographers, it's an ideal time to view and photograph the superior planets,” Todd said.

If you're on the Oregon coast or Washington coast, varying amount of clouds will be present, so that could dampen your ability to see Saturn. For other areas of the Pacific Northwest, places like Seattle, Portland or Spokane will be dealing with haze and / or smoke, while southern Oregon will definitely be seeing more smoke.

However, Saturn began entering opposition early this month and it will take a couple of weeks before that brightness diminishes.

Washington Coast Weather - Oregon Coast Weather

“The planet Saturn will be in opposition on Sunday, August 27th,” Todd said. “At a distance of 814 million miles or 8.76 AU, the ringed planet will be making its closest approach to Earth and its face will be fully illuminated by the Sun. At a magnitude of 0.41, Saturn will be brighter than any other time of the year. Around its August 26-27 opposition, Saturn is rising in the east at sunset and visible all night. This happens because when Saturn lies opposite the Sun in the sky, the solar system is lined up so that Saturn, the Earth, and the Sun form a straight line with the Earth in the middle, on the same side of the Sun as Saturn.”



Above Cannon Beach (Oregon Coast Beach Connection)

You'll find Saturn easy to spot in the nighttime sky, Todd said. Look to the horizon to the south during most of the year, and there Saturn sits fairly high in the sky. While in opposition, the ringed planet hangs out in lower elevations as darkness falls. It doesn't get higher than 33 degrees in the sky, however. That happens about 1:10 a.m.

Todd said this is the best time to view Saturn's rings.

Also see Green Nightglow Above Us All the Time, You Just Didn't Know: Washington / Oregon Coast Science - Also called chemiluminescence, once you see it you can't unsee it

“The rings of Saturn can be seen in any telescope that magnifies at least 25 times, but the larger the aperture and the sharper the image, the more detail that can be made out,” he told Oregon Coast Beach Connection. “A medium-sized or larger telescope will allow you to see Saturn's largest moon, Titan nearby. In opposition, Saturn’s rings are tilted by 8.1 degrees, relative to earthly viewers. “



Courtesy NASA / Cassini spacecraft



Afterward, for the rest of 2023, Saturn will remain visible in the evening sky. It will finally disappear in the sunset glare by February 2024.

Todd said Saturn comes to opposition nearly every earthly year. A year is the length of time Earth takes to travel once around the sun. But Saturn’s orbit around the sun takes 29.4 Earth years. So each year we have to travel slightly farther in orbit to catch up to and pass, Saturn again. Thus Saturn's oppositions are roughly 378 days apart and Saturn’s opposition comes about two weeks later each year.

You can learn more about Saturn and the current night sky in OMSI Planetarium’s show, Starry Night Live!. For a schedule, go to OMSI.edu.

Oregon Coast Hotels for this event - South Coast Hotels - Where to eat - Maps - Virtual Tours







MORE PHOTOS BELOW













Bandon, Photo Courtesy Manuela Durson Fine Arts

More About Oregon Coast hotels, lodging.....

More About Oregon Coast Restaurants, Dining.....



Coastal Spotlight



Andre' GW Hagestedt is editor, owner and primary photographer / videographer of Oregon Coast Beach Connection, an online publication that sees over 1 million pageviews per month. He is also author of several books about the coast.

LATEST Related Oregon Coast Articles

Back to Oregon Coast

Contact Advertise on Oregon Coast Beach Connection

All Content, unless otherwise attributed, copyright Oregon Coast Beach Connection. Unauthorized use or publication is not permitted",https://www.beachconnection.net/news/nasa_saturn.jpg,,Science
"['Jamie Carter', 'Contributing Writer', 'Social Links Navigation']",2023-08-27 13:00:10+00:00,Which U.S. states will October's 'ring of fire' solar eclipse be visible from?,"The May 10, 1994 annular eclipse that swept across the U.S. from the desert Southwest to New England.

Where to go for the annular solar eclipse on October 14, 2023 , is largely down to where the eclipse path is.

On that day the entire Americas will experience a partial solar eclipse , but the 'ring of fire' will only be visible from within a 125-mile (200-kilometer) wide path heading from the northwest U.S. through Central America to Brazil.

That path of the eclipse is the moon 's antumbra, where the moon appears completely within the sun 's disk to create the 'ring of fire' effect. The light levels will also noticeably fade as 90% of the sun is covered. Outside of the path is the moon's penumbra — its fuzzier outer shadow — where a partial solar eclipse will be visible across North, Central and South America

Related: How to read and understand a solar eclipse map

Although it won't be as dramatic as the total solar eclipse 177 days later on April 8, 2024, in Mexico the U.S. and Canada, this annular solar eclipse will be worth watching. ""The 'ring of fire' will be a spectacle all of its own,"" Michael Zeiler, cartographer and eclipse-chaser at GreatAmericanEclipse.com told Space.com during a Zoom interview. ""With eclipse glasses, you'll see the eerie sight of the sun appearing as a brilliant ring of sunlight.""

How to make a plan for the 'ring of fire' solar eclipse

The path of annularity crossing the U.S. on October 14, 2023. (Image credit: NASA Scientific Visualization Studio)

When planning where to go, research where has the best climate and likelihood of clear skies. ""I would recommend the U.S. National Parks in the 'Four Corners' area where Colorado, New Mexico, Utah and Ariana meet because it's a sunny time of year after the monsoon season and before the winter storms,"" says Zeiler. ""An ideal trip would be to rent an RV and visit some of the magnificent places in the area at a time of year when you're not going to encounter huge crowds, except on eclipse day."" However, it would be wise to stay mobile and keep plans relatively fluid, checking weather apps like Windy in the days before the eclipse and re-locating if necessary.

It all begins with the position of the path of annularity on October 14, 2023. Only eight U.S. states, from Oregon through Texas, will see the 'ring of fire' (we've not included Idaho since only a tiny sliver of that state is crossed by the path). Here's where you need to be on the day of the eclipse to see the most of what this solar eclipse has to offer.

Related: Annular solar eclipse October 2023: Plan your trip to see the amazing 'ring of fire' eclipse with these top tips

1. Southern Oregon

Oregon's coastal dunes and beaches will see the 'ring of fire'. (Image credit: Marli Miller/UCG/Universal Images Group via Getty Images)

Eclipse details When: 9:15-9:24 a.m. PDT Maximum duration of 'ring of fire': 4 mins and 32 secs. Key locations: Crater Lake National Park, Oregon Dunes National Recreation Area, Klamath Falls. Climate: High chance of cloud west of the Cascades, likely clear to the east

As the 'ring of fire' arrives in the Beaver State it will be just 17 degrees up in the southeast, so photographers will likely line its beautiful coast between Lincoln Beach and Denmark. However, it's an often misty coast, so it's a risky choice.

Ditto the sight of the 'ring of fire' reflecting in America's deepest lake at Crater Lake National Park . Nearby is Klamath Falls and its EclipseFest 2023 . Clear skies are more likely on the eastern side of the Cascade mountain range, with the Oregon Outback Scenic Byway in the arid high desert potentially a good option. Either way, it could get busy in Oregon. ""The path is a two-hour drive south from Portland and six hours from Seattle,"" says Zeiler. ""That's a lot of people.""

Related: 10 breathtaking locations to see October 2023's 'ring of fire' annular solar eclipse

2. Northeastern California

Eclipse details When: 9:18-9:22 a.m. PDT Maximum duration of 'ring of fire': 4 mins and 39 secs Key locations: Lava Beds National Monument, Tule Lake National Wildlife Refuge Climate: Clear skies likely

Although the annular solar eclipse comes to California, the path only clips its northeast corner. ""It's a very lightly populated part of California,"" says Zeiler, who doesn't think the area will get too many visits from within the state. ""For people in the San Francisco Bay area or southern California, their shortest journey into the path takes them into Nevada or Utah."" One scenic location within California is Lava Beds National Monument close to the northern edge of the path, where a long display of Baily's beads is expected.

Related: 'Ring of fire' from US national parks: 7 great places to see the annular solar eclipse 2023

3. Northern Nevada

The 'ring of fire' will be seen from the Ward Charcoal Ovens near Ely, Nevada. (Image credit: Bernard Friel/Education Images/Universal Images Group via Getty Images.)

Eclipse details When: 9:18-9:28 a.m. PDT Maximum duration of 'ring of fire': 4 mins and 37 secs. Key locations: Great Basin National Park, Ely, Winnemucca Climate: Clear skies likely

Massacre Rim Dark Sky National Conservation Area in remote northwestern Nevada might attract the adventurous, but most will head from California or Salt Lake City on Interstate 80 (which intersects the path and passes many small towns, such as Winnemucca), or from Las Vegas in the south. A popular target will be Great Basin National Park in the Snake Range. Nearby Ely will host a NASA live-streaming team at its Ring of Fire Eclipse Festival .

4. Southern Utah

The 'ring of fire' will be visible from the Grand View Point Overlook in Canyonlands National Park in Utah. (Image credit: Andrew Lloyd/Loop Images/Universal Images Group via Getty Images)

Eclipse details When: 10:24-10:35 a.m. MDT Maximum duration of 'ring of fire': 4 mins and 40 secs. Key locations: Capitol Reef National Park, Bryce Canyon National Park, Grand Staircase-Escalante National Monument, Natural Bridges National Monument, Hovenweep National Monument and Bears Ears National Monument, Canyonlands National Park Climate: Clear skies likely

The path through Utah crosses some of the most iconic landscapes in the U.S. Visitors from Salt Lake City and Las Vegas can intersect the path using Interstate 15, but to its southeast are U.S. National Parks including Bryce Canyon , Capitol Reef and Canyonlands . However, choices are almost endless, with other beauty spots in the path including State Parks like Kodachrome Basin , Goosenecks and Goblin Valley , the National Monuments of Natural Bridges , Bear Ears and Hovenweep . Valley of the Gods near Mexican Hat is also in the path.

Related: Dark Sky Utah: A complete guide to astro-travel in America's darkest state

5. Southwest Colorado

Eclipse details When: 10:30-10:35 a.m. MDT Maximum duration of 'ring of fire': 4 mins and 30 secs Key locations: Mesa Verde National Park, Canyon of the Ancients National Monument, Yucca House National Monument Climate: Clear skies expected

Colorado is another state just shaved by the eclipse path, but this Mesa Verde Region of the Colorado Plateau includes the famous Mesa Verde National Park and the less visited Canyons of the Ancients National Monument and Yucca House National Monument as well as the town of Cortez. A popular place — with the longest-lasting 'ring of fire' in Colorado — will be the Four Corners National Monument where Colorado meets Utah, New Mexico and Arizona.

Related: The ultimate guide to planning epic stargazing road trips in the US southwest

6. Northeastern Arizona

Eclipse details When: 10:29-10:35 a.m. MDT Maximum duration of 'ring of fire': 4 mins and 26 secs. Key locations: Monument Valley Navajo Tribal Park, Canyon de Chelly National Monument, Navajo National Monument Climate: Clear skies likely

Monument Valley Navajo Tribal Park in Navajo Nation on the border with Utah is easily the most well-known destination in the area of Arizona crossed by the eclipse path. However, there are two others; Canyon de Chelly National Monument to the east and Navajo National Monument to the south. Eclipse-chasers at all of these locations should respect indigenous attitudes to eclipses . Popular tourist sites around Page, Arizona — such as Horseshoe Bend, Antelope Canyon and Lake Powell — are sadly just beyond the southern limits of the path.

7. New Mexico

Albuquerque Balloon Fiesta will host a ""balloon glow"" during the ""ring of fire"". (Image credit: Leo York/Anadolu Agency/Getty Images)

Eclipse details When: 10:30-10:46 a.m. MDT Maximum duration of 'ring of fire': 4 mins and 46 secs Key locations: Chaco Canyon, Albuquerque Balloon Fiesta, Roswell Climate: Highest chance of clear skies

The path dissects New Mexico from northwest to southeast, crossing some remote areas on either side of one of the biggest cities anywhere in the path. ""Albuquerque is going to be 'ground zero' for the annular and it's the perfect place to see it,"" says Jayne Aubele from Albuquerque's New Mexico Museum of Natural History and Science. ""The sun will be fairly high in the sky and it happens on the last Saturday of the Albuquerque International Balloon Fiesta ."" Albuquerque is going to be very busy on eclipse day, but there are plenty of other places to consider, from Shiprock, Aztec Ruins National Monument and Chaco Culture National Historic Park to Santa Fe and Roswell.

Related: How to build your own solar eclipse viewer (video)

8. Texas

Eclipse details When: 11:41-12:03 p.m. CDT Maximum duration of 'ring of fire': 4 mins and 52 secs Key locations: San Antonio, Texas Hill Country, Padre Island National Seashore Climate: Likely clear in West Texas, potentially cloudy elsewhere

The most populous part of the entire eclipse path, Texas is the final U.S. state where a ""ring of fire"" will be visible. San Antonio and Corpus Christi both get the peak experience, with Odessa and Midland in the state's west ideal for a more remote experience (with a higher chance of clear skies). In between is Texas Hill Country, 120 square miles of which will also experience totality during the total solar eclipse on April 8, 2024. Places that will see both eclipses include Concan, Vanderpool, Bandera, Kerrville and Uvalde.

Related: 10 best events across the US to celebrate the Oct. 14 annular solar eclipse

Additional resources",https://cdn.mos.cms.futurecdn.net/RcmzyTfswX9iABkXr7R8jc-1200-80.jpg,https://www.space.com/which-us-states-oct-ring-of-fire-annular-solar-eclipse-visible-from,Science
[],,An annular solar eclipse will bring a 'ring of fire' over San Antonio,,https://i.ytimg.com/vi/vL40lWczzOI/maxresdefault.jpg,https://www.youtube.com/watch?v=vL40lWczzOI,Science
"['Katu Staff', 'Https', 'Www.Facebook.Com Katunews']",,Prepare for Oregon's 'ring of fire' eclipse next month,"Prepare for Oregon's 'ring of fire' eclipse next month

Annular solar eclipse May 20, 2012. (Bill Dunford/NASA)",https://katu.com/resources/media/89a2955b-6f7b-43cf-99f9-7e4abcc5135f-large16x9_74_annular_eclipse_detailbilldunfordnasamay202012.jpg,https://katu.com/news/local/prepare-for-oregons-ring-of-fire-annular-solar-eclipse-next-month,Science
"['Neuroscience News', 'Neuroscience News Posts Science Research News Labs', 'Universities', 'Hospitals', 'News Departments Around The World.', 'Science Articles Cover Neuroscience', 'Psychology', 'Ai', 'Robotics', 'Neurology']",2023-08-27 20:11:14+00:00,A Protein Guardian of Our Genes and Immune System Identified,"Summary: Researchers identified a critical protein called midnolin that degrades short-lived nuclear proteins, solving a long-standing biological mystery. These proteins play essential roles in gene expression, affecting brain development, learning, and immune responses.

Midnolin ushers these proteins into the cell’s waste disposal system—the proteasome—for destruction. This groundbreaking discovery has promising implications for therapies targeting neurological disorders and cancers.

Key Facts

Midnolin directly targets short-lived proteins for degradation, facilitating crucial cellular processes such as gene modulation and immune response. This discovery resolves decades-long questions about a ubiquitin-independent mechanism for protein degradation. Manipulating the midnolin-proteasome pathway may lead to new therapies for a range of diseases including neurological disorders and certain cancers.

Source: Harvard

Short-lived proteins control gene expression in cells to carry out a number of vital tasks, from helping the brain form connections to helping the body mount an immune defense. These proteins are made in the nucleus and are quickly destroyed once they’ve done their job.

Despite their importance, the process by which these proteins get broken down and removed from cells once they are no longer needed has eluded scientists for decades — until now.

In a cross-departmental collaboration, researchers from Harvard Medical School identified a protein called midnolin that plays a key role in degrading many short-lived nuclear proteins.

Other proteins like IRF4 activate genes that support the immune system by ensuring that cells can make functional B and T cells. Credit: Neuroscience News

The study shows that midnolin does so by directly grabbing the proteins and pulling them into the cellular waste-disposal system, called the proteasome, where they are destroyed.

The findings are published Aug. 24 in Science.

“These particular short-lived proteins have been known for over 40 years, but no one had established how they are actually degraded,” said co-lead author Xin Gu, a research fellow in neurobiology at HMS.

Because the proteins broken down by this process modulate genes with important functions related to the brain, the immune system, and development, scientists may eventually be able to target the process as a way of controlling protein levels to alter these functions and correct any dysfunction.

“The mechanism we found is very simple and quite elegant,” added co-lead author Christopher Nardone, a PhD candidate in genetics at HMS. “It is a basic science discovery, but there are many implications for the future.”

A molecular mystery

It is well established that cells can break down proteins by tagging them with a small molecule called ubiquitin. The tag tells the proteasome that the proteins are no longer needed, and it destroys them. Much of the pioneering research on this process was done by the late Fred Goldberg at HMS.

However, sometimes the proteasome breaks down proteins without the help of ubiquitin tags, leading researchers to suspect that there was another, ubiquitin-independent mechanism of protein degradation.

“There has been sporadic evidence in the literature that somehow the proteasome can directly degrade unmarked proteins, but no one understood how that can happen,” Nardone said.

One group of proteins that seemed to be degraded by an alternative mechanism are stimuli-induced transcription factors: Proteins rapidly made in response to cellular stimuli that travel to the nucleus of a cell to turn on genes, after which they are rapidly destroyed.

“What struck me in the beginning is that these proteins are extremely unstable and they have a very short half-life — once they are produced, they carry out their function, and they are quickly degraded afterwards,” Gu said.

These transcription factors support a range of important biological processes in the body, yet even after decades of research, “the mechanism of their turnover was largely unknown,” said Michael Greenberg, the Nathan Marsh Pusey Professor of Neurobiology in the Blavatnik Institute at HMS and a co-senior author on the paper with Stephen Elledge, the Gregor Mendel Professor of Genetics and of Medicine at HMS and Brigham and Women’s Hospital.

From a handful to hundreds

To investigate this mechanism, the team began with two familiar transcription factors: Fos, studied extensively by the Greenberg lab for its role in learning and memory, and EGR1, which is involved in cell division and survival.

Using sophisticated protein and genetic analyses developed in the Elledge lab, the researchers homed in on midnolin as a protein that helps break down both transcription factors.

Follow-up experiments revealed that in addition to Fos and EGR1, midnolin may also be involved in breaking down hundreds of other transcription factors in the nucleus.

Gu and Nardone recall being shocked and skeptical about their results. To confirm their findings, they decided they needed to figure out exactly how midnolin targets and degrades so many different proteins.

“Once we identified all these proteins, there were many puzzling questions about how the midnolin mechanism actually works,” Nardone said.

With the aid of a machine learning tool called AlphaFold that predicts protein structures, plus results from a series of lab experiments, the team was able to flesh out the details of the mechanism. They established that midnolin has a “Catch domain” — a region of the protein that grabs other proteins and feeds them directly into the proteasome, where they are broken down.

This Catch domain is composed of two separate regions linked by amino acids (think mittens on a string) that grab a relatively unstructured region of a protein, thus allowing midnolin to capture many different types of proteins.

Of note are proteins like Fos that are responsible for turning on genes that prompt neurons in the brain to wire and rewire themselves in response to stimuli. Other proteins like IRF4 activate genes that support the immune system by ensuring that cells can make functional B and T cells.

“The most exciting aspect of this study is that we now understand a new general, ubiquitination-independent mechanism that degrades proteins,” Elledge said.

Tantalizing translational potential

In the short term, the researchers want to delve deeper into the mechanism they discovered. They are planning structural studies to better understand the fine-scale details of how midnolin captures and degrades proteins. They are also making mice that lack midnolin to understand the protein’s role in different cells and stages of development.

The scientists say their finding has tantalizing translational potential. It may offer a pathway that researchers can harness to control levels of transcription factors, thus modulating gene expression, and in turn, associated processes in the body.

“Protein degradation is a critical process and its deregulation underlies many disorders and diseases,” including certain neurological and psychiatric conditions, as well as some cancers, Greenberg said.

For example, when cells have too much or too little of transcription factors such as Fos, problems with learning and memory may arise. In multiple myeloma, cancer cells become addicted to the immune protein IRF4, so its presence can fuel the disease.

The researchers are especially interested in identifying diseases that may be good candidates for the development of therapies that work through the midnolin-proteasome pathway.

“One of the areas we are actively exploring is how to tune the specificity of the mechanism so it can specifically degrade proteins of interest,” Gu said.

Authorship, funding, disclosures

Additional authors on the paper include Nolan Kamitaki of HMS and Aoyue Mao of HMS, Brigham and Women’s, and Harvard University.

Funding: Funding was provided by a National Mah Jongg League Fellowship from the Damon Runyon Cancer Research Foundation, a National Science Foundation Graduate Research Fellowship, and the National Institutes of Health (T32 HG002295; R01 NS115965; AG11085).

Elledge is a founder of TScan Therapeutics, Maze Therapeutics, ImmuneID, and Mirimus, serves on the scientific advisory boards of Homology Medicines, ImmuneID, Maze Therapeutics, X-Chem, and TScan Therapeutics, and is an advisor for MPM Capital.

About this genetics research news

Author: Dennis Nealon

Source: Harvard

Contact: Dennis Nealon – Harvard

Image: The image is credited to Neuroscience News

Original Research: Closed access.

“The midnolin-proteasome pathway catches proteins for ubiquitination-independent degradation” by Xin Gu et al. Science

Abstract

The midnolin-proteasome pathway catches proteins for ubiquitination-independent degradation

INTRODUCTION

In mammals, the transcriptional response to growth factor, neuronal, and immune stimuli is mediated by a group of genes called immediate-early genes (IEGs), which encode transcription factors of the Fos, EGR, and NR4A families.

IEG proteins are activated stereotypically in virtually all mammalian cells but promote the transcription of late-response genes (LRGs) that are cell-type specific and crucial for the appropriate response to the initial stimulus. The physiological importance of IEGs is underscored by the fact that misregulation of their expression can lead to cancer, immune deficiencies, and neurological disorders.

The IEG mRNAs accumulate within minutes after the initial stimulus and, once translated, their proteins are rapidly degraded to allow for a transient burst of protein expression. Although the mechanisms that regulate IEG transcription are well characterized, how IEG proteins are swiftly targeted for destruction has remained mysterious for many years.

RATIONALE

Eukaryotic cells rely on a macromolecular protease called the proteasome that canonically degrades proteins marked with ubiquitin. It has been suggested that the Fos family is targeted to the proteasome by both ubiquitination-dependent and -independent mechanisms, but the molecular events that orchestrate these processes have remained elusive. We hypothesized that there exists a cellular pathway dedicated to the rapid destruction of c-Fos and other IEG proteins. By harnessing the power of forward genetic screens, we sought to identify the machinery that controls the degradation of these proteins.

RESULTS

We performed genome-wide CRISPR-Cas9 screens to search for genes that regulate the stability of IEG proteins. We found that midnolin, a largely uncharacterized protein in mammals, promoted the proteasomal destruction of IEG proteins from structurally distinct families including c-Fos, FosB, EGR1, and NR4A1. These results prompted us to search for additional midnolin targets.

We used the global protein stability (GPS) assay with a human open reading frame library (ORFeome) to assess changes in protein stability for ~12,000 human proteins simultaneously. In addition to IEG proteins, midnolin promoted the degradation of IRF4, NeuroD1, PAX8, GATA1, and many other cell-type–specific transcriptional regulators in the nucleus, where midnolin itself resides.

Diverse stimuli that activate IEGs also induced midnolin, and midnolin overexpression was sufficient to cause the destruction of its targets by a mechanism that does not require ubiquitination. Multiple lines of evidence support this ubiquitination-independent mechanism of protein degradation.

Midnolin still bound to and promoted the degradation of many targets that had been mutated to lack lysine residues. Moreover, inhibition of the proteasome, but not E1 ubiquitin–activating enzymes, abrogated midnolin function.

Additionally, midnolin does not contain RING or HECT domains that are characteristic of E3 ubiquitin ligases or ubiquitin-binding domains found in proteasomal processivity factors such as Rad23.

Instead, midnolin engaged substrates using its “Catch” domain, which was necessary and sufficient to interact with unstructured regions within substrates that have the potential to form a β strand upon binding midnolin. These unstructured regions with the propensity to form a β strand were also necessary and sufficient to bind the Catch domain, thus functioning as a midnolin degron.

In addition, midnolin stably associated with the proteasome through a C-terminal α helix and promoted the degradation of Catch-bound targets using its N-terminal ubiquitin-like domain.

Thus, midnolin contains three conserved structural domains that function in concert to directly target a large set of nuclear proteins to the proteasome for ubiquitination-independent degradation.

CONCLUSION

Our study suggests that the midnolin-proteasome pathway may represent a general mechanism by which the proteasome bypasses the canonical ubiquitination system to achieve selective degradation of nuclear proteins, many of which are crucial for transcription. Within substrates, midnolin recognizes relatively degenerate amphipathic regions with the potential to form β strands, so the midnolin degron may be a common structural component of numerous proteins. How the midnolin-proteasome pathway is regulated by various cues in diverse cell types to control transcriptional programs will be an important subject of future exploration.",https://neurosciencenews.com/files/2023/08/genetics-immune-system-neuroscience.jpg,https://neurosciencenews.com/midnolin-genetics-immune-system-23837/,Science
['Harvard Medical School'],2023-08-26 21:34:36-07:00,Molecular Mystery Solved – Harvard Scientists Discover a Previously Unknown Way Cells Break Down Proteins,"The mechanism degrades short-lived proteins that support brain and immune functions

Short-lived proteins control gene expression in cells and execute critical roles ranging from assisting brain connectivity to fortifying the body’s immune response. Originating in the nucleus, these proteins are swiftly degraded after fulfilling their purpose.

For decades, the mechanism behind the degradation and removal of these essential proteins from cells remained a mystery to researchers — until now.

In a cross-departmental collaboration, researchers from Harvard Medical School identified a protein called midnolin that plays a key role in degrading many short-lived nuclear proteins. The study shows that midnolin does so by directly grabbing the proteins and pulling them into the cellular waste-disposal system, called the proteasome, where they are destroyed.

The findings were recently published in the journal Science.

“These particular short-lived proteins have been known for over 40 years, but no one has established how they are actually degraded,” said co-lead author Xin Gu, a research fellow in neurobiology at HMS.

Because the proteins broken down by this process modulate genes with important functions related to the brain, the immune system, and development, scientists may eventually be able to target the process as a way of controlling protein levels to alter these functions and correct any dysfunction.

“The mechanism we found is very simple and quite elegant,” added co-lead author Christopher Nardone, a PhD candidate in genetics at HMS. “It is a basic science discovery, but there are many implications for the future.”

A molecular mystery

It is well-established that cells can break down proteins by tagging them with a small molecule called ubiquitin. The tag tells the proteasome that the proteins are no longer needed, and it destroys them. Much of the pioneering research on this process was done by the late Fred Goldberg at HMS.

However, sometimes the proteasome breaks down proteins without the help of ubiquitin tags, leading researchers to suspect that there was another, ubiquitin-independent mechanism of protein degradation.

“There has been sporadic evidence in the literature that somehow the proteasome can directly degrade unmarked proteins, but no one understood how that can happen,” Nardone said.

One group of proteins that seemed to be degraded by an alternative mechanism are stimuli-induced transcription factors: Proteins rapidly made in response to cellular stimuli that travel to the nucleus of a cell to turn on genes, after which they are rapidly destroyed.

“What struck me, in the beginning, is that these proteins are extremely unstable and they have a very short half-life — once they are produced, they carry out their function, and they are quickly degraded afterward,” Gu said.

These transcription factors support a range of important biological processes in the body, yet even after decades of research, “the mechanism of their turnover was largely unknown,” said Michael Greenberg, the Nathan Marsh Pusey Professor of Neurobiology in the Blavatnik Institute at HMS and a co-senior author on the paper with Stephen Elledge, the Gregor Mendel Professor of Genetics and of Medicine at HMS and Brigham and Women’s Hospital.

From a handful to hundreds

To investigate this mechanism, the team began with two familiar transcription factors: Fos, studied extensively by the Greenberg lab for its role in learning and memory, and EGR1, which is involved in cell division and survival. Using sophisticated protein and genetic analyses developed in the Elledge lab, the researchers homed in on midnolin as a protein that helps break down both transcription factors. Follow-up experiments revealed that in addition to Fos and EGR1, midnolin may also be involved in breaking down hundreds of other transcription factors in the nucleus.

Gu and Nardone recall being shocked and skeptical about their results. To confirm their findings, they decided they needed to figure out exactly how midnolin targets and degrades so many different proteins.

“Once we identified all these proteins, there were many puzzling questions about how the midnolin mechanism actually works,” Nardone said.

With the aid of a machine learning tool called AlphaFold that predicts protein structures, plus results from a series of lab experiments, the team was able to flesh out the details of the mechanism. They established that midnolin has a “Catch domain” — a region of the protein that grabs other proteins and feeds them directly into the proteasome, where they are broken down. This Catch domain is composed of two separate regions linked by amino acids (think mittens on a string) that grab a relatively unstructured region of a protein, thus allowing midnolin to capture many different types of proteins.

Of note are proteins like Fos that are responsible for turning on genes that prompt neurons in the brain to wire and rewire themselves in response to stimuli. Other proteins like IRF4 activate genes that support the immune system by ensuring that cells can make functional B and T cells.

“The most exciting aspect of this study is that we now understand a new general, ubiquitination-independent mechanism that degrades proteins,” Elledge said.

Tantalizing translational potential

In the short term, the researchers want to delve deeper into the mechanism they discovered. They are planning structural studies to better understand the fine-scale details of how midnolin captures and degrades proteins. They are also making mice that lack midnolin to understand the protein’s role in different cells and stages of development.

The scientists say their finding has tantalizing translational potential. It may offer a pathway that researchers can harness to control levels of transcription factors, thus modulating gene expression, and in turn, associated processes in the body.

“Protein degradation is a critical process and its deregulation underlies many disorders and diseases,” including certain neurological and psychiatric conditions, as well as some cancers, Greenberg said.

For example, when cells have too much or too little of transcription factors such as Fos, problems with learning and memory may arise. In multiple myeloma, cancer cells become addicted to the immune protein IRF4, so its presence can fuel the disease. The researchers are especially interested in identifying diseases that may be good candidates for the development of therapies that work through the mindolin-proteasome pathway.

“One of the areas we are actively exploring is how to tune the specificity of the mechanism so it can specifically degrade proteins of interest,” Gu said.

Reference: “The midnolin-proteasome pathway catches proteins for ubiquitination-independent degradation” by Xin Gu, Christopher Nardone, Nolan Kamitaki, Aoyue Mao, Stephen J. Elledge and Michael E. Greenberg, 25 August 2023, Science.

DOI: 10.1126/science.adh5021

Funding was provided by a National Mah Jongg League Fellowship from the Damon Runyon Cancer Research Foundation, a National Science Foundation Graduate Research Fellowship, and the National Institutes of Health (T32 HG002295; R01 NS115965; AG11085).",https://scitechdaily.com/images/Glowing-Green-Cells.jpg,https://scitechdaily.com/molecular-mystery-solved-harvard-scientists-discover-a-previously-unknown-way-cells-break-down-proteins/,Science
['University Of Sydney'],2023-08-25 21:09:23-07:00,Unraveling the Secrets to Brain Diseases – When Proteins Get Stuck at Solid,"Viewing proteins at the nanoscale offers insights for treating neurodegenerative diseases.

Many diseases affecting the brain and nervous system are linked to the formation of protein aggregates, or solid condensates, in cells from their liquid form condensate, however, little is known about this process.

This liquid-to-solid transition can trigger the formation of what are called amyloid fibrils. These can further form plaques in neurons causing neurodegenerative diseases such as Alzheimer’s.

Biomedical engineers at the University of Sydney, in collaboration with scientists at the University of Cambridge and Harvard University, have now developed sophisticated optical techniques to monitor at close range the process by which these protein aggregates form.

By testing a protein associated with Amyotrophic Lateral Sclerosis – ALS disease, which affected astrophysicist Professor Stephen Hawking – the Sydney engineers closely monitored the transition of this protein from its liquid to solid phase.



3D confocal microscopy scan of a FUS protein condensate incubated for 24 hours showing the characteristic core-shell structure unveiled by this research. Credit: The University of Sydney

“This is a huge step forward to understanding how neurogenerative diseases develop from a fundamental perspective,” said Dr Yi Shen, lead author of the research published in the Proceedings of the National Academy of Sciences (PNAS) in the United States.

“We can now directly observe the transition of these critical proteins from liquid to solid at the nanoscale – a millionth of a meter in scale,” said Dr. Daniele Vigolo, a senior lecturer in the School of Biomedical Engineering and a member of the University of Sydney Nano Institute.

Proteins regularly form condensates during liquid-to-liquid phase separation in a wide range of critical and healthy biological functions, such as the formation of human embryos. This process assists biochemical reactions where protein concentrations are critical and also promotes healthy protein–protein interactions.

“However, this process also increases the risk of dysfunctional aggregation, where unhealthy aggregates of solid proteins form in human cells,” said Dr Shen, who is an ARC DECRA Fellow in the School of Chemical and Biomolecular Engineering and also a member of Sydney Nano.

“This can lead to aberrant structures associated with neurodegenerative diseases because the proteins no longer exhibit rapid reversibility back to liquid form. It is therefore crucial to monitor condensate dynamics, as they directly affect pathological states,” she said.

The world-first nanoscale optical observation of this process has allowed the team to determine that the transition from liquid to solid protein starts at the interface of the protein condensates. This window onto the phase transition also revealed that the internal structures of these protein agglomerates are heterogenous, where previously they were thought to be homogeneous.

Dr Vigolo said: “Our findings promise to greatly improve our understanding of neurogenerative diseases from a fundamental perspective.

“This means a promising new area of research to better understand how Alzheimer’s disease and ALS develops in the brain, affecting millions of people worldwide.”

Reference: “The liquid-to-solid transition of FUS is promoted by the condensate surface” by Yi Shen, Anqi Chen, Wenyun Wang, Yinan Shen, Francesco Simone Ruggeri, Stefano Aime, Zizhao Wang, Seema Qamar, Jorge R. Espinosa, Adiran Garaizar, Peter St George-Hyslop, Rosana Collepardo-Guevara, David A. Weitz, Daniele Vigolo and Tuomas P. J. Knowles, 7 August 2023, Proceedings of the National Academy of Sciences.

DOI: 10.1073/pnas.2301366120

The study was funded by the Frances and Augustus Newman Foundation, the Wellcome Trust, the European Research Council, the US Alzheimer Association, ALS Canada-Brain Canada, the Canadian Institutes of Health Research, and the National Institute on Aging.",https://scitechdaily.com/images/Nanoscale-Scan-Image-Showing-Protein-Condensate-Interaction.jpg,https://scitechdaily.com/unraveling-the-secrets-to-brain-diseases-when-proteins-get-stuck-at-solid/,Science
['Kobe University'],2023-08-27 23:15:20-07:00,The Orchid and the Fruit Fly – Scientists Discover Unique New Plant-Animal Relationship,"For the first time, orchids that consume fungi have been observed offering their flowers to fungi-eating fruit flies in return for pollination services. This discovery represents the first evidence of nursery pollination in orchids. This unique new plant-animal relationship hints at an evolutionary transition towards mutualistic symbiosis.

Orchids are well known to trick their pollinators into visiting the flowers by imitating food sources, breeding grounds, or even mates without actually offering anything in return. The fungi-eating, non-photosynthetic orchid genus Gastrodia is no different: To attract fruit flies (Drosophila spp.), the plants usually emit a smell like their common diet of fermented fruits or decaying mushrooms.

The fruit flies get lured into the flowers, are trapped there for a short while, and get pollen attached to their backs which they then transport to other plants of the same species. Thus, this deceptive relationship offers benefits to only one partner.

Kobe University plant biologist Suetsugu Kenji, a specialist on these orchids, noticed that a certain species of this genus, Gastrodia foetida, has particularly fleshy petals that decompose and fall off a few days after pollination. He decided to investigate these plants in the search for the first example of orchids engaging in “nursery pollination”, which is a plant offering a breeding ground to its pollinator.

And indeed, in the study now published in the journal Ecology, he reports that fruit flies often lay their eggs into the plant’s flowers and that their larvae can fully develop into adult flies in this environment.

Suetsugu says: “The most intriguing aspect is that contrary to its common name as the ‘fruit’ fly, Drosophila bizonata, a species specialized in mushroom-feeding, predominantly utilizes decaying Gastrodia foetida flowers as brood sites. A possible explanation is the fact that Gastrodia foetida is a non-photosynthetic orchid that feeds on fungi. These non-photosynthetic orchids often exhibit chemical resemblance to the fungi they assimilate, underlining the age-old adage ‘You are what you eat.’ As a plant that feeds on mushrooms, G. foetida likely tastes similar to a mushroom, making it a prime target for the mushroom-specialized fruit fly.” This discovery is significant because it uncovers a new type of nursery pollination system, going beyond deceptive strategies commonly found in the genus.

The Kobe University researcher further explains that the relationship is neither obligatory nor specific, that is, the fruit flies also lay fully developing eggs on fungi. Thus, this finding may represent an example of the transition from a deceptive relationship towards mutualistic symbiosis, suggested by two factors: the low cost to the plant, since the petals are not needed anymore after pollination; and that closely related Gastrodia dominantly utilize a deceptive strategy without providing a nursery.

Suetsugu concludes: “This study represents the first evidence of nursery pollination in orchids, comprising nearly 30,000 species, and being the most diverse plant group in the world. In addition, it contributes a vital understanding of the intricate and mutually beneficial relationships that can develop in nature. The understanding of how plants can offer genuine benefits rather than merely deceiving pollinators could impact the broader study of plant-animal interactions and their evolutionary dynamics.”

Reference: “A novel nursery pollination system between a mycoheterotrophic orchid and mushroom-feeding flies” by Kenji Suetsugu, 23 August 2023, Ecology.

DOI: 10.1002/ecy.4152

The study was funded by the Japan Science and Technology Agency.",https://scitechdaily.com/images/A-Fruit-Fly-Lays-Its-Eggs-Inside-a-Flower-of-Gastrodia-foetida.jpg,https://scitechdaily.com/the-orchid-and-the-fruit-fly-scientists-discover-unique-new-plant-animal-relationship/,Science
[],,Scientists spot edge of supermassive black hole accidentally,"Scientists have managed to look at the never-before-seen outskirts of a supermassive black hole's accretion disk, the metaphorical buffet for the all-consuming masses at the centers of galaxies, and they did it all by complete accident, according to a recent study.

The groundbreaking observations were made possible despite the many obstacles surrounding looking at such a faraway object in space bordering something that absorbs all light.

The findings of this study were published in the peer-reviewed academic periodical The Astrophysical Journal Letters.

A black hole's buffet: What is an accretion disk and why are they so hard to see?

A normal black hole is formed when a large star dies, causing a concentration of gravity so strong that it pulls in everything around it, even light. This, naturally, makes them incredibly mysterious and difficult to actually see, with scientists only having ever figured it out by seeing how their gravity impacts everything around them.

But supermassive black holes are even larger, technically measuring over 100,000 solar masses but could even measure millions and billions of solar masses. To put that into perspective, one solar mass is equal to the Sun.

Artist impression of a supermassive black hole at the center of a galaxy. (credit: Wikimedia Commons)

These black holes are incredibly important in the universe as they sit at the centers of almost every galaxy. This includes our own Milky Way Galaxy, home to the supermassive black hole Sagittarius A*.

Surrounding every supermassive black hole at the center of a galaxy is an accretion disk. This term specifically refers to the process (accretion) by which black holes gather more material.

These disks are filled with fast-rotating high-temperature gases that give off light – though the black holes themselves do not.

In fact, the accretion disks can be so bright that they can contribute to the development of active galactic nuclei, an especially bright region at a galaxy's center with characteristics indicating that the light isn't being produced by stars.

Scientists have considerable interest in studying accretion disks because since they are what feed black holes, studying them can help us understand how black holes develop and how galaxies develop around them. But they're very hard to see. The only way scientists can actually be sure one is around a supermassive black hole is if there is a very specific emission line pattern known as a double-peaked profile, barring the only two cases where an accretion disk has been outright imaged directly thanks to the Event Horizon Telescope taking pictures of black holes.

These emissions are from when atoms start releasing light as their energy level drops, and they often appear in spectra analyses as sharp spikes. In accretion disks around supermassive black holes, though, these lines usually seem more like peaks.

How do you study something as relatively small as an accretion disk?

The scientists behind this study managed to do just that by complete accident.

This was done using the Gemini North telescope. Located in Hawaii, this telescope is often used for studying supermassive black holes, star formation, distant quasars, and more.

Using this, the researchers were able to detect the hard-to-spot near-infrared emission lines from the accretion disk of the faraway galaxy III Zw 002.

But the findings themselves were spotted by accident, during observations with the Gemini Near-Infrared Spectrograph in order to supplement findings from prior studies about III Zw 002.

What does this mean?

Well, emission lines have to originate somewhere. One of the two lines spotted in this study came from the inner region of the disk where the lines originate from. But one of the other lines came from somewhere else – a region of an accretion disk never before observed.

""For the first time, the detection of such double-peaked profiles puts firm constraints on the geometry of a region that is otherwise not possible to resolve,"" said Brazilian researcher Alberto Rodriguez-Ardila, who was involved in the study. ""And we now have clear evidence of the feeding process and the inner structure of an active galaxy.""

More studies of this galaxy and its accretion disk may reveal even more information about these enigmatic objects in space.","https://images.jpost.com/image/upload/f_auto,fl_lossy/c_fill,g_faces:center,h_407,w_690/549998",https://www.jpost.com/science/space/article-756435,Science
[],,"Scientists discover fish that can see with its skin, even after death","A reef-dwelling hogfish can be seen in this picture. — South Atlantic Fishery Management Council

A new study revealed a bizarre characteristic of a hogfish that can change the colour of its own skin according to its surrounding environment with the help of special sensing cells even after they are no longer alive.

This study has allowed scientists to comprehend more about the nature and conduct of these fish alongside their adaptability to their surroundings. adapt.

A co-author of the study Lori Schweikert said: ""They appear to be watching their own colour change.""

Sonke Johnsen, another author of the study said: ""In a way they can tell the animal what its skin looks like, since it can’t really bend over to look.""

There are a number of sea creatures that can change their colour which helps them adjust as per the environmental temperature changes, attracting mates and providing camouflage, said researchers.

According to the researchers including those from the University of North Carolina, Wilmington in the US, cells on their bodies called chromatophores, contain pigments, crystals or tiny reflective plates, enabling these species to make changes in their colours rapidly.

The reef-dwelling fish — commonly found in the Atlantic Ocean from North Carolina to Brazil — does this to camouflage and escape predators, or maybe for social signalling.

Scientists were surprised to see that activity of colour changes even after their death.

In the new research published in the journal Nature Communications, experts used microscopy to determine the impact of light on different parts of the fish.

They found that light receptors, called SWS1, underneath the chromatophore, may be involved in the process.

Cells are sensitive to the light shining through colours expressed by chromatophores, specifically the wavelength of light that is present in their coral reef habitat, researchers said.

They also maintained that these receptors provide feedback to the fish on where and how changes are taking place in different parts of their skin.

Scientists wrote in the study: ""By examining the morphology, physiology, and optics of dermal photoreception in hogfish [Lachnolaimus Maximus], we describe a cellular mechanism in which chromatophore pigment activity [i.e., dispersion and aggregation] alters the transmitted light striking SWS1 receptors in the skin.""

""The animals can literally take a photo of their own skin from the inside. In a way they can tell the animal what its skin looks like, since it can't really bend over to look,"" Dr Johnsen explained.

""Just to be clear, we’re not arguing that hogfish skin functions like an eye,"" Dr Schweikert said, adding that ""eyes are capable of more than just detecting light.""",https://www.thenews.com.pk/assets/uploads/updates/2023-08-27/l_1104042_022706_updates.jpg,https://www.thenews.com.pk/latest/1104042-scientists-discover-fish-that-can-see-with-its-skin-even-after-death,Science
['Web Desk'],,Skin used as eyes: Researchers discover fish that changes colour even 'after death',"A fish can be seen in this picture. — Unsplash/File

Scientists have discovered in their new study a kind of fish called hogfish — Lachnolaimus Maximus — that can adapt to the colour in its surroundings even after it dies.

This study enabled experts to make sense of the evolution, habitat and other behaviours of the hogfish fish alongside their ability to adapt quickly.



Sonke Johnsen, an author of the study said: ""In a way they can tell the animal what its skin looks like, since it can’t really bend over to look.""



There are a number of sea creatures that can change their colour which helps them adjust as per the environmental temperature changes, attracting mates and providing camouflage, said researchers.

According to the researchers including those from the University of North Carolina, Wilmington in the US, cells on their bodies called chromatophores, contain pigments, crystals or tiny reflective plates, enabling these species to make changes in their colours rapidly.

The reef-dwelling fish — commonly found in the Atlantic Ocean from North Carolina to Brazil — does this to camouflage and escape predators, or maybe for social signalling.

Scientists were surprised to see that activity of colour changes even after their death.

In the new research published in the journal Nature Communications, experts used microscopy to determine the impact of light on different parts of the fish.

They found that light receptors, called SWS1, underneath the chromatophore, may be involved in the process.

Cells are sensitive to the light shining through colours expressed by chromatophores, specifically the wavelength of light that is present in their coral reef habitat, researchers said.

They also maintained that these receptors provide feedback to the fish on where and how changes are taking place in different parts of their skin.

Scientists wrote in the study: ""By examining the morphology, physiology, and optics of dermal photoreception in hogfish [Lachnolaimus Maximus], we describe a cellular mechanism in which chromatophore pigment activity [i.e., dispersion and aggregation] alters the transmitted light striking SWS1 receptors in the skin.""

""The animals can literally take a photo of their own skin from the inside. In a way they can tell the animal what its skin looks like, since it can't really bend over to look,"" Dr Johnsen explained.

""Just to be clear, we’re not arguing that hogfish skin functions like an eye,"" Dr Schweikert said, adding that ""eyes are capable of more than just detecting light.""",https://www.geo.tv/assets/uploads/updates/2023-08-27/l_506977_024813_updates.jpg,https://www.geo.tv/latest/506977-skin-used-as-eyes-researchers-discover-fish-that-changes-colour-even-after-death,Science
[],2023-08-25 17:23:45-04:00,"Dead or Alive, Hogfish “See” with Their Skin","In the 2020 adaptation of The Invisible Man (streaming now on Peacock!) inventor Adrian Griffin (Oliver Jackson-Cohen) develops a high-tech optical suit which pays attention to the surrounding environment and mimics it. The result blends seamlessly into the environment, rendering the wearer entirely invisible.

To date, we haven’t managed to crack the technology necessary for a functional invisibility suit (not for lack of trying) but nature has! Complex camouflage has evolved several times in disparate parts of the plant and animal kingdoms with varying degrees of success. The humble hogfish isn’t quite as good at camouflage as their cephalopod peers, but they’re certainly no slouches, as evidenced by a new study from marine biologist Lorian Schweikert, and colleagues, published in the journal Nature Communications.

How Hogfish Match Their Environment, Even When They’re Dead

Schweikert had a eureka moment regarding the camouflage of hogfish not in the lab, but on a boat, according to the New York Times. A dead hogfish, killed by the injuries of a fishing spear, changed its exterior color to match that of the boat despite a clear break between the eyes and the skin, by virtue of it being dead.

RELATED: Be the Stick. Some Camouflage is Better Than Others

Recognizing that the eyes couldn’t have been controlling the action, Schweikert realized there must be something else at play. Then they headed to the lab. Hogfish typically take on one of three general styles, or morphs. There’s a sort of rusty brown costume, a speckled red and white getup, and a plain white fit for when they want to be classy. It’s a rather small wardrobe, but those three options work surprisingly well to allow the fish to blend in with their environment. The question is how they know when to change how they present.

Hogfish,(Lachnolaimus maximus),in Los Roques,Venezuela,Caribbean Sea Photo: Humberto Ramirez/Getty Images

In the lab, Schweikert and the team identified a new type of cellular relationship buried deep within the skin. It’s a two-part system that works together to monitor the environment and control color change in real time. In short, hogfish skin can see the environment even if the fish itself consciously can’t. Even if the fish in question is dead.

The trick, it turns out, is a combination of chromatophores (pigmented cells capable of changing their appearance) and a kind of light-receptive protein called opsins. In humans, opsins are found in the eyes where they belong, but you’ll also find them in the brain and in the skin, where they do things like help control melanin production, hair growth, and healing.

RELATED: Predator's camouflage creeps closer to reality with new color-changing smart gels

In hogfish, the opsins are buried beneath the chromatophores in the skin. At first glance, you might think that would obscure their ability to sense the outside world, and you’d be right, but that’s actually why they work so well. Researchers found that the chromatophores act as a filter, blocking some of the light before it gets to the opsins. That creates a feedback loop which allows the cells to more accurately match the surrounding environment, even and especially if the fish can’t see what it’s trying to match.

Nature is often better at solving engineering problems like invisibility suits because it has to be. In the game of life, you either figure out how to build better defenses or you die. Sometimes, if you’re a hogfish, you die and then show off your defenses anyway.

See what it might be like to be a hogfish in The Invisible Man, streaming now on Peacock!",https://www.syfy.com/sites/syfy/files/2023/03/screen_shot_2023-03-30_at_10.34.53_am_0.jpg,https://www.syfy.com/syfy-wire/dead-or-alive-hogfish-see-with-their-skin,Science
['Duke University'],2023-08-26 01:27:36-07:00,Beyond Eyes: This Fish Can See With Its Skin,"Now researchers think they know why.

Several years back, during a fishing expedition in the Florida Keys, biologist Lori Schweikert came face to face with an unusual quick-change act. She caught a pointy-snouted reef fish known as a hogfish and placed it on her boat’s deck. However, when she later intended to transfer it to a cooler, she observed a peculiar phenomenon: its skin had taken on the same color and pattern as the deck of the boat.

A common fish in the western Atlantic Ocean from North Carolina to Brazil, the hogfish is known for its color-changing skin. The species can morph from white to mottled to reddish-brown in a matter of milliseconds to blend in with corals, sand, or rocks.

Still, Schweikert was surprised because this hogfish had continued its camouflage even though it was no longer alive. This got her wondering: Can hogfish detect light using only their skin, independently of their eyes and brain?

“That opened up this whole field for me,” Schweikert said.

In the years that followed, Schweikert started researching the physiology of “skin vision” as a postdoctoral fellow at Duke University and Florida International University. In 2018, Schweikert and Duke biologist Sönke Johnsen published a study showing that hogfish carry a gene for a light-sensitive protein called opsin that is activated in their skin and that this gene is different from the opsin genes found in their eyes.

Other color-changing animals from octopuses to geckos have been found to make light-sensing opsins in their skin, too. But exactly how they use them to help change color is unclear.

“When we found it in hogfish, I looked at Sönke and said: Why have a light detector in the skin?” said Schweikert, now an assistant professor at the University of North Carolina Wilmington.

One hypothesis is that light-sensing skin helps animals take in their surroundings. But new findings suggest another possibility — “that they could be using it to view themselves,” Schweikert said. In a study recently published in the journal Nature Communications, Schweikert, Johnsen, and colleagues teamed up to take a closer look at hogfish skin.

The researchers took pieces of skin from different parts of the fish’s body and took pictures of them under a microscope.

Up close, a hogfish’s skin looks like a pointillist painting. Each dot of color is a specialized cell called a chromatophore containing granules of pigment that can be red, yellow, or black. It’s the movement of these pigment granules that changes the skin color. When the granules spread out across the cell, the color appears darker. When they cluster together into a tiny spot that’s hard to see, the cell becomes more transparent.

Next, the researchers used a technique called immunolabeling to locate the opsin proteins within the skin. They found that in the hogfish, opsins aren’t produced in the color-changing chromatophore cells. Instead, the opsins reside in other cells directly beneath them.

Images taken with a transmission electron microscope revealed a previously unknown cell type, just below the chromatophores, packed with opsin protein. This means that light striking the skin must pass through the pigment-filled chromatophores first before it reaches the light-sensitive layer, Schweikert said.

The researchers estimate that the opsin molecules in hogfish skin are most sensitive to blue light. This happens to be the wavelength of light that the pigment granules in the fish’s chromatophores absorb best. The findings suggest that fish’s light-sensitive opsins act somewhat like internal Polaroid film, capturing changes in the light that are able to filter through the pigment-filled cells above as the pigment granules bunch up or fan out.

“The animals can literally take a photo of their own skin from the inside,” Johnsen said. “In a way, they can tell the animal what its skin looks like, since it can’t really bend over to look.”

“Just to be clear, we’re not arguing that hogfish skin functions like an eye,” Schweikert added. Eyes do more than merely detect light — they form images. “We don’t have any evidence to suggest that’s what’s happening in their skin,” Schweikert said.

Rather, it’s a sensory feedback mechanism that lets the hogfish monitor its own skin as it changes color, and fine-tune it to fit what it sees with its eyes.

“They appear to be watching their own color change,” Schweikert said.

The researchers say the work is important because it could pave the way to new sensory feedback techniques for devices such as robotic limbs and self-driving cars that must fine-tune their performance without relying solely on eyesight or camera feeds.

“Sensory feedback is one of the tricks that technology is still trying to figure out,” Johnsen said. “This study is a nice dissection of a new sensory feedback system.”

“If you didn’t have a mirror, and you couldn’t bend your neck, how would you know if you’re dressed appropriately?” Schweikert said. “For us, it may not matter,” she added. But for creatures that use their color-changing abilities to hide from predators, warn rivals, or woo mates, “it could be life or death.”

Reference: “Dynamic light filtering over dermal opsin as a sensory feedback system in fish color change” by Lorian E. Schweikert, Laura E. Bagge, Lydia F. Naughton, Jacob R. Bolin, Benjamin R. Wheeler, Michael S. Grace, Heather D. Bracken-Grissom and Sönke Johnsen, 22 August 2023, Nature Communications.

DOI: 10.1038/s41467-023-40166-4

The study was co-authored by researchers from the Florida Institute of Technology, Florida International University, and the Air Force Research Laboratory. Financial support came from Duke University, Florida International University, the Marine Biological Laboratory and the National Science Foundation.",https://scitechdaily.com/images/Hogfish.jpg,https://scitechdaily.com/beyond-eyes-this-fish-can-see-with-its-skin/,Science
"['Nora Lowe', 'Nasa S Goddard Space Flight Center']",2023-08-27 00:15:40-07:00,Wired To Explore: NASA’s 45-Mile Long “Nervous System” for Roman Space Telescope,"NASA’s Roman Space Telescope team is integrating a complex electrical harness, crucial for the spacecraft’s communication and power. After a detailed two-year construction and a preparatory “bakeout” process, assembly into the spacecraft is ongoing, with future installations planned for power components.

NASA’s Nancy Grace Roman Space Telescope team has begun integrating and testing the spacecraft’s electrical cabling, or harness, which enables different parts of the observatory to communicate with one another. Additionally, the harness provides power and helps the central computer monitor the observatory’s function via an array of sensors. This brings the mission a step closer to surveying billions of cosmic objects and untangling mysteries like dark energy following its launch by May 2027.

“Just as the nervous system carries signals throughout the human body, Roman’s harness connects its components, providing both power and commands to each electronic box and instrument,” said Deneen Ferro, the Roman harness project development lead at NASA’s Goddard Space Flight Center in Greenbelt, Maryland. “Without a harness, there is no spacecraft.”

Harness Specifications and Construction

Weighing around 1,000 pounds, the harness is made up of approximately 32,000 wires and 900 connectors. If the wires were laid out end-to-end, they would span 45 miles. Directed upward, they would reach eight times higher than the peak of Mount Everest.



This video shows the Nancy Grace Roman Space Telescope’s wire harness being transferred from a mockup to the flight structure. Credit: NASA’s Goddard Space Flight Center

Achieving this milestone was no small task. Over the course of about two years, a team of 11 Goddard technicians spent time at the workbench and perched on ladders, cutting wire to length, meticulously cleaning each component, and repeatedly connecting everything together.

Preparation for Space Conditions

The entire harness was built on an observatory mock-up structure before being transported to Goddard’s Space Environment Simulator – a massive thermal vacuum chamber used in this case for “bakeout.” When observatories like Roman are sent to space, the resulting vacuum and orbital temperatures can cause certain materials to release harmful vapors, which can then condense within electronics and create problems like short circuits or deposits on sensitive optics, degrading the telescope’s performance. Bakeout releases these gases on Earth so they aren’t emitted inside the spacecraft when in space.



Timelapse of the wire harness as it is lifted on its custom transport basket from the mock primary structure to the flight structure. Credit: NASA’s Goddard Space Flight Center

Final Assembly Stages

Now, engineers will weave the harness through the flight structure in Goddard’s big clean room. This ongoing process will continue until most of the spacecraft components are assembled. In the meantime, the Goddard team will soon begin installing electronics boxes that will eventually provide power via the harness to all the spacecraft’s science instruments.",https://scitechdaily.com/images/NASA-Roman-Space-Telescope-Concept.jpg,https://scitechdaily.com/wired-to-explore-nasas-45-mile-long-nervous-system-for-roman-space-telescope/,Science
"['Var Template_Content', 'Sso_Login_Box', 'Xwelcome Backorenter The Email Address Or Mobile Number Associated With Your Account To Sign In. Show Passwordsign Innew To The Indian Express Signupxcreate Your Account It Is Quick', 'Easy.Or Show Passwordnextvalidate Otpregisteralready Have An Account', 'Signin', 'Sso_Social_Box', 'Sign In Withgmailfacebookapple', 'Var Follow_Widget_Data', 'Af_Article_Count', 'Ie_Mobile_Check']",2023-08-27 17:07:41+05:30,"Vikram lander observes temperature variation on lunar surface, records high of 70 degree Celsius","The payload was developed by a team led by the Space Physics Laboratory (SPL) of ISRO's Vikram Sarabhai Space Centre (VSSC) in collaboration with Physical Research Laboratory (PRL), Ahmedabad. (Representational, File photo)

ISRO on Sunday released a graph of the temperature variation on the lunar surface and a senior scientist of the space agency expressed surprise over the high temperature recorded on the Moon.

The national space agency said Chandra’s Surface Thermophysical Experiment (ChaSTE) payload onboard Chandrayaan-3’s Vikram lander measured the temperature profile of the lunar topsoil around the pole to understand the thermal behaviour of the Moon’s surface.

“Here are the first observations from the ChaSTE payload onboard Vikram Lander. ChaSTE (Chandra’s Surface Thermophysical Experiment) measures the temperature profile of the lunar topsoil around the pole to understand the thermal behaviour of the moon’s surface,” ISRO said in an update on social media platform ‘X’.

India on August 23 scripted history as ISRO’s ambitious third Moon mission Chandrayaan-3 touched down on the lunar surface, making it only the fourth country to accomplish the feat, and first to reach the uncharted south pole of Earth’s only natural satellite.

Advertisement

Prime Minister Narendra Modi on Saturday announced that the spot where Chandrayaan-3 Vikram lander touched down would henceforth be called ‘Shiv Shakti Point’, and the site where the Chandrayaan-2 lander crash-landed on the Moon’s surface in 2019 would be known as ‘Tiranga Point’.

Besides, August 23 would be celebrated as ‘National Space Day’ to mark the day when Chandrayaan-3 lander touched down on the lunar surface, Modi said.",https://images.indianexpress.com/2023/08/Chandrayaan-3-File-photo.jpg,https://indianexpress.com/article/technology/science/isro-releases-graph-of-temperature-variation-on-lunar-surface-measured-by-chandrayaan-3s-payload-8911915/,Science
[],,Chandrayaan-3 Measures Moon’s South Pole Soil Temperature,,https://i.ytimg.com/vi/DDLplJBvfoo/maxres2.jpg?sqp=-oaymwEoCIAKENAF8quKqQMcGADwAQH4AbYIgAKAD4oCDAgAEAEYZSBlKGUwDw==&rs=AOn4CLBQfuFTvtr7M4rQBKR2ID1tTtyRDA,https://www.youtube.com/watch?v=DDLplJBvfoo,Science
[],,First Scientific Data Sent By Chandrayaan-3 From Moon's South Pole,"Chandrayaan-3's touchdown spot was named Shiv Shakti point.

The Indian space agency has obtained the first ever scientific data from the Moon's unexplored South Polar region, marking a major success of its Chandrayaan-3 mission.

The thermal probe of the Vikram lander recorded how temperature varies at surface, near surface and deeper on the lunar surface.

ChaSTE (Chandra's Surface Thermophysical Experiment) measures the temperature profile of the lunar topsoil around the pole, to understand the thermal behaviour of the moon's surface, said the Indian Space Research Organisation (ISRO).

""It has a temperature probe equipped with a controlled penetration mechanism capable of reaching a depth of 10 cm beneath the surface. The probe is fitted with 10 individual temperature sensors,"" it added.

Chandrayaan-3 Mission:

Here are the first observations from the ChaSTE payload onboard Vikram Lander.



ChaSTE (Chandra's Surface Thermophysical Experiment) measures the temperature profile of the lunar topsoil around the pole, to understand the thermal behaviour of the moon's… pic.twitter.com/VZ1cjWHTnd — ISRO (@isro) August 27, 2023

Moon has no atmosphere and the temperature varies drastically on the lunar surface. ISRO presented the variations in the form of a graph.

""The presented graph illustrates the temperature variations of the lunar surface/near-surface at various depths, as recorded during the probe's penetration. This is the first such profile for the lunar south pole. Detailed observations are underway,"" said ISRO.

ISRO scientist BHM Darukesha said the temperature recorded was surprisingly higher than what was expected. ""We believed the temperature could be somewhere around 20-30 degrees centigrade on the surface but it is 70 degrees,"" he told PTI, referring to the graph.

Science Minister Jitendra Singh said the Chandrayaan-3 mission is expected to send back information about the Moon's atmosphere, soil and minerals, which may be the first of its kind for the scientific community across the world.

“The low density and high thermal insulation of the regolith (Moon's layer of rocks) enhances its potential as a basic building block for future habitats while the assessment of the wide range of temperature variations are crucial for survivability,” the minister added.

ChaSTE, a key instrument mounted on the Vikram Lander, is equipped with 10 high-precision thermal sensors, which will dig into the moon's top soil to study temperature variations. It is the first-ever experiment to study the thermophysical properties of the first 10 cm of the lunar surface.

The Moon's surface undergoes substantial temperature variations during the lunar day and night. The minimum temperatures dip below 100 degrees Celsius around lunar midnight while the maximum go beyond 100 degrees around noon.

The porous lunar topsoil, about 5-20 metres thick, is expected to be an excellent insulator, due to which and the absence of air, very significant temperature difference is expected between the top surface and interior of the regolith.

Vikram lander touched down on August 23, making India the only country to land in the lunar South Polar region. The touchdown spot was later named Shiv Shakti point.

Chandrayaan-3 has accomplished two of its three objectives - soft landing and rover roving on the lunar surface - and the third - in-situ scientific experiments - is underway, ISRO said Saturday.","https://c.ndtvimg.com/2023-08/a9j292js_chandrayaan-pragyan-rollout_625x300_25_August_23.jpg?im=FeatureCrop,algorithm=dnn,width=650,height=400",https://www.ndtv.com/india-news/chandrayaan-3-sends-back-first-scientific-data-from-moons-south-pole-4333823,Science
[],,Chandrayaan-3 shares first observations about moon's soil temperature | Latest News | WION,,https://i.ytimg.com/vi/F6UW4FumPOM/maxresdefault.jpg,https://www.youtube.com/watch?v=F6UW4FumPOM,Science
['Christopher Mcfadden'],2023-08-27 11:42:19+00:00,New technique opens door for encoding data on single photons,"Researchers at Los Alamos National Laboratory have successfully developed a new way to produce a specific type of photon that could prove critical for quantum data exchange, notably encryption. The specific kind of photons, called ""circularly polarized light,"" have thus far proved challenging to create and control, but this new technique makes the process easier and, importantly, cheaper. This was achieved, the team explains, by stacking two different, atomically thin materials to ""twist"" (polarize) photons in a predictable fashion.

Encoded, ""twisted,"" photons

“Our research shows that it is possible for a monolayer semiconductor to emit circularly polarized light without the help of an external magnetic field,” explained Han Htoon, a scientist at Los Alamos National Laboratory. “This effect has only been achieved before with high magnetic fields created by bulky superconducting magnets, by coupling quantum emitters to very complex nanoscale photonics structures, or by injecting spin-polarized carriers into quantum emitters. Our proximity-effect approach has the advantage of low-cost fabrication and reliability,"" he added.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/26/image/jpeg/KCPzxW1cF99rLfkfm8XtoEHq0ht0sF3Vgjpl6Q4r.jpg,https://interestingengineering.com/science/encoding-data-on-single-photons,Science
['Los Alamos National Laboratory'],2023-08-25 13:50:22-07:00,Quantum Illumination: Advanced Device Generates Single Photons and Encodes Information,"New approach is a step toward using single photons in quantum communication and information processing.

Researchers at the Los Alamos National Laboratory have developed a novel technique to generate a stream of circularly polarized single photons, crucial for quantum information and communication. Using atomically thin materials, they’ve shown that a monolayer semiconductor can emit circularly polarized light without an external magnetic field. The research team utilized nanometer-scale indentations to achieve this, resulting in a crucial step towards quantum cryptography, communication, and the potential for a hyper-secure quantum internet.

Revolutionary Quantum Light Emitters

A team of scientists at Los Alamos National Laboratory team stacked two different atomically thin materials to realize a chiral quantum light source. This new approach to quantum light emitters generates a stream of circularly polarized single photons, or particles of light, that may be useful for a range of quantum information and communication applications.

“Our research shows that it is possible for a monolayer semiconductor to emit circularly polarized light without the help of an external magnetic field,” said Han Htoon, scientist at Los Alamos National Laboratory. “This effect has only been achieved before with high magnetic fields created by bulky superconducting magnets, by coupling quantum emitters to very complex nanoscale photonics structures or by injecting spin-polarized carriers into quantum emitters. Our proximity-effect approach has the advantage of low-cost fabrication and reliability.”

The polarization state is a means of encoding the photon, so this achievement is an important step in the direction of quantum cryptography or quantum communication.

“With a source to generate a stream of single photons and also introduce polarization, we have essentially combined two devices in one,” Htoon said.

Indentation Key to Photoluminescence

As described in a paper published in the journal Nature Materials, the research team worked at the Center for Integrated Nanotechnologies to stack a single-molecule-thick layer of tungsten diselenide semiconductor onto a thicker layer of nickel phosphorus trisulfide magnetic semiconductor. Xiangzhi Li, postdoctoral research associate, used atomic force microscopy to create a series of nanometer-scale indentations on the thin stack of materials. The indentations are approximately 400 nanometers in diameter, so over 200 of such indents can easily be fit across the width of a human hair.

The indentations created by the atomic microscopy tool proved useful for two effects when a laser was focused on the stack of materials. First, the indentation forms a well, or depression, in the potential energy landscape. Electrons of the tungsten diselenide monolayer fall into the depression. That stimulates the emission of a stream of single photons from the well.

The nanoindentation also disrupts the typical magnetic properties of the underlying nickel phosphorus trisulfide crystal, creating a local magnetic moment pointing up out of the materials. That magnetic moment circularly polarizes the photons being emitted. To provide experimental confirmation of this mechanism, the team first performed high magnetic field optical spectroscopy experiments in collaboration with National High Magnetic Field Laboratory’s Pulsed Field Facility at Los Alamos. The team then measured the minute magnetic field of the local magnetic moments in collaboration with the University of Basel in Switzerland.

The experiments proved that the team had successfully demonstrated a novel approach to control the polarization state of a single photon stream.

Encoding Quantum Information

The team is currently exploring ways to modulate the degree of circular polarization of the single photons with the application of electrical or microwave stimuli. That capability would offer a way to encode quantum information into the photon stream.

Further coupling of the photon stream into waveguides — microscopic conduits of light — would provide the photonic circuits that allow the propagation of photons in one direction. Such circuits would be the fundamental building blocks of an ultra-secure quantum internet.

Reference: “Proximity-induced chiral quantum light generation in strain-engineered WSe 2 /NiPS 3 heterostructures” by Xiangzhi Li, Andrew C. Jones, Junho Choi, Huan Zhao, Vigneshwaran Chandrasekaran, Michael T. Pettes, Andrei Piryatinski, Märta A. Tschudin, Patrick Reiser, David A. Broadway, Patrick Maletinsky, Nikolai Sinitsyn, Scott A. Crooker and Han Htoon, 17 August 2023, Nature Materials.

DOI: 10.1038/s41563-023-01645-7

Funding: Laboratory Directed Research and Development (LDRD) program at Los Alamos National Laboratory; the U.S. Department of Energy Basic Energy Sciences, QIS Infrastructure Development Program; and the Quantum Science Center, a national QIS Research Center supported by the DOE Office of Science.",https://scitechdaily.com/images/Chiral-Quantum-Light-Emissions-Cover.jpg,https://scitechdaily.com/quantum-illumination-advanced-device-generates-single-photons-and-encodes-information/,Science
"['Christopher Plain', 'Var Molongui_Authorship_Front_Params', 'Byline_Prefix', 'Byline_Suffix', 'Byline_Separator', 'Byline_Last_Separator', 'Byline_Link_Title', 'View All Posts By', 'Byline_Link_Class', 'Byline_Dom_Tree']",2023-08-25 12:51:56+00:00,Breakthrough Method of Creating Individually Polarized Photons Could Yield Unhackable Quantum Internet,"Researchers at Los Alamos National Laboratory say they have developed a method of generating and selectively polarizing individual photons that may be the breakthrough needed to create an ultra-secure quantum internet.

Previous methods of creating individual photons were bulky and expensive, as were methods of polarizing individual photons. The newly proposed process combines both tools into one low-cost system, and if scalable, could be a critical tool for encoding and transmitting data in a quantum internet.

Quantum Internet Would Be Ultra-Fast and Virtually Unhackable

In the macro world, the speed of communication and the paths communicated data must take are governed by seemingly immutable laws of physics like the speed of light or Newton’s Laws of Motion. But in the quantum world, individual particles can behave in ways that seemingly violate those laws.

Those unique properties of quantum physics have led engineers and security professionals alike to envision the concept of a quantum internet. In many ways, a quantum internet would function like the current one. But behind the scenes, the way data is communicated, and the speed at which it is communicated might be totally different and virtually impossible to hack.

These potential benefits have even led the U.S. Government to declare its intention of one day equipping the country with a quantum internet. However, as companies and organizations working on quantum computers have learned, taking advantage of the unique properties of the quantum world, like quantum superposition and quantum entanglement, has proven particularly fleeting or elusive for practical applications.

The reasons are many, but one of the main limitations is the cost and difficulty of producing individual photons that can be polarized on demand, a necessary step toward quantum entanglement that is at the very heart of quantum internet proposals. Now, researchers say they have discovered just such a process. And if their follow-up efforts continue to show success, the goals of a quantum internet may be closer than ever before.

Generating Individual Photons While Controlling Polarization

The first step in the Los Alamos team’s process involved stacking a single-molecule-thick layer of tungsten diselenide semiconductor onto a thicker layer of nickel-phosphorus trisulfide magnetic semiconductor. Next, atomic force microscopy was used to forge a series of tiny (nanometer scale) indentations onto the surface of the bi-layer material.

According to a press release announcing the published research, each indentation was roughly 400 nanometers in size. For comparison, they note that “over 200 of such indents can easily be fit across the width of a human hair.”

As hoped, when the team focused a laser onto the newly indented bilayer material, electrons from the tungsten diselenide monolayer fell off and settled into the potential energy wells, or depressions, within the nanoscale indentations. Plus, the indentations seemed to alter the normal magnetic properties of the nickel-phosphorus trisulfide, creating what the researchers described as magnetic “moments” over each depression. These magnetic moments caused a circular polarization of the emitted photons, essentially offering the researchers a way to control the polarization of these sub-atomic particles.

“The polarization state is a means of encoding the photon,” the press release explains, “so this achievement is an important step in the direction of quantum cryptography or quantum communication.”

This sentiment was confirmed by Han Htoon, one of the Los Alamos research team, who reiterated the benefit of both producing and polarizing photons in a single process.

“With a source to generate a stream of single photons and also introduce polarization, we have essentially combined two devices in one,” Htoon said.

Applying Generating and Programming Photons Toward the Vision of a Quantum Internet

Following the publication of their work in the journal Nature Materials, the team says they are working on a process using electrical and microwave stimuli to modulate the degree of the circular polarization they create. If successful, it would offer a more precise means of encrypting information into the photon stream, another key step toward a quantum internet.

Last, the team will tinker with coupling their photon stream into waveguides. These microscopic conduits of light would be the main components of a photonic circuit, allowing for the propagation of photons in one direction, just like in an electrical circuit. These types of circuits, the researchers say, “would be the fundamental building blocks of an ultra-secure quantum internet.” And they reiterate their new approach is much simpler and more cost-effective than previous methods.

“Our research shows that it is possible for a monolayer semiconductor to emit circularly polarized light without the help of an external magnetic field,” said Htoon. “This effect has only been achieved before with high magnetic fields created by bulky superconducting magnets, by coupling quantum emitters to very complex nanoscale photonics structures, or by injecting spin-polarized carriers into quantum emitters. Our proximity-effect approach has the advantage of low-cost fabrication and reliability.”",https://thedebrief.b-cdn.net/wp-content/uploads/2023/08/resize-Low-Res_Chiral-quantum-light-emission.jpg,https://thedebrief.org/breakthrough-method-of-creating-individually-polarized-photons-could-yield-unhackable-quantum-internet/,Science
['University Of Bayreuth'],2023-08-26 13:29:45-07:00,Scientists Invent New Glass With Supreme Toughness,"Scientists have produced an oxide glass with unprecedented toughness. Under high pressures and temperatures, they succeeded in paracrystallizing an aluminosilicate glass: The resulting crystal-like structures cause the glass to withstand very high stresses and are retained under ambient conditions. Paracrystallization thus proves to be a promising process for producing extremely break-resistant glasses.



In many respects, glass is an attractive material for modern technologies. However, its inherent brittleness, which makes it prone to cracks and fractures, limits its potential applications. Research attempts to significantly bolster the toughness of glass while retaining its advantageous properties have largely failed to produce the desired results.

Innovative Approach and Process

The new approach presented in the scientific journal Nature Materials starts with oxide glasses which have a rather disordered internal structure and are the most widely commercially utilized glass materials. Using aluminosilicate, which contains silicon, aluminum, boron, and oxygen, as an example, the research team in Germany and China has now succeeded in giving it a new structure. To this end, they employed high-pressure and high-temperature technologies at the Bavarian Research Institute of Experimental Geochemistry and Geophysics (BGI) of the University of Bayreuth.

At pressures between 10 and 15 gigapascals and a temperature of around 1,000 degrees Celsius, the silicon, aluminum, boron, and oxygen atoms grouped together to form crystal-like structures. These structures are called “paracrystalline” because they differ significantly from a completely irregular structure, but they do not approach the clear regular structure of crystals. Both empirical analyses using spectroscopic techniques and theoretical calculations clearly showed this intermediate state between crystal structures and amorphous irregularity.

Implications of Paracrystallization

Even after a drop in pressure and temperature to normal ambient conditions, the paracrystalline structures in the aluminosilicate glass remain. The penetration of the glass with these structures results in the toughness of the glass being many times higher than before paracrystallization. It now reaches a value of up to 1,99 ± 0,06 MPa (m)¹/². This is a toughness never before measured for oxide glasses. At the same time, the transparency of the glass is not seriously affected by the paracrystalline structures.

The researchers explain the extraordinary strengthening of the glass by the fact that forces acting on the glass from outside, which would normally lead to breakage or internal cracks, are now primarily directed against the paracrystalline structures. They dissolve areas of these structures and transform them back into an amorphous, random state. In this way, the glass as a whole acquires greater internal plasticity, so that it does not break or crack when it is exposed to these or even to stronger forces.

Future Prospects

“Our discovery highlights an effective strategy for developing highly damage-tolerant glass materials, which we plan to pursue with our research in the coming years,” said Dr. Hu Tang, first author of the new study.

“The increase in toughness due to paracrystallization shows that structural changes at the atomic level can have a significant impact on the properties of oxide glasses. At this level, there is great potential for optimizing glass as a material that is far from being exhausted,” adds Prof. Dr. Tomoo Katsura of the Bavarian Research Institute of Experimental Geochemistry and Geophysics.

Reference: “Toughening oxide glasses through paracrystallization” by Hu Tang, Yong Cheng, Xiaohong Yuan, Kai Zhang, Alexander Kurnosov, Zhen Chen, Wenge Xiao, Henrik S. Jeppesen, Martin Etter, Tao Liang, Zhidan Zeng, Fei Wang, Hongzhan Fei, Lin Wang, Songbai Han, Ming-Sheng Wang, Guang Chen, Howard Sheng and Tomoo Katsura, 7 August 2023, Nature Materials.

DOI: 10.1038/s41563-023-01625-x",https://scitechdaily.com/images/Hammer-Cell-Phone.gif,https://scitechdaily.com/scientists-invent-new-glass-with-supreme-toughness/,Science
['Kayla Clarke'],2023-08-27 00:00:00,University of Michigan scientists study giant black hole that destroyed a massive star,"This artist’s illustration depicts the ""tidal disruption event"" (TDE) called ASASSN-14li, which is the focus of the latest study. As a star approached too closely to the supermassive black hole at the system, the strong gravity tore the star apart. This artist's impression depicts the aftermath of this destruction. After the star was ripped apart, some of its gas (red) was left orbiting around and falling into the black hole. A portion of the gas was driven away in a wind (blue).

ANN ARBOR, Mich. – What happens when a star gets too close to a giant black hole? In a scenario studied by a University of Michigan astronomer, a star that got too close to a black hole got torn apart and its insides were tossed out into space.

A research team used NASA’s Chandra X-ray Observatory and ESA’s XMM-Newton to study the amount of nitrogen and carbon near a black hole that was known to have torn a star apart. Astronomers believe the nitrogen and carbon were created inside the star as it neared the black hole before it was ripped apart.

“We are seeing the guts of what used to be a star,” said Jon Miller, U-M professor of astronomy who led the study. “The elements left behind are clues we can follow to figure out what sort of star met its demise.”

Tidal disruption events

When the gravitational forces of a massive black hole destroy a star and material is blown away from the black hole is known as a “tidal disruption.”

There have been many examples of tidal disruption events in recent years. The events cause a flare, which can be seen in optical and ultraviolet light, and x-rays, as the star’s debris is heated up.

When ASASSN-14li was discovered in November 2014, it was the closest tidal disruption to Earth -- only 290 million light-years away. Because of that, researchers have been able to discover a lot about the destroyed star.

“Here, we have used X-rays to look at the elemental composition of a tidal disruption event, and found a strange pattern that is consistent with a moderately massive (3 solar masses) star,” Miller said. “This gives us confidence that it really was a single star that was shredded, but it also points to an unexpectedly high stellar mass for such an event. This may tell us about the population of stars that are closest to massive black holes in other galaxies.”

‘Observing the destruction of a massive star by a supermassive black hole is spellbinding’

The star in ASASSN-14li might be the most massive one that astronomers have seen ripped apart by a black hole.

“ASASSN-14li is exciting because one of the hardest things with tidal disruptions is being able to measure the mass of the unlucky star, as we have done here,” said co-author Enrico Ramirez-Ruiz of the University of California, Santa Cruz. “Observing the destruction of a massive star by a supermassive black hole is spellbinding because more massive stars are expected to be significantly less common than lower mass stars.”

A different team of astronomers reported a “Scary Barbie” event where they estimated a star with about 14 times the mass of the sun was destroyed by a black hole. In that case, the estimate of the star’s mass is based on the brightness of the flare and not on a detailed analysis of material around the black hole.

Because researchers can estimate stellar masses of tidally disrupted stars, this means there might be a way to identify the presence of star clusters around supermassive black holes in galaxies that are further away.

Until this study, there was a possibility that what was seen in X-rays might have come from gas released during eruptions from the supermassive black hole. Researchers believe the elements analyzed in this case appear to have come from a single star.

Miller said the work done at the University of Michigan is done using orbiting telescopes that span a huge range of light.

“We are fortunate to have a very active and energetic group of scientists here that study black holes in X-rays,” Miller said.

The results of their research have been published in The Astrophysical Journal Letters.","https://res.cloudinary.com/graham-media-group/image/upload/f_auto/q_auto/c_thumb,w_700/v1/media/gmg/2KAMS6LMKJD7NOQZJO73J5SXSA.jpg?_a=ATAPphC0",https://www.clickondetroit.com/all-about-ann-arbor/2023/08/27/university-of-michigan-scientists-study-giant-black-hole-that-destroyed-a-massive-star/,Science
['Nasa S Chandra X-Ray Observatory'],2023-08-27 02:55:23-07:00,Mysterious ASASSN-14li: Massive Star Obliterated by a Giant Black Hole,"A giant black hole 290 million light-years away destroyed a large star and threw its pieces into space.

290 million light-years away destroyed a large star and threw its pieces into space. NASA ’s Chandra X-ray Observatory and ESA’s XMM-Newton scoured the wake of this event for information.

’s Chandra X-ray Observatory and ESA’s XMM-Newton scoured the wake of this event for information. The X-ray data reveals the relative amount of nitrogen compared to carbon in this stellar debris field.

Comparison with models shows that a star with three times the mass of the Sun was destroyed, making it one of the largest known “tidal disruption events.”

Using NASA’s Chandra X-ray Observatory, ESA’s XMM-Newton, and other telescopes, astronomers have determined that a giant black hole has destroyed a large star and strewn its contents into space. By analyzing the details of the X-ray data, the team were able to estimate the relative amount of nitrogen compared to carbon in the aftermath of this gravitational assault. These elements provide valuable clues to the researchers for what type of star met its demise.

Artistic Representation of the Event

An artist’s illustration (at the top of this article) brings to life the “tidal disruption event” (TDE) called ASASSN-14li, which is the focus of the latest study. As a star approached too closely to the supermassive black hole in the system, the strong gravity tore the star apart. This artist’s impression depicts the aftermath of this destruction. After the star was ripped apart, some of its gas (red) was left orbiting around and falling into the black hole. A portion of the gas was driven away in a wind (blue).

Analyzing the Elements

Scientists used an X-ray spectrum — that is, a plot of X-ray brightness compared to wavelength — from Chandra and XMM to probe the elements contained in this wind. The Chandra spectrum is shown in the inset, where the data is colored blue (jagged lines) and the uncertainties for each data point are blue vertical lines. A model of the spectrum is given in red, highlighting the detection of nitrogen from the dip in the spectrum, and the non-detection of carbon from the lack of a dip.

The amount of nitrogen and the maximum amount of carbon that could escape detection provides a minimum value for the ratio of nitrogen to carbon that agrees with the data. This value indicates that the shredded star in ASASSN-14li was about three times the mass of the Sun. This would make it one of the largest stars ever known to be devastated in a TDE.

Historical Context and Future Implications

ASASSN-14li was first discovered in November 2014 by ground-based telescopes, when it was realized that this was the closest TDE to Earth in about a decade. In the years since, many telescopes, including Chandra, have observed this system.

In addition to the unusual size of the destroyed star and the ability to conduct detailed forensics on it, ASASSN-14li is also exciting because of what it means for future studies. Astronomers have seen moderately massive stars like ASASSN-14li’s in the star cluster containing the supermassive black hole in the center of our galaxy. Therefore, the ability to estimate stellar masses of tidally disrupted stars potentially gives astronomers a way to identify the presence of star clusters around supermassive black holes in more distant galaxies.

Until this study, there was a strong possibility that the elements observed in X-rays might have come from gas released in previous eruptions from the supermassive black hole. The pattern of elements analyzed here, however, appears to have come from a single star.

Reference: “Evidence of a Massive Stellar Disruption in the X-Ray Spectrum of ASASSN-14li” by Jon M. Miller, Brenna Mockler, Enrico Ramirez-Ruiz, Paul A. Draghis, Jeremy J. Drake, John Raymond, Mark T. Reynolds, Xin Xiang, Sol Bin Yun and Abderahmen Zoghbi, 21 August 2023, The Astrophysical Journal Letters.

DOI: 10.3847/2041-8213/ace03c

A paper describing these results has been published in The Astrophysical Journal Letters. The authors are Jon M. Miller (University of Michigan, Ann Arbor), Brenna Mockler (Carnegie Observatories), Enrico Ramirez-Ruiz (University of California, Santa Cruz), Paul Draghis (University of Michigan), Jeremy Drake (Center for Astrophysics | Harvard & Smithsonian), John Raymond (CfA), Mark Reynolds (University of Michigan), Xin Xiang (University of Michigan), Sol Bin Yun (University of Michigan), and Abderahmen Zoghbi (University of Maryland).

NASA’s Marshall Space Flight Center manages the Chandra program. The Smithsonian Astrophysical Observatory’s Chandra X-ray Center controls science operations from Cambridge, Massachusetts, and flight operations from Burlington, Massachusetts.",https://scitechdaily.com/images/Giant-Black-Hole-Destroys-Massive-Star-scaled.jpg,https://scitechdaily.com/mysterious-asassn-14li-massive-star-obliterated-by-a-giant-black-hole/,Science
"['Hannah Kane', 'Image', 'Nasa Cxc M.Weiss', 'Avalon']",2023-08-28 00:55:48+00:00,NASA captures black hole ‘assassin’ tearing up star and spitting it out across space,"First spotted back in late 2014, ASASSN-14li was the closest tidal disruption event to Earth discovered in a decade at the time, at just 290 million light-years away

Incredible new images captured by NASA show a giant black hole killing a huge star.

Astronomers have been studying the remnants of the star torn apart by the 'assassin' black hole in what's known as a “tidal disruption event”, for it is a deeply exaggerated version of the effect that allows the Moon’s gravity to produce tides in Earth’ ocean. Scientists have named the black hole ASASSN-14li.

It's an apt name when you consider that some of the star's innards have been tossed out across space. First spotted back in late 2014, ASASSN-14li was the closest tidal disruption event to Earth discovered in a decade at the time, at just 290 million light-years away.

NASA have been able to use the Chandra X-ray observatory due to close proximity of the remains of the dead star as well as the European Space Agency’s XMM-Newton space telescope in incredible detail. The study was undertaken by astronomer Professor Jon Miller of the University of Michigan and his colleagues.

Image: NASA/CXC/M.Weiss / Avalon) NASA/CXC/M.Weiss / Avalon)

Drawing parallels between their work and the analysis of a crime scene, Prof. Miller said: “We are seeing the guts of what used to be a star. The elements left behind are clues we can follow to figure out what sort of star met its demise.”

Paper co-author Dr Brenna Mockler is an astrophysicist at Carnegie Observatories and the University of California, Los Angeles. She said: “These X-ray telescopes can be used as forensic tools in space. The relative amount of nitrogen to carbon that we found points to material from the interior of a doomed star weighing about three times the mass of the Sun.”

This means that the star destroyed to produce the ASASSN-14li event is one of — if not the — most massive astronomers have seen involved in a tidal disruption event to date.

Astrophysicist Professor Enrico Ramirez-Ruiz of the University of California, Santa Cruz said: “ASASSN-14li is exciting because one of the hardest things with tidal disruptions is being able to measure the mass of the unlucky star, as we have done here.

“Observing the destruction of a massive star by a supermassive black hole is spellbinding because more massive stars are expected to be significantly less common than lower-mass stars.” The full findings of the study were published in The Astrophysical Journal Letters.",https://i2-prod.mirror.co.uk/incoming/article30801077.ece/ALTERNATES/s1200/1_Astronomers-have-observed-material-being-blown-away-from-a-black-hole-after-it-tore-a-star-apart-Th.jpg,https://www.mirror.co.uk/news/weird-news/nasa-captures-black-hole-assassin-30801074,Science
"['Briley Lewis', 'Freelance Science Writer', 'Social Links Navigation']",2023-08-26 14:00:00+00:00,A black hole 'assassin' ripped a star to shreds and left its guts strewn about the galaxy,"In a way, stars are like doughnuts: You have to rip them apart to see what's inside. Luckily for astronomers, sometimes the cosmos does just that — when a black hole shreds a star that passes by too closely in a violent spectacle called a tidal disruption event (TDE). (The phenomenon is more whimsically known as ""spaghettification"").

In new research published in The Astrophysical Journal Letters , astronomers used a TDE to precisely measure the amounts of certain elements — namely, nitrogen and carbon — around a black hole to infer that a huge star three times bigger than the sun was destroyed there. This is the opposite problem of guessing the doughnut's filling; instead, you see a smear of raspberry and powdered sugar and infer what came before the chaos.

Related: Newly discovered black hole 'speed limit' hints at new laws of physics

The new study is a detailed reanalysis of X-ray observations from a particularly spectacular TDE known as ASASSN-14li , featuring the most massive star astronomers have ever seen destroyed by a black hole . When it was discovered in 2014, ASASSN-14li was the closest and brightest TDE to Earth in the past decade.

""ASASSN-14li is exciting because one of the hardest things with tidal disruptions is being able to measure the mass of the unlucky star, as we have done here,"" Enrico Ramirez-Ruiz , an astrophysicist at University of California, Santa Cruz and co-author of the new work, said in a statement .

An illustration of a black hole surrounded by the remnants of the dead star it tore apart. The inset chart shows the X-ray spectra of the area around the black hole, revealing the chemical composition of the dead star. (Image credit: NASA/CXC/Univ of Michigan/J. Miller et al.; Illustration: NASA/CXC/M.Weiss)

TDEs shine bright in the X-ray spectrum, so to peer at these violent events, the astronomers used two X-ray telescopes: NASA's Chandra X-ray Observatory and the European Space Agency's XMM-Newton. They recorded detailed information and observations about ASASSN-14li, thus enabling this astro-forensic analysis.

""These X-ray telescopes can be used as forensic tools in space,"" study co-author Brenna Mockler , an astronomer at Carnegie Observatories and UCLA, said in the statement. ""The relative amount of nitrogen to carbon that we found points to material from the interior of a doomed star weighing about three times the mass of the Sun.""

Scientists think these events with gigantic stars are rare, too, so having such detailed information on one is exciting, the team said. ""Observing the destruction of a massive star by a supermassive black hole is spellbinding because more massive stars are expected to be significantly less common than lower-mass stars,"" Ramirez-Ruiz said.",https://cdn.mos.cms.futurecdn.net/rRNtyhxEeuNvDiMbvzs5Yi-1200-80.jpg,https://www.livescience.com/space/black-holes/a-black-hole-assassin-ripped-a-star-to-shreds-and-left-its-guts-strewn-about-the-galaxy,Science
['Loukia Papadopoulos'],2023-08-27 12:50:53+00:00,"Gene transcription may be responsible for aging, study finds","University of Cologne researchers in Germany have figured out how to slow down aging by potentially controlling gene transcription. This process, they argue, becomes faster and more error-prone as we age and slowing it down and fixing it may be key to thwarting time.

This is according to a report by Euronews Next published on Saturday.

A major discovery

Dr Andreas Beyer, the lead researcher, told the news outlet this is a “major discovery.”

He further explained how ""each cell is different, and what makes them different are the different genes that are activated in it. This activation is called transcription"". This process must be error-free in order to ensure that genes function properly.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/27/image/jpeg/uXNowFSnVqmfJwLub2IdjhlPcWnzV7MeLEthIBh1.jpg,https://interestingengineering.com/health/gene-transcription-may-be-responsible-for-aging-study-finds,Science
['Mike Mcrae'],2023-08-28 07:27:56+00:00,Physicists Visualize Quantum Yin-Yang in Entangled Light Experiment,"Never let it be said that scientists don't have an eye for the sublime.

Encoding and deciphering a Chinese symbol for duality and harmony into the quantum states of two entangled photons, physicists recently demonstrated the superior efficiency of a new analytical technique.

Researchers from the Sapienza University of Rome and the University of Ottawa in Canada used a method similar to a popular holographic technique to quickly and reliably measure information of a particle's position.

By improving on existing methods for capturing critical details on various states in entangled particles, the team hopes to provide engineers with new computing and imaging tools that form the basis of quantum technologies.

Individual photons, like any particle, are best described as a slowly evolving range of possibilities before a measurement bestows hard, factual numbers on them. Polarization, spin, momentum, even their position, are as unsettled as a coin tumbling through the air until a metaphorical hand slaps it into a single state.

If two photons share a history of some kind – like two coins plucked from the same purse – slapping one is as good as stopping the other mid-flight. Entangled as they are, knowing something about one will give you a measure of the other as if it too were slapped into place.

The fundamentals of this game-of-chance form the very basis of quantum computers. Numerous entangled particles called qubits can have one of their states read in ways that will rapidly answer specially formulated mathematical questions.

Yet why use just one state when particles have so many undecided characteristics to choose from, turning simple 2D qubits into 'multi-dimensional' qudits?

To build a more complex picture of a particle, physicists can take a series of measures, just as multiple X-rays are used to build a 3D picture of a body in computerized tomography.

One major problem with adapting quantum tomography to capture numerous dimensions of a particle is the work required. As the number of states being read grows, measurements skyrocket, costing time and dramatically increasing the risk of errors.

Biphoton digital holography could change that. Just as conventional holograms allow us to retrieve 3D information from a 2D surface, it's possible to use the way waves interfere with one another to quickly and precisely infer additional dimensions from just a few details carried between a pair of photons.

Physicists already use the interference of entangled particles to map hidden objects in what's known as ghost imaging. Knowing just enough about the positioning of one photon sent down a single pathway, it's possible to learn the secrets of its partner's journey down a second passage by overlapping their waves.

Applying tricks of holography, the researchers were able to read positional information in the interference of two separated light waves, recovering enough information to recreate a yin-and-yang symbol programmed into the photon-generating apparatus.

As simple as the yin-and-yang looks, this single static image represents a significant leap in measuring numerous quantum states in a short time.

""This method is exponentially faster than previous techniques, requiring only minutes or seconds instead of days,"" says University of Ottawa physicist Alessio D'Errico.

""Importantly, the detection time is not influenced by the system's complexity – a solution to the long-standing scalability challenge in projective tomography.""

This research was published in Nature Photonics.",https://www.sciencealert.com/images/2023/08/yin_yang_symbol_entangled_photons.jpg,https://www.sciencealert.com/physicists-visualize-quantum-yin-yang-in-entangled-light-experiment,Science
['Jet Propulsion Laboratory'],2023-08-27 09:35:38-07:00,Behind the Spacecraft: New Video Series Reveals What Drives NASA’s Psyche Mission Team,"“Behind the Spacecraft” is a series of short videos that offer glimpses of the people who’ve helped make this upcoming journey to a metal-rich asteroid possible.

What motivates someone to dedicate years to help construct something that will be rocketed into space, never to be seen again on our planet? For the scientists, engineers, and technicians behind NASA’s Psyche mission to a metal-rich asteroid, the answers are wide-ranging. However, they share a common thread: a passion to explore the unknown.

That inspiration is highlighted in the new “Behind the Spacecraft” video series, in which five members of the Psyche team tell the story of how they ended up on a mission designed to answer questions about the mysterious asteroid Psyche.

Watch a trailer about the series:



Meet some of the engineers who helped build NASA’s Psyche mission, which is set to launch in October on a journey of 2.2 billion miles (3.6 billion kilometers) to a metal-rich asteroid of the same name. Credit: NASA

Christina Hernandez , a flight systems engineer at NASA’s Jet Propulsion Laboratory in Southern California, helped guide the team through the verification-and-validation phase of the mission to ready the spacecraft for the extreme conditions of space. For her, engineering is a way to make science fiction reality. And as a heavy metal fan, she’s excited that Psyche is a mission bound for a metal world.

, a flight systems engineer at NASA’s Jet Propulsion Laboratory in Southern California, helped guide the team through the verification-and-validation phase of the mission to ready the spacecraft for the extreme conditions of space. For her, engineering is a way to make science fiction reality. And as a heavy metal fan, she’s excited that Psyche is a mission bound for a metal world. Meena Sreekantamurthy , a power electronics engineer at the Johns Hopkins Applied Physics Laboratory, worked on the power supply unit for one of the spacecraft’s science instruments. She paints and draws in her free time and marvels that something she helped build with her own hands will reach the asteroid belt.

, a power electronics engineer at the Johns Hopkins Applied Physics Laboratory, worked on the power supply unit for one of the spacecraft’s science instruments. She paints and draws in her free time and marvels that something she helped build with her own hands will reach the asteroid belt. Ben Inouye is an engineer who worked on the team that designed and built the spacecraft power system. Before coming to JPL , which manages the mission, he worked as a marine engineer. Now he draws a line from the discoveries made at sea to those that the Psyche mission’s robotic quest hopes to make.

is an engineer who worked on the team that designed and built the spacecraft power system. Before coming to , which manages the mission, he worked as a marine engineer. Now he draws a line from the discoveries made at sea to those that the Psyche mission’s robotic quest hopes to make. Julie Li oversaw development of the spacecraft’s sci-fi-worthy solar electric propulsion hardware at Maxar Technologies. As a child, she wanted to be an astronaut, and her first job after college was as a design engineer on NASA’s space shuttle. Today, the spacecraft builder is also an outdoor adventurer.

oversaw development of the spacecraft’s sci-fi-worthy solar electric propulsion hardware at Maxar Technologies. As a child, she wanted to be an astronaut, and her first job after college was as a design engineer on NASA’s space shuttle. Today, the spacecraft builder is also an outdoor adventurer. Luis Dominguez is the systems and electrical lead at JPL for the assembly, test, and launch operations phase of the mission. As someone who never imagined as a child that he’d be an engineer working somewhere like JPL, he urges the kids he meets to embrace their curiosity. (The video featuring Dominguez will also be available in Spanish.)



Meet Christina Hernandez, a flight systems engineer on NASA’s Psyche mission, which will be the first to explore a metal-rich asteroid, also named Psyche. In this video Hernandez, from NASA’s Jet Propulsion Laboratory, talks about getting Psyche ready for launch through the spacecraft’s verification-and-validation phase and her passion for heavy metal music. Credit: NASA

Livestreams and Broadcasts

Produced by NASA 360, the videos will be released weekly on Tuesdays. The first (embedded above) was released on August 22. JPL will host a livestream with Julie Li at 1 p.m. EDT (10 a.m. PDT) on September 13 and one with Luis Dominguez at 1 p.m. EDT (10 a.m. PDT) on September 20 on JPL YouTube, Facebook, and X. Questions can be submitted via the livestream chats.

Psyche is set to launch atop a SpaceX Falcon Heavy from Launch Complex 39A at Kennedy Space Center at 10:38 a.m. EDT (7:38 a.m. PDT) on October 5, with additional opportunities scheduled through October 25.

More About the Mission

Spanning approximately 173 miles (279 kilometers) at its broadest, the asteroid Psyche may be a fragmentary core of a planetesimal (one of the building blocks of a rocky planet), or it could be primordial material that never melted. The primary objective of the Psyche mission is to discern between these possibilities. The mission will further shed light on the mysteries surrounding Earth’s metallic core and the genesis of our solar system. Upon its scheduled arrival at Psyche in 2029, the spacecraft will embark on a 26-month observation period, capturing images and collecting data to enhance our understanding of the asteroid.",https://scitechdaily.com/images/Psyche-Spacecraft-Asteroid-Composite-scaled.jpg,https://scitechdaily.com/behind-the-spacecraft-new-video-series-reveals-what-drives-nasas-psyche-mission-team/,Science
[],,Scientists' research concludes that neurotic astronauts not ideal for Martian colony,"If you are thinking of becoming one of the first humans to colonize Mars, you might need to consider your personality type. Research examining the optimal personality types to be able to help a Mars colony become stable and sustainable found that those with neurotic personality traits are a risk to themselves and others.

4 Reviews

With human exploration of Mars inching towards becoming a reality, scientists have been researching what are the optimal personality types for such a mission. With getting to Mars taking us to the very limits of what science and technology can achieve, it makes sense that should humans successfully land on Mars the explorers will want to avoid issues arising from the psychology and personality of the astronauts and potentially future settlers.

A team of scientists from George Mason University created computer simulations of a Mars settlements with between 10 and 50 people, which they found to be all that was necessary to get a colony up and running - previous studies had suggested between 100 to 300 would be needed. Each of the simulated settlers were given one of four aggregated personality types and included “agreeables”, ‘socials’, ‘reactives’ and ‘neurotics’. While the simulation did not factor in sexual relationships, it did allow members of the settlement to die or succumb to health issues linked to issues with food supplies or challenges with life support related functions.

Living in a harsh and dangerous environment like Mars inevitably means that there will be conflict among the colonists. After running simulations with multiple models for the equivalent of 28 years, the most likely to survive were the ‘agreeables’ because of their high sociability, low aggression, and low competitiveness, which worked in their favor. The least likely to survive were the ‘neurotics’, whose propensity for being highly competitive and difficulty coping with changes in routine worked against them. Dropping the neurotic personality types also increased the likelihood for the colony to be stable.

The research is yet to be peer reviewed, while the team also notes that the algorithms they ran didn’t accommodate for how people might change over time among other limitations.

Purchase a LEGO Technics Perseverance Rover for $99.95 from Amazon.",https://www.notebookcheck.net/fileadmin/Notebooks/News/_nc3/mars.png,https://www.notebookcheck.net/Scientists-research-concludes-that-neurotic-astronauts-not-ideal-for-Martian-colony.743896.0.html,Science
"['Passant Rabie', '.Wp-Block-Post-Author-Name Font-Family', 'Var --Wp--Preset--Font-Family--Secondary', 'Sans-Serif', '.Wp-Block-Post-Author-Name A Where', 'Not .Wp-Element-Button', 'Text-Decoration', 'None', 'Hover Color', 'Var --Wp--Preset--Color--Primary']",2023-08-27 00:01:00+00:00,How Many People Does It Take to Start a Colony on Mars?,"It might only take 22 people to establish a colony on Mars, though that small group of cosmic inhabitants should have agreeable personality types to survive on the Red Planet, according to new research.

Mars has been home to robotic explorers for nearly 60 years, but when it comes to landing humans on the Red Planet, things get a little more complicated. In a recent study uploaded to the preprint arXiv server, a group of scientists decided to look into the behavioural and psychological interactions among future Mars colonists and came up with a surprisingly small population size they say could build and sustain the colony: 22 would-be-Martians.

The scientists created a model to simulate a Mars colony based on high-performing teams of people in isolated, high-stress environments such as Arctic exploration or the International Space Station. The simulation played out interactions between people with varying levels of skill, resilience, stress and one of four psychological traits: neurotic, reactive, social, or agreeable, in addition to the environmental factors on Mars.

The simulation ran for 28 Earth days, with varying numbers in each group that ranged from 10 to 170 people. The scientists found that an initial population of 22 was the minimum required to maintain a viable colony size, and that the agreeable personality type was the one more likely to survive on Mars. Neurotic personality types, on the other hand, died at a much higher rate than others, according to the study.

“We tend to often treat humans as just numbers or particles devoid of personal incentives, heterogeneity and adaptability,” Anamaria Berea, associate professor of computational and data sciences at George Mason University and co-author of the study, told The Register. “Human groups are complex systems where the outcome is not the sum of its parts, but synergistic.”

The researchers wanted to highlight the importance of considering human behaviour as part of future space exploration. “We wanted to show that if we neglect the social, behavioural and psychological aspects of space explorations, we can err grossly in our estimations, predictions and projections,” Berea added.",https://gizmodo.com.au/wp-content/uploads/2023/08/271c56abecc547eea1b1a9e9786725ff.jpg?quality=75,https://gizmodo.com.au/2023/08/how-many-people-does-it-take-to-start-a-colony-on-mars/,Science
['Jon Kelvey'],2023-08-25 14:00:00-04:00,"To create a small Mars colony, leave the jerks on Earth","When it comes to building a sustainable settlement on Mars, the technological and engineering challenges are steep. But they take a back seat to the Human Resources department. Forget sophisticated vehicles or sensitive instrumentation—the most temperamental, fragile things we send to the Red Planet will be humans.

After all, NASA’s Opportunity rover roamed Mars for 14 years, separated from Earth by a half-hour communications delay, scoured by dust storms and irradiated by cosmic rays, and never complained or got into a fight with a colleague.

Humans, though, will be sequestered “in a confined space about the size of a small RV for three years,” James Driskell, a research psychologist at the Florida Maxima Corporation, says of most plausible NASA Mars mission scenarios. Driskell and his company have consulted with the space agency and the US military on the psychological issues of crews in isolated and stressful situations. In tight quarters, “people get angry at each other.”

Current Mars plans, such as NASA’s proposed Artemis mission, would send astronauts there and back on a three-year round trip. But you can imagine how stressful dynamics—danger, isolation, other people—might increase on a permanent base or research station, if crews stayed for a decade (or forever). Or, rather than using your imagination, you can rely on the computer simulation of a Mars settlement produced by George Mason University Computational Social Scientist Anamaria Berea and her colleagues.

In a forthcoming study that hasn’t yet undergone full peer review, Berea and her colleagues detail how they used an “agent-based modeling” approach—a computer system not all that different from a large video game—to calculate the survivability of different population sizes of Mars settlers. They’ve incorporated personality types, too, for the long haul. They came to two main conclusions: that only a few tens of initial settlers are needed to create a sustainable colony, and that people with more agreeable social traits did better for themselves and the larger settlement.

[Related: Rodent astronauts suggest trips to Mars will make us anxious, forgetful, and afraid]

The new study originated as a response to other papers suggesting that between 100 and 300 people would be the minimum necessary to begin a sustainable settlement on Mars. The nonprofit Blue Marble Science Institute, which studies questions of planetary science and habitability, contacted Berea to see whether her team could verify the other studies’ minimally viable population numbers.

Berea says she had a better idea: Creating a simulation for a space habitat that included “human, social, and behavioral factors.” Berea and her team at the computational social sciences department had created simulated humans, who were assigned a set of skills necessary for running a Mars settlement, such as producing food or maintaining life support systems.

Each faux settler had one of four aggregate personality types: There were the “agreeables,” highly social and low in scores of aggressions or competitiveness; “socials,” extroverts with a bit more of a competitive edge; “reactives,” who were more still competitive and fixated on fixed routines; and “neurotics,” highly competitive people with difficulty coping with changes in routine or boredom. Settlement members could die in accidents, or due to “health” conditions determined by the available food and life support resources, but could also be replenished by resupply shuttles every 18 months—the researchers chose not to model sex and reproduction.

After running multiple computer models for more than 20 simulated years, the study authors found that settlements could begin with far fewer than 100 settlers and remain sustainable, despite accidents or dips in food supplies. The lowest number to kickstart a sustainable settlement was 22 people, but that is not a hard limit, according to Berea. “It’s somewhere between 10 and 50,” she says. “It’s in the tens; It’s not in the hundreds like the other papers were saying.”

[Related: NASA rover finds evidence of carbon-based chemistry in Martian crater]

They also found that agreeable personality types were the most likely to survive to the end of each simulation run. But Bera is careful to note that the agents—the algorithmic representations of humans—do not remain static through the simulation, just as people, whatever their personalities, change over time. “The neurotic that puts his or her foot down on the planet on day zero might not be the neurotic on day 100. They interact, and they adjust,” she says.

This can be seen in real-world Mars mission simulations, such as the Hawaii Space Exploration Analog and Simulation (HI-SEAS) missions, which places crews of six people in a simulated Mars habituated on the rocky lava slopes of Mauna Loa. There, it’s vital to anticipate the ways people change over time.

“For the first few weeks, usually of people living under stressful conditions, they can still kind of have a ‘honeymoon period’ where everyone’s still very polite and patient and can kind of get along despite some challenges,” says astrobiologist Michaela Musilova, the former director of HI-SEAS from 2018 until 2022. “Usually after the first few weeks is when people really start to struggle and if they’re not prepared for it properly.”

That struggle could take the form of depression or rudeness with other crew members or mission control. Over the 30 simulated Moon and Mars missions for which Musilova served as commander, she found the answer was to consciously forge bonds between crew members using shared meals and evening recreation, such as karaoke.

“The more the crew bonded, the longer the ‘honeymoon period’ lasted and even when it wore off, the crew still behaved politely towards one another,” she says.

Musilova also found that selecting as diverse a group of people as possible, in terms of skills, life experience and ethnicity, helped ensure a better functioning team.

That’s one thing that Berea and her colleagues didn’t model—all of their simulations contained equal numbers of the four personality types they had defined, rather than trying to build teams composed of different proportions of different types of people. Purposefully screening for personality is something Driskell notes is important for building teams going into difficult and isolated conditions.

“What type of trait profiles do we want in that team? That sociability and extraversion is really good, but you don’t want a team full of it, because then they’re going to really want to just interact and get along and talk,” Driskell says. At the same time, he adds, you have people who are very competent and follow the rules and keep things running, but who are just a complete pain to live with. “Everybody’s got an example of somebody who was extremely technically adept, but you just could not get along with them,” he says. “I guess Elon Musk is a good example.”

Neither human nor computer simulations of Mars missions can ever fully predict the experience of putting human boots on the Red Planet, but each approach also takes a different slice of the problem. Computer simulations such as Berea’s and her colleagues can give researchers some idea of the large-scale population dynamics and psychology of a Mars settlement over many years. A 12-month HI-SEAS Mars mission, meanwhile, helps tease out real-life psychological nuance you can’t get from a computer model.

Berea hopes to do more to integrate both approaches in the future, noting that NASA has just launched a new Mars analog mission, the Crew Health and Performance Exploration Analog (CHAPEA) in the Mars Dune Alpha habitat. “Once they are done with that project, it would be great to get the data and compare that with our model for validation,” she says.",https://www.popsci.com/uploads/2023/08/25/Drilling-on-Mars.jpg?auto=webp,https://www.popsci.com/science/mars-colony-population-psychology/,Science
"['Harry Baker', 'Staff Writer', 'Social Links Navigation']",2023-08-25 19:05:56+00:00,"Just 22 people are needed to colonize Mars — as long as they are the right personality type, study claims","An artist's interpretation of what a future colony on Mars could look like.

Only 22 people are needed to create a colony on Mars , an optimistic new study suggests. However, not everyone agrees, and some experts think many more people would be needed to create a lasting human presence on the Red Planet.

In the study, which was uploaded to the pre-print database arXiv on Aug. 11 and has not been peer-reviewed, researchers used a computer program, known as an agent-based model (ABM), to predict how many people would be needed to sustain a colony on Mars. ABMs simulate how well groups react to challenging scenarios based on their personality types.

The model looked at four personality types: agreeables, who are not very competitive or aggressive; socials, who are extroverted and do well in social settings; reactives, who struggle to deal with changes to routine; and neurotics, who are highly competitive and aggressive. The model then varied the number of each type when doing key tasks such as Martian mining and farming.

The researchers found that iIf most people were agreeables or socials, just 22 people could sustain a colony. With more neurotics and reactives, larger groups were needed to succeed.

Limiting the size of the first Martian colonies will be very important, because the more people and equipment that are needed, the more expensive it will be.

Related: How long will it take for humans to colonize Mars?

Personality types will influence how well future Martian astronauts live alongside one another. (Image credit: Shutterstock)

However, the study has major limitations. For example, the model assumed that someone else had built the colony's infrastructure, such as buildings, vehicles and other equipment. The first colonists were also assumed to have seven years' worth of energy from a mini nuclear reactor, like the ones that power the Mars rovers, and to receive regular supplies from Earth.

The model also only simulated the first 28 years of the colony. Models were deemed a success as long as at least 10 people survived to the mission's end.

As a result, not everyone is convinced that a colony with so few people would work out in reality, especially if the end goal is creating a self-sustaining civilization on the Red Planet.

""Twenty-two people is not enough to build and sustain a fully functioning and autonomous colony on Mars,"" Jean-Marc Salotti, an astronautics researcher at the IMS (integration from material to systems) laboratory in Bordeaux, France, told Live Science. Salotti's research had previously found the minimum to be 110 people.

Just 22 people may survive on the planet for a limited time — as long as they have the necessary infrastructure, energy and resources — but they would not thrive, he added.

And while the new study's idea of factoring in personality types was a smart move, it also has its limitations, Salotti said.

Mars and its moons Deimos and Phobos. (Image credit: Getty Images)

""For a colony, a simple dispute or conflict could lead to a disaster,"" Salotti said. But the four personality types used in the study are ""oversimplified, he added. Building and sustaining an autonomous colony on Mars requires more people with a greater range of knowledge and skills to overcome the challenges they would face, Salotti said. So he stands by his minimum estimate of 110 for future missions.

A long-term Martian colony would also require a much larger gene pool than 22 people, Salotti said. If not, Martian babies would run into problems with inbreeding, which would reduce resilience and increase the odds of a disease or physiological defect wiping them out.

In a 2018 paper, also uploaded to arXiv, researchers calculated that producing a genetically viable human population on a one-way trip to Proxima Centauri, the nearest star system, would require at least 98 people. A similar number would be needed on Mars, Salotti said.",https://cdn.mos.cms.futurecdn.net/33WeLBhgTH3TjYGb863FUC-1200-80.jpg,https://www.livescience.com/space/mars/just-22-people-are-needed-to-colonize-mars-as-long-as-they-are-the-right-personality-type-study-claims,Science
['Brian Koberlein'],2023-08-27 16:47:43+00:00,"The Early Universe Should Be Awash in Active Galaxies, but JWST Isn't Finding Them","For decades the most distant objects we could see were quasars. We now know they are powerful active black holes. Active galactic nuclei so distant that they resemble star-like points of light. It tells us that supermassive black holes in the early Universe can be powerful monsters that drive the evolution of their galaxies. We had thought most early supermassive black holes went through such an active phase, but a new study suggests most supermassive black holes don’t.

Most galaxies contain a supermassive black hole. They contain millions or billions of solar masses. They can power tremendous jets of ionized gas streaming away from a galaxy at nearly the speed of light, rip stars apart to seed a galaxy with gas and dust, and even strip galaxies of dust to winnow star formation. They can also remain quiet for billions of years, hiding in a galaxy’s central bulge, as does the central black hole in the Milky Way. But the sheer mass of these black holes suggests they must have grown quickly in their youth, suggesting a period of extreme activity similar to distant quasars.

This new study looks at a period of cosmic history known as cosmic noon. It’s the time when the Universe was about 3 – 6 billion years old and marks the age when star production in the Universe was at its peak. This is also around the time when we would expect supermassive black holes to be active since their churning of gas and dust can trigger star formation. Using the James Webb Space Telescope, the team gathered data from a patch of sky known as the Extended Groth Strip (ESG).

The Extended Groth Strip as seen by Hubble. Credit: NASA, ESA, and M. Davis (University of California, Berkeley)

The ESG is a small, barren region of sky between the constellations of Ursa Major and Boötes. It was observed in detail by the Hubble Space Telescope in 2004 and 2005, which found more than 50,000 galaxies. In 2011, the Spitzer Space Telescope observed the region at infrared wavelengths as part of the All-Wavelength Extended Groth Strip International Survey (AEGIS). Spitzer saw the glow of lots of active black holes, but not as many as anticipated. This wasn’t too unexpected, since it was quite possible Spitzer wasn’t sensitive enough to see smaller AGNs, or those deeply shrouded in dust.

This new survey made by JWST expected to see more, but that wasn’t the case. The Cosmic Evolution Early Release Science program (CEERS) found about the same number of active black holes as before. And with the higher resolution and sensitivity of JWST we can just discount the conclusions.

What this team discovered is that active black holes are rare during cosmic noon, meaning that most galactic black holes grow at a slower pace. The team also found that within smaller galaxies there wasn’t a tremendous amount of dust. Many of the galaxies observed resembled the Milky Way. Spiral galaxies with limited dust and a quite central black hole. This suggests the possibility that our galaxy never had an AGN period.

It should be noted that this initial result only focuses on about 400 galaxies. The team plans to complete a larger survey of 5,000 galaxies next year.

Reference: Kirkpatrick, Allison, et al. “CEERS Key Paper VII: JWST/MIRI Reveals a Faint Population of Galaxies at Cosmic Noon Unseen by Spitzer.” arXiv preprint arXiv:2308.09750 (2023).",https://www.universetoday.com/wp-content/uploads/2023/08/agn.jpg,https://www.universetoday.com/162930/the-early-universe-should-be-awash-in-active-galaxies-but-jwst-isnt-finding-them/,Science
['Stowers Institute For Medical Research'],2023-08-26 23:26:34-07:00,Hidden Hazards: Scientists Uncover Unexpected Effects of Anti-Cancer Drugs,"The findings could potentially improve the success rate of cancer drug development.

Approximately 90% of drugs don’t reach the market, highlighting the clear need for increased efficiency in drug development. The story isn’t different for drugs aimed at treating cancer, with many failing due to various reasons. Now, researchers have revealed one reason why certain anti-cancer compounds can cause unexpected side effects. This research could help guide an understanding of why some drugs show more promise than others, providing a new tool that can be used to identify those drugs and drug candidates.

One of the most essential and energy-consuming cellular processes is ribosome biogenesis, the formation of the cellular machines that manufacture all proteins. For cancer cells, this process is paramount. A recent study published in the journal eLife from the Stowers Institute for Medical Research screened over 1,000 existing anti-cancer drugs to assess how they impact the structure and function of the nucleolus, the ubiquitous cellular organelle where ribosomes are made.

“All cells must make proteins to function, so they have to make ribosomes, which are also protein complexes themselves,” said lead author Tamara Potapova, Ph.D., a research specialist in the lab of Investigator Jennifer Gerton, Ph.D. “In cancer cells, ribosome production must be in overdrive to compensate for high proliferation rates requiring even more proteins.”

The nucleolus is a special part of the cell nucleus that houses ribosomal DNA, and where ribosomal RNA production and ribosome assembly largely takes place. Nucleoli can vary greatly in appearance, serving as visual indicators of the overall health of this process. Thus, the team found a way to capitalize on this variation and asked how chemotherapy drugs impact the nucleolus, causing nucleolar stress.

“In this study, we not only evaluated how anti-cancer drugs alter the appearance of nucleoli but also identified categories of drugs that cause distinct nucleolar shapes,” said Gerton. “This enabled us to create a classification system for nucleoli based on their appearance that is a resource other researchers can use.”

Because cancer’s hallmark is unchecked proliferation, most existing chemotherapeutic agents are designed to slow this down. “The logic was to see whether these drugs, intentionally or unintentionally, are affecting ribosome biogenesis and to what degree,” said Potapova. “Hitting ribosome biogenesis could be a double-edged sword—it would impair the viability of cancer cells while simultaneously altering protein production in normal cells.”

Different drugs impact different pathways involved in cancer growth. Those that influence ribosome production can induce distinct states of nucleolar stress that manifest in easily seen morphological changes. However, nucleolar stress can be difficult to measure.

“This was one of the issues that impeded this field,” said Potapova. “Cells can have different numbers of nucleoli with different sizes and shapes, and it has been challenging to find a single parameter that can fully describe a “normal” nucleolus. Developing this tool, which we termed “nucleolar normality score,” allowed us to measure nucleolar stress precisely, and it can be used by other labs to measure nucleolar stress in their experimental models.”

Through the comprehensive screening of anti-cancer compounds on nucleolar stress, the team identified one class of enzymes in particular, cyclin-dependent kinases, whose inhibition destroys the nucleolus almost completely. Many of these inhibitors failed in clinical trials, and their detrimental impact on the nucleolus was not fully appreciated previously.

Drugs often fail in clinical trials due to excessive and unintended toxicity that can be caused by their off-target effects. This means that a molecule designed to target one pathway may also be impacting a different pathway or inhibiting an enzyme required for cellular function. In this study, the team found an effect on an entire organelle.

“I hope at a minimum this study increases awareness that some anti-cancer drugs can cause unintended disruption of the nucleolus, which can be very prominent,” said Potapova. “This possibility should be considered during new drug development.”

Reference: “Distinct states of nucleolar stress induced by anti-cancer drugs” by Tamara A. Potapova, Jay R. Unruh, Juliana Conkright-Fincham, Charles A. S. Banks, Laurence Florens, David A. Schneider and Jennifer L. Gerton, 13 July 2023, eLife.

DOI: 10.7554/eLife.88799.1

This work was funded by institutional support from the Stowers Institute for Medical Research.",https://scitechdaily.com/images/Fluorescent-Image-Showing-Cells-With-Normal-Nucleoli-in-Nuclei.jpg,https://scitechdaily.com/hidden-hazards-scientists-uncover-unexpected-effects-of-anti-cancer-drugs/,Science
[],2023-08-28 09:08:22+05:30,"Massive sunspot set to spark dangerous M-class solar flares directed at Earth, says NASA","As we approach the solar maximum, the Sun's output is expected to increase in the coming months. As per NASA, the solar minimum occurred in 2019, which also marked the start of the solar maximum, a period where we could see the greatest number of sunspots. It is expected to peak in 2025 and the Sun could unleash CMEs, solar flares, solar storms, and other particles towards Earth with potentially disastrous consequences. Astonishingly, experts have revealed that the Sun has already exceeded the predicted number of sunspots that were expected in the current solar maximum.

NASA's Solar Dynamics Observatory (SDO), which carries a full suite of instruments to observe the Sun, has recently revealed that Earth could be in the firing line of a sunspot and dangerous solar flares could be hurled out that could have the potential to wreak havoc.

Dangerous sunspot

According to a report by spaceweather.com, NASA's Solar Dynamics Observatory (SDO), forecasts that an active region on the Sun's surface, termed Sunspot AR3415, has a “beta-delta” magnetic field that could trigger solar flares. There is a 90 percent chance of C-class flares and a 20 percent chance of M-class flares being hurled out towards Earth today, August 28.

It states, “Sunspot AR3415 has a 'beta-delta' magnetic field that harbours energy for M-class solar flares.”

Moreover, while the chances are slim, the report states that there is a 5 percent chance of X-class solar flares too. For the unaware, X-class solar flares are the most dangerous flares hurled out by the Sun. It can disrupt global communications and damage satellites. It has also been revealed that these flares can even give small doses of radiation to people flying in aeroplanes. X-class flares can potentially harbour as much energy as a billion hydrogen bombs!

About NASA Solar Dynamics Observatory

The NASA Solar Dynamics Observatory (SDO) uses three very crucial instruments to collect data from various solar activities. They include the Helioseismic and Magnetic Imager (HMI) which takes high-resolution measurements of the longitudinal and vector magnetic field over the entire visible solar disk, Extreme Ultraviolet Variability Experiment (EVE) which measures the Sun's extreme ultraviolet irradiance, and Atmospheric Imaging Assembly (AIA) which provides continuous full-disk observations of the solar chromosphere and corona in seven extreme ultraviolet (EUV) channels.",https://images.hindustantimes.com/tech/img/2023/08/28/1600x900/solar-flare-67532_640_1693193841991_1693193853484.jpg,https://tech.hindustantimes.com/tech/news/massive-sunspot-set-to-spark-dangerous-m-class-solar-flares-directed-at-earth-says-nasa-71693193591704.html,Science
['Evrim Yazgin'],2023-08-25 22:27:00+09:30,Mars rover Perseverance sees sunspot rotating toward Earth,"NASA’s Perseverance Mars rover has caught a glimpse of a huge sunspot, indicating a region of high solar activity, on the far side of the Sun which will turn to face Earth in the coming days.

“Because Mars is orbiting over the far side of the sun, Perseverance can see approaching sunspots more than a week before we do,” a blog post on spaceweather.com states. “Consider this your one-week warning: A big sunspot is coming.”

The sunspot was captured by Perseverance’s Mastcam-Z. According to NASA’s website, the main job of Mastcam-Z is to “take high-definition video, panoramic colour and 3D images of the Martian surface and features in the atmosphere.”

This illustration depicts NASA’s Perseverance rover operating on the surface of Mars. Credit NASA/JPL-Caltech.

The rover, whose mission is to analyse the surface of the Red Planet and look for potential ancient signs of life on Mars, took a moment from its usual tasks to take a look up.

Perseverance takes pictures of the Sun every day to measure the amount of dust in Mars’s atmosphere. But this image revealed a structure on our central star’s surface which caught scientists’ attention.

Sunspots are cool, dark regions on the Sun’s surface where the magnetic field is particularly strong. It is usually from these active regions that solar flares and coronal mass ejections originate. These expulsions push plasma, ionising matter and high-energy charged particles at great velocity into space.

As the Sun enters the maximum of the 25th Solar Cycle, such activity is expected to increase.

If coronal mass ejections reach Earth, they could have a disruptive impact on communications satellites, power grids and navigation.

For now, Perseverance has done its bit to give us Earthlings a heads up.

It will now continue on its journey across the floor of the 45-km wide Jezero Crater, picking up rocks and taking pictures of structures along with its helicopter buddy Ingenuity to help us better understand Mars and its ancient past.",https://cosmosmagazine.com/wp-content/uploads/2023/08/m4yB72LvLpqyAKu4y6iuHB-1200-80.jpg,https://cosmosmagazine.com/space/exploration/mars-rover-perseverance-sunspot/,Science
[],,Massive sunspot seen by Mars rover may disrupt satellites and cover Earth with auroras,"A team of experts from NASA has recently spotted a colossal sunspot, predicted to expand and shift until it directly faces Earth in the coming week.

The scientists cautioned that this darker, cooler region of the sun might unleash powerful eruptions such as solar flares (intense bursts of high-frequency radiation) and coronal mass ejections (CMEs; vast solar plasma eruptions).

These types of eruptions have the potential to intersect with the Earth and interfere with satellite navigation and even trigger power outages, making sunspot monitoring far more crucial than mere scientific curiosity.

Sunspot captured by NASA’s Perseverance rover

While the exact dimensions of the sunspot remain uncertain, it was NASA’s Perseverance rover that captured its imagery from a staggering distance of over 152 million miles away from the sun. Between August 17 and August 20, the rover documented the sunspot while navigating the Jezero Crater on Mars.

“Because Mars is orbiting over the far side of the sun, Perseverance can see approaching sunspots more than a week before we do. Consider this your one-week warning: a big sunspot is coming,” experts from Spaceweather reported.

These captured images have been converted into an animation, presenting a faint sun against the void of space, with a notable shadowy mass sweeping across its facade. And as scientists stressed, to show up in such low-resolution images, the sunspot must be considerably big.

How do sunspots form?

The formation of sunspots is attributed to the sun’s magnetic field, which is approximately 2,500 times stronger than that of Earth. Due to this intense magnetic field, the magnetism’s pressure heightens, causing the adjacent atmospheric pressure to drop.

Consequently, this reduces the temperature in comparison to its neighboring regions because the dense magnetic field restricts the influx of warm gas from the Sun’s core to its exterior.

Thus, sunspots appear darker, as they are around 4,000 degrees Fahrenheit less warm than the surrounding regions. By contrast, the sun’s external atmosphere can soar beyond a million degrees.

Decoding mysteries of the sun

Back in February, NASA showcased breathtaking images of our mammoth star, delineating its diverse temperature zones. Utilizing the Nuclear Spectroscopic Telescope Array (NuSTAR), the U.S. space agency traced varying X-rays discharged by the hottest substances in the sun’s aura. Areas emitting high-energy X-rays were few, while regions radiating low-energy X-rays and ultraviolet light spanned the entire gaseous orb.

Through these insights, scientists aspire to decode one of the sun’s profound enigmas: the reason behind its external atmosphere being over a million degrees – a temperature at least 100 times hotter than its surface.

More about sunspots

Sunspots are temporary phenomena on the Sun’s photosphere that appear visibly as dark spots compared to surrounding regions. They are caused by the Sun’s magnetic field’s intense activity, which inhibits convection by an effect known as magnetic confinement.

As a result, sunspots are cooler areas on the Sun’s surface, though “cooler” is relative. While the surrounding photosphere may be around 5,500°C (9,932°F), sunspots are about 3,000-4,500°C (5,432-8,132°F).

Here are some key points about sunspots:

Magnetic fields

The Sun’s magnetic fields can become twisted and distorted as the Sun rotates, due to differential rotation. When these twisted magnetic fields poke through the Sun’s surface, they can create sunspots.

Solar cycle

Sunspots follow an approximately 11-year cycle, known as the solar cycle, during which the number of sunspots increases to a maximum and then decreases to a minimum. The solar cycle affects various space and Earth-bound phenomena.

Structure: Sunspots usually have two parts:

Umbra: The central, darkest part where the magnetic field is strongest.

Penumbra: The outer region, which is lighter than the umbra and has a more complex structure.

Effects

The presence and number of sunspots can influence space weather and solar radiation. They are associated with solar flares and coronal mass ejections (CMEs), which can have significant effects on Earth’s magnetosphere and can potentially disrupt communication and power systems.

Additionally, high sunspot activity can influence the Earth’s climate. However, the relationship is complex and not fully understood.

Observation

Sunspots have been observed for centuries. The invention of the telescope in the early 17th century allowed for more systematic observations, with astronomers like Galileo Galilei and Christoph Scheiner among the first to document them.

Sunspot number

Astronomers track sunspot activity by calculating the sunspot number, which is a measure of the total sunspot activity on the sun. The number is a combination of the individual spots and their groupings.

Maunder minimum

Between 1645 and 1715, there was a period with very few sunspots observed, coinciding with a period of cooler temperatures in Europe known as the “Little Ice Age.” This period of low sunspot activity is referred to as the Maunder Minimum.

If you ever wish to observe sunspots, it is crucial to use the proper equipment and precautions to protect your eyes. Never look directly at the Sun without specialized solar viewing equipment.

The study of sunspots and solar activity is crucial in understanding the Sun’s processes and its effects on Earth’s space environment, climate, and technological systems.

More about sun eruptions

Sun eruptions, often referred to as solar flares or coronal mass ejections (CMEs), are massive bursts of energy and matter from the Sun’s surface and its outer atmosphere. Here’s a brief overview:

Solar flares

These are sudden, intense variations in brightness. They are our sun’s version of earthquakes, caused by the interaction of magnetic fields. Solar flares release a lot of energy, including radiations across virtually the entire electromagnetic spectrum, from radio waves to x-rays and gamma rays.

Coronal mass ejections (CMEs)

CMEs are massive bursts of solar wind and magnetic fields rising above the solar corona or being released into space. CMEs often accompany solar flare outbreaks but can occur independently as well. These are huge bubbles of gas threaded with magnetic field lines.

Impacts of sun eruptions

Space weather

Solar flares and CMEs can produce strong x-rays that can affect Earth’s upper atmosphere and potentially disrupt radio signals. If directed at Earth, the charged particles from a CME can also disturb our planet’s magnetosphere, leading to geomagnetic storms.

Satellite operations

Strong geomagnetic storms can interfere with satellite electronics and even reduce their operational lifespans.

Astronaut safety

High doses of the solar energetic particles from CMEs can pose a threat to astronauts outside of Earth’s protective magnetosphere.

Power grids

In extreme cases, geomagnetic storms can induce electric currents in power lines, potentially damaging transformers and other components of a power grid.

Auroras

On a positive note, the interaction of charged particles from the Sun with Earth’s magnetic field and atmosphere leads to the creation of beautiful auroras (Northern and Southern Lights).

Understanding solar flares and CMEs is essential not just for our technological infrastructure but also for future deep space missions, as they can impact the safety of astronauts traveling beyond Earth’s protective magnetic field.

—-

By Andrei Ionescu, Earth.com Staff Writer

Check us out on EarthSnap, a free app brought to you by Eric Ralls and Earth.com.",https://cff2.earth.com/uploads/2023/08/26092755/solar-flare_earth-magnetic-field_auroras_1medium.jpg,https://www.earth.com/news/giant-sunspot-may-soon-disrupt-earths-power-grids/,Science
[],2023-08-26 00:00:00,NASA scientist confirms life on other planets: We're pretty close,"In the wake of mankind's latest advances in science, space and planetary research, scientists are coming to conclusions that would have been unimaginable years ago.

India has reached the lunar south pole for the first time, NASA is going to study the surface of Venus, and Neptune's dark spots have been examined.

Thanks to all these advances, there are scientists, even from NASA, who already believe that extraterrestrial life exists, as is the case of Michelle Thaller.

Covering the subject of deep space at an exhibition in New York, the doctor wanted to answer the question that every human being has ever asked: is there extraterrestrial life, to which the scientist answered without any doubt.

""Definitely, I believe we will find life on another planet,"" Thaller explained to The US Sun.

She believes that within the galaxy where we are positioned, there is a good chance of finding the extraterrestrial life we so desperately want to know about.

""I think in our own Solar System we're pretty close to that, but again, we don't have that 100 percent,"" she continued.

""According to our research on neighboring planets, the red planet Mars was once like Earth, only it currently has no magnetic field and no greenhouse gases, so it has no liquid state, which means it cannot support life.""

Mars and Venus, potential planets with life in their past

Mars more than 4 billion years ago was liquid, which meant that its temperatures were warmer. NASA is analyzing the red planet using the Curiosity rover and there they found data on amino acids.

""Finding certain amino acids on Mars would be considered a potential sign of ancient Martian life because they are widely used by terrestrial life as a building block for proteins,"" the NASA scientist posted in a blog on their website.

""Proteins are essential for life, as they are used to produce enzymes that accelerate or regulate chemical reactions and to form structures.""

Venus is also a rocky planet, like Earth and Mars. The doctor has some hope for it, saying they see ""something in its atmosphere that looks a lot like what bacteria might have produced.""",https://phantom-marca.unidadeditorial.es/1f1227d12ba99f2a115f642df52e8e40/resize/1200/f/jpg/assets/multimedia/imagenes/2023/08/26/16930733771111.jpg,https://www.marca.com/en/lifestyle/world-news/2023/08/26/64ea54e7ca4741a6118b4587.html,Science
['Alex Daniel'],2023-08-27 07:52:44+00:00,Material discovered on Mars would be ’signs of life’ if found on Earth,"A Nasa scientist has said chemicals found on Mars would be considered signs of ancient life if they were found on Earth, leading to suggestions the Red Planet could potentially have harboured life.

Dr Michelle Thaller said: “On Mars we see chemistry that on Earth, if it were here, we would say is due to life.

“But the question is, how well do we understand Mars and are we being fooled by something?”

It’s not a done deal, of course. Signs of ancient life that we find regularly on Earth may not mean the same thing elsewhere, particularly with the vastly different conditions between the two planets.

Dr Thaller told The Sun she is certain there is life out there in our solar system, but did not reveal the exact chemical substance that had been found.

Nasa has previously found methane on Mars, which it said “could have supported ancient life”, and the organisation has also revealed plans to look for amino acids that haven’t yet been destroyed by space radiation.

Life on Mars? iStock

Organic chemicals like amino acids are used by archaeologists to determine whether life was present.

A blog post from the US space agency said: “Amino acids can be created by life and by non-biological chemistry.

“However, finding certain amino acids on Mars would be considered a potential sign of ancient Martian life because they are widely used by terrestrial life as a component to build proteins.

“Proteins are essential to life as they are used to make enzymes which speed up or regulate chemical reactions and to make structures.”

Alexander Pavlov of Nasa’s Goddard Space Flight Center in Greenbelt, Maryland, added: “Our results suggest that amino acids are destroyed by cosmic rays in the Martian surface rocks and regolith at much faster rates than previously thought.

“Current Mars rover missions drill down to about two inches (around five centimeters).

“At those depths, it would take only 20 million years to destroy amino acids completely.”

That may sound like a long time, but Nasa is looking for life that is billions of years old, because scientists think Mars would have been more like Earth back then.

Dr Thaller said it was important not to actually say there were signs of life until there is 100 per cent confirmation.

“The solar system may be teeming with simple life, microbial life.

“We just have to get that 100% certainty to say that we found it and we don’t have that yet.”

Sign up to our free Indy100 weekly newsletter

Have your say in our news democracy. Click the upvote icon at the top of the page to help raise this article through the indy100 rankings.",https://www.indy100.com/media-library/cracked-mud-on-mars-may-point-to-extraterrestrial-life.jpg?id=28050635&width=1200&height=600&coordinates=0%2C0%2C0%2C776,https://www.indy100.com/science-tech/aliens-mars-science-nasa,Science
[],,NASA Scientist Reveals Which Planet Could Host Alien Life,"After a recent hearing on Capitol Hill, officials are left discussing what their next steps are when it comes to UFOs and UAP (unidentified anomalous phenomena). As those in Washington try to get a select UFO committee established, one NASA official says they're certain aliens are taking residency out there amongst the stars, perhaps even on the surface of one of our celestial neighbors. In a new interview with The Sun, Dr. Michelle Thayer revealed it's her belief life could currently be found on Venus.

""I definitely think we'll find life on another planet,"" the astronomer told the tabloid. ""I think that in our own Solar System, we're quite close to it but once again we don't have that 100 percent thing.""

She added, ""We see possible signs of life in the atmosphere of Venus. Possibly underneath the ice in the icy moons of Jupiter and Saturn. The Solar System may be teaming with simple life, microbial life. We just have to get that 100 percent certainty to say that we found it and we don't have that yet.""

Earlier this year, scientists revealed they discovered certain molecules of Venus that are typically only produced living things. A team led by the University of Cardiff's Jane Greaves found evidence of phosphines in the Venusian atmosphere.

""We've made significant progress since we obtained the initial data in 2017,"" Greaves said in a chat with IFLScience. ""We have now discovered phosphine on five separate occasions, allowing us to analyze its behavior. The focus is no longer solely on finding it; it's about understanding how it changes over time and what implications that might have.""

""Finding it there shows that there really is a source either in the clouds or below the clouds,"" Greaves continued. ""And that's really interesting because the clouds are the interesting part… because there might be a possibility, a long shot, that there might be some kind of living organisms there.""

Are aliens real?

At no point during the aforementioned of the hearing was alien life confirmed to exist. Much of the discourse online has been centered on testimony from David Grusch, a former member of the intelligence committee who claimed under oath he had heard from colleagues the United States government had retrieved ""non-human"" biologics from UFO crash sites.

""As I've stated publicly already … biologics came with some of these recoveries, yeah,"" Grusch said in response to a question from Rep. Nancy Mace (R-NC). When pressed on if those biologics were human or extraterrestrial, the official confirmed ""non-human"" biologics are what have been recovered from certain UFO crashes.

For additional space and cosmic stories, check out our ComicBook Invasion hub here.",https://sportshub.cbsistatic.com/i/2023/03/29/86a9532f-3b4b-42e1-97bf-574f75731f3c/venus-picture-invasion.jpg?width=1200,https://comicbook.com/irl/news/nasa-which-planet-has-alien-life-revealed/,Science
['Matt Drake'],2023-08-27 15:51:23+01:00,China may be to blame for UFOs: Nasa chief says unidentified flying objects are real and may be 'unfriendly' advanced technology,"UFOs may be 'unfriendly' advanced technology, according to Nasa experts.

Unidentified Flying Objects have been in popular culture since at least the 1950s.

While many believe they could be the result of alien life, some experts believe there may be other explanations and could be aircraft from hostile nations.

Dr Thomas Zurbuchen, Nasa's longest-serving associate administrator for the Science Mission Directorate, said he remains convinced there is something out there after reading to numerous reports and speaking to witnesses, The Telegraph reported.

Although, he said it is important to question whether Chinese spy balloons might be to blame.

Dr Thomas Zurbuchen is Nasa's longest-serving associate administrator for the Science Mission Directorate

It comes after a US fighter pilot shot one down in February as it crossed the Atlantic.

He said: 'The whole balloon phenomenon we cannot ignore because if we ignore what we see then we will suddenly get surprised.'

The UFO expert recently left Nasa for ETH Zurich in his home country of Switzerland.

Before leaving, he examined evidence of UFO sightings thoroughly such as a 1952 photograph of a sighting over Passaic, New Jersey.

Dr Zurbuchen added: 'Not only did I talk to pilots, I talked to individuals who had sightings and they were really convinced. I really felt they told me the subjective truth. They were not lying, they were not making things up. I think they were telling me what they saw.

'The fact that there are unexplained phenomena is not a question for me. What they are and what they mean, and how we prove they exist is something that needs more work.

'There could be multiple explanations. If we are looking at technology then it may not be friendly and that is something we should know. It could be technology from other places on Earth and that would be pretty scary.

'It could be a natural phenomenon like luminescent clouds, or something we've never seen before, and that would be pretty interesting, or it could be some kind of camera problem that occurs.'

There are some experts out there who believe UFOs may genuinely be evidence of alien life

Government officials believe that surveillance operations by foreign powers and weather balloons or other airborne clutter explain most recent incidents of unidentified aerial phenomenon

Prof Greg Eghigian of Penn State University believes that trends and events could have influenced UFO sightings.

He said: 'Like most things in history, the answer lies more likely in a confluence of events and trends.

'The discovery of thousands of exoplanets by astronomers since the 1990s has made life on other planets appear more likely than previously thought and the development of drones has contributed to spikes in UFO sightings.

'The development of new sensors and sophisticated spying technologies has made it possible for militaries to detect anomalies more precisely; it has also made concerns about bad actors surveilling military operations more pressing.

'And speculation about UFOs has always thrived in environments where questions are being raised about the trustworthiness of authorities and experts.'

However, there are still people who believe that UFOs really are evidence of alien life but that space agencies and governments chose to ignore it or are keeping it under wraps.

Dr Rudolph Schild, an astrophysicist with the Centre for Astrophysics at the Harvard-Smithsonian, said: 'In the mid-1960s, after becoming an astrophysicist with the Harvard-Smithosonian, I began to hear rumours that the bodies of extraterrestrials and the wreckage from their craft, were under study in a special facility in Building 18 at Wright-Patterson Air Force Base.

'It was rumoured that a senior colleague with a joint appointment with the physics department at Harvard, had examined the wreckage and seen the bodies. When I questioned him, he became upset and didn't want to talk about it.

'The hearings before the US Congress merely affirmed what many of us had known, or at least strongly suspected for decades. The military has acquired extraterrestrial bodies from the wreckage of UFOs.

'It stands to reason that if UAPs and extraterrestrials have crashed on Earth, then it is equally likely they have crashed to the surface of other planets, and that their remains and wreckage can be found on Mars.'",https://i.dailymail.co.uk/1s/2023/08/27/15/74766631-0-image-a-5_1693147765339.jpg,https://www.dailymail.co.uk/news/article-12450287/China-blames-UFOs-Nasa-chief-says-unidentified-flying-objects-real-unfriendly-advanced-technology.html,Science
[],2023-08-26 00:00:00,Has the world’s ‘Leading Alien Hunter’ found extraterrestrial life?,"1. How relevant is this ad to you?

Video player was slow to load content Video content never loaded Ad froze or did not finish loading Video content did not start after ad Audio on ad was too loud Other issues","https://media.cnn.com/api/v1/images/stellar/prod/230826101500-smr-avi-loeb-and-ufo-globe.jpg?c=16x9&q=w_800,c_fill",https://www.cnn.com/videos/us/2023/08/26/smr-extraterrestrial-object.cnn,Science
['Stuart Clark'],2023-08-26 00:00:00,Astrophysicist Avi Loeb: ‘UFOs should be the subject of mainstream inquiry. Science must bring clarity’,"Abraham Loeb, known as Avi, is a professor of astrophysics at Harvard University and he has done the unthinkable. He has repeatedly been willing to contemplate the existence of nonhuman technology and how it may explain certain perplexing astronomical observations that mainstream science struggles with. Loeb, 61, is the author of Interstellar: The Search for Extraterrestrial Life and Our Future Beyond Earth, a follow-up to his New York Times bestseller Extraterrestrial: The First Sign of Intelligent Life Beyond Earth. On the day we spoke, the US government was preparing to hold a House of Representatives oversight and accountability committee hearing on UFOs with retired air force officer and former intelligence official David Grusch, who turned whistleblower in June, claiming that the US government had retrieved pieces of crashed alien spacecraft.

When it comes to UFOs, why is it always a government cover-up? Why don’t astronomers see UFOs – aren’t they the people looking at the sky the most?

The government would be a natural first to recognise anything unusual in the sky or in crash sites because their day job is to worry about national security and to monitor the nearby environment. Astronomers always train their telescopes on very distant, slow-moving objects. They are not looking for anything fast-moving or nearby. So it’s possible that if anything unusual happened, the US government would notice it first.

But your project Galileo (to look for evidence of extraterrestrial technological artefacts) aims to change that…

We’ve built the first Galileo Project observatory at Harvard University and we monitor the sky all the time in the infrared, optical, radio and audio. We use machine-learning software to figure out whether everything we see is either natural – birds or bugs, or human-made like balloons, drones or aeroplanes – or maybe something else. The oceans and the sky are not classified. We can explore them scientifically. We don’t need to wait for the government to declassify information.

What started your interest in UFOs, or unidentified anomalous phenomena (UAPs) as they are now called?

I was triggered by the discovery of the interstellar object Oumuamua back in October 2017. It passed close to Earth and was flagged as a near-Earth object. But it was actually moving faster than the escape speed of the solar system, so it had come from outside the solar system. Then it was found to be unusual in terms of its shape – most likely flat, based on the variation of light as it was tumbling. And then it was seen being pushed away from the sun without showing any evidence for evaporation, so it was not a comet. I suggested it was pushed by the reflection of sunlight [off its surface] and that brought in the possibility that it [its surface] was a membrane produced by technological means. A few years later, there was another object discovered that shared the same quality of being pushed away from the sun but with no cometary evaporation. It ended up being a rocket booster that Nasa launched in 1966. So here was a technological object that we produced; the question is: who produced Oumuamua?

Academics are jealous. They see the attention my research gets and try to step on this flower that rises above the grass

What made you organise a maritime expedition to trawl the Pacific Ocean near Papua New Guinea last month for possible extraterrestrial technological artefacts?

In January 2019, I was interviewed for a radio programme about a meteor that exploded above the Bering Sea. In reading about meteors, I found this catalogue that Nasa compiled of 273 meteors with velocity information. I told my student Amir Siraj: “Why don’t we go over this catalogue and check the fastest moving meteors – perhaps one of them is like Oumuamua and came from outside the solar system.” Sure enough, we found this meteor from 8 January 2014 that moved at 60 kilometres per second [about 37 miles per second]. Three years later, the US government confirmed that it was interstellar (with 99.9% certainty) and provided information about the fireball. That convinced me to lead the expedition because the government data indicated that it exploded in the lower atmosphere. Therefore, it must have been tougher than all the other meteors in the catalogue. To me, that raised the possibility that maybe it was made of some artificial alloy, maybe stainless steel, and also was moving fast because it benefited from propulsion. So that led us to the Pacific Ocean, where it fell.

What did you find?

We localised the meteor explosion site using seismometer data, and then went there with a sledge that has magnets on both sides and collected 500 spherules – these are molten droplets from the surface of the object. Now we are engaged in analysing their composition so that we can answer the question of whether the material is from outside the solar system and whether it’s of technological origin. If that material was stainless steel, we can figure it out. If it was semiconductor material, or computer screens, we can tell because the abundance of elements will be different. I have assigned the materials to three laboratories to figure out the composition. We will see what we find.

You have received some pointed criticism for speaking on these topics. What do you think motivates that backlash?

Academic jealousy. They see the attention that my research is getting and they try to step on this flower that rises above the grass level. My point is that science can be exciting if it resonates with the public’s interest. The fact that the government cares about and talks about objects that cannot be identified should make this a subject of inquiry within the mainstream of science. It’s our civic duty as scientists to bring clarity, using scientific instrumentation and methodology. Instead of ridiculing it or being jealous of the attention I am getting, scientists should join me in pursuing it. If we insist that anything we see must fit with past knowledge, we will never ever learn something new. So that’s one aspect of my book Interstellar.

What other aspects do you cover in the book?

I argue that finding extraordinary evidence requires extraordinary funding. Instead of focusing on disputes and military conflicts, if we invest $2tn a year in space exploration, we could send a probe to every star in the Milky Way galaxy within this century. It’s just a matter of priorities. It could elevate us to a higher level of intelligence so that we will be worthy of attention from other civilisations. I jog every morning at sunrise and I did that on the ship. There was a film crew with me and the director asked me: “Are you running away from something or towards something?” I said: “Both.” I’m running away from some of my colleagues who have strong opinions without seeking evidence. And I’m running towards a higher intelligence in interstellar space.",https://i.guim.co.uk/img/media/2272d18cc3a2085a4278deb5425c177f2942d3c6/0_0_2100_1260/master/2100.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdG8tZGVmYXVsdC5wbmc&enable=upscale&s=a2d25fbb56a87326d91798f0a5783beb,https://www.theguardian.com/world/2023/aug/26/astrophysicist-avi-loeb-ufo-extraterrestrial-life-space-science-interview,Science
"['Emily Burnham', 'More Emily Burnham']",2023-08-26 00:00:00,This Mainer may one day help Harvard scientists discover evidence of alien life,"Two years ago, Portland-based audio engineer and Bangor native Andrew Mead emailed Harvard astrophysicist Avi Loeb on a whim. He had read an article about how Loeb believed UAPs, or unidentified aerial phenomenon commonly known as UFOs, were deserving of legitimate scientific study, and was about to launch a new project at Harvard to do just that. A fascinated Mead made the case in his email that the study of acoustics, his specialty, would need to be a part of such a program.

Two days later, Mead found himself a part of the team for The Galileo Project, Loeb’s Harvard-based initiative that, using its own telescopes, cameras and sensors, searches the skies of North America for anomalous objects, sounds and atmospheric phenomena.

“Suddenly I was sitting in a call with people like Avi, people like [computer scientist] Stephen Wolfram, all these incredible minds. It was pretty surreal,” Mead said. “I definitely felt some imposter syndrome. But it quickly became clear that the team needed people with expertise from all areas, academic or not.”

Mead is one of two leads on the acoustic engineering team for Galileo. He and his team primarily focus on developing highly sophisticated audio sensors and software that can automatically recognize normal sounds, such as aircraft or wind, and differentiate them from anomalous sounds that could potentially come from extraterrestrial objects.

Just this past spring, Mead was part of a scientific paper published in the Journal of Astronomical Instrumentation detailing the systems the group has developed.

“Just as we use telescopes and cameras to see what might be out there, we also use audio instruments to identify sounds, like potential means of propulsion,” Mead said. “It paints a far more detailed, data-rich picture of what might be out there.”

There are two Galileo Project observatories, one in Colorado and one near Harvard. Five more are expected to come on line in the coming months and years. The end result will be a comprehensive survey of the North American skies, with the ability to capture and analyze any unusual phenomenon that may arise.

“We’re capturing everything we can, in the hopes that maybe we find that one thing that leads to something concrete,” Mead said. “There are hundreds of UAP sightings each year. Statistically, if we cast a wide enough net, we might be able to catch one and see what’s actually going on.”

Mead, 35, has been fascinated by sound all his life, starting as a kid growing up in Bangor, where he would play around with a four-track recorder owned by his dad, Maine Supreme Judicial Court judge Andrew Mead. After graduating from Bangor High School in 2006 and then from Tufts University in 2010, he co-founded the band The Other Bones in Portland, followed by a solo project and producing albums from other bands.

As with most of the members of The Galileo Project, Mead volunteers his time each week, helping to further test and calibrate systems and record data, while still holding a full-time job with a California multimedia production firm. While he does most of the work from home, he travels to Harvard regularly to meet with the rest of the team.

And as the project has grown, Mead has enlisted the help of more volunteers, including a longtime friend in the Portland music scene, Dominic Lavoie. Lavoie, a Madawaska native, is also a talented audio engineer, and is now helping to build and wire the acoustic monitoring systems Mead and his team have created.

“He’s an invaluable team member, and I love that he lives ten minutes away from me,” Mead said. “And to think we both come out of the northern half of Maine, and out of the Portland music scene, and we’re working on this really exciting, groundbreaking stuff, it’s just so cool.”

This artist’s rendering provided by the European Southern Observatory shows the interstellar object named “Oumuamua” which was discovered on Oct. 19, 2017 by the Pan-STARRS 1 telescope in Hawaii. In the Wednesday, June 27, 2018 edition of the journal Nature, a European-led team makes the case it is a comet, not an asteroid. Credit: M. Kornmesser/European Southern Observatory via AP

UFOs, UAPs and the search for extraterrestrial life has long been a fringe topic, shunned by most of mainstream academia, denied by the government and championed by enthusiastic but rather unusual individuals.

But sightings continue and public attitudes have begun to shift from mockery and toward cautious curiosity. Just last month, there was an unprecedented congressional hearing on UAPs, including sworn testimony from military members.

“I do think we are at a kind of tipping point in terms of lessening the stigma around this field of research,” Mead said. “We’re edging closer to the mainstream, as there’s more government transparency and more interest from the general public.”

The Galileo Project isn’t just looking for alien spacecraft or evidence of extraterrestrial technology on Earth. It’s also looking for interstellar objects, like Oumuamua, a mysteriously long and thin object first detected in our solar system in 2017. It was later discovered that Oumuamua is most likely a chunk of rock and ice set adrift from a planetary system somewhere else in the galaxy.

“We’re not going into this with any agenda, except to figure out what these objects are. If they are all weather balloons, fine. If they’re interstellar objects, great. If it’s from an extraterrestrial intelligence, well, we’d certainly want to know that,” said Mead. “These are unknown things, and we are putting scientific rigor to the process of trying to figure out just what they are.”",https://bdn-data.s3.amazonaws.com/uploads/2023/08/andrew-mead-uap-ufo-harvard-1.jpg,https://www.bangordailynews.com/2023/08/26/news/bangor/mainer-galileo-project-investigation-joam40zk0w/,Science
['Posted'],,CERN's Large Hadron Collider Makes Its First Observations of Neutrinos,"Physicists have observed neutrinos originating ""from the sun, cosmic rays, supernovae and other cosmic objects, as well as particle accelerators and nuclear reactors,"" writes Phys.org. But one remaining goal was observing neutrinos inside "" collider"" particle accelerators (which direct two particle beams).It's now been accomplished using neutrino detectors located at CERN's Large Hadron Collider (LHC) in Switzerland by two distinct research collaborations:- FASER (Forward Search Experiment)- SND (Scattering and Neutrino Detector)@LHCPhys.org argues the two achievements ""could open important new avenues for experimental particle physics research. """,https://a.fsdn.com/sd/topics/science_64.png,https://science.slashdot.org/story/23/08/27/210213/cerns-large-hadron-collider-makes-its-first-observations-of-neutrinos,Science
['Michelle Starr'],2023-08-26 21:00:42+00:00,A Hidden State Between Liquid And Solid May Have Been Found,"Glass might look and feel like a perfectly ordered solid, but up close its chaotic arrangement of particles more closely resemble the tumultuous mess of a freefalling liquid frozen in time.

Known as amorphous solids, materials in this state defy easy explanation. New research involving computation and simulation is yielding clues. In particular, it suggests that, somewhere in between liquid and solid states is a kind of rearrangement we didn't know existed.

According to scientists Dimitrios Fraggedakis, Muhammad Hasyim, and Kranthi Mandadapu of the University of California, Berkeley, there is a behavior on the temperature boundary of supercooled liquids and solids where the static particles remain excited, 'twitching' in place.

We're largely familiar with three fundamental states of matter in everyday life: solid, liquid, and gas, or vapor. Each is defined by the relationships between their particles and surrounds.

When one of these changes into another one – a solid melting into a liquid, or a liquid evaporating into a gas, for instance – this is known as a state transition.

But matter is quite a bit more complex than just those three basic states. Atoms can become so hot, for example, their charges fly apart to form a plasma. Cooled right down, some classes of particle can lose their identity altogether to blend into a quantum blur.

frameborder=""0″ allow=""accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"" allowfullscreen>

Amorphous solids are strange mixes of well-ordered solids and loosely-bound liquids. Where particles within solids tend to form predictable connections with their neighbors once they lock into place at suitably low temperatures, amorphic solids have the disordered arrangement of a liquid.

Just how these seemingly haphazard connections switch from viscous streams of flowing molecules to a static landscape is far from obvious.

Using glass as the most familiar example, its constituent elements of oxygen and silicon flow when heated. Cooled slowly, those particles have time to form into an ordered crystal structure called quartz. If it cools quickly, the particles somehow retain a disordered arrangement; this is the point at which it becomes an amorphous solid, and the temperature at which it occurs is the onset temperature.

Fraggedakis, Hasyim, and Mandadapu used computation and simulation, combined with the results of past experiments, to determine that this transition might not be so neat, featuring a special activity of particles sitting between their normal liquid and supercooled states.

""Our theory predicts the onset temperature measured in model systems and explains why the behavior of supercooled liquids around that temperature is reminiscent of solids even though their structure is the same as that of the liquid,"" Mandadapu explains.

""The onset temperature for glassy dynamics is like a melting temperature that 'melts' a supercooled liquid into a liquid. This should be relevant for all supercooled liquids or glassy systems.""

Although the overall flow of atoms in a supercooled liquid is effectively zilch, the particles are continuously changing their configurations while stuck in place, resulting in movements called excitations. The researchers treated these excitations in a 2D supercooled liquid as defects in a crystalline solid, and calculated what happens as the temperature changes.

They found that bound pairs of excitations become unbound at the onset temperature, causing the material to lose its rigidity and behave as a normal liquid.

The team believes that their model can be expanded to understand how the transition works in three dimensions, too, and offer a theoretical underpinning for future experimental work.

""The whole quest is to understand microscopically what separates the supercooled liquid and a high temperature liquid,"" Mandadapu says.

""It's fascinating from a basic science point of view to examine why these supercooled liquids exhibit remarkably different dynamics than the regular liquids that we know.""

The research has been published in the Proceedings of the National Academy of Sciences.",https://www.sciencealert.com/images/2023/08/hidden-phase-transition.jpg,https://www.sciencealert.com/a-hidden-state-between-liquid-and-solid-may-have-been-found,Science
"['Joshua Hawkins', 'José Adorno', 'Chris Smith']",2023-08-26 14:33:00+00:00,This 240-million-year-old giant amphibian was discovered by a chicken farmer,"In the 1990s, a chicken farmer discovered the 240-million-year-old fossil of a giant amphibian that researchers believe to be the ancestor of today’s Chinese giant salamander (pictured above). The retired farmer had obtained the rocks from a nearby quarry and intended to use them in building a garden retaining wall before eventually donating the rock and fossil to the Australian museum.

Tech. Entertainment. Science. Your inbox. Sign up for the most interesting tech & entertainment news out there. Email: SIGN UP By signing up, I agree to the Terms of Use and have reviewed the Privacy Notice.

Now, after almost two decades, researchers have finally given the fossil of this giant amphibian and the species responsible for it a name. Arenaerpeton supinatus, which means ‘supine sand creeper,’ is believed to have existed during the Triassic period, 240 million years ago. As such, the exact age of the fossil is unclear.

Part of what makes this particular fossil so exciting is that it gives us a nearly complete view of the entire skeleton of the Arenaerpeton supinatus. “We don’t often find skeletons with the head and body still attached, and the soft tissue preservation is an even rarer occurrence,” Lachlan Hart, a PhD candidate in the School of Biological, Earth and Environmental Sciences at UNSW said in a statement.

The researchers say that the fossil makes the giant amphibian look very similar to its modern-day descendants, the Chinese giant salamander. The Arenaerpeton also looks like it had very sharp teeth, including fang-like tusks that sit on the roof of its mouth. It likely used these fangs to hunt for ancient fish. Researchers at the University of South Wales continue to investigate the giant amphibian to try to learn more about it.

In the meantime, this is one of the most important fossils that has been discovered in New South Wales within the last 30 years or so, according to Dr. Matthew Curry, Senior Lecturer in UNSW’s School of BEES and Curator of Palaeontology at the Australian Museum. Fossils like this, and even those fossilized footprints from before dinosaurs existed, help teach us more about our world’s past.",https://bgr.com/wp-content/uploads/2023/08/AdobeStock_551166285.jpeg?quality=82&strip=all,https://bgr.com/science/this-240-million-year-old-giant-amphibian-was-discovered-by-a-chicken-farmer/,Science
[],2023-08-27 12:48:32-07:00,"This Week @NASA: Webb Captures a Cosmic Ring, Giant Black Hole Destroys a Massive Star","NASA’s Webb Space Telescope captures a cosmic ring …

The team behind NASA’s upcoming Psyche mission …

And the unique thing about a star that was ripped apart by a black hole …

A few of the stories to tell you about – This Week at NASA!

Webb Observes Ring Nebula in Unprecedented Detail

NASA’s James Webb Space Telescope has observed the Ring Nebula in unprecedented detail. Formed by a dying star throwing off its outer layers as it runs out of fuel, the Ring Nebula is one of the best-known examples of a planetary nebula. It is relatively close to Earth at roughly 2,200 light-years away.



Meet some of the engineers who helped build NASA’s Psyche mission, which is set to launch in October on a journey of 2.2 billion miles (3.6 billion kilometers) to a metal-rich asteroid of the same name. Credit: NASA

Video Series Highlights Psyche Mission Team

NASA’s Psyche spacecraft is targeted for launch no earlier than October 5 to a metal-rich asteroid, also named Psyche. A new video series called, “Behind the Spacecraft” highlights several members of the Psyche team and their contributions to the mission. The videos are being released on several of NASA’s Jet Propulsion Laboratory’s social media platforms. The mission could help answer fundamental questions about how rocky planets like Earth formed, and about the formation of our solar system.

A Giant Black Hole Destroys a Massive Star

Astronomers used NASA’s Chandra X-ray Observatory and ESA’s XMM-Newton to study material believed to be from a star that was ripped apart by a giant black hole – an event being called ASASSN-14li. The relative amount of nitrogen to carbon astronomers found indicates that the material weighs about three times the mass of our Sun – which would make the star in ASASSN-14li one of the most massive ever seen ripped apart by a black hole to date.

Integrating the Roman Space Telescope’s Nervous System

The Nancy Grace Roman Space Telescope team has begun integrating and testing the spacecraft’s harness – the electrical cabling that functions as the telescope’s nervous system. The harness provides power and commands to Roman’s instruments, enables different parts of the telescope to communicate with one another, and helps the central computer monitor the telescope’s functions. Roman will survey billions of cosmic objects and help untangle mysteries like dark energy following its launch by May 2027.

That’s what’s up this week @NASA!",https://scitechdaily.com/images/Ring-Nebula-Webb-NIRCam-Image.jpg,https://scitechdaily.com/this-week-nasa-webb-captures-a-cosmic-ring-giant-black-hole-destroys-a-massive-star/,Science
"['Maya Posch', 'Gregg Eshelman', 'Saywhat']",2023-08-27 00:00:00,When Does Impedance Matching A PCB Trace Become Unavoidable?,"A common joke in electronics is that every piece of wire and PCB trace is an antenna, with the only difference being whether this was intentional or not. In practical terms, low-frequency wiring is generally considered to be ‘safe’, while higher frequency circuits require special considerations, including impedance (Z) matching. Where the cut-off is between these two types of circuits is not entirely clear, however, with various rules-of-thumb in existence, as [Sebastian] over at Baltic Lab explains.

A popular rule is that no impedance matching between the trace and load is necessary if the critical length of a PCB trace (l crit ) is 1/10th of the wavelength (λ). Yet is this rule of thumb correct? Running through a number of calculations it’s obvious that the only case where the length of the PCB trace doesn’t matter is when trace and load impedance are matched.

According to these calculations, the 1/10 rule is not a great pick if your target is a mismatch loss of less than 0.1 dB, with 1/16 being a better rule. Making traces wider on the PCB can be advisable here, but ultimately you have to know what is best for your design, as each project has its own requirements. Even when the calculations look good, that’s no excuse to skip the measurement on the physical board, especially with how variable the dielectric constant of FR4 PCB material can be between different manufacturers and batches.

Heading image: Input impedance plotted as a function of trace impedance for trace lengths of 1/10, 1/16, and 1/20 of a wavelength. (Credit: Baltic Labs)",https://hackaday.com/wp-content/uploads/2023/08/PCB_Trace_Length_Impact_Trace_Impedance.png,https://hackaday.com/2023/08/27/when-does-impedance-matching-a-pcb-trace-become-unavoidable/,Science
"['Joe Wertz', 'Colorado Public Radio']",,Strange lights in the sky reported by pilots around eastern Colorado,"×

Pilots on different routes that crossed the state Thursday night reported seeing strange lights in the sky above eastern Colorado, audio recordings of air traffic communications show.

One pilot of a Southwest flight traveling from Phoenix to Minneapolis told air traffic controllers around 11 p.m., he saw bright lights appear, move from left to right and disappear in the sky outside the plane.

The pilot of a United plane headed from New York to Las Vegas confirmed the sighting to controllers at the Denver Air Route Traffic Control Center, which manages flights in a region that includes eastern Colorado, western Kansas and southern Nebraska.

The Southwest pilot told controllers he saw the lights appear and disappear in the sky near the Big Dipper constellation. In another radio dispatch, which CPR News was alerted to by Daryl Orr, a storm-chaser who lives in Cheyenne, Wyoming, the pilot told controllers the lights were white with a greenish tint.

“Now there’s two or three different lights, but they all disappear after about 15 seconds,” the pilot said.

An air traffic controller later sent out a radio alert to all pilots in the area that they’d received five reports with the same description.

“All the aircraft that have seen it have said it was by the Big Dipper,” the controller radioed.

The lights did not cause any disruption in air travel.

CPR reviewed radio traffic between air traffic controllers and pilots recorded and archived by LiveATC.net.

In another conversation with controllers, one pilot suggested the lights might be related to Starlink, the satellite internet company operated by Elon Musk. Starlink satellites are often visible from the ground and can appear as flickering orbs of light as they cross the sky.

Officials with the Federal Aviation Administration and representatives from Southwest Airlines and United Airlines did not respond to requests for comment. A spokesperson for Denver International Airport said they had not received any reports of strange lights.

CPR News also asked officials with the National UFO Reporting Center if they had received any reports in the area but did not receive a reply before publication.

To read more stories from Colorado Public Radio, visit To read more stories from Colorado Public Radio, visit www.cpr.org.",https://imengine.public.prod.dur.navigacloud.com/?uuid=ac17ecfa-238c-563e-960d-9ee3d7bd2b76&function=fit&type=preview,https://www.durangoherald.com/articles/strange-lights-in-the-sky-reported-by-pilots-around-eastern-colorado/,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
['Loukia Papadopoulos'],2023-08-26 20:09:59+00:00,Artemis Moon tree seedlings to be planted throughout the US,"NASA and the USDA Forest Service have joined forces to supply education and community organizations throughout the United States with “a living piece of spaceflight history” in the shape of “a seedling grown from a tree seed that flew around the Moon on NASA's Artemis I mission.”

This is according to a press release by the space agency published on Thursday.

The initiative is meant to promote interest in the fields of science, technology, engineering, and mathematics (STEM).

The Artemis Moon tree seedlings consist of five different species, sycamores, sweetgums, Douglas-firs, loblolly pines, and giant sequoias, and come from seeds that traveled 270,000 miles from Earth aboard the Orion spacecraft during Artemis I in late 2022. It is estimated that nearly 2,000 seeds were flown aboard the craft and will soon be planted on Earth throughout the United States.",https://dnd2oi6izkvoi.cloudfront.net/2023/08/26/image/jpeg/UCGYyTFKImpWqnxJTnarCGhDS76dCoLafLggpb2G.jpg,https://interestingengineering.com/science/artemis-moon-tree-seedlings-to-be-planted-throughout-the-us,Science
['Keith Cowing'],2023-08-26 23:18:39+00:00,"NASA, Forest Service to Share Moon Tree Seedlings, Promote STEM","Artemis 1 Moon Trees NASA

Education and community organizations can apply to receive a living piece of spaceflight history to promote science, technology, engineering, and mathematics: a seedling grown from a tree seed that flew around the Moon on the NASA’s Artemis I mission in late 2022.

NASA and the USDA Forest Service will distribute Artemis Moon Tree seedlings of five different species to create new ways for communities on Earth to connect with humanity’s exploration of space for the benefit of all. Nearly 2,000 seeds were flown to space.

Organizations like schools, libraries, museums, and others engaging with students, or the public, are encouraged to apply for a Moon Tree seedling through NASA’s Artifact Module. The application period closes Friday, Oct. 6.

Examples of eligible institutions include formal and informal K-12-serving organizations, universities, community organizations, museums and science centers, and government organizations.

“NASA’s Artemis moon trees are bringing the science and ingenuity of space exploration back down to Earth,” said NASA Administrator Bill Nelson. “Last year, these seeds flew on the Artemis I mission 40,000 miles beyond the Moon. With the help of the USDA, this new generation of Moon trees will plant the spirit of exploration across our communities and inspire the next generation of explorers.”

This is the second generation of Moon Trees for distribution on Earth. In 1971, Apollo 14 Command Module Pilot Stuart Roosa, a former Forest Service smoke jumper, carried hundreds of tree seeds as a part of his personal kit. Following the successful return of Apollo 14, the Forest Service germinated the seeds. The Apollo Moon Tree seedlings were planted around the nation, many as part of the U.S. bicentennial celebration in 1976.

Today, a new generation of Moon Trees will soon take root in American soil and carry on the legacy of inspiration launched more than 50 years ago. The seeds that journeyed 270,000 miles from Earth aboard the Orion spacecraft during Artemis I included sycamores, sweetgums, Douglas-firs, loblolly pines, and giant sequoias. Through the care of the Forest Service, the seeds were germinated and grown into seedlings in preparation for their new roles as Artemis Moon Trees.

“The seeds that flew on the Artemis mission will soon be Moon Trees standing proudly on campuses and institutions across the country,” said Randy Moore, Forest Service chief. “These future Moon Trees, like those that came before them, serve as a potent symbol that when we put our mind to a task, there is nothing we can’t accomplish. They will inspire future generations of scientists, whose research underpins all that we do here at the Forest Service.”

How to Apply

Instructions for submitting a proposal, and information on Moon Tree seedling criteria, is available online. NASA and USDA Forest Service will review submitted applications to determine the viability to successfully host a seedling; the Forest Service will identify the seedling species for selected recipients based on geographical region in the contiguous United States. NASA is working with the Forest Service to identify timelines for seedling distribution in 2023 and 2024.

This opportunity is made possible through a collaboration between NASA’s Next Gen STEM project and the Forest Service. Through NASA’s Office of STEM Engagement, Next Gen STEM provides resources and opportunities designed to bring STEM and space content to formal and informal K-12 e ducators and students. Through Forest Service Environmental Education programs, people develop the knowledge and critical thinking skills needed to understand complex environmental issues.

For the latest NASA STEM events, activities, and news, visit: https://stem.nasa.gov",https://media2.spaceref.com/wp-content/uploads/2023/08/26191807/moontrees.jpg,https://spaceref.com/newspace-and-tech/nasa-forest-service-to-share-moon-tree-seedlings-promote-stem/,Science
"['Laura Baisas', 'Laura Is A Science News Writer', 'Covering A Wide Variety Of Subjects', 'But She Is Particularly Fascinated All Things Aquatic', 'Paleontology', 'Nanotechnology', 'Exploring How Science Influences Daily Life. Laura Is A Proud Former Resident Of The New Jersey Shore', 'A Competitive Swimmer', 'A Fierce Defender Of The Oxford Comma.']",2023-08-25 11:15:00-04:00,How to get NASA moon seeds for your community park,"In 2022, NASA’s Artemis I mission traveled 1.4 million miles into space. When the Orion spacecraft flew by the moon, future trees were on board. The uncrewed spacecraft contained seeds for five tree species, including sweetgums, Douglas-firs, sycamores, loblolly pines, and giant sequoias. After the 25.5 day mission, the Forest Service successfully germinated the seeds. Now, community organizations and schools across the United States now apply to receive a seedling grown from one of the tree seeds that flew by the moon that will grow to become official Artemis Moon Trees.

[Related: Artemis I’s solar panels harvested a lot more energy than expected.]

NASA and the United States Department of Agriculture Forest Service will distribute the Artemis Moon Tree seedlings in an effort to “create new ways for communities home on Earth to connect with humanity’s exploration of space for the benefit of all” and promote STEM in the classroom and beyond.

Institutions that can apply for a seedling include universities, museums, science centers, organizations that serve K-12 schools, and government organizations. Applications are posted here and are due by Friday October 6.

Seeds for five tree species that flew on the Artemis I mission. CREDIT: NASA/USDA Forest Service.



The Artemis I Mission launched on November 16, 2022 and was the first integrated test of NASA’s latest deep space exploration technology: the Orion spacecraft itself, the all-powerful Space Launch System rocket, and the ground systems at Kennedy Space Center. Orion returned to Earth after 25.5 days in space, where it journeyed 270,000 miles away from Earth, orbited the moon, and collected crucial data along the way. A plush Snoopy zero-gravity indicator, LEGO minifigures, and three ‘moonikins,’ were also aboard the spacecraft with the Artemis seeds.

“NASA’s Artemis moon trees are bringing the science and ingenuity of space exploration back down to Earth,” NASA Administrator Bill Nelson said in a statement. “Last year, these seeds flew on the Artemis I mission 40,000 miles beyond the Moon. With the help of the USDA, this new generation of Moon trees will plant the spirit of exploration across our communities and inspire the next generation of explorers.”

[Related: Before the Artemis II crew can go to the moon, they need to master flying high above Earth.]

The Artemis seeds are also the second generation of Moon Trees. In 1971, Apollo 14 Command Module Pilot Stuart Roosa, carried hundreds of tree seeds about the mission as a part of his personal kit. Roosa was a former Forest Service smokejumper, a group of specially trained wildland firefighters who are often the first to respond to remote firefighters. When Apollo 14 returned, the Forest Service germinated the seeds and the first generation of Apollo Moon Tree seedlings were then planted around the United States.

NASA and the Forest Service hope that this next 21st Century generation of Moon Trees carry on the legacy of inspiration launched over 50 years ago.

“The seeds that flew on the Artemis mission will soon be Moon Trees standing proudly on campuses and institutions across the country,” Forest Service chief Randy Moore said in a statement. “These future Moon Trees, like those that came before them, serve as a potent symbol that when we put our mind to a task, there is nothing we can’t accomplish. They will inspire future generations of scientists, whose research underpins all that we do here at the Forest Service.”",https://www.popsci.com/uploads/2023/08/25/artemis-1-orion-moon.jpg?auto=webp,https://www.popsci.com/science/moon-trees-artemis-1/,Science
['University Of Bath'],2023-08-27 18:38:50-07:00,Scientists Discover New “Primitive Cousins of T. Rex” – Finding Sheds Light on the End of the Age of Dinosaurs in Africa,"Scientists in Morocco have uncovered fossils of primitive cousins of T. rex that had short, bulldog snouts and even shorter arms have been discovered by scientists in Morocco. These two newly identified dinosaur species are members of the Abelisauridae family, which were the carnivorous counterparts to the Northern Hemisphere’s tyrannosaurs. Existing during the final stages of the Cretaceous period, these discoveries underscore the rich diversity of dinosaurs in Africa right before an asteroid led to their widespread extinction 66 million years ago.

Two new species of dinosaur have been found from the end of the Cretaceous in Morocco, just outside of Casablanca. One species, found near the town of Sidi Daoui, is represented by a foot bone from a predator about two and a half meters (eight feet) long. The other, from nearby Sidi Chennane, is the shin bone of a carnivore that grew to around five meters (15 feet) in length.

Both were part of a family of primitive carnivorous dinosaurs known as abelisaurs and lived alongside the much larger abelisaur Chenanisaurus barbaricus, showing that Morocco was home to diverse dinosaur species just before a giant asteroid struck at the end of the Cretaceous, ending the age of dinosaurs.

Dr Nick Longrich, from the Milner Centre for Evolution at the University of Bath, led the study. He said: “What’s surprising here is that these are marine beds.

“It’s a shallow, tropical sea full of plesiosaurs, mosasaurs, and sharks. It’s not exactly a place you’d expect to find a lot of dinosaurs. But we’re finding them.”

Even though dinosaurs account for a small proportion of the fossils, the region is so rich in fossils, it has produced the best picture of African dinosaurs from the end of the age of dinosaurs. Rather than finding the same few species, paleontologists often recover fossils from new species, suggesting the beds host an extremely diverse dinosaur fauna.

So far, the small number of dinosaur fossils that have been recovered represent five different species – a small duckbill dinosaur named Ajnabia, a long-necked titanosaur, the giant abelisaur Chenanisaurus, and now the two new abelisaurs.

Dr Longrich said: “We have other fossils as well, but they’re currently under study. So we can’t say much about them at the moment, except that this was an amazingly diverse dinosaur fauna.”

The last dinosaurs vanished around 66 million years ago, along with as much as 90% of all species on earth, including mosasaurs, plesiosaurs, pterosaurs and ammonites. The pattern of the end-Cretaceous extinction and its causes have been debated for over two hundred years. A giant asteroid impact in the Yucatan peninsula has been linked to their demise, although it’s been argued that dinosaurs were already in decline. The Moroccan dinosaurs suggest that they thrived in North Africa up to the very end.

“The end of the Cretaceous in western North America definitely seems to become less diverse at the end,” said Longrich. “But that’s just one small part of the world. It’s not clear that you can generalize from the dinosaurs of Wyoming and Montana to the whole world.

“It also grew colder near the end, so it might not be surprising if dinosaurs at higher latitudes became less diverse. But we don’t know much about dinosaurs from lower latitudes.”

In Morocco at least, they seem to have remained diverse and successful up until the end.

“When T. rex reigned as a mega predator in North America, abelisaurs sat at the top of the food chains in North Africa,” said Nour-Eddine Jalil, a professor at the Natural History Museum and a researcher at Universite Cadi Ayyad in Morocco, who was a co-author on the paper.

“The dinosaur remains, despite their rarity, give the same messages as the more abundant marine reptile remains.

“They tell us that, just before the Cretaceous-Paleogene crisis, biodiversity was not declining but on the contrary, was diverse.”

Reference: “New fossils of Abelisauridae (Dinosauria: Theropoda) from the upper Maastrichtian of Morocco, North Africa” by Nicholas R. Longrich, Erik Isasmendi, Xabier Pereda-Suberbiola and Nour-Eddine Jalil, 22 August 2023, Cretaceous Research.

DOI: 10.1016/j.cretres.2023.105677",https://scitechdaily.com/images/Abelisaurs-scaled.jpg,https://scitechdaily.com/scientists-discover-new-primitive-cousins-of-t-rex-finding-sheds-light-on-the-end-of-the-age-of-dinosaurs-in-africa/,Science
['German Primate Center'],2023-08-26 06:22:54-07:00,Debunking the Myth: The Human Adolescent Growth Spurt Isn’t Unique After All,"Growth spurts during puberty are not unique in evolutionary terms.

Up to this point, it has been widely agreed that the growth spurt in body length during human adolescence is a unique evolutionary feature not present in other primates. However, a recent study published in the journal eLife indicates that many primate species, including humans, actually experience a growth spurt in body weight during adolescence. The study suggests that the discrepancy may arise from methodological issues.

Mind the scale…

In their scientific work, the researchers used three approaches: They first outlined how scaling problems and incorrect comparisons between growth rates of body length (linear) and weight (volume) can lead to misleading interpretations, effectively comparing apples to oranges.

… leads to correct results

Subsequently, the research team applied a scale-corrected approach to an extensive dataset of 258 zoo-living bonobos. These data included weight and length growth, as well as several physiological markers related to growth and puberty. “We found pronounced growth spurts in body weight and body length in both sexes.

Weight and length growth curves corresponded with each other and with patterns of testosterone and IGFBP-3 levels that resemble adolescent hormone surges in humans,” says first author Andreas Berghänel from the Konrad Lorenz Institute of Ethology (KLIVV) at the University of Veterinary Medicine about the results.

Re-interpretation of studies provides different insights

In a third step, data published in other studies on non-human primates were reinterpreted. The results showed that adolescent growth spurt in weight and length occurs not only in bonobos but very likely also in other monkeys.

“Our results underline the importance of taking scaling laws into account when interpreting growth curves in general,” summarizes Verena Behringer, a scientist in the Endocrinology Laboratory at the German Primate Center and senior author of the publication. “Furthermore, our data show that pronounced, human-like adolescent growth spurts in body weight and body length exist not only in bonobos but probably also in many other non-human primates.”

Reference: “Adolescent length growth spurts in bonobos and other primates: Mind the scale” by Andreas Berghänel, Jeroen M.G. Stevens, Gottfried Hohmann, Tobias Deschner and Verena Behringer, 29 June 2023, eLife.

DOI: 10.7554/eLife.86635.1

The study was conducted in cooperation with researchers from Odisee University of Applied Sciences, Antwerp Zoo Centre for Research and Conservation, the Antwerp University, the Max Planck Institutes for Evolutionary Anthropology and for Animal Behaviour, and the Institute of Cognitive Science at the University of Osnabrück. In addition, 19 zoos provided their data and contributed significantly to the success of the study.",https://scitechdaily.com/images/Bonobo-Mother-With-an-Infant-scaled.jpg,https://scitechdaily.com/debunking-the-myth-the-human-adolescent-growth-spurt-isnt-unique-after-all/,Science
['Brian Koberlein'],2023-08-26 15:35:51+00:00,Pulsars Detected the Background Gravitational Hum of the Universe. Now Can They Detect Single Mergers?,"Current gravitational wave observatories have two significant limitations. The first is that they can only observe powerful gravitational bursts such as the mergers of black holes and neutron stars. The second is that they can only observe these mergers for wavelengths on the order of hundreds to thousands of kilometers. This means we can only observe stellar mass mergers. Of course, there’s a lot of interesting gravitational astronomy going on at other wavelengths and noise levels, which has motivated astronomers to get clever. One of these clever ideas is to use pulsars as a telescope.

The concept is known as a pulsar timing array (PTA). Pulsars are rotating neutron stars with a strong magnetic field aligned in such a way that it sweeps a burst of radio energy toward Earth with each rotation. We see them as a very regular radio flash. Some pulsars, known as millisecond pulsars, rotate so quickly that they emit hundreds of radio pulses a second. Since the rotation of a neutron star is almost as regular as clockwork, pulsars can be used as a kind of cosmic timepiece.

Because of this, if a pulsar moves in any way, such as orbiting a star, the relative motion of the pulsar causes the pulses to shift slightly. We can measure these shifts with extreme accuracy. Our observations are so precise pulsars were used to measure the orbital decay of binary systems as indirect evidence of gravitational waves long before we could observe them directly.

Even when pulsars aren’t part of a binary system, small gravitational tugs cause them to shift slightly. So when a gravitational wave passes through them, their pulses will shift by a tiny amount. These shifts are essentially at the random fluctuation level of the pulses themselves, so we can’t see the gravitational wave effect from a single pulsar. We need observations of lots of pulsars to see the statistical fluctuations. Hence, we need an array of pulsar timings.

Multiple pulsars can pinpoint the source of gravitational waves. Credit: Kato & Takahashi

Earlier this year astronomers from the NANOGrav used an array of 67 pulsars with 15 years of data and were able to measure the background gravitational rumble of the Universe. The likely sources of this background are supermassive binary black holes (SMBHs), but the results weren’t entirely conclusive. One problem with the data is that while the team could measure the gravitational waves, they couldn’t pinpoint the point of origin for them.

There are several ongoing PTA projects, meaning that we will soon have a wealth of observational data. In a new study, a team proposes how this data could be used to pinpoint the sources of background gravitational waves. Their idea focuses on making precise distance measurements of the pulsars in an array. At the moment, while we know the distance to some pulsars very accurately, the distance of many pulsars is fuzzy. Detailed observations of PTA pulsars through observatories such as the Very Long Baseline Array could give us the precision we need. Knowing both the distance and the timing variation of a pulsar would give us a range for the source. With an array of pulsars, ranges would overlap to triangulate the source.

As the paper shows, a good level of accuracy could be obtained with a PTA of only a dozen pulsars. This initial study only focused on a 2-dimensional array, but a more 3D array should also be reasonably accurate. Certainly accurate enough to prove whether these background waves come from supermassive binary black holes, or something we don’t yet fully understand.

Reference: Kato, Ryo, and Keitaro Takahashi. “Precision of localization of single gravitational-wave source with pulsar timing array.” arXiv preprint arXiv:2308.10419 (2023).",https://www.universetoday.com/wp-content/uploads/2023/08/pta.jpg,https://www.universetoday.com/162925/pulsars-detected-the-background-gravitational-hum-of-the-universe-now-can-they-detect-single-mergers/,Science
[],,New Moon map reveals structures hidden beneath the lunar surface,"Scientists have used recordings from a first-of-its-kind rover to create a new moon map that reveals structures hidden deep beneath the lunar surface.

The background: In 2019, China made history as the first nation to soft land a spacecraft on the far side of the Moon, giving the world its first up-close look at the moon’s more rugged hemisphere.

Though the mission was only expected to last a year, the lander and its rover — Chang’e 4 and Yutu-2, respectively — are still going strong, recording new data and collecting lunar samples for future analysis.

The new Moon map reveals the first 1,000 feet below the lunar surface.

What’s new? In 2020, researchers used recordings from Yutu-2’s Lunar Penetrating Radar (LPR) — an instrument that sends radio signals into the moon and then records the echoes that come back — to map the first 130 feet below the Moon’s surface.

Now, an international team led by researchers at the Planetary Science Institute in Arizona has used Yutu-2’s LPR recordings to create a new Moon map that reveals the first 1,000 feet below the lunar surface in an area near the south pole.

The discoveries: Lead study author Jianqing Feng told Live Science the team found evidence of a crater in the top 130 feet of the Moon, along with layers of dust and broken rock they believe were ejected at the time of impact.

Farther down, the new Moon map depicts five layers of volcanic rock. According to the researchers, these likely formed billions of years ago when asteroids or comets hit and cracked the Moon’s surface, causing volcanic eruptions.

“[The Moon] was slowly cooling down and running out of steam.” JIANQING FENG

The fact that layers closer to the surface were thinner than ones farther down suggests that less lava was released during more recent eruptions.

“[The Moon] was slowly cooling down and running out of steam in its later volcanic stage,” Feng told Live Science. “Its energy became weak over time.”

Why it matters: Experts believe the Moon has been orbiting the Earth since soon after our planet formed, so the more we can learn about its history, the better our understanding of the conditions that caused our planet to become what it is today.

That information could help in the hunt for other planets like ours — including ones hospitable to life.

This article was originally published by our sister site, Freethink.","https://bigthink.com/wp-content/uploads/2023/08/moon-map.jpg?resize=1200,630",https://www.freethink.com/space/moon-map,Science
[],2023-08-26 12:00:00+00:00,Aerobic Exercises for Seniors: 10 Minutes to Kicked Up Cardio,"Running will help you stay active as you age, but when you’re out clocking miles, your body is consistently working in the sagittal plane (as in, moving forward). This limits your range of motion in other planes of movement, which can restrict your overall mobility in the long-term. Without exercises that get you moving in new ways and building strength, you also risk injury.

This is precisely why you need to an aerobic workout designed for seniors, like the one below, that gets you out of your comfort zone, elevates your heart rate, and helps you stay nimble and strong on and off the road.

Related Story 20-Minute Bodyweight Workout to Boost Your Cardio

The Benefits of an Aerobic Workout for Senior Runners

As you get older, it’s important to maintain your running routine and stay active throughout the day, as research shows exercise can help you maintain bone health, prevent hospitalizations, and help you live longer.

Plus, with a quick aerobic workout like this that includes multi-plane exercises, you challenge your balance, enhance your strength, and increase your aerobic capacity—all important fitness factors for masters athletes.

“With these exercises you’ll move through multiple planes, which will expand your range of motion and allow you to go through your day-to-day activities feeling strong and confident,” says Amber Rees, chief curriculum lead at Barry’s in New York City and cofounder of the Brave Body Project, and creator of this workout. Consider this workout an all-inclusive approach to targeting muscles that you use in your daily life, she adds.

More specifically, this routine includes two different squat variations—and the squat is a traditional exercise known for building strength in your lower body, while improving mobility at the hip, knee, and ankle. Because squats strengthen your hips, glutes, quads, and hamstrings, they can also help to reduce back and joint pain, Rees says.

The fast pace of the side-step jack, side step to knee raise, and standing knee drive included here also get you to work at a high intensity, while kicking up the heart rate to help improve your cardio endurance. Even better: All of these exercises are low-impact, offering a break for your joints (and making the moves a great complement to running!), while you get your blood pumping and reap some wellness gains like an energy and mood boost, says Rees.

Related Story A Senior’s Guide to Running Recovery

How to use this list: On a rate of perceived exertion (RPE) scale of 1-10, with 10 being your all-out effort, practice this routine at a 5 to 7 intensity.

Perform each exercise in the order listed below for 40 seconds each and rest for 20 seconds in between each exercise. Complete 2 rounds of this list, resting for 60 seconds in between rounds.

Rees demonstrates the exercises so you can learn proper form. You don’t need any equipment, but an exercise mat is optional.

1. Squat

Amber Rees

Why it works: Squats—one of the most functional exercises, as you perform it every time you sit down and stand up—target your hips, glutes, quads, and hamstrings, which you need strong for your runs and everyday life.

How to do it: Stand with feet slightly wider than hip-width apart, toes slightly pointed out, and arms down by sides. Send hips back and down, bending knees to lower into a squat, and lift arms in front of you. Press feet into ground to stand back up and bring arms down by sides. Repeat.

2. Side-Step Jack

Amber Rees

Why it works: This modification of the jumping jack gets you moving in a frontal plane (side to side), without adding impact.

How to do it: Stand with feet together and arms down by sides. Step to the left while simultaneously bringing arms to shoulder height and cross left hand over right hand. Return left foot to center, then step out with right foot while simultaneously crossing right hand over left. Return right foot to center. Continue alternating.

3. Side Step to Knee Raise

Amber Rees

Why it works: Practicing this exercise will improve your coordination and balance, while also improving knee drive.

How to do it: Stand with feet together and arms at sides, elbows bent. Take three to four steps to the left, starting with left foot then right, while swinging arms back and forth in opposite directions. On the last step, drive the right knee up to hip height. Repeat moving to the right, and driving left knee up to hip height on the last step. Continue alternating.

4. Knee Drive

Amber Rees

Why it works: This exercise will help you improve single-leg stability while also strengthening your legs and glutes.

How to do it: Start with both arms above head, hands together, left leg bent and right leg extend out behind you. Drive right knee to chest while bringing hands down to tap right thigh. Then drive right foot back to tap the ground. Repeat for 20 seconds then switch to the other side.

5. Squat With Knee Raise

Amber Rees

Why it works: This exercise will challenge your balance, while building strength in your lower body.

How to do it: Stand with feet hip-width apart, and arms down by sides. Send hips back and down, bending knees to lower into a squat, and bring arms in front of you. Press feet into ground to stand back up, then shift weight to right leg and bend left knee to raise knee to hip height, balancing on right leg. Step left knee back down and repeat the squat. This time, perform the knee raise on the right side. Continue alternating as you perform the squat.

","https://hips.hearstapps.com/hmg-prod/images/squats-64e764afa7fab.jpeg?crop=0.819xw:0.611xh;0.0769xw,0.325xh&resize=1200:*",https://www.runnersworld.com/training/a44892539/aerobic-exercise-for-seniors/,Science
['University Of Birmingham'],2023-08-27 16:07:02-07:00,“Great Cut” Unveiled – Mississippi Mud Reveals Secrets of Antarctica’s Ancient Expansion,"Clues regarding the development of massive ice layers in Antarctica have been uncovered in mud samples taken from Mississippi, shedding light on a major climate cooling event often referred to as the Grande Coupure or “great cut.”

A recent study in Nature Communications, led by researchers from the University of Birmingham, examined material taken from cores drilled near Jackson, Mississippi in the USA.

Material found in layers of the cores suggests that there was a major transfer of carbon from plant remains in coastal environments into the atmosphere, driven by sea level falls of around 40 meters as Antarctic ice caps formed.

While the initial formation of those ice caps, and the beginning of the modern, colder climate of the past 34 million years was due to long-term burial, or sequestering of carbon in sediments; the team found that the falling sea levels led to a 300,000-year break on climate cooling.

Falling seas exposed coastal regions and their soft sediments to intense erosion by rain and rivers. Organic carbon, such as plant material, that was once bound up in these sediments and environments – think of today’s tropical mangrove swamps – was then exposed to oxygen in the air and was available for bacteria to eat and convert back into carbon dioxide that can be released to the atmosphere.

Dr. Tom Dunkley Jones from the University of Birmingham is the senior author of the paper, and said:

“We’ve unearthed information from the Mississippi mud to answer a key question about how Antarctic ice massively expanded to continental scale.

“The Eocene Oligocene transition is probably the planet’s biggest climate cooling event and has had a major impact on the earth’s history. As sea levels fell over this transition, we can observe how a temporary brake on atmospheric cooling took place with the release of large amounts of carbon dioxide sequestered in coastal regions around the basin of the Mississippi River.

“This solves a puzzle about the timeline of the transition and suggests that the beginnings of this event and the build-up of Antarctic ice sheets started some 300,000 years earlier. Once the brake of organic carbon was used up, the transition was freed to continue its move to the colder state of the past 34 million years.”

The research team studied samples from marine clays covering a depth of around 137m – and compared these to other key records of this event, especially from the middle of the Pacific Ocean. The team were able to use the data from the new samples to fill in gaps in the geological record, showing how sediments deposited in the area changed over time, and providing more precise timings for the sea level fall which signaled the formation of the ice sheets.

Dr Kirsty Edgar, the University of Birmingham said:

“Our paper gives us a valuable new clue about how Earth’s climate can undergo dramatic shifts and how this is often strongly linked to the biosphere and carbon cycle.

“Understanding these past events gives us a clearer picture of the beauty and complexity of the Earth’s climate and ecology.”

Reference: “Multi-proxy evidence for sea level fall at the onset of the Eocene-Oligocene transition” by Marcelo A. De Lira Mota, Tom Dunkley Jones, Nursufiah Sulaiman, Kirsty M. Edgar, Tatsuhiko Yamaguchi, Melanie J. Leng, Markus Adloff, Sarah E. Greene, Richard Norris, Bridget Warren, Grace Duffy, Jennifer Farrant, Masafumi Murayama, Jonathan Hall and James Bendle, 8 August 2023, Nature Communications.

DOI: 10.1038/s41467-023-39806-6",https://scitechdaily.com/images/Colorful-Sunset-Antarctica.jpg,https://scitechdaily.com/great-cut-unveiled-mississippi-mud-reveals-secrets-of-antarcticas-ancient-expansion/,Science
['Thamarasee Jeewandara'],,Bioactive near-infrared II clusters for 3D imaging and acute inflammation inhibition,"This article has been reviewed according to Science X's editorial process and policies . Editors have highlighted the following attributes while ensuring the content's credibility:

Schematic diagram of the properties and biomedical applications of Au22 clusters. We introduced Cu single-atom active sites to the atomic-precision Au22 clusters having strong NIR-II fluorescence. This atom engineering procedure reduces the bandgap from 1.33 to 1.28 eV via contributions of Cu s and p states, and Cu atom with lost electron states contributes to potent enzyme-mimicking activities. Consequently, the bioactive NIR-II clusters exhibit good capacities for highly accurate monitoring of cisplatin-induced kidney injury and inhibition of oxidative stress and inflammation in multiple organs of the cisplatin-treated mouse model, particularly in the kidneys and brain. Credit: Science Advances, doi: 10.1126/sciadv.adh7828

The bioactivity of most near-infrared II (NIRII) fluorophores are limited, thereby conflicting the achievement of strong fluorescence and high catalytic activities, due to a lack of free electrons in the method.

To overcome this challenge, Huizhen Ma and a research team in translational medicine, neural engineering, physics, and materials at the Tianjin University China developed atomically precise gold clusters with strong near-infrared II fluorescence to show potent enzyme-mimetic activities by using atomic engineering, to form active copper single-atom sites.

These gold-copper clusters (Au 21 Cu 1 ) showed higher antioxidant nature with a 90-fold catalase-like and 3-fold higher superoxide dismutase-like activity compared to gold clusters alone. These clusters can be cleared through the kidney to monitor cisplatin-induced renal injury within a 20–120-minute window to visualize the process in 3D via near-infrared light-sheet microscopy.

The clusters prevented oxidative stress and inflammation in the kidney and the brain in a mouse model, which occurred as side-effects when treated with the anticancer drug cisplatin. The research is published in the journal Science Advances.

Monitoring the pathological evolution of oxidative-stress and inflammation in real-time

The method of near-infrared II (NIR-II) imaging offers high tissue penetration depth and signal-to-noise ratio to monitor the pathogenesis and pathological evolution of cancer with applications in neuroscience. The biocatalytic near-infrared II molecular agent is applicable to conduct real-time monitoring of pathological processes and molecular mechanisms of treatment.

Most oxidative stress-based diseases require early intervention to monitor pathological evolution in real-time. Biologists have conventionally relied on non-invasive imaging methods such as computed tomography and magnetic resonance imaging to achieve precise diagnostics and real-time analysis.

Oxidative stress and inflammation-related pathologies are however, common in clinics, necessitating real-time monitoring and intervention. Additionally, some chemotherapeutic agents often cause injury to normal tissues during medical treatment. For example, the anticancer drug cisplatin can crosslink DNA and induce oxidative stress and inflammation to result in neurotoxicity and nephrotoxicity.

Structural characterization of gold clusters. (A) The structure illustration of Au22. Both blue and yellow represent Au atoms, and red represents S atoms. (B) Typical TEM image of Au22 clusters with an average size of 1.5 nm. (C) The hydrodynamic size was measured to be 2.01 nm using DLS. (D) The ESI-MS of Au22 clusters. The illustration shows the molecular weight of Au22 in the m/z range from 1967 to 1970. (E) Ultraviolet-visible (UV-vis) absorption spectra and emission spectra of Au22 clusters. The black line represents the absorption spectrum, and the red line represents the emission spectrum. (F) UV-vis absorption spectra and NIR-II fluorescence images of Au22 cluster aqueous solution excited at 808 nm before and after filtration with the 100 K ultrafiltration tube (illustration: 1000 nm long pass filter, 100 ms). (G) Photostability of Au22 clusters excited with an 808 nm laser for 30 min. (H) NIR-II fluorescence stability of Au22 clusters in DI water and PBS before and after a week. (I) Stability of optical characteristic absorption peaks of Au22 clusters of 7 days in water. (J) Au 4f region of Au22 and Au21Cu1 clusters. (K) Cu 2p XPS spectrum of Au21Cu1 clusters. (L) Fourier-transformed magnitude of the Cu K-edge EXAFS spectra of Au21Cu1 and Cu foil, showing the radial distance of Cu-S bond and Cu-Cu bond. Credit: Science Advances, doi: 10.1126/sciadv.adh7828

Cisplatin-induced acute kidney injury is a common side-effect that can cause a sudden decrease in kidney function within a few hours or days. Acute kidney injury must be monitored in real-time for early diagnosis and early intervention to prevent oxidative stress and acute inflammation.

It is desirable to engineer biocatalytic NIR-II molecular agents for real-time monitoring, to synchronously achieve the inhibition of oxidative stress and early inflammation. In this work, Ma et al. developed atomic precision gold clusters with NIR-II emersion and bioactive enzyme mimicry to inhibit oxidative stress and inflammation in the injured kidney and brain.

Doping gold clusters

The team prepared gold clusters (Au 22 ) and purified them according to previous reports to create a stable structure, which they examined using transmission electron microscopy to reveal an ultrasmall size.

This allowed for efficient clearance during renal filtration. The gold clusters showed excellent photostability to reveal well-defined atomic precision engineering, water solubility, and a stable structure suited for further applications.

The team also included atomic engineering to modify gold clusters with various other metallic elements to obtain optical absorption spectra of the doped clusters. The outcomes highlighted gold-copper clusters to possess good homogeneity and dispersion, consistent with gold clusters alone.

DFT calculations of gold clusters. The geometrically optimized structures of (A) Au22, (E) Au21Cu1-tetramer, and (I) Au21Cu1-trimer clusters. Orange, yellow, and blue balls represent Au, S, and Cu atoms, respectively. The locally enlarged version of charge density difference of (B) Au22, (F), Au21Cu1-tetramer, and (J) Au21Cu1-trimer clusters. The ELF images of (C) Au22, (G) Au21Cu1-tetramer, and (K) Au21Cu1-trimer clusters. The energy levels of (D) Au22, (H) Au21Cu1-tetramer, and (L) Au21Cu1-trimer clusters were simulated by density DFT. (M) The energy level diagram of Au22 and Au21Cu1 clusters. (N) The imaginary part of the dielectric function ɛ2 (ω). (O) The absorption spectra of the Au22, Au21Cu1-tetramer, and Au21Cu1-trimer system. Credit: Science Advances, doi: 10.1126/sciadv.adh7828

Enzymatic properties of gold clusters

The gold-copper clusters containing a single copper atom active site showed high catalytic activity. The researchers further assessed the reactive oxygen and nitrogen species absorption capacity on the molecules. The catalytic activity of the doped clusters were 90 times higher than of the pure gold alone.

This work also highlighted the impact of clusters with NIR-II properties in detail for the first time, as it plays a key role in the life sciences. The bioengineered bioactive NIR-II molecules also provided an urgent and significant platform to understand the mechanism. Ma et al. followed these experiments with density functional theory calculations of gold clusters.

Monitoring the kidney in real-time

The scientists next examined the impact of gold clusters for real-time kidney monitoring to examine kidney injury on mice in advance of clinical diagnosis. To accomplish this, they administered the anticancer drug cisplatin to mice via injection, the outcomes highlighted severe impairment of kidney function and influence on the nervous system upon cisplatin injection, where the filtering effect of the glomeruli weakened to accumulate gold clusters in the kidney.

The team conducted cytotoxicity tests to pinpoint the region of enzymatic biological activity of the clusters by monitoring proximal tubular cells and mouse microglia. The outcomes showed the capacity of the clusters to regulate oxidative stress and induce favorable biological activities without toxicity at high concentrations.

The enzyme-mimicking activity of gold clusters. (A) Schematic illustration of the enzyme-mimicking activity of Au22 clusters. (B) The adsorption energy of ABTS•+ on Au22, Au21Cu1-trimer, and Au21Cu1-tetramer clusters, respectively. Time-dependent curves (C) and quantitative results (D) of ABTS•+ of Au22 and Au21M1 (M: Ag, Zn, Cu, Pt, Cd, and Er) clusters. (E) The adsorption energy of O2•− on Au22, Au21Cu1-trimer, and Au21Cu1-tetramer clusters, respectively. Time-dependent curves (F) and quantitative results (G) of O2•− of Au22 and Au21M1 clusters. (H) The adsorption energy of H2O2 on Au22, Au21Cu1-trimer, and Au21Cu1-tetramer clusters, respectively. Diagram (I) and quantitative results (J) of the CAT-like activity of Au22 and Au21M1 clusters. (K) The adsorption energy of ONOO− on Au22, Au21Cu1-trimer, and Au21Cu1-tetramer clusters, respectively. Time-dependent curves (L) and quantitative results (M) of ONOO− of Au22 and Au21M1 clusters. Credit: Science Advances, doi: 10.1126/sciadv.adh7828

In vitro treatment of cisplatin-induced AKI with gold clusters. (A) Schematic diagram of cellular level experiments. HK2 cell viability in the presence of cisplatin with or without treatment of Au22 clusters (B) and Au21Cu1 (C) determined by CCK8 assays (n = 3 per group). BV2 cell viability in the presence of cisplatin with or without treatment of Au22 clusters (D) and Au21Cu1 (E) determined by CCK8 assays (n = 3 per group). (F) Fluorescence microscopic images of intracellular ROS and O2•− levels induced by cisplatin with or without gold clusters. Quantitative analysis of ROS (G) and O2•− (H) fluorescence intensity (n = 3 per group). (I to K) Fluorescence quantification of HK2 cells staining for ROS and O2•− by flow cytometry (n = 3 per group). (L to N) Fluorescence-activated cell sorting (FACS) results and fluorescence quantification of BV2 cells staining for ROS and O2•− by flow cytometry (n = 3 per group). The level of TNF-α in the cellular supernatant of HK2 cells (O) and BV2 cells (P) (n = 2 per group). (Q) Representative fluorescence image of TLR4 in HK2 cells. (R) Quantitative analysis of TLR4 fluorescence intensity. Data are presented as means ± SD; *P < 0.05, **P < 0.01, and ***P < 0.001 compared with the control group and cis group, analyzed by one-way analysis of variance (ANOVA) with the Tukey test. Credit: Science Advances, doi: 10.1126/sciadv.adh7828

Ma and colleagues studied the regulation of oxidative stress and inflammation induced by cisplatin. While cisplatin is an anticancer drug, it is limited by strong side-effects relative to nephrotoxicity and ischemic injury. The association with severe reactive oxygen species and inflammation leads to mortality and comorbidities in the brain.

This can be diagnosed in advance by monitoring serum creatinine and blood urea nitrogen; clinical manifestations of nitrogenous waste buildup that provide effective indices of kidney excretory function.

Outlook

In this way, Huizhen Ma and colleagues detailed atomic engineering of gold-copper clusters where a single copper atom allowed ultrahigh enzymatic mimicry. The antioxidant activity of the gold clusters were increased by introducing copper and the biological experiments showed capacity to inhibit both oxidation stress and inflammation in the kidney-brain axis during kidney disease.

The clusters also underwent effective renal clearance and revealed non-toxicity at a high dose, to provide a compound with efficient biosafety and multifunctionality, coupled with near-infrared II fluorescence. The gold clusters showed great potential for real-time imaging and early intervention during acute kidney injury with promising impact from the lab to clinical translation.

© 2023 Science X Network",https://scx2.b-cdn.net/gfx/news/hires/2023/bioactive-near-infrare.jpg,https://phys.org/news/2023-08-bioactive-near-infrared-ii-clusters-3d.html,Science
[],,AOL is part of the Yahoo family of brands,"When you use our sites and apps, we use cookies to:

We, AOL, are part of the Yahoo family of brands.

Accept all', we and If you click '', we and our partners will also use cookies and your personal data (such as IP address, precise location, and browsing and search data) to:

display personalised ads and content based on interest profiles

measure the effectiveness of personalised ads and content, and

develop and improve our products and services

If you do not want us and our partners to use cookies and personal data for these additional purposes, click 'Reject all'.

If you would like to customise your choices, click 'Manage privacy settings'.

You can change your choices at any time by clicking on the 'Privacy & cookie settings' or 'Privacy dashboard' links on our sites and apps. Find out more about how we use your personal data in our privacy policy and cookie policy.",https://s.yimg.com/oa/build/images/favicons/aol.png,,Science
"['Edd Gent', 'Http', 'Www.Eddgent.Com', 'I Am A Freelance Science', 'Technology Writer Based In Bangalore', 'India. My Main Areas Of Interest Are Engineering', 'Computing', 'Biology', 'With A Particular Focus On The Intersections Between The Three.']",2023-08-27 00:00:00,New Codes Could Accelerate the Advent of Practical Quantum Computing,"One of the biggest stumbling blocks for quantum computers is their tendency to be error-prone and the massive computational overhead required to clean up their mistakes. IBM has now made a breakthrough by dramatically reducing the number of qubits required to do so.

All computers are prone to errors, and even the computer chip in your laptop runs code designed to fix things when a bit flips accidentally. But fragile quantum states are far more vulnerable to things like environmental noise, which means correcting errors in quantum processors will require considerable resources.

Most estimates predict that creating just a single fault-tolerant qubit, or logical qubit, that can carry out useful operations will require thousands of physical qubits dedicated to error correction. Given that today’s biggest processors have just hundreds of qubits, this suggests we’re still a long way from building practical quantum computers that can solve real problems.

But now researchers at IBM say they’ve discovered a new approach that slashes the number of qubits required for error correction by a factor of 10. While the approach currently only works on quantum memory rather than computation, the technique could open the door to efficient new approaches to creating fault-tolerant devices.

“Practical error correction is far from a solved problem,” the researchers write in a blog post. “However, these new codes and other advances across the field are increasing our confidence that fault tolerant quantum computing isn’t just possible, but is possible without having to build an unreasonably large quantum computer.”

The leading approach to error correction today is known as the surface code, which involves arranging qubits in a specially configured 2D lattice and using some to encode data and others to make measurements to see if an error has occurred. The approach is effective, but it requires a large number of physical qubits to pull off—as many as 20 million for some key problems of interest, according to IBM.

The new technique, outlined in a preprint on arXiv, comes from the same family of error-correction approaches as the surface code. But while each qubit in the surface code is connected to four others, the new technique connects them to six others, which makes it possible to encode more information into the same number of physical qubits.

As a result, the researchers say they can reduce the number of qubits required by an order of magnitude. Creating 12 logical qubits using their approach would require only 288 physical qubits, compared to more than 4,000 when using the surface code.

There are some significant caveats, though. For a start, it’s currently impossible to achieve the kind of six-way connectivity the team envisages. While the surface code operates on a single plane and can therefore be easily implemented on the kind of flat chip already found in quantum processors, the new approach requires connections to distant qubits that aren’t located on the same surface.

The researchers say this isn’t an insurmountable barrier, and IBM is already developing the kind of long-range couplers required to make these kinds of corrections. The technologies needed are certainly plausible, Jérémie Guillaud at French quantum computing startup Alice & Bob told New Scientist, and could be here in just a matter of years.

A bigger open question, though, is the fact that so far the approach only works with a small number of logical operations. This means that while it works for reading and writing to a quantum memory in a fault-tolerant way, it wouldn’t support most quantum computations.

But the IBM researchers say the techniques they’ve unveiled are just a stepping stone that points toward a rich new vein of even better error-correction approaches. If they’re right and scientists are able to find more efficient alternatives to the surface code, it could significantly accelerate the advent of practical quantum computing.

Image Credit: IBM",https://singularityhub.com/wp-content/uploads/2023/08/IBMQuantum-Lab-Maika-Takita.jpg,https://singularityhub.com/2023/08/27/ibms-new-codes-could-accelerate-the-advent-of-practical-quantum-computing/,Science
['Spie International Society For Optics'],2023-08-27 01:08:22-07:00,Charge Migration: Measuring the Speed Inside Molecules,"New experimental research for the first time measures the speed of molecular charge migration.

Researchers developed a method to measure charge migration speed in molecules, discovering it can move several angstroms per femtosecond. The study provides insights into ultrafast molecular dynamics and potential chemical reaction control.

To discover how light interacts with molecules, the first step is to follow electron dynamics, which evolve at the attosecond timescale. The dynamics of this first step have been called charge migration (CM). CM plays a fundamental role in chemical reactions and biological functions associated with light–matter interaction. For years, visualizing CM at the natural timescale of electrons has been a formidable challenge in ultrafast science due to the ultrafine spatial (angstrom) and ultrafast temporal (attosecond) resolution required.

The Complexities and Challenges of Charge Migration

Experimentally, the sensitive dependence of CM on molecular orbitals and orientations has made the CM dynamics complex and difficult to trace. There are still some open questions about molecular CM that remain unclear. One of the most fundamental questions: how fast does the charge migrate in molecules? Although molecular CM has been extensively studied theoretically in the last decade by using time-dependent quantum chemistry packages, a real measurement of the CM speed has remained unattainable, due to the extreme challenge.

Breakthrough Research on Measuring CM Speed

As reported on August 24 in the journal Advanced Photonics, a research team from Huazhong University of Science and Technology (HUST), in cooperation with theoretical teams from Kansas State University and University of Connecticut, recently proposed a high harmonic spectroscopy (HHS) method for measuring the CM speed in a carbon-chain molecule, butadiyne (C 4 H 2 ).

The principle of HHS is based on the three-step model of high-order harmonic generation (HHG): ionization, acceleration, and recombination. Strong field ionization first creates a hole wave packet in the ion, which evolves in the laser field and is probed by the returning electron wave packet at the recombination moment, with the hole dynamics recorded in the generated harmonic spectra.

The researchers used a two-color HHS scheme in combination with an advanced machine learning reconstruction algorithm to reconstruct the CM in C 4 H 2 at the most fundamental level for each single fixed-in-space angle of the molecule. The method achieved a temporal resolution of 50 as.

Discoveries and Future Implications

From the retrieved time-dependent hole densities, the movement of the center of charge is identified. From there, the CM speed is quantified, which is about several angstrom per femtosecond. Moreover, the dependence of the CM speed on the alignment angles of the molecule with respect to the laser polarization is also revealed. The CM under the laser control is demonstrated to be faster than the field-free one. This work for the first time offers an experimentally derived answer regarding the speed of CM in a molecule.

Corresponding author Pengfei Lan, a professor in the HUST School of Physics, remarks, “This work provides deep insight into CM dynamics in molecules and could strengthen our understanding of these ultrafast dynamics.”

Lan notes that the control of CM speed by molecular alignment also suggests a promising way to manipulate the rate of a chemical reaction — a path his team aims to explore in the near future.

Reference: “Attosecond probing and control of charge migration in carbon-chain molecule” by Lixin He, Yanqing He, Siqi Sun, Esteban Goetz, Anh-Thu Le, Xiaosong Zhu, Pengfei Lan, Peixiang Lu and Chii-Dong Lin, 24 August 2023, Advanced Photonics.

DOI: 10.1117/1.AP.5.5.056001",https://scitechdaily.com/images/Charge-Migration-in-a-Linear-Carbon-Chain-Molecule.jpg,https://scitechdaily.com/charge-migration-measuring-the-speed-inside-molecules/,Science
['Sandy Baker'],2023-08-26 16:00:11+00:00,Why You Should Always Sanitize Your Containers For A New Plant,"Why You Should Always Sanitize Your Containers For A New Plant

It's time to transfer your thriving plant to a new container. You may have picked up a new container, perhaps even purchased soil, but have you thought about what is lurking in that container? Many people do not know they should clean a container and even sanitize to disinfect it before they transfer a plant into it. Just like drinking from a new glass you just purchased at the home improvement store, your plants are likely to grow and flourish a bit easier in a clean environment right from the start.

Even if you pull a container out of your shed, where you've had it stored for some time, it's critical to sanitize that container before using it for your plants. This is because microorganisms can live and even thrive on these surfaces, according to the University of Minnesota Extension. When you're moving a young plant or even a strong, healthy one to a new environment, you're creating a stressor. If there are germs to fight off as well, it's going to make it that much harder for the plant to do well in their new environment.

Unfortunately, there's no way to see what's present on the surface of your plant containers since most of these microbes are much too small. That's why it's always a good idea to simply assume that even a brand-new container has pathogens growing on it.",https://www.housedigest.com/img/gallery/why-you-should-always-sanitize-your-containers-for-a-new-plant/l-intro-1692718473.jpg,https://www.housedigest.com/1372474/always-sanitize-garden-plant-containers/,Science
[],2023-08-26 00:00:00,What Can Dr. Know Tell Us About the Mysterious Cylinders Found Along Southeast 17th Avenue?,"What can you tell us about the mysterious cylinders found along Southeast 17th Avenue? They’re about 10 inches in diameter, 36 inches high, and made of what appears to be steel set in a concrete base. Also, they’re hollow—you can tell by the vertical rows of 1-inch holes drilled all around them. Ventilators for an underground squirrel passageway? —Maurice

Don’t be ridiculous, Maurice. There’s no special passageway for underground squirrels; if you have any, just grind them a little longer and put them through the regular squirrel passageway.

Thanks, I’m here all week. Seriously, though, this question did something near-unprecedented: It got my fat ass out of the house for some honest-to-God field reporting. Comparing cues from the reader’s attached photo to Google Street View, I found the exact site pictured. (I’m not giving the address—if you think Jim Morrison’s grave is a mess, you don’t want to see what fans might do to the only known site where Dr. Know ever did any actual work.)

My verdict? Field reporting is overrated. I don’t know if you can see the photo, but I assure you that it’s not hiding any subtle nuances that can only be appreciated in person. I was still stumped. Luckily, sources at the city were able to give me some hints. (They would have given me more than hints if I hadn’t contacted the wrong bureau, but that’s life.)

I’ll end the suspense: What we’re looking at here appears to be a ventilation standpipe for an underground utility vault, also known as a “vault vent.” The words “underground vault” may conjure images of spacious subterranean chambers à la Buffy the Vampire Slayer. Sadly, real-life civil engineers largely ignore the needs of future screenwriters when designing these spaces—they’re no bigger than they absolutely have to be.

Still, over time even small spaces can accumulate hazardous gases (methane, hydrogen sulfide, carbon monoxide, etc.) that can be flammable or toxic or both. Good ventilation keeps the concentration of such gases low. Ventilation also reduces the risk of moisture condensation in the vault, which can result in damage to equipment.

So, there you have it. I couldn’t conclusively establish what this particular vault holds, but the vent’s design is a type sources say is often used in California for electrical wiring and telecom cabling. (There was also a footnote about “mole people,” but it looked boring so I didn’t read it.)

Questions? Send them to dr.know@wweek.com.",https://wweek-wweek-prod.cdn.arcpublishing.com/resizer/AXNkW9LYmg6_KqaOfORMpi-QH6o=/1200x630/filters:format(jpg):quality(70)/cloudfront-us-east-1.images.arcpublishing.com/wweek/YLVXY657VNFLDFEGDMGNHSY5QI.jpeg,https://www.wweek.com/news/dr-know/2023/08/26/what-can-dr-know-tell-us-about-the-mysterious-cylinders-found-along-southeast-17th-avenue/,Science
['The Daily Beast'],2023-08-27 03:21:01.998000+00:00,"Controversial Climate Solution May Cool Earth, but at What Cost?","Listen to this full episode of The New Abnormal on Apple Podcasts, Spotify, Amazon and Stitcher.

UCLA environmental law professor Ted Parson tells The New Abnormal how reflecting sunlight, through a process called ‘stratospheric aerosol injection,’ may help cool the Earth’s temperature by 1 degree Celsius within a few years and help ward off catastrophic climate disasters.

He said the process, which involves releasing particles of sulfur dioxide into the upper atmosphere to reflect sunlight away from the Earth, could help reverse rising temperatures.

“All the current indications are that with this stuff you could cool the Earth by a degree Celsius within a couple of years for a cost of about $10 billion or $20 billion a year, and the side effects and harm based on earlier research look like they’re really pretty… small.”

Subscribe to The New Abnormal on Apple Podcasts, Spotify, Google Podcasts, Stitcher, Amazon Music, or Overcast.

However, critics of the process say it runs the risk of damaging the ozone layer and could spark a wave of respiratory illnesses from the increased sulfur.

In June, the Biden administration said it would not be advancing solar engineering solutions to combat climate change but admitted that it was worth further research by others.

Parson says many leaders have been reluctant to embrace the active intervention approach to cooling the planet because it is not a permanent solution to climate change and they don’t want to deter efforts to cut greenhouse gas emissions.

“The few hundred people thinking about it have been trying to get governments... to pay attention for about 10 years. They mostly have refused to do so basically because people are afraid that it would even further weaken efforts to cut emissions, which we still have to do because this stuff cannot solve the problem entirely. This would be just a partial fix,” he said.

Listen to this full episode of The New Abnormal on Apple Podcasts, Spotify, Amazon and Stitcher.","https://img.thedailybeast.com/image/upload/c_crop,d_placeholder_euli9k,h_1688,w_3000,x_0,y_0/dpr_2.0/c_limit,w_740/fl_lossy,q_auto/v1693011556/082723-tna-hero_kwv2hr",https://www.thedailybeast.com/controversial-climate-solution-may-cool-earth-but-at-a-cost-professor-ted-parson-tells-the-new-abnormal,Science
['Ella Creamer'],2023-08-26 00:00:00,Loren Grush on Nasa’s first female astronauts: ‘People thought they’d be a distraction to the men in space’,"Your parents both worked on the space shuttle programme for decades, and you have gone on to write about Sally Ride, Anna Fisher, Judy Resnik, Shannon Lucid, Rhea Seddon and Kathy Sullivan – the first six American female astronauts. Were you always interested in space?

As a child growing up with two Nasa parents, I thought space was not cool at all. It wasn’t until I left my home town that I started to understand just how special my upbringing was. When I went into journalism, I realised that I was actually drawn to stories about space.

Nasa sent the first American man to space in 1961. The first American woman didn’t go up for another 22 years. Why the delay?

When Nasa was first created, the requirements were that you had to be able to be a jet pilot, but you couldn’t get jet pilot experience without being in the military. Women were banned from flying jets in the military. Nasa was so hellbent on getting to the moon that being inclusive and letting women into the programme was seen as a distraction. It went all the way up to Lyndon B Johnson. There is a memo of his where he writes “Stop this now” on a document related to getting women into the space programme.

Loren Grush. Photograph: Christopher White

What concerns did people have about women going into space?

There were crazy articles about whether they would be mentally unwell, and also the role that they thought women could play in space. How could women be subservient to men? How could they help them? Would they be a distraction to men in space? They were never considered astronauts outright.

How did the six women get selected by Nasa?

First they had to send in an application. The selection team narrowed down more than 8,000 applicants. Then they had to go on a week-long trip to Houston and were put through medical testing and psych evaluations with a “good cop” and “bad cop”. One of them would talk in very nice tones and ask “How’s your relationship with your parents?” or “Tell me about your childhood”. And then there was a bad cop who would demand they count backwards from 100 by seven, and if they messed up, he would proclaim it loudly and see how they reacted. There was also a “personal rescue sphere” – it was a very small enclosure, and they would zip them up and see how they handled claustrophobia.

There was a press frenzy around the women when they got selected, with one paper calling them “eye popping space gals”. And the atmosphere at Nasa itself was pretty masculine – one astronaut had a Playboy calendar on his door. How did that play out?

There were culture clashes. Some men weren’t accustomed to working with women at that level, some men’s wives didn’t like the women flying with them. But it was the press that asked them the most ridiculous questions. During Sally’s press conference before her flight, one of the reporters asked if she ever wept in the simulator if things went wrong. When Anna went into space she knew there was going to be a lot of talk about the fact she was a mum. She had fathers on her flight as well, but nobody asked them whether or not being an astronaut was compatible with being a father, they only asked her if being an astronaut was compatible with being a mother.

Giant steps … Judy Resnik beside a model of a space shuttle at Johnson Space Center in Houston, Texas in 1978. Photograph: Space Frontiers/Getty

Did the women feel pressure to perform?

These women definitely understood that they were being watched much more closely than their male colleagues. If they made a mistake, the press would have a field day. Judy had a mishap with her hair in orbit [it got stuck in an Imax camera] and she made all the guys swear not to say anything. Even though they kept to their word, Judy’s hair was a big topic of discussion on the ground because it was large, and in zero gravity your hair doesn’t lay flat.

In the book, you chronicle the astronauts’ early flights. What happened to them after that?

Sally only spent about seven years at Nasa – she went back into academia. Many of the astronauts flew multiple times. Kathy flew the mission that deployed the Hubble space telescope, and she took a voyage down to Challenger Deep [the lowest known location on the planet] in 2020 on a submersible, so that makes her the only person to have walked in space and travelled to the deepest part of the ocean. Judy was one of the members of crew who sadly lost their lives when the Challenger exploded during its launch.

What other milestones is Nasa yet to achieve in terms of representation?

While new classes of astronauts are much more equal in terms of gender and racial breakdown, we still have quite a way to go. Less than one sixth of the people who’ve gone to space have been women, and the statistics for women of colour are much more dismal.

skip past newsletter promotion Sign up to Inside Saturday Free weekly newsletter The only way to get a look behind the scenes of the Saturday magazine. Sign up to get the inside story from our top writers as well as all the must-read articles and columns, delivered to your inbox every weekend. Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply. after newsletter promotion

What surprised you most when you were writing the book?

How different the women were. They knew how to come together and provide a united front, but they had extremely diverse backgrounds – we had an astrophysicist, a geologist, doctors, chemists, an electrical engineer – which I found inspiring because it goes to show there really is no one clear path to space.",https://i.guim.co.uk/img/media/138cc43491633027011d16a3f2483ad58becb6ee/1071_808_2219_1331/master/2219.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=3feb1bd00eee28c94a9fb3ead974f89f,https://www.theguardian.com/books/2023/aug/26/loren-grush-on-nasas-first-female-astronauts-people-thought-theyd-be-a-distraction-to-the-men-in-space,Science
['Bella Richards'],2023-08-27 01:20:19+00:00,"ESA’s Space Rider likely to launch third quarter of 2025, program manager says","The European Space Agency’s (ESA) Space Rider program has officially begun its validation and testing phase, as it prepares for a maiden flight in the third quarter of 2025. Space Rider is Europe’s reusable uncrewed robotic laboratory that will provide an “end-to-end integrated space transportation system” for commercial customers. After launching into space, Space Rider will spend two months in orbit while customers complete experiments and technology demonstrations onboard, before returning to Earth.

Space Rider was originally set to begin flights end of this year after having received funding in 2019; however, several delays have pushed back its inaugural launch. Yet, entering into Phase D marks a significant step toward launch as ESA is preparing for several drop tests to validate the capability of Space Rider’s autonomous landing algorithms.

NSF sat down with Space Rider program manager Dante Galli, to discuss the reasons for the delay, the challenges involved in an autonomous landing, and its success so far.

What is Space Rider?

According to ESA, Space Rider aims to give Europe access to “affordable” and “independent” access to space by providing an end-to-end launch service. With the ability to transport payloads to several orbital altitudes and inclinations, customers will be able to complete technology demonstrations and science experiments, whether it’s within pharmaceuticals, biomedicine, or robotic exploration, and have the ability to bring them back to Earth.

The spacecraft will be about the size of two minivans, according to ESA, massing approximately 4,900 kilograms at launch. With the ability to carry up to 800 kilograms of payloads in mass, Space Rider will remain in orbit for two months, while customers complete their missions utilizing microgravity to validate technology.

Payloads will be integrated into the re-entry module cargo bay and will launch into orbit atop a four-stage Vega C rocket from Centre Spatial Guyanais in Kourou, French Guiana. The re-entry module is coupled with the AVUM orbital module, which is an extension of Vega C’s fourth stage and supplies the power, data-handling, and telemetry capability to maintain the two-month mission. Coupled with AVUM is AVUM Life Extension Kit (ALEK), which is the adaptation kit required for orbital life extension, acting as the service module during the orbital phase and providing power with two solar arrays, guidance and navigation, and propulsion. AVUM and ALEK will stay attached to Space Rider during the two-month orbital phase of the mission and will finally provide the de-orbiting boost for the re-entry module to come back to Earth.

When the mission concludes, Space Rider will complete a re-entry through the Earth’s atmosphere going 28,000 kilometers per hour and softly land on a runway. At about five kilometers from the landing strip, Space Rider will release a parafoil and steer itself to a soft landing with 150-meter accuracy.

Following its landing, Space Rider will be refurbished for re-use, as each vehicle is designed to make at least five re-flights.

Dante Galli explained that there was a multitude of reasons to develop the spacecraft, including the shift toward increasing in-orbit services, and the desire for ESA to offer services that are commercially viable. “One of the main objectives of the program is to address so-called reusability,” Galli said. “When we think about the stage of the Falcon 9 reused several times, it was told that the capability of having a spacecraft that can land autonomously on the ground and be refurbished in a limited amount of time… was something that had to be addressed by ESA.”

While the program was initially conceived in 2016, Space Rider was officially approved at the ESA Ministerial Council held in Seville in November 2019, and is a follow-up from the intermediate experimental vehicle mission which performed a perfect suborbital flight and atmospheric re-entry with a sea landing in February 2015.

In December 2020, ESA signed two contracts with Thales Alenia Space Italy and Avio to deliver the Space Rider flight model, including the re-entry module and AVUM module. A further contract was inked with Telespazio and Altec to deliver the ground segment.

Two landing sites were being considered, including French Guiana or Santa Maria in the Azores archipelago in Portugal. French Guiana was seen to allow maximum mission performance, whereas Santa Maria was considered more suitable for high-altitude inclination orbits.

Delayed to 2025

In late June, ESA announced it received the green light to enter Phase D of the program, which is focused on building and testing the spacecraft. Other than developing the system, this phase will primarily involve the completion of several drop tests to refine the autonomous landing technology and the capabilities of the parafoil.

Tests on a smaller parafoil began in July, in preparation for a full-scale test later in 2023 using a 70 square meter parafoil, ESA explained. “The smaller tests will allow engineers to tweak the algorithms that will pilot the spacecraft using winches to pull and release the canopy — just like a human parapente [paraglider] pilot does,” the agency said. A drop test amid the worst weather conditions is also slated to take place, to determine the spacecraft’s landing system, software, and parafoil regardless of wind.

The teams are also preparing to complete a series of autonomous landing tests by dropping a scaled mock-up of the re-entry module from a helicopter at different altitudes to test its ability to land by itself. ESA will first test the mock-up by dropping it from 1.5 kilometers in altitude, and then eventually from three kilometers.

Space Rider was initially scheduled to complete its maiden flight in 2023, however, several delays have pushed the date back. According to Galli, the new target date is now the third quarter of 2025.

“As an outcome of the previous ministerial council of 2019, the Space Rider received quite significant financial support to cope with Phase C and D activities. However, the participating states contributed in a way that was not possible — due to the need to comply with the Geo-return mechanism — to keep the industrial consortium as it was operating up to that moment [end-2019],” Galli said.

ESA’s Geo-return mechanism was established to boost fairness among member states, ensuring that the nations that invest in the agency will generate a “fair return.” In a nutshell, participating states in an optional development program should receive industrial contracts in a proportional way with respect to their contribution to that program to ensure that money invested benefits the countries that actually contributed to that program. That is to say for example, if you put 30% of the funds into the program, you are expected to receive as close as possible to industrial contracts accounting for 30% of the overall program.

As the program must abide by the Geo-return mechanism, Galli explained that the initial consortium involved was required to significantly be rebuilt “in compliance with the available funds and their member state relevant origin.”

“This caused first a not negligible delay in setting up the new industrial consortium… that was finally concluded only in late 2020 with the signature of the new contract with the prime contractors. And then, a so-called bridging design phase was needed on the subsystems affected by the change of industrial supplier, resulting in a longer-than-expected completion of the design phase.

“Some other challenges were instead technical challenges, that arose, as it is natural in complex development programs with a lot of novelties when digging more and more into the detailed design phase,” Galli continued. “One of them for sure is the autonomous landing with 150 meter precision under a parafoil, a really complex and challenging objective to be achieved and for which we are indeed preparing an extensive test campaign for validation of the guidance and navigation control algorithms”.

Challenges to face

There are several challenges involved in developing an end-to-end space service. However, Galli said that the “autonomous landing on the ground under a parafoil with a precision landing of 150 meters” will prove to be the most difficult.

👍 Space Rider, @esa‘s reusable space vehicle got a thumbs up to move into phase 🇩 of development: building and testing.https://t.co/6JbOv6es1X pic.twitter.com/ixpfHVyuw0 — ESA Space Transport (@ESA_transport) July 28, 2023

Unlike many missions that are piloted by astronauts, the spacecraft will land completely on its own. “In our case, we need to ensure this precision in a fully autonomous way by relying on weather predictions. However, weather predictions by definition are unpredictable… a human being is able to feel and see the wind to understand it and follow it, but an autonomous system has to make predictions based on some extrapolation of data provided by the system, and this is a real challenge.”

Galli said this requires a specific algorithm of guidance that can not only succeed on paper but can also be tested successfully.

Another challenge that could grow in the future is the Vega C’s current grounding. In late 2022, a Vega C rocket launched from French Guiana carrying two satellites onboard. But just under three minutes into the flight, an anomaly occurred on the Zefiro 40 — the second stage — and therefore prematurely ended the mission, destroying two satellites in the process. Since then, the Vega C has been grounded, and Arianespace, the operator of the rocket, has not disclosed when it will return to the skies.

Despite its unclear future, Galli said the grounding has not impacted Space Rider so far. “I expect that the issues will be resolved before the inaugural flight,” Gallis said. “Industry and the prime contractors and the industrial chain shall work regardless of the Vega C situation,” Galli continued. “This shall not be used in any way as an excuse… we are already in a delay with this program… now it’s time to move on and really see the concrete results of our design”.

Seeing success despite the delay

While the delay of the program presents issues of its own, Galli said the interest in Space Rider has been “huge” so far. In October 2021, ESA announced it was offering the opportunity for customers to ride on board the first flight. The agency released a dedicated announcement of opportunity with no restriction on nationality for commercial or institutional customers, and Galli said this generated over 40 applications.

At this time, there are 16 payloads slated to ride onboard the maiden flight. “Most of these payloads that are trying to demonstrate some technologies or applications in microgravity have already signed a memorandum of understanding,” Galli said. “It is not a binding contract, but upon a successful outcome on the first flight, [the customers] could commit to future flights.” According to Galli, there is still room for more payloads to join the inaugural flight depending on size.

Although ESA has previously said customers will pay roughly $40,000 per kilogram, Galli said they are still considering how the pricing will work, as Space Rider will provide end-to-end launch solutions, rather than only sending payloads into orbit.

(Lead image: Artist’s interpretation of Space Rider module in orbit for two months. Credit: ESA)",https://www.nasaspaceflight.com/wp-content/uploads/2023/08/Space_Rider_pillars.jpg,https://www.nasaspaceflight.com/2023/08/space-rider-update/,Science
['David Nield'],2023-08-26 23:30:02+00:00,"Teeth Can Preserve The Signal of Pathogens For Hundreds of Years, Study Finds","An analysis of antibodies extracted from 800-year-old teeth has provided a new way to identify pathogens our ancestors contended with.

The process could potentially help us understand how human antibodies – proteins naturally produced by our bodies in self-defense – have developed through history.

Building on previous research, a team led by researchers from the University of Nottingham and University College London (UCL) in the UK conducted a process called affinity purification to identify molecules through the way they bind to other molecules.

These kinds of bindings are a crucial part of how the human immune system works, and they can help researchers retroactively identify antibodies and what they were designed to fight against.

Intact antibodies from teeth recovered from an English grave dated to between 1285 and 1470 CE had their protein sequences read and their reactivity tested against potential antigens. Crucially, the antibodies recovered from the teeth retained a large part of their original structure, and were still biologically active, enabling the scientists to measure their response against current viruses.

""In this case we found that antibodies from medieval teeth were able to recognize the Epstein-Barr virus, which causes glandular fever,"" says Anisur Rahman, a rheumatologist at UCL.

""In the future it could be possible to look at how antibodies from ancient specimens react to diseases present during those periods, such as the Black Death.""

Although this study only involved three teeth, it demonstrates how viable this type of analysis is – and how it could be scaled up in the future.

This emerging field of research is known as paleoproteomics, where the latest chemical analysis techniques are used to identify proteins on ancient remains – proteins that are typically more resilient than any DNA fragments that might also be recovered.

In theory, we could be able to look back even further through our immunological history. Indeed, the researchers also looked at a mammoth bone dated back to some 37,000 years ago, showing that similar techniques could also be used to purify and recover proteins on much older samples.

Now this precedent has been set, more research can be done to verify exactly what these extracted proteins can tell us – including the way that diseases have evolved and how our bodies have evolved to fight them.

""In discovery science we come to expect the unexpected, but the realization that intact, functional antibodies can be purified from skeletal remains in the archaeological record was quite astonishing,"" says University of Nottingham biochemist Robert Layfield.

The research has been published in iScience.",https://www.sciencealert.com/images/2023/08/OldTeeth.jpg,https://www.sciencealert.com/teeth-can-preserve-the-signal-of-pathogens-for-hundreds-of-years-study-finds,Science
[],,Before you continue,"Deliver and maintain Google services

Track outages and protect against spam, fraud, and abuse

Measure audience engagement and site statistics to understand how our services are used and enhance the quality of those services

Develop and improve new services

Deliver and measure the effectiveness of ads

Show personalized content, depending on your settings

Show personalized ads, depending on your settings

If you choose to “Reject all,” we will not use cookies for these additional purposes.

Non-personalized content is influenced by things like the content you’re currently viewing, activity in your active Search session, and your location. Non-personalized ads are influenced by the content you’re currently viewing and your general location. Personalized content and ads can also include more relevant results, recommendations, and tailored ads based on past activity from this browser, like previous Google searches. We also use cookies and data to tailor the experience to be age-appropriate, if relevant.

We use cookies and data toIf you choose to “Accept all,” we will also use cookies and data toSelect “More options” to see additional information, including details about managing your privacy settings. You can also visit g.co/privacytools at any time.",https://www.google.com/favicon.ico,,Science
